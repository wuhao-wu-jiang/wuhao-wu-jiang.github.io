<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Helvetica:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.24.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js" defer></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="WOW">
<meta property="og:url" content="http://example.com/page/41/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/41/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/41/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>WOW</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">WOW</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">你生之前悠悠千載已逝<br>未來還會有千年沉寂的期待</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">201</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/02/26/The-Remainder-Term-in-Taylor-Series/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | WOW">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/02/26/The-Remainder-Term-in-Taylor-Series/" class="post-title-link" itemprop="url">The Remainder Term in Taylor Series</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-02-26 13:57:00" itemprop="dateCreated datePublished" datetime="2020-02-26T13:57:00-05:00">2020-02-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2020-02-27 19:22:58" itemprop="dateModified" datetime="2020-02-27T19:22:58-05:00">2020-02-27</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="taylor-series">Taylor Series</h2>
<p>The philosophy of Taylor series is to approximate a function with
polynomials that use only the information of a single point in the
domain of the function. Consider the function <span
class="math inline">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span> and
a point <span class="math inline">\(a \in \mathbb{R}\)</span>. Further,
we would like to use <span class="math inline">\((x-a)^0\)</span>, <span
class="math inline">\((x- a)^1\)</span>, <span class="math inline">\((x-
a)^2\)</span>, ..., <span class="math inline">\((x- a)^n\)</span> as the
basic building blocks of our approximation. The polynomial constructed
is of the form: <span class="math display">\[
p_n(x) = c_0 + c_1 (x - a) + c_2(x - a)^2 + ... + c_n (x - a)^n
\]</span> Now, assume that the <span class="math inline">\(n\)</span>-th
derivative of <span class="math inline">\(f\)</span> exits. To
approximate <span class="math inline">\(f\)</span> well, <span
class="math inline">\(p_n\)</span> should satisfy <span
class="math display">\[
p_n(a) = f(a)
\]</span> so that <span class="math inline">\(c_0 = f(a)\)</span>.</p>
<p>Further, <span class="math inline">\(f&#39;(a)\)</span> tell how the
function <span class="math inline">\(f(x)\)</span> changes when <span
class="math inline">\(x\)</span> moves from <span
class="math inline">\(a\)</span> by a little bit. We require <span
class="math inline">\(p_n(x)\)</span> to exhibit the same behavior:
<span class="math display">\[
p&#39;_n(a) = f&#39;(a)
\]</span> so that <span class="math inline">\(c_1 =
f&#39;(a)\)</span>.</p>
<p>To fit <span class="math inline">\(f(x)\)</span> even better, we
force the second order derivative of <span
class="math inline">\(p_n(x)\)</span> at <span
class="math inline">\(x\)</span> comply with <span
class="math inline">\(f&#39;&#39;(a)\)</span>, hence <span
class="math display">\[
p_n&#39;&#39;(a) = f&#39;&#39;(a)
\]</span> and <span class="math inline">\(c_2 = \frac{1}{2}
f&#39;&#39;(a)\)</span>.</p>
<p>Following the above procedure,we get <span class="math display">\[
c_i = \frac{1}{i!}f^{(i) } (a)
\]</span> and <span class="math display">\[
p_n(x) = \sum_{k = 0}^n \frac{ f^{( k ) }(a) }{ k! }  (x - a)^k
\]</span> where <span class="math inline">\(f^{(0)} \doteq f\)</span>,
<span class="math inline">\(0! \doteq 1\)</span>. We have just show that
the construct polynomial satisfies</p>
<p><strong><em>Theorem. <span class="math inline">\(p^{ (k) }_n (a) =
f^{ (k) } (a)\)</span>, for <span class="math inline">\(k \in
[n]\)</span>.</em></strong></p>
<h2 id="remainder">Remainder</h2>
<p>One natural to ask is that, how accurate is the <span
class="math inline">\(p_n(x)\)</span>. In particular, given <span
class="math inline">\(x \neq a\)</span>, we want to measure the error
<span class="math display">\[
r_n(x) = f(x) - p_n(x)
\]</span> quantitively.</p>
<p>Note that if the function <span class="math inline">\(f\)</span> is
itself a polynomial up to order <span class="math inline">\(n\)</span>,
then the approximation is accurate that is <span
class="math inline">\(r_n(x) \equiv 0\)</span> for <span
class="math inline">\(x \in \mathbb{R}\)</span>. In this case, we
recover <span class="math inline">\(f\)</span> globally using only local
information at <span class="math inline">\(a\)</span>.</p>
<p>In general, if <span class="math inline">\(f^{ (n + 1)} (x)\)</span>
exists and is continuous, then the error is characterized as</p>
<p><strong><em>Theorem</em></strong> <span class="math display">\[
r_n(x) = \frac{1}{n!} \int_a^x f^{ (n + 1) } (t) (x - t)^{n } dt =
-\int_a^x f^{ (n + 1) } (t)  d \left( \frac{(x - t)^{n + 1} }{(n + 1)!}
\right)
\]</span> <em>Proof.</em></p>
<p>By fundamental theorem of calculus, we have <span
class="math display">\[
f(x) = f(a) + \int_{a}^x f&#39;(t) dt
\]</span> On the other hand <span class="math display">\[
\frac{\partial [f&#39;(t) (t - x)] }{\partial t} = f&#39;&#39;(t) (t -
x) + f&#39;(t)
\]</span> Therefore, <span class="math display">\[
f&#39;(t) (t - x) \mid_{t = a}^x = f&#39;(a) (x -a)  = \int_{a}^x
f&#39;&#39;(t) (t - x) dt  + \int_{a}^x f&#39;(t) dt
\]</span> and <span class="math display">\[
f(x) = f(a) + f&#39;(a) (x - a) +  \int_{a}^x f&#39;&#39;(t) (x - t) dt
\]</span> Similarly, <span class="math display">\[
\begin{aligned}
\int_{a}^x f&#39;&#39;(t) (x - t) dt
    &amp;= - \int_{a}^x f&#39;&#39;(t) d \frac{ (x - t)^2}{2!} \\
    &amp;= f&#39;&#39;(a) \frac{ (x - a)^2}{2!} + \int_{a}^x \frac{ (x -
t)^2}{2!} f^{(3) } (t) dt
\end{aligned}
\]</span> As just shown, the proof can be finished by induction. <span
class="math inline">\(\square\)</span></p>
<p><strong><em>Weighted Mean Value Theorem.</em></strong> Given a
continuous functions <span class="math inline">\(f \ge 0\)</span> and an
Riemann integral function <span class="math inline">\(g \ge 0\)</span>
defined on an closed interval <span class="math inline">\(I\)</span>,
then <span class="math display">\[
\int_I f(t) g(t) dt = f(c) \int_I g(t) dt
\]</span> for some <span class="math inline">\(c \in I\)</span>.</p>
<p><em>Proof.</em> As <span class="math inline">\(f\)</span> is
continuous and <span class="math inline">\(I\)</span> is closed, <span
class="math inline">\(\exists m, M \in \mathbb{R}\)</span>, s.t., <span
class="math display">\[
m \le f(t) \le M, \qquad \forall t \in I
\]</span></p>
<p>Therefore, <span class="math display">\[
mg(t) \le f(t) g(t) \le M g(t), \qquad \forall t \in I
\]</span></p>
<p>Define <span class="math inline">\(S = \int_I g(t) dt\)</span>. By
monotonicity of Riemann integration, we have <span
class="math display">\[
m S \le \int_I f(t) g(t) dt \le M S
\]</span></p>
<p>Note that <span class="math inline">\(S f(t)\)</span> is a continuous
function in <span class="math inline">\(I\)</span>. Hence, by mean value
theorem, <span class="math inline">\(\exists c \in I\)</span>, such that
<span class="math display">\[
S f(c) = \int_I f(t) g(t) dt
\]</span> <span class="math inline">\(\square\)</span></p>
<p><strong><em>Corollary 1.</em></strong> By weighted mean value
theorem, we have <span class="math display">\[
\begin{aligned}
r_n(x)
    &amp;= \frac{1}{n!} \int_a^x f^{ (n + 1) } (t) (x - t)^{n } dt  \\
    &amp;= f^{ (n + 1) } (c) \int_a^x  \frac{1}{n!} (x - t)^{n } dt  \\
    &amp;= \frac{f^{ (n + 1) } (c ) }{(n + 1) ! } (x - a)^{n + 1 }  
\end{aligned}
\]</span></p>
<p>for some <span class="math inline">\(c \in [a, x]\)</span>.</p>
<p><strong><em>Corollary 2.</em></strong> Let <span
class="math inline">\(f:\rightarrow \mathbb{R}^n \rightarrow
\mathbb{R}\)</span> be a function with continuous second partial
derivatives, then given <span class="math inline">\(a \in
\mathbb{R}^n\)</span>, it holds that <span class="math display">\[
f(x) = f(a) + [\nabla f(c)]^T (x - a)
\]</span> for some <span class="math inline">\(c \in a + t(x -
a)\)</span>, where <span class="math inline">\(t \in [0,
1]\)</span>.</p>
<p><em>Proof:</em> Define <span class="math inline">\(g(t) = f(a + t (x-
a)) : [0,1] \rightarrow \mathbb{R}\)</span>. Then</p>
<ol type="1">
<li><span class="math inline">\(g(0) = f(a)\)</span>.</li>
<li><span class="math inline">\(g(1) = f(x)\)</span>.</li>
<li><span class="math inline">\(g&#39;(t) = [\nabla f(a + t (x- a) ) ]^T
(x - a)\)</span></li>
<li>By mean value theorem, <span class="math inline">\(\exists t \in [0,
1]\)</span>, s.t., <span class="math display">\[
\frac{g(1) - g(0)}{1} = f(x) - f(a) = g&#39;(t) = [\nabla f(a + t (x- a)
) ]^T (x - a)
\]</span></li>
</ol>
<p><span class="math inline">\(\square\)</span></p>
<p><strong><em>Corollary 3.</em></strong> Let <span
class="math inline">\(f\)</span>, <span class="math inline">\(g\)</span>
and <span class="math inline">\(c\)</span> as defined before, then <span
class="math display">\[
f(x) = f(a) + [\nabla f(a)]^T (x - a) + \frac{1}{2} (x - a)^T [\nabla^2
f(c)] (x - a)
\]</span></p>
<p><em>Proof:</em> <span class="math display">\[
g&#39;&#39;(t) = (x - a)^T [\nabla^2 f(a + t (x- a) ) ] (x - a)
\]</span></p>
<p>Then applying Corollary 1 gives <span class="math display">\[
g(1) = g(0) + g&#39;(0)(1 - 0) + \frac{1}{2} g&#39;&#39;(t) (1 - 0)^2
\]</span></p>
<p>for some <span class="math inline">\(t \in [0, 1]\)</span>.</p>
<p><span class="math inline">\(\square\)</span></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/02/24/Eigenvalues-and-Eigenvectors/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | WOW">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/02/24/Eigenvalues-and-Eigenvectors/" class="post-title-link" itemprop="url">Eigenvalues, Eigenvectors and SVD</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-02-24 21:57:00" itemprop="dateCreated datePublished" datetime="2020-02-24T21:57:00-05:00">2020-02-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-03-18 20:27:33" itemprop="dateModified" datetime="2022-03-18T20:27:33-04:00">2022-03-18</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="eigenvector-and-eigenvalues">Eigenvector and Eigenvalues</h1>
<blockquote>
<p><strong>Theorem</strong>. Given a symmetric matrix <span
class="math inline">\(A \in \mathbb{R}^{n \times n}\)</span> that is
positive semi-definitive, there exists an orthogonal matrix <span
class="math inline">\(V \in \mathbb{R}^{n \times n}\)</span>, and a
diagonal matrix <span class="math inline">\(\Sigma \in \mathbb{R}^{n
\times n}\)</span> with all entries non-negative, such that <span
class="math display">\[
A = V \Sigma V^T.
\]</span></p>
</blockquote>
<p>We need the following fact for the proof.</p>
<blockquote>
<p><strong>Fact.</strong> If a function <span class="math inline">\(f: S
\rightarrow \mathbb{R}\)</span> is continuous on a closed set <span
class="math inline">\(S\)</span>, then it achieves maximum value at some
point of <span class="math inline">\(S\)</span>.</p>
</blockquote>
<p><strong>Proof.</strong> Consider the maximization problem: <span
class="math display">\[
    \begin{aligned}
    &amp;\max &amp; \frac{1}{2} x^T A x \\
    &amp;s.t. &amp;  x^T x = 1
    \end{aligned}
\]</span></p>
<blockquote>
<p><em><strong>Question to ponder:</strong> Explain the geometric
meaning of the term <span class="math inline">\(x^T A
x\)</span>.</em></p>
</blockquote>
<p>The corresponding Lagrange function is given by <span
class="math display">\[
    L(x, \lambda) = \frac{1}{2} x^T A x - \lambda (x^T x  - 1)
\]</span></p>
<p>Taking derivative with respect to <span
class="math inline">\(x\)</span> gives <span class="math display">\[
    \frac{\partial L}{\partial x} = Ax - \lambda x.
\]</span></p>
<p><strong><em>Existence of maximum solution:</em></strong> Note that
<span class="math inline">\(\{ x : x^T x = 1 \}\)</span> is defined the
boundary of the unit cycle, which is a closed set. Combined with the
fact that <span class="math inline">\(f \doteq (1 / 2) \cdot x^T A
x\)</span> is a continuous function (with respect to <span
class="math inline">\(x\)</span>), it takes its maximum value at some
point in <span class="math inline">\(\{ x : x^T x = 1 \}\)</span>.
Denote this point <span class="math inline">\(v_1 \in \{ x : x^T x = 1
\}\)</span>.</p>
<p><strong><em>Gradient at the maximum point:</em></strong> At this
point, it holds that <span class="math display">\[
    \frac{\partial L}{\partial x} \mid_{x = v_1} = Av_1 - \lambda v_1 =
0,
\]</span></p>
<p>which implies that <span class="math inline">\(v_1\)</span> is an
eigenvector of <span class="math inline">\(A\)</span>. Denote its
corresponding eigenvalue <span
class="math inline">\(\lambda_1\)</span>.</p>
<blockquote>
<p><em><strong>Question to ponder:</strong> Prove that <span
class="math inline">\(\lambda_1\)</span> is the largest
eigenvalue.</em></p>
</blockquote>
<p>After finding <span class="math inline">\(v_1\)</span>, consider a
new optimization problem: <span class="math display">\[
    \begin{aligned}
    &amp;\max   &amp; \frac{1}{2} x^T A x \\
    &amp;s.t.   &amp;  x^T x = 1 \\
    &amp;       &amp;  v_1^T x = 0
    \end{aligned}
\]</span></p>
<p>That is, we want to find a new unit vector that is orthogonal to
<span class="math inline">\(v_1\)</span> while maximizing <span
class="math inline">\(\frac{1}{2} x^T A x\)</span>.</p>
<p><strong><em>Existence of maximum solution.</em></strong> By the lemma
and the facts: 1. <span class="math inline">\(\{x : x^T x = 1\} \cap \{
x : v_1^T x = 0 \}\)</span> is closed.<br />
2. <span class="math inline">\(\frac{1}{2} x^T A x\)</span> is
continuous.</p>
<p>Denote this maximum point <span class="math inline">\(v_2\)</span>.
Now consider the new Lagrange function for the optimization <span
class="math display">\[
    L(x, \lambda) = \frac{1}{2} x^T A x - \lambda (x^T x  - 1) -
\beta(v_1^T x - 0).
\]</span></p>
<p><strong><em>Gradient at the maximum point:</em></strong> At this
point, it holds that <span class="math display">\[
    \frac{\partial L}{\partial x} \mid_{x = v_2} = Av_2 - \lambda v_2 -
\beta v_1 = 0.
\]</span></p>
<p>Left multiplying <span class="math inline">\(v_1^T\)</span> gives
<span class="math display">\[
    (v_1^T A)v_2 - \lambda v_1^T v_2 - \beta v_1^T v_1 = (A v_1)^T
v_2  - \beta = \lambda_1 v_1^T v_2 - \beta = -\beta = 0,
\]</span> where <span class="math inline">\(v_1^T A = (A v_1)^T\)</span>
follows from the symmetry of <span class="math inline">\(A\)</span>,
i.e., <span class="math inline">\(A = A^T\)</span>.</p>
<p>Therefore, <span class="math display">\[
    Av_2 - \lambda v_2 = 0.
\]</span></p>
<p>It follows that <span class="math inline">\(v_2\)</span> is an
eigenvector of <span class="math inline">\(A\)</span>. Denote its
associated eigenvalue <span
class="math inline">\(\lambda_2\)</span>.</p>
<p>In a similar manner, we can define <span class="math display">\[
    \begin{aligned}
    &amp;\max   &amp; \frac{1}{2} x^T A x \\
    &amp;s.t.   &amp;  x^T x = 1 \\
    &amp;       &amp;  v_1^T x = 0 \\
    &amp;       &amp;  v_2^T x = 0 \\
    \end{aligned}
\]</span></p>
<p>There exists an optimal point <span
class="math inline">\(v_3\)</span>. The derivative of Lagrange function
at this point is <span class="math display">\[
    \frac{\partial L}{\partial x} \mid_{x = v_3} = Av_3 - \lambda v_3 -
\beta_1 v_1 - \beta_2 v_2 = 0,
\]</span> for some parameters <span class="math inline">\(\lambda,
\beta_1, \beta_2\)</span>. Left multiplying <span
class="math inline">\(v_1^T\)</span> or <span
class="math inline">\(v_2^T\)</span> gives <span
class="math inline">\(\beta_1 = 0\)</span> and <span
class="math inline">\(\beta_2 = 0\)</span> so that <span
class="math inline">\(v_3\)</span> is an eigenvector of <span
class="math inline">\(A\)</span>.</p>
<p>Following the procedure, we can find <span
class="math inline">\(n\)</span> eigenvectors <span
class="math inline">\(v_1, v_2, \ldots, v_n\)</span> of <span
class="math inline">\(A\)</span>. Define <span class="math display">\[
    \Sigma =
        \begin{bmatrix}
            \lambda_1   &amp;           &amp;   \\
                        &amp;\lambda_2  &amp;   \\
                        &amp;           &amp;   \ldots \\
                        &amp;           &amp;      &amp; \lambda_n
        \end{bmatrix},
    \qquad
    V =
        \begin{bmatrix}
            v_1, v_2, \ldots, v_n
        \end{bmatrix}.
\]</span></p>
<p>Then <span class="math display">\[
    A V = V \Sigma.
\]</span></p>
<p>Hence, <span class="math display">\[
    A = V \Sigma V^{-1} = V \Sigma V^T.
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h1 id="singular-vector-decomposition">Singular Vector
Decomposition</h1>
<p>In general, a matrix <span class="math inline">\(A \in \mathbb{R}^{m
\times n}\)</span> is considered a linear mapping from <span
class="math inline">\(\mathbb{R}^n\)</span> to <span
class="math inline">\(\mathbb{R}^m\)</span>. It takes a vector <span
class="math inline">\(x \in \mathbb{R}^n\)</span> to a new one <span
class="math inline">\(Ax \in \mathbb{R}^m\)</span>. We are interested in
the following question.</p>
<blockquote>
<p>Is there a vector <span class="math inline">\(x\)</span>, whose
length ratio, <span class="math display">\[
\max_{x \in \mathbb{R}^n } \frac{ \Vert Ax  \Vert }{ \Vert x \Vert },
\]</span> is maximized by the mapping?</p>
</blockquote>
<p>As <span class="math inline">\(\Vert x \Vert\)</span> is a number,
<span class="math display">\[
    \frac{ \Vert Ax \Vert  }{ \Vert x \Vert } = \left\Vert A
\frac{x}{\Vert x \Vert} \right\Vert .
\]</span></p>
<p>Hence, it suffices to consider unit vectors, and the following
optimization problem: <span class="math display">\[
    \begin{aligned}
        &amp;\max &amp; \frac{1}{2} x^T A^T Ax \\
        &amp;s.t. &amp;  x^T x = 1
    \end{aligned}.
\]</span></p>
<p>In this case, the objective function is <span
class="math inline">\(0.5 \cdot \Vert Ax \Vert^2 = 0.5 \cdot (Ax)^T (Ax)
= 0.5 \cdot x^T A^T A x\)</span>.</p>
<p>Following similar process of previous section, we can find a set of
eigenvectors <span class="math inline">\(v_1, v_2, \ldots, v_n\)</span>
of <span class="math inline">\(A^T A\)</span>. Define <span
class="math inline">\(U \in \mathbb{R}^{m \times n}\)</span> <span
class="math display">\[
    U
        = A V { \sqrt{\Sigma^{-1} } }
        = AV
        \begin{bmatrix}
        \sqrt { 1 / \lambda_1}  &amp;                       &amp; \\
                                &amp;\sqrt { 1 / \lambda_2} &amp; \\
                                &amp;                       &amp; \ldots
\\
                                &amp;                       &amp;
&amp;\sqrt {1/\lambda_n}
        \end{bmatrix}.
\]</span></p>
<p>Then <span class="math inline">\(U { \sqrt \Sigma } V^T = A\)</span>,
which is called the <em>singular vector decomposition</em> of <span
class="math inline">\(A\)</span>.</p>
<p>Finally, we can verify that the columns of <span
class="math inline">\(U\)</span> are perpendicular: <span
class="math inline">\(\forall i \neq j, i, j \in [n]\)</span>, <span
class="math display">\[
    u_i^T u_j
        = \left(\sqrt{\frac{1}{\lambda_i}} A V_i \right)^T
            \left( \sqrt{\frac{1}{\lambda_j}} A V_j \right)
        = \sqrt {\frac{1}{\lambda_i}} \sqrt{\frac{1}{\lambda_j}} v_i^T
A^T A v_j  = 0,
\]</span> as <span class="math inline">\(v_i\)</span> and <span
class="math inline">\(v_j\)</span> are orthogonal eigenvectors of <span
class="math inline">\(A^T A\)</span>.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/02/20/Ellipsoid/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | WOW">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/02/20/Ellipsoid/" class="post-title-link" itemprop="url">Ellipsoid method</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-02-20 21:19:42" itemprop="dateCreated datePublished" datetime="2020-02-20T21:19:42-05:00">2020-02-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-06-21 02:51:15" itemprop="dateModified" datetime="2022-06-21T02:51:15-04:00">2022-06-21</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Ellipsoid method is a weakly polynomial algorithm for solving linear
programming. The preliminary version was introduced by the Russian
mathematician Shor in 1977 for general convex optimization problems.
Then it was applied to linear programming by Khachyan in 1979 [1].
Before interior point method, it was the first polynomial time algorithm
for LP.</p>
<h1 id="feasibility-implies-optimality">Feasibility implies
Optimality</h1>
<p>Now, consider the primal LP: <span class="math display">\[
  \mathcal{P}:  \qquad
  \begin{aligned}
    &amp;\max   &amp;c^T x    &amp; \\
    &amp;s.t.   &amp;Ax \le b &amp; \\
    &amp;       &amp; x \ge 0 &amp;
  \end{aligned}
\]</span></p>
<p>whose dual is given by <span class="math display">\[
  \mathcal{D}:  \qquad
  \begin{aligned}
    &amp;\min   &amp;y^Tb    \ \  &amp; \\
    &amp;s.t.   &amp;y^TA \ge c^T &amp; \\
    &amp;       &amp;y \ge 0 \ \  &amp;
  \end{aligned}
\]</span></p>
<p>The ellipsoid does not optimize the primal directly. Instead, it try
to return a feasible point <span class="math inline">\((x, y)\)</span>
that satisfies the following constraints: <span class="math display">\[
\begin{aligned}
         c^T x &amp;= y^Tb  &amp; \\
         Ax    &amp;\le b   &amp; \\
          x    &amp;\ge 0       &amp; \\
         y^TA  &amp;\ge c^T &amp; \\
         y     &amp;\ge 0 \ \  &amp;
\end{aligned}
\]</span></p>
<p>By weak duality, if such point exists, then <span
class="math inline">\(x\)</span> is the optimal solution for the primal
program. (Note that, if there is no feasible point for the third
program, the primal could be either infeasible or unbounded.)</p>
<h1 id="ellipsoid">Ellipsoid</h1>
<p>Ellipsoid is a unit ball that has been squashed or stretched along
orthogonal directions. We illustrate this by an example in two
dimension. The following picture shows an ellipse obtained by enlarging
the unit ball by a facto of <span class="math inline">\(2\)</span> along
the <span class="math inline">\(v_1\)</span> direction and squashing it
ball by half along the <span class="math inline">\(v_2\)</span>
direction, where <span class="math inline">\(v_1\)</span> and <span
class="math inline">\(v_2\)</span> constitute an orthogonal base.</p>
<p><img
src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/Ellipsoid/EllipsoidMethod1.jpg" /></p>
<p>It is equivalent to first squash or stretch the ball along the
directions of <span class="math inline">\(e_1, e_2\)</span>,</p>
<p><img
src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/Ellipsoid/EllipsoidMethod2.jpg" /></p>
<p>then rotate the resulting ellipsoid to corresponding orthogonal
directions.</p>
<p><img
src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/Ellipsoid/EllipsoidMethod3.jpg" /></p>
<p>The rotation can be done by left multiplying an orthogonal matrix
<span class="math display">\[
V = [v_1, v_2]
\]</span></p>
<p>where <span class="math inline">\(v_1, v_2\)</span> are the
orthogonal base for which the squash and stretch are performed.</p>
<p>To recover the unit ball, we can first perform the reverse rotation:
<span class="math display">\[
x \leftarrow V^T x
\]</span></p>
<p>followed by a reverse scaling: <span class="math display">\[
  x \leftarrow  
    \begin{bmatrix}
      1/2  &amp; \\
      &amp;  2
    \end{bmatrix}
    x
\]</span></p>
<p>Note that the reverse rotation is represented by matrix <span
class="math inline">\(V^T\)</span> as <span class="math inline">\(V
V^T  = I\)</span>. Therefore, the ellipsoid is denoted as <span
class="math display">\[
  \left(
  \begin{bmatrix}
    1/2  &amp; \\
    &amp;  2
  \end{bmatrix}
  V^T x \right)^T
  \left(
  \begin{bmatrix}
    1/2  &amp; \\
    &amp;  2
  \end{bmatrix}
  V^T x \right)
  \le 1
\]</span></p>
<p>That is <span class="math display">\[
  x^T \left( V
  \begin{bmatrix}
    1/2  &amp; \\
    &amp;  2
  \end{bmatrix}^2
  V^T \right) x  \le 1
\]</span></p>
<p>In general, an ellipsoid is represented by <span
class="math display">\[
  E(s, P) = \{ x : (x - s)^T P^{-1} (x - s) \le 1\}
\]</span> where <span class="math inline">\(s \in \mathbb{R}^n\)</span>
is the center of the ellipsoid and <span
class="math inline">\(P\)</span> is a positive semi-definite matrix.</p>
<p>Recall that a positive semi-definite matrix <span
class="math inline">\(P\)</span> can be rewritten as <span
class="math display">\[
  P = V \Sigma V^T
\]</span> and <span class="math display">\[
  P^{-1} = V \Sigma^{-1} V^T
\]</span></p>
<p>where <span class="math inline">\(V\)</span> is an orthogonal matrix
and <span class="math inline">\(\Sigma\)</span> is a diagonal matrix.
Geometrically, <span class="math inline">\(V\)</span> are the directions
and <span class="math inline">\(\sqrt \Sigma\)</span> are the ratios of
the squashes or stretches. If we define <span class="math inline">\(B =
V \sqrt \Sigma\)</span>, then <span class="math inline">\(B^T = \sqrt
\Sigma V^T\)</span>, <span class="math inline">\(B^{-1} = \sqrt
\Sigma^{-1} V^T\)</span> and <span class="math inline">\(P = B
B^T\)</span>, <span class="math inline">\(P^{-1} = (B^{-1} )^T
B^{-1}\)</span>.</p>
<p>The representation can be viewed as merely a recipe for converting
the ellipsoid back to the unit ball:</p>
<ol type="1">
<li><p>First perform a translation <span class="math inline">\(x
\leftarrow (x - s)\)</span> so that the center of the ellipsoid is now
the center.</p></li>
<li><p>Rotate the ellipsoid, such that its axes are aligned with <span
class="math inline">\(e_1, e_2, ..., e_n\)</span>. This is done by
multiplying the matrix <span class="math inline">\(V^T\)</span>: <span
class="math inline">\(x \leftarrow V^T x\)</span>.</p></li>
<li><p>Squash or stretch along the axes <span class="math inline">\(e_1,
e_2, ..., e_n\)</span>: <span class="math inline">\(x \leftarrow \sqrt
\Sigma^{-1} x\)</span>.</p></li>
<li><p>Therefore, the linear transformation for the recovery is <span
class="math display">\[
  x \leftarrow B^{-1} (x - s)
\]</span></p></li>
</ol>
<p>Conversely, <span class="math inline">\(E(s, P) = E(s, V \sqrt \Sigma
\sqrt \Sigma V^T)\)</span> tells us how to get the ellipsoid from the
unit ball:</p>
<ol type="1">
<li><p>Scale unit ball along the axes <span class="math inline">\(e_1,
e_2, .., e_n\)</span> by factors that <span class="math inline">\(\sqrt
\Sigma_{1, 1}, \sqrt \Sigma_{2, 2}, ..., \sqrt \Sigma_{n,
n}\)</span>.</p></li>
<li><p>Rotate the ellipsoid by matrix <span
class="math inline">\(V\)</span>.</p></li>
<li><p>Move the ellipsoid by <span
class="math inline">\(s\)</span>.</p></li>
</ol>
<p>That is, <span class="math inline">\(x \leftarrow V \sqrt \Sigma y +
s\)</span> takes the unit ball <span class="math inline">\(\{ y : y^T y
\le 1 \}\)</span> to the corresponding ellipsoid <span
class="math inline">\(\{ x : (x - s)^T V \Sigma^{-1} V^T (x - s) \le 1
\}\)</span>.</p>
<h1 id="goal">Goal</h1>
<p>Now return to our discussion of ellipsoid method. Without lose of
generality, we consider only the following problem:</p>
<blockquote>
<p>Given <span class="math inline">\(F = \{x : Ax \le b\}\)</span>,
output any <span class="math inline">\(x \in F\)</span> or report <span
class="math inline">\(F = \emptyset\)</span>, where <span
class="math inline">\(A \in \mathbb{R}^{m \times n}, x \in \mathbb{R}^n,
b \in \mathbb{R}^m\)</span>.</p>
</blockquote>
<p>We assume further that</p>
<ol type="1">
<li><p><span class="math inline">\(\exists R \in \mathbb{R}\)</span>,
<span class="math inline">\(F \subseteq B(0, R)\)</span>. Besides, if
<span class="math inline">\(F \neq \emptyset\)</span>, <span
class="math inline">\(\exists r \in \mathbb{R}\)</span>, and <span
class="math inline">\(t \in \mathbb{R}^n\)</span>, s.t., <span
class="math inline">\(B(t, r) \subseteq F\)</span>. Here <span
class="math inline">\(B(0, R) = \{ x : \Vert x\Vert_2 \le R \}\)</span>
and <span class="math inline">\(B(t, r) = \{ x : \Vert x - t\Vert_2 \le
r \}\)</span>.</p></li>
<li><p><em>Separation Oracle:</em> Given a vertex <span
class="math inline">\(s \in \mathbb{R}^n\)</span>, the separation oracle
is a mechanism that asserts</p>
<ul>
<li>either <span class="math inline">\(s \in F\)</span></li>
<li>or <span class="math inline">\(s \notin F\)</span> and returns a
direction (which is a unit vector) <span class="math inline">\(d \in
\mathbb{R}^n\)</span>, such that <span class="math inline">\(d^T s \ge
d^T x\)</span> for <span class="math inline">\(\forall x \in
F\)</span>.</li>
</ul></li>
</ol>
<p>The first assumption says that <span class="math inline">\(F\)</span>
is neither too "large" nor too "small". Note that <span
class="math inline">\(B(t, r) \subseteq F\)</span> also implies that
<span class="math inline">\(F\)</span> has full dimension.</p>
<p>For LP, the separation is straightforward to implement: we just check
whether <span class="math inline">\(As \le b\)</span>. If so, then <span
class="math inline">\(s \in F\)</span>. Otherwise, <span
class="math inline">\(\exists i \in [m]\)</span>, such that the <span
class="math inline">\(i^{th}\)</span> constraint is violated: <span
class="math inline">\((A s)_i &gt; b_i\)</span>. Just return <span
class="math inline">\(d^T = A_{i, \cdot}\)</span>.</p>
<blockquote>
<p>Question to ponder: the feasible region of an LP may not satisfy the
first assumption? It is possible to reduce it to one satisfying the
first assumption?</p>
</blockquote>
<h1 id="the-algorithm">The Algorithm</h1>
<p>The algorithm begins with a special ellipsoid <span
class="math inline">\(E_0 = B(0, R)\)</span>. At each step, it queries
the <em>separation oracle</em> and generates a smaller ellipsoid (with
reduced volume). If <span class="math inline">\(F\)</span> is not empty,
the ellipsoid at each step is guaranteed to contain it. The algorithm
stops before the volume of the ellipsoid decreases below $ (B(t,
r))$.</p>
<p>The algorithmic flow is shown below:</p>
<table style="width:53%;">
<colgroup>
<col style="width: 52%" />
</colgroup>
<tbody>
<tr>
<td style="text-align: left;">1. <span class="math inline">\(i =
0\)</span>.</td>
</tr>
<tr>
<td style="text-align: left;">2. <span class="math inline">\(E_0 = B(0,
R)\)</span>.</td>
</tr>
<tr>
<td style="text-align: left;">3. <em>While</em> <span
class="math inline">\(\mathtt{vol} (E_i(s_i, P_i)) \ge  \mathtt{vol}
(B(t, r))\)</span>:</td>
</tr>
<tr>
<td style="text-align: left;">4. <span
class="math inline">\(\qquad\)</span> <em>if</em> <span
class="math inline">\(s_i \in F\)</span>, output <span
class="math inline">\(s_i\)</span>.</td>
</tr>
<tr>
<td style="text-align: left;">5. <span
class="math inline">\(\qquad\)</span> <em>else</em>,</td>
</tr>
<tr>
<td style="text-align: left;">6. <span
class="math inline">\(\qquad\)</span> <span
class="math inline">\(\qquad\)</span> Obtain a direction <span
class="math inline">\(d_i\)</span>, s.t., <span
class="math inline">\(d_i^T s_i \ge d_i^T x\)</span> for <span
class="math inline">\(x \in F\)</span>*.</td>
</tr>
<tr>
<td style="text-align: left;">7. <span
class="math inline">\(\qquad\)</span> <span
class="math inline">\(\qquad\)</span> Calculate a ellipsoid <span
class="math inline">\(E_{i + 1} \supset E_{i} \cap \{x : d_i^T s_i \ge
d_i^T x \}\)</span>.</td>
</tr>
<tr>
<td style="text-align: left;">8. <span
class="math inline">\(\qquad\)</span> <span
class="math inline">\(\qquad\)</span> <span class="math inline">\(i
\leftarrow i + 1\)</span>.</td>
</tr>
<tr>
<td style="text-align: left;">9. Output <span class="math inline">\(F =
\emptyset\)</span>.</td>
</tr>
</tbody>
</table>
<p>For the one dimension case, it is nothing more than a variant of
binary search.</p>
<h2 id="bounding-the-number-of-iterations">Bounding the Number of
Iterations</h2>
<p>The main result that characterizes the running time is</p>
<blockquote>
<p><strong>Theorem.</strong> It is guaranteed that for each <span
class="math inline">\(i\)</span>, <span class="math display">\[
\frac{ \mathtt{vol} ( E_{i + 1} ) } { \mathtt{vol} (E_i) } \le \exp
\left( -\frac{1}{2 (n + 1) } \right).
\]</span></p>
</blockquote>
<blockquote>
<p><strong>Corollary.</strong> The number of iterations of the ellipsoid
method is bounded by <span class="math display">\[
2n(n + 1) \ln \frac{R}{r}.
\]</span></p>
</blockquote>
<p>To simplify the notation further, we write <span
class="math inline">\(E_i = E(s, P)\)</span>, <span
class="math inline">\(d_i = d\)</span> and <span
class="math inline">\(E_{i + 1} = E(s&#39;, P&#39;)\)</span>. The key
lemma for the theorem is:</p>
<blockquote>
<p><strong>Lemma.</strong> Given an ellipsoid <span
class="math inline">\(E(s, P) = \{ x \in \mathbb{R}^n : (x - s)^T P^{-1}
(x - s) \le 1\}\)</span> and the half space <span
class="math inline">\(H(s, d) = \{ x \in \mathbb{R}^n : d^T (x - s)\le 0
\}\)</span>, we can find an ellipsoid <span
class="math inline">\(E(s&#39;, P&#39;)\)</span>, such that</p>
<ol type="1">
<li><p><span class="math inline">\(E(s&#39;, P&#39;)\)</span> contains
the intersection of <span class="math inline">\(E(s, P)\)</span> and
<span class="math inline">\(H(s, d)\)</span> : <span
class="math display">\[
E(c, P) \cap H(s, d).
\]</span></p></li>
<li><p>The volume of <span class="math inline">\(E(s&#39;,
P&#39;)\)</span> is at most <span class="math inline">\(\exp \left(
-\frac{1}{2 (n + 1) } \right)\)</span> times that of <span
class="math inline">\(E(s, P)\)</span>.</p></li>
</ol>
</blockquote>
<p>In particular, <span class="math inline">\(s&#39;\)</span> and <span
class="math inline">\(P&#39;\)</span> is given by <span
class="math display">\[
  \begin{aligned}
    s&#39; &amp;= s - \frac{1}{n + 1} \frac{P d}{\sqrt{d^T P d} } \\
    P&#39; &amp;= \frac{n^2}{n^2 - 1} \left( P - \frac{2}{n + 1}
\frac{Pd}{\sqrt{d^T P d} } \left( \frac{Pd}{\sqrt{d^T P d} } \right)^T
\right)
  \end{aligned}
\]</span></p>
<p><strong>Proof.</strong> The transformation <span
class="math inline">\(y = B^{-1} (x - s)\)</span> maps <span
class="math inline">\(E(s, P)\)</span> to <span
class="math inline">\(E(0，I)\)</span>, and <span
class="math display">\[
  \{x \in R^n: d^T B (B^{-1} (x - s)) \le 0\}
\]</span> to <span class="math display">\[
  H(0, B^T d) = \{y \in R^n: d^T B y \le 0\}.
\]</span></p>
<p>Let <span class="math display">\[
e&#39; = \frac{B^T d}{\sqrt{d^T B B^T d} } = \frac{B^T d}{\sqrt{d^T P d}
}
\]</span> so that <span class="math inline">\(H(0, B^Td)\)</span> is
equivalent to <span class="math inline">\(H(0, e&#39;)\)</span>.</p>
<p>It suffices to find an ellipsoid that contains <span
class="math inline">\(E(0, I) \cap H(0, e&#39;)\)</span>. Then applying
the reverse transformation <span class="math inline">\(x = By +
s\)</span> will give us an ellipsoid that contains <span
class="math inline">\(E(s, P) \cap H(s, d)\)</span>.</p>
<p>We can further reduce the problem to finding an ellipsoid that covers
<span class="math inline">\(E(0, I) \cap H(0, e_1)\)</span> as we can
recover the ellipsoid by rotating <span
class="math inline">\(e_1\)</span> to <span
class="math inline">\(e&#39;\)</span>.</p>
<blockquote>
<p><strong>Claim.</strong> The ellipsoid that covers <span
class="math inline">\(E(0,I) \cap H(0, e_1)\)</span> is given by <span
class="math display">\[
E \left( -\frac{1}{n + 1}e_1, \frac{n^2}{n^2 - 1} \left( I - \frac{2}{n
+ 1}e_1 e_1^T \right) \right)
\]</span> and has minimum volume <span class="math inline">\(\exp (
-\frac{1}{2(n + 1)} )\)</span>.</p>
</blockquote>
<p>To under the ellipsoid, we check how it transforms the unit ball to
an ellipsoid:</p>
<ol type="1">
<li><p>It squashes the ball along the <span
class="math inline">\(e_1\)</span> axis, by a factor of <span
class="math inline">\(\sqrt{ \frac{n^2} {n^2 - 1} \frac{n - 1} {n + 1} }
= \frac{n}{ n + 1 }\)</span>.</p></li>
<li><p>Then it stretches all other directions <span
class="math inline">\(e_2, e_3, ..., e_n\)</span> by a factor of <span
class="math inline">\(\sqrt \frac{n^2}{n^2 - 1}\)</span>.</p></li>
<li><p>Finally, move the center of the ellipsoid to <span
class="math inline">\(-\frac{1}{n + 1}e_1\)</span>.</p></li>
</ol>
<p>Note that the ellipsoid has volume <span class="math display">\[
  \begin{aligned}
    \left(1 - \frac{1}{n + 1} \right) \left( 1 + \frac{1}{n^2 -1}
\right)^{(n - 1) / 2}
    &amp;\le
    \exp \left( - \frac{1}{n + 1} + \frac{1}{n^2 -1} (n - 1) / 2 \right)
\\
    &amp;= \exp \left( - \frac{1}{2(n + 1)} \right).
  \end{aligned}
\]</span> This is also the ratio of the ellipsoid over that of the unit
ball, whose value is 1.</p>
<p>Before we prove the claim, we show how to transform the ellipsoid
back to <span class="math inline">\(E(s&#39;, P&#39;)\)</span> that
covers <span class="math inline">\(E(s, P) \cap H(s, d)\)</span>. First,
by symmetry, the ellipsoid that covers <span class="math inline">\(E(0,
I) \cap H(0, e&#39;)\)</span> is given by <span class="math display">\[
  E \left( -\frac{1}{n + 1}e&#39;, \frac{n^2}{n^2 - 1} \left( I -
\frac{2}{n + 1}e&#39; (e&#39;)^T \right) \right)
\]</span></p>
<p>Applying the mapping <span class="math inline">\(B y + s =
x\)</span>: <span class="math display">\[
  E \left( -\frac{1}{n + 1} e&#39;, \frac{n^2}{n^2 - 1} \left( I -
\frac{2}{n + 1}e&#39; (e&#39;)^T \right) \right) \\
  \longrightarrow
  E \left( s - \frac{1}{n + 1} B^T e&#39;, \frac{n^2}{n^2 - 1} B \left(
I - \frac{2}{n + 1}e&#39; (e&#39;)^T \right) B^T \right).
\]</span></p>
<p><em>As linear transformation preserves the ratio of volumes, the
ratio of the volume of the final ellipsoid over that of <span
class="math inline">\(E(s, P)\)</span> is also <span
class="math inline">\(\exp(- \frac{1}{2 (n + 1)} )\)</span>.</em></p>
<blockquote>
<p><strong>Question to ponder:</strong> 1. Show that <span
class="math inline">\(\frac{n^2}{n^2 - 1} (I - \frac{2}{n + 1}e_1
e_1^T)\)</span> is positive definite.</p>
<ol start="2" type="1">
<li><p>Show that <span class="math inline">\(\left( \frac{n^2}{n^2 - 1}
(I - \frac{2}{n + 1}e_1 e_1^T) \right)^{-1} =  \frac{n^2 - 1}{n^2} I +
\frac{2n + 2}{n^2} e_1 e_1^T\)</span>.</p></li>
<li><p>Show that <span class="math inline">\(\frac{n^2}{n^2 - 1} B (I -
\frac{2}{n + 1}e&#39; (e&#39;)^T) B^T\)</span> is positive
definite.</p></li>
</ol>
</blockquote>
<p><strong>Proof of the Claim.</strong> As both <span
class="math inline">\(E(0,I)\)</span> and <span
class="math inline">\(H(0, e_1)\)</span> are symmetric to <span
class="math inline">\(e_1\)</span>, so should the ellipsoid covering the
intersection of them. Therefore it should be of the form <span
class="math display">\[
  a_1 (x_1 - \lambda) + \sum_{i = 2}^n a_i x_i^2 \le 1
\]</span></p>
<p>where <span class="math inline">\(a_i\)</span>'s and <span
class="math inline">\(\lambda\)</span> (<span class="math inline">\(0
&lt; \lambda &lt; 1\)</span>) are the parameters to be determined. The
goal is to minimize its volume: <span class="math display">\[
  \sqrt{\frac{1}{a_1} \prod_{i = 2}^n \frac{1}{a_i} }  \mathtt{vol} [
E(0, I) ].
\]</span></p>
<p>where $ [ E(0, I) ] = 1$ is the volume of unit ball in <span
class="math inline">\(R^n\)</span>. It is equivalent to maximize <span
class="math display">\[
  a_1 \prod_{i = 2}^n a_i.
\]</span></p>
<p>As the ellipsoid covers <span class="math inline">\(E(0,I) \cap H(0,
e_1)\)</span> and should has as small volume as possible, the points
<span class="math inline">\(e_i\)</span> (<span class="math inline">\(i
= 1, 2, ..., n\)</span>) should be on its boundary. Therefore, <span
class="math display">\[
  \begin{aligned}
    a_1 (1 - \lambda)^2 + \sum_{i = 2}^n a_i 0^2 &amp;= 1
&amp;\rightarrow a_1(1 - \lambda)^2 = 1 &amp;\\
    a_1 (0 - \lambda)^2 + a_i 1^2 &amp;= 1  &amp;\rightarrow a_i = 1 -
a_1 \lambda^2  &amp;\quad  \forall i = 2, 3, ..., n  \\
  \end{aligned}
\]</span></p>
<p>Replacing <span class="math inline">\(a_i\)</span> with <span
class="math inline">\(1 - a_1 \lambda^2\)</span> and then <span
class="math inline">\(a_1\)</span> with <span
class="math inline">\(\frac{1}{(1 - \lambda)^2}\)</span>, the goal
becomes <span class="math display">\[
  \max \quad \frac{1}{(1 - \lambda)^2} \left[ 1 - \frac{\lambda^2}{(1 -
\lambda)^2} \right]^{n - 1}
\]</span></p>
<p>Substitute <span class="math inline">\(\frac{1}{1 - \lambda}\)</span>
by a variable <span class="math inline">\(x &gt; 1\)</span>, and let
<span class="math display">\[
  f \doteq x^2 [1 - (x - 1)^2]^{n - 1}
\]</span></p>
<p>Its derivative is <span class="math display">\[
  f&#39; = 2x [1 - (x - 1)^2]^{n - 1} - 2 (n - 1)(x - 1) x^2 [1 - (x -
1)^2]^{n - 2}
\]</span></p>
<p>Setting the derivative to zero, we obtain <span
class="math display">\[
  \begin{aligned}
    &amp;[1 - (x - 1)^2] - (n - 1)(x - 1)x = 0 \\
    &amp;\Rightarrow 1 - x^2 + 2x - 1- (n -1 )x^2 + (n -1 )x = 0 \\
    &amp;\Rightarrow - n x^2 + (n + 1) x = 0 \\
    &amp;\Rightarrow x = \frac{n + 1}{n}
  \end{aligned}
\]</span> It follows that <span class="math inline">\(a_1 = (\frac{n +
1}{n})^2\)</span>, <span class="math inline">\(\lambda = \frac{1}{n +
1}\)</span> and <span class="math inline">\(a_i = \frac{n^2 -
1}{n^2}\)</span> for <span class="math inline">\(\forall i = 2, 3, ...,
n\)</span>.</p>
<!-- Therefore, 
$$
c_1 = \left[ 
    \begin{matrix}
\frac{1}{n + 1} \\
 0 \\
  ...\\
0
\end{matrix}
\right] 
= \frac{1}{n + 1} e_1
$$
and 
$$
P_1^{-1} = \left[ 
\begin{matrix}
(\frac{n + 1}{n} )^2 &                       &   ...     \\
                    &   \frac{n^2 - 1}{n^2}  &   ...     \\
                    &                        &   ...     \\
                    &                        &   &\frac{n^2 - 1}{n^2}
\end{matrix}
\right] = \frac{n^2 - 1}{n^2} I + 2\frac{n + 1}{n^2} e_1 e_1^T \\
P_1 = \left[ 
\begin{matrix}
(\frac{n}{n + 1} )^2 &                       &   ...     \\
                    &   \frac{n^2}{n^2 - 1}  &   ...     \\
                    &                        &   ...     \\
                    &                        &   &\frac{n^2}{n^2 - 1}
\end{matrix}
\right] = \frac{n^2}{n^2 - 1} (I - \frac{2}{n + 1}e_1 e_1^T)
$$

The volume ratio between $E(c_1, P_1)$ and $E(0, I)$ is 

$$
\begin{aligned}
\sqrt{\frac{1}{a_1} \prod_{i = 2}^n \frac{1}{a_i} } 
&= \frac{n}{n + 1} \left[ \frac{n^2 }{n^2 - 1} \right]^{(n - 1) / 2} \\
&\le \exp \left( -\frac{1}{n + 1} + \frac{1}{2}\frac{n - 1}{n^2 - 1} \right) \\
&= \exp \left( -\frac{1}{2} \frac{1}{n + 1} \right)
\end{aligned}
$$ -->
<h1 id="reference">Reference</h1>
<p>[1]. <em>Michel X. Goemans, 7. Lecture notes on the ellipsoid
algorithm, 18.433: Combinatorial Optimization, MIT</em></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="Previous page" aria-label="Previous page" href="/page/40/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/40/">40</a><span class="page-number current">41</span><a class="page-number" href="/page/42/">42</a><span class="space">&hellip;</span><a class="page-number" href="/page/67/">67</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/42/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">WOW</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
