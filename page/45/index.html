<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Helvetica:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.24.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js" defer></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="WOW">
<meta property="og:url" content="http://example.com/page/45/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/45/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/45/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>WOW</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">WOW</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">你生之前悠悠千載已逝<br>未來還會有千年沉寂的期待</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">200</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/11/02/Frequency-Estimators/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | WOW">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/11/02/Frequency-Estimators/" class="post-title-link" itemprop="url">Frequency Estimators</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2019-11-02 20:47:52" itemprop="dateCreated datePublished" datetime="2019-11-02T20:47:52-04:00">2019-11-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2021-03-11 20:28:57" itemprop="dateModified" datetime="2021-03-11T20:28:57-05:00">2021-03-11</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="problem">Problem</h1>
<p>A stream <span class="math inline">\(S\)</span> (viewed as a
multi-set) of <span class="math inline">\(n\)</span> elements each from
a domain <span class="math inline">\(U = [1, , 2, ..., u]\)</span>.
Estimate the number of times each element appears in the <span
class="math inline">\(S\)</span>.</p>
<p>If we use a balanced binary search, this can be done in <span
class="math inline">\(O(n \log \min\{n, u\})\)</span> time and <span
class="math inline">\(\Theta(\min\{n, u\})\)</span> space. If we use a
hash table, this can be done in <span
class="math inline">\(\Theta(\min\{n, u\})\)</span> time and space.</p>
<p><strong><em>Question to ponder</em></strong>: can we do it with
sub-linear space?</p>
<p>By allowing errors, this is possible. Let <span
class="math inline">\(a = \left&lt; a_1, a_2, ..., a_{u}
\right&gt;\)</span> be the frequency of elements in <span
class="math inline">\(U\)</span> and <span class="math inline">\(b =
\left&lt; b_1, ..., b_{u} \right&gt;\)</span> be our estimation. Our
goal is to minimize the <span class="math inline">\(\ell_\infty\)</span>
error: <span class="math display">\[
    || a - b ||_\infty \doteq \max_i |b_i - a_i|.
\]</span></p>
<h1 id="count-min-sketch">Count-Min Sketch</h1>
<p>We use array <span class="math inline">\(A\)</span> with size <span
class="math inline">\(m &lt; \min\{n, u\}\)</span> such that each
element in <span class="math inline">\(U\)</span> is allocated a bucket
in <span class="math inline">\(A\)</span> to keep its frequency. Some
elements must share the buckets. Now we apply the following
strategy:</p>
<blockquote>
<ol type="1">
<li>Pick a perfect hash function <span class="math inline">\(h : U
\rightarrow [m]\)</span> (this condition can be weaken, but for
convenience of discussion, we assume perfectness here), that maps the
elements uniformly to every bucket in the array.<br />
</li>
<li>For <span class="math inline">\(\forall s \in S\)</span>,<br />
<span class="math inline">\(\qquad A[h(s)] \leftarrow A[h(s)] +
1\)</span> .</li>
<li>Return <span class="math inline">\(b_i = A[h(i)]\)</span> as the
estimation of <span class="math inline">\(a_i\)</span>.</li>
</ol>
</blockquote>
<p>Intuitively, each slot obtains <span
class="math inline">\(\frac{1}{m}\)</span> fraction of the total mass
<span class="math inline">\(\sum_i a_i = |a|\)</span> (where <span
class="math inline">\(|\cdot |\)</span> denotes the <span
class="math inline">\(\ell_1\)</span> norm). Conditioned on <span
class="math inline">\(i\)</span>-th element is hashed to the <span
class="math inline">\(h(i)\)</span> slots, <span
class="math inline">\(\frac{1}{m}\)</span> fraction of the rest mass
<span class="math inline">\(\sum_{j \neq i} a_j = n - a_i\)</span> is
hashed to the <span class="math inline">\(h(i)\)</span>-th slot.
Therefore, in expectation, <span class="math display">\[
0 \le \mathbb{E}[b_i - a_i] \le \frac{|a|}{m}
\]</span></p>
<p>An interesting property is that, if some <span
class="math inline">\(a_j\)</span> (<span class="math inline">\(j \neq
i\)</span>) (or a small subset of <span
class="math inline">\(a_j\)</span>'s) constitutes, say <span
class="math inline">\(0.99\)</span> percent of the mass <span
class="math inline">\(|a|\)</span>, as long as it is not hashed to <span
class="math inline">\(h(i)\)</span>, then the expected error is less
than <span class="math inline">\(0.01 \frac{|a|}{m}\)</span>.</p>
<p>Formally, define the binary random variables <span
class="math inline">\(X_j\)</span> for <span class="math inline">\(j
\neq i\)</span> such that <span class="math display">\[
X_j = \begin{cases}
    a_j     &amp;\quad \text{if} \quad h(i) = h(j)\\
    0       &amp;\quad \text{otherwise}
\end{cases}
\]</span> Then by perfectness of <span class="math inline">\(h\)</span>,
<span class="math inline">\(\Pr[X_j = a_j] = \frac{1}{m}\)</span> and
<span class="math inline">\(\mathbb{E}[X_j] = \frac{a_j}{m}\)</span>.
(Indeed, pairwise independence of <span class="math inline">\(h\)</span>
suffices to guarantee this condition).</p>
<p>Then <span class="math display">\[
    \mathbb{E} [b_i - a_i] = \mathbb{E} \left[ \sum_{j \neq i} X_j
\right] = \sum_{j \neq i} \mathbb{E}[X_j] \le \frac{|a|}{m}
\]</span></p>
<p>As <span class="math inline">\(b_i - a_i\)</span> is non-negative, by
Markov inequality, <span class="math display">\[
\Pr \left[ b_i - a_i \ge \epsilon |a| \right] \le \frac{\mathbb{E}[b_i -
a_i]}{\epsilon |a|}  \le \frac{1}{\epsilon m}
\]</span> If we would like to achieve failure probability <span
class="math inline">\(\delta\)</span>, we can set <span
class="math inline">\(m = \epsilon^{-1} \delta^{-1}\)</span>.</p>
<p>Question to ponder: can we improve this?</p>
<p>Yes, by repetition. Instead of using just one array, we set <span
class="math inline">\(d\)</span> arrays (to be set latter) and choose
<span class="math inline">\(d\)</span> hash functions independently.
Then the probability that all estimations deviate more than <span
class="math inline">\(\epsilon |a|\)</span> is at most <span
class="math display">\[
\left( \frac{1}{\epsilon m} \right)^d
\]</span></p>
<p>When <span class="math inline">\(d = \ln{\delta} / \ln
\frac{1}{\epsilon m} = \ln{ \frac{1}{\delta} } / \ln \epsilon
m\)</span>, the failure probability decreases to <span
class="math inline">\(\delta\)</span>. To minimize the space usage, we
solve the following optimization problem: <span class="math display">\[
\begin{aligned}
    &amp;\min           &amp;\ln \frac{1} {\delta} \frac{m}{\ln m + \ln
\epsilon} \\
    &amp;\text{s.t. }   &amp;m \ge \frac{1}{\epsilon}
\end{aligned}
\]</span></p>
<p>Solving the equation gives <span class="math inline">\(m = e
\epsilon^{-1}\)</span>. The space consumption is <span
class="math inline">\(\frac{e}{\epsilon} \ln
\frac{1}{\delta}\)</span>.</p>
<p>Note: suppose that <span class="math inline">\(|a| = 10000\)</span>
and <span class="math inline">\(\epsilon = 0.1\)</span>, <span
class="math inline">\(\delta = 0.01\)</span>, then with <span
class="math inline">\(10 \cdot e \ln 100 \approx 125\)</span> words, we
can estimate a particular <span class="math inline">\(a_i\)</span> with
the absolute error less than <span class="math inline">\(1000\)</span>.
If <span class="math inline">\(a_i = 9000\)</span>, the relative error
is small. However, if <span class="math inline">\(a_i = 1\)</span>,
basically our estimation if rather inaccurate.</p>
<p>Question to ponder: what if we analyze this by Chernoff style
inequality?</p>
<p>If we make <span class="math inline">\(d\)</span> repetition, then
the confidence interval of the mean estimation is given by (Hoeffding's
inequality) <span class="math display">\[
|a|\sqrt{\frac{\log \frac{2}{\delta} }{2 d} }
\]</span> If we want this interval to be smaller than <span
class="math inline">\(\epsilon |a|\)</span>, then we need <span
class="math inline">\(d = \frac{ \log \frac{2}{\delta} }{2
\epsilon^2}\)</span>, which is a <span
class="math inline">\(\frac{1}{\epsilon }\)</span> worse than the above
analysis. Intuitively, we require stronger condition for concentration
of mean value than that for existence of near-min value.</p>
<h1 id="count-sketch">Count-Sketch</h1>
<p>One drawback of Count-Min Sketch is that the estimator constructed is
one-sided and not unbiased. This can be fixed by introducing an
additional function <span class="math inline">\(g : U \rightarrow \{ -
1, 1 \}\)</span> that gives each elements in <span
class="math inline">\(U\)</span> a sign ("+" or "-") independently and
uniformly at random. Now,</p>
<ol start="2" type="1">
<li>For each element <span class="math inline">\(s \in S\)</span>, we
increase the counter <span class="math inline">\(h(s)\)</span> in the
array by 1 if <span class="math inline">\(g(s) &gt; 0\)</span> or <span
class="math inline">\(-1\)</span> if <span class="math inline">\(g(s)
&lt; 0\)</span>.</li>
<li>Finally, we set <span class="math inline">\(b_i = A[h(i)] \cdot
g(i)\)</span> as the estimation of <span
class="math inline">\(a_i\)</span>.</li>
</ol>
<p>In expectation, each slot obtains <span
class="math inline">\(\frac{1}{m}\)</span> fraction of the total mass
<span class="math inline">\(\sum_i a_i = |a|\)</span>. But as each
element "flips" it sign randomly, the expected value obtained is 0. Now,
conditioned on <span class="math inline">\(i\)</span>-th element is
hashed to the <span class="math inline">\(h(i)\)</span> slots, <span
class="math inline">\(\frac{1}{m}\)</span> fraction of the rest mass
<span class="math inline">\(\sum_{j \neq i} a_j = n - a_i\)</span> is
hashed to the <span class="math inline">\(h(i)\)</span>-th slot. With
their signs flipped randomly, they contribute 0 to the <span
class="math inline">\(h(i)\)</span>-th slot. Hence, <span
class="math display">\[
\mathbb{E}[b_i - a_i] = 0
\]</span> Formally, define the binary random variables <span
class="math inline">\(X_j\)</span> for <span class="math inline">\(j
\neq i\)</span> such that <span class="math display">\[
X_j = \begin{cases}
    a_j     &amp;\text{if} \quad h(i) = h(j) \wedge g(j) = g(i) \\
    - a_j   &amp;\text{if} \quad h(i) = h(j) \wedge g(j) \neq g(i) \\
    0       &amp;\text{otherwise}
\end{cases}
\]</span> Then by perfectness and independence of <span
class="math inline">\(h\)</span> and <span
class="math inline">\(g\)</span>,</p>
<p><span class="math display">\[
    \Pr[X_j = a_j] = \frac{1}{2m} \\
    \Pr[X_j = -a_j] = \frac{1}{2m} \\
    \Pr[X_j = 0] = 1 - \frac{1}{m}
\]</span></p>
<p>and <span class="math display">\[
\begin{aligned}
    \mathbb{E}[X_j]
    &amp;= 0 \\
    \mathbb{E}[b_i - a_i]
    &amp;= \mathbb{E}[\sum_{j \neq i} X_j]
    = \sum_{j \neq i} \mathbb{E}[X_j]
    = 0 \\
    \mathbb{Var} \left[ X_j \right]
    &amp;= \mathbb{E} [X_j^2] - (\mathbb{E}[X_j])^2
    = \frac{a_j^2}{m} \\
    \mathbb{Var} \left[ \sum_{j \neq i} X_j \right]
    &amp;= \sum_{j \neq i} \mathbb{Var} [X_j]
    = \sum_{j \neq i} \frac{a_j^2}{m}
    \le \frac{|a|_2^2}{m}
    \end{aligned}
\]</span></p>
<p>where <span class="math inline">\(|a|_2^2\)</span> is the <span
class="math inline">\(l_2\)</span> norm of <span
class="math inline">\(a\)</span>. Note that the above analysis requires
only pair independence. The random variable <span
class="math inline">\(X_j\)</span> is two sided, therefore we can not
use Markov Inequality for analysis.</p>
<p>Question to ponder: is it possible to analyze this directly by
Chernoff style inequality?</p>
<p>The tool we resort to is Chebyshev's inequality: <span
class="math display">\[
\Pr \left[ |\sum_{j \neq i} X_j - 0| \ge \epsilon |a|_2 \right] \le
\frac{\mathbb{Var} [\sum_{j \neq i} X_j]}{\epsilon^2 |a|_2^2 } \le
\frac{1}{m\epsilon^2 }
\]</span> we take <span class="math inline">\(m =
k\epsilon^{-2}\)</span> for some integer <span
class="math inline">\(k&gt; 2\)</span>.</p>
<p>How do we amplify the successful probability? We repeat the
experiment <span class="math inline">\(d\)</span> times, and take the
median. The only way that the median makes a mistake is when more than
half of the estimations deviate more <span
class="math inline">\(\epsilon |a|_2\)</span>. Denote <span
class="math inline">\(Y\)</span> the number of estimation such that the
error is more than <span class="math inline">\(\epsilon |a|_2\)</span>.
By Chernoff, <span class="math display">\[
\begin{aligned}
    \Pr \left[ Y - \frac{d}{k}\ge \frac{d}{2} - \frac{d}{k} \right]
    &amp;= \Pr \left[ Y - \frac{d}{k}\ge (\frac{1}{2} -
\frac{1}{k})\cdot k \cdot \frac{d}{k} \right] \\
    &amp;\le \exp \big( -\frac{d}{3 k} (\frac{k}{2} - 1)^2  \big) \\
    &amp;= \delta
\end{aligned}
\]</span></p>
<p>which solves to <span class="math display">\[
d= \frac{3k}{(k/2  -1)^2} \log \frac{1}{\delta}
\]</span> The overall space usage is therefore <span
class="math display">\[
md = \frac{3k^2}{\epsilon^2 (k/2  -1)^2} \log \frac{1}{\delta}
= \frac{3}{\epsilon^2 (1/2  - \frac{1}{k} )^2} \log \frac{1}{\delta}
\]</span> Question to ponder: the expression is wired, which implies
that <span class="math inline">\(k \rightarrow \infty\)</span>, the
space usage converges to <span
class="math inline">\(\frac{12}{\epsilon^2} \log
\frac{1}{\delta}\)</span>, which is worse than count-min hash than a
<span class="math inline">\(\frac{1}{\epsilon}\)</span> factor.</p>
<h4 id="relation-between-a_1-and-a_2.">Relation between <span
class="math inline">\(|a|_1\)</span> and <span
class="math inline">\(|a|_2\)</span>.</h4>
<p>Their relation is given as follows (by concavity of the <span
class="math inline">\(\sqrt \cdot\)</span> function) <span
class="math display">\[
|a|_2 \le |a|_1 \le \sqrt{ |u| } |a|_2
\]</span> In particular, when <span class="math inline">\(|u| =
2\)</span>, the inequality becomes <span class="math display">\[
|a_1 + a_2| \le \sqrt 2 \sqrt{a_1^2 + a_2^2 }
\]</span> When the dimension is higher than <span
class="math inline">\(2\)</span>, the factor in the RHS can not bounded
to <span class="math inline">\(\sqrt 2\)</span>.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/11/02/AM-GM-Inequality/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | WOW">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/11/02/AM-GM-Inequality/" class="post-title-link" itemprop="url">AM-GM Inequality</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2019-11-02 10:48:17" itemprop="dateCreated datePublished" datetime="2019-11-02T10:48:17-04:00">2019-11-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2019-12-02 18:18:10" itemprop="dateModified" datetime="2019-12-02T18:18:10-05:00">2019-12-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>The AM-GM inequality states that for <span class="math inline">\(x_1,
x_2, ..., x_n &gt;0\)</span> and <span class="math inline">\(\lambda_1,
\lambda_2, ..., \lambda_n \ge 0\)</span>, such that <span
class="math inline">\(\sum_{i = 1}^n \lambda_i = 1\)</span>, we have
<span class="math display">\[
\prod_{i} x_i^{\lambda_i} \le \sum_i \lambda_i x_i
\]</span> If particular, when <span class="math inline">\(\lambda_i =
\frac{1}{n}\)</span>, the inequality becomes <span
class="math display">\[
\sqrt[^n]{\prod_i x_i} \le \frac{\sum_i x_i}{n}
\]</span> Replaying <span class="math inline">\(x_i =
\frac{1}{y_i}\)</span>, we obtain <span class="math display">\[
\frac{n}{\sum_i \frac{1}{y_i}} \le \sqrt[^n]{\prod_i y_i}
\]</span> Another famous case is <span class="math inline">\(n =
2\)</span> and <span class="math inline">\(\lambda_1 =
\frac{1}{p}\)</span>, <span class="math inline">\(\lambda_2 =
\frac{1}{q}\)</span> and <span class="math inline">\(x_1 = x^p\)</span>,
<span class="math inline">\(x_2 = y^q\)</span>, we get the Young's
inequality <span class="math display">\[
xy = (x^p)^\frac{1}{p} (y^q)^\frac{1}{q} \le \frac{x^p}{p} +
\frac{y^q}{q}
\]</span> The proof of AM-GM inequality is rather simple and follows
immediately from the concavity of <span
class="math inline">\(\log\)</span> function: <span
class="math display">\[
\sum_i \lambda_i \log x_i \le \log \sum_i \lambda_i x_i
\]</span></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/10/31/Polynomials/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | WOW">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/10/31/Polynomials/" class="post-title-link" itemprop="url">Polynomials</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2019-10-31 21:38:36" itemprop="dateCreated datePublished" datetime="2019-10-31T21:38:36-04:00">2019-10-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-11-04 14:25:02" itemprop="dateModified" datetime="2024-11-04T14:25:02-05:00">2024-11-04</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="introduction">Introduction</h1>
<p>Polynomials constitute of a rich class of functions. A polynomial in
a single variable defined on a field <span
class="math inline">\(\mathbb{F}\)</span> is a function of the form:
<span class="math display">\[
p(x) = c_d x^d + c_{d - 1} x^{d - 1} + ... + c_1 x + c_0
\]</span> where the variable <span class="math inline">\(x\)</span> and
coefficients <span class="math inline">\(c_i \in \mathbb{F}, \forall i
\in [d]\)</span>. The integer <span class="math inline">\(d\)</span> is
called the degree of <span class="math inline">\(p(x)\)</span>.</p>
<h1 id="properties">Properties</h1>
<p>Polynomials have two fundamental properties:</p>
<blockquote>
<ol type="1">
<li><strong>A non-zero polynomial of degree <span
class="math inline">\(d\)</span> has at most <span
class="math inline">\(d\)</span> distinct roots.</strong><br />
</li>
<li><strong>Given <span class="math inline">\(d + 1\)</span> pairs <span
class="math inline">\(\{ (a_i, b_i) \in \mathbb{F}^2 : i \in [d + 1]
\}\)</span>, such that <span class="math inline">\(a_i \neq a_j\)</span>
for <span class="math inline">\(i \neq j\)</span>, there is a unique
polynomial <span class="math inline">\(p(x)\)</span> with degree at most
<span class="math inline">\(d\)</span> that goes through all these
points.</strong></li>
</ol>
</blockquote>
<h2 id="number-of-distinct-roots">Number of Distinct Roots</h2>
<p>We prove claim 1 by induction.</p>
<ol type="1">
<li><p>The base case is <span class="math inline">\(d = 0\)</span>. As
the polynomial is non-zero, it does not have any root.</p></li>
<li><p>Suppose the claim holds for non-negative integers <span
class="math inline">\(\le d\)</span> and <span
class="math inline">\(p(x)\)</span> is a polynomial of degree <span
class="math inline">\(d + 1\)</span>. If <span
class="math inline">\(p(x)\)</span> has a root <span
class="math inline">\(z\)</span>, by polynomial division, we can rewrite
<span class="math inline">\(p(x)\)</span> as <span
class="math display">\[
p(x) = (x - a)^k q(x)
\]</span> where <span class="math inline">\(k \ge 1\)</span> is the
largest integer such that <span class="math inline">\((x - a )^k |
p(x)\)</span>. Hence <span class="math inline">\(q(x)\)</span> has
degree <span class="math inline">\(d + 1 - k\)</span>. For any <span
class="math inline">\(z \neq a\)</span>, if <span
class="math inline">\(p(z) = (z - a)^k q( z ) = 0\)</span>, then <span
class="math inline">\(q(z) = 0\)</span>, which implies that <span
class="math inline">\(z\)</span> is a root of <span
class="math inline">\(q(x)\)</span>. By the inductive hypothesis, it has
at most <span class="math inline">\(d + 1 - k\)</span> distinct
roots.</p></li>
</ol>
<p><strong>Remark:</strong> <em>We don't claim that <span
class="math inline">\(p(x)\)</span> must have a root, but it has at most
<span class="math inline">\(d\)</span> distinct roots, if it has degree
<span class="math inline">\(d\)</span>.</em></p>
<h2 id="unique-interpolation">Unique Interpolation</h2>
<p>We first prove the existence of the interpolation, then prove its
uniqueness.</p>
<h3 id="existence-of-interpolation">Existence of Interpolation</h3>
<p>The method is called Lagrange Interpolation. Our basic building
blocks are a collection of special polynomials <span
class="math inline">\(\{ \delta_i( x ) : i \in [d + 1] \}\)</span>,
which we call signal functions, such that <span
class="math inline">\(\forall i \in [d + 1]\)</span>,</p>
<ol type="1">
<li><p>The polynomial <span class="math inline">\(\delta_i( x )\)</span>
has degree <span class="math inline">\(d\)</span>.</p></li>
<li><p>The polynomial takes value 1 at <span
class="math inline">\(a_i\)</span>, i.e., <span
class="math inline">\(\delta_i(a_i) = 1\)</span>.</p></li>
<li><p>The polynomial takes value 0 at <span
class="math inline">\(a_j\)</span> for <span class="math inline">\(j
\neq i\)</span>, i.e., <span class="math inline">\(\delta_i(a_j) =
0\)</span>.</p></li>
</ol>
<p>First, define <span class="math inline">\(\delta_i&#39;(x) = \prod_{j
\neq i} (x - a_j)\)</span>. It equals to <span
class="math inline">\(0\)</span> on <span class="math inline">\(a_j,
\forall j \neq i\)</span>. We normalize its value at <span
class="math inline">\(a_i\)</span>, to obtain</p>
<p><span class="math display">\[
    \delta_i(x) = \frac{\delta_i&#39;(x)}{\delta_i&#39;(a_i)} =
\frac{\prod_{j \neq i} (x - a_j) }{ \prod_{j \neq i} (a_i - a_j) }.
\]</span></p>
<p>With proper scaling and summation, <span
class="math inline">\(p(x)\)</span> is given by <span
class="math display">\[
    p(x) = \sum_{i = 1}^{d + 1} b_i \cdot \delta_i(x)
\]</span></p>
<h3 id="uniqueness-of-interpolation">Uniqueness of Interpolation</h3>
<p>Suppose for contradiction that there is another polynomial <span
class="math inline">\(q(x)\)</span>, s.t., <span
class="math inline">\(p(a_i) = q(a_i), \forall i \in [d + 1]\)</span>.
Let <span class="math inline">\(r(x) = p(x) - q(x)\)</span>. If <span
class="math inline">\(r(x) \equiv 0\)</span>, then the claim holds
trivially. Otherwise, <span class="math inline">\(r(x)\)</span> is a
non-zero polynomial with degree at most <span
class="math inline">\(d\)</span>. Claim 1 asserts that <span
class="math inline">\(r(x)\)</span> has at most <span
class="math inline">\(d\)</span> distinct roots, contradicting that
<span class="math inline">\(r(a_i) = 0\)</span> for <span
class="math inline">\(i \in  [d + 1]\)</span>.</p>
<!-- *Question to ponder*: does claim 2 implies claim 1?  -->
<p><em>Remark</em>: uniqueness can also be proven by showing the
following equation has unique solution <span class="math inline">\([
c_d, c_{d - 1}, ..., c_0]\)</span>: <span class="math display">\[
    \begin{bmatrix}
        a_1^d &amp; a_1^{d - 1} &amp; ... &amp;  a_1 &amp; 1\\
        a_2^d &amp; a_2^{d - 1} &amp; ... &amp;  a_2 &amp; 1\\
        ...\\
        a_{d + 1}^d &amp; a_{d + 1}^{d - 1} &amp; ... &amp;  a_{d + 1}
&amp; 1
    \end{bmatrix}
    \begin{bmatrix}
        c_d         \\
        c_{d - 1}   \\
        ...         \\
        c_0
    \end{bmatrix} =
    \begin{bmatrix}
    b_1 \\
    b_{1} \\
    ...\\
    b_{d + 1}
    \end{bmatrix} \\
\]</span></p>
<p>The left matrix is called Vandermonde Matrix, whose determinant is
<span class="math display">\[
    \begin{aligned}
        &amp;\det
            \begin{bmatrix}
            a_1^d &amp; a_1^{d - 1} &amp; ... &amp;  a_1 &amp; 1\\
            a_2^d &amp; a_2^{d - 1} &amp; ... &amp;  a_2 &amp; 1\\
            ...\\
            a_{d + 1}^d &amp; a_{d + 1}^{d - 1} &amp; ... &amp;  a_{d +
1} &amp; 1
            \end{bmatrix}  \\
        =&amp;
        \det
            \begin{bmatrix}
            0&amp; 0 &amp; ... &amp;  0 &amp; 1\\
            a_2^d - a_1 a_2^{d - 1} &amp; a_2^{d - 1} - a_1 a_2^{d -
2}&amp; ... &amp;  a_2 - a_1 &amp; 1\\
            ...\\
            a_{d + 1}^d - a_1 a_{d + 1}^{d - 1} &amp;  a_{d + 1}^{d - 1}
- a_1 a_{d + 1}^{d - 2}&amp; ... &amp;  a_{d + 1} - a_ 1&amp; 1
            \end{bmatrix}  \\
        =&amp;\prod_{i = 1}^{d + 1} (a_i - a_1) \det
            \begin{bmatrix}
            a_2^d &amp; a_2^{d - 1} &amp; ... &amp;  a_2 &amp; 1\\
            ...\\
            a_{d + 1}^d &amp; a_{d + 1}^{d - 1} &amp; ... &amp;  a_{d +
1} &amp; 1
            \end{bmatrix}  \\
            ...\\
        =&amp; \prod_{i &lt; j} (a_j - a_i)
    \end{aligned}
\]</span> which is non-zero when <span class="math inline">\(a_i \neq
a_j\)</span>.</p>
<h1 id="applications">Applications</h1>
<h2 id="pairwise-independent-hash-function.">Pairwise Independent Hash
Function.</h2>
<p>Assume that we want to map a set of elements <span
class="math inline">\(\mathcal{U} \doteq \{0, 1, ..., u - 1\}\)</span>
into some set <span class="math inline">\(\mathbb{F}\)</span>, by
picking a function <span class="math inline">\(h\)</span> uniformly at
random from a family of functions <span
class="math inline">\(\mathcal{H} \doteq \{ h : \mathcal{U} \rightarrow
\mathbb{F} \}\)</span>. For an <span class="math inline">\(i \in
\mathcal{U}\)</span>, the value <span class="math inline">\(Y_i \doteq
h(i)\)</span> is a random variable. The <span
class="math inline">\(Y_i\)</span>'s are called pairwise independent, if
for <span class="math inline">\(i, j \in \mathcal{U}, i \neq j\)</span>
and <span class="math inline">\(b_i, b_j \in \mathbb{F}\)</span>, <span
class="math display">\[
    \Pr_{h \in \mathcal{H} } [Y_i = b_i, Y_j = b_j] = \Pr_{h \in
\mathcal{H} } [Y_i = b_i] \Pr_{h \in \mathcal{H} } [Y_j = b_j].
\]</span></p>
<p>Similarly we can define <span class="math inline">\(k\)</span>-wise
independence. For any <span class="math inline">\(0 \le i_1 &lt; i_2
&lt;... &lt; i_k &lt; u\)</span>, and <span
class="math inline">\(b_{i_1} , b_{i_2}, ..., b_{i_k} \in
\mathbb{F}\)</span>, we have <span class="math display">\[
    \Pr_{h \in \mathcal{H} } [ Y_{i_1} = b_{i_1}, ... Y_{i_k} = b_{i_k}
] = \prod_{j} \Pr_{h \in \mathcal{H} } [ Y_{i_j} = b_{i_j}].
\]</span></p>
<h3 id="finite-field-mathbbf_p">Finite Field <span
class="math inline">\(\mathbb{F}_p\)</span></h3>
<p>Now we restrict our discussion to the finite field <span
class="math inline">\(\mathbb{F}_p = \{0, 1, ..., p - 1\}\)</span>,
where <span class="math inline">\(p\)</span> is a prime larger than
<span class="math inline">\(u\)</span>.</p>
<blockquote>
<p>Theorem. The set of all possible functions from <span
class="math inline">\(\mathcal{U}\)</span> to <span
class="math inline">\(\mathbb{F}_p\)</span> is pairwise independent.</p>
</blockquote>
<p><em>Proof:</em> <span class="math display">\[
    \begin{aligned}
        \Pr[Y_i = a, Y_j = b]
        = \frac{p^{u - 2}}{p^u}
        = \frac{1}{p^2}
        = \Pr[Y_i = a] \cdot \Pr[Y_j = b].
    \end{aligned}
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<p>However, each of the functions takes <span class="math inline">\(u
\log p\)</span> bits to represent. To reduce the space, we restrict to
the family: <span class="math display">\[
    \mathcal{H_1} = \{ p(x) = c_1 x + c_0 \mid c_1, c_0 \in \mathbb{F}_p
\}
\]</span></p>
<p>which contains all polynomials with degree at most 1 in the field
<span class="math inline">\(\mathbb{F}_p\)</span>, i.e., all lines in
<span class="math inline">\(\mathbb{F}_p\)</span>. There are <span
class="math inline">\(p^2\)</span> such functions.</p>
<p>We know that, for given <span class="math inline">\(x_1, x_2 \in
\mathcal{U}, x_1 \neq x_2\)</span>, then <span
class="math inline">\(\forall y_1, y_2 \in \mathbb{F}_p\)</span>, there
is a unique line that goes through <span class="math inline">\((x_1,
y_1), (x_2, y_2)\)</span>. If we pick a line uniformly at random from
<span class="math inline">\(\mathcal{H}_1\)</span>, then the probability
that it goes through this pair of points is <span
class="math inline">\({1} / {p^2}\)</span>.</p>
<p>This already implies pairwise independence, as <span
class="math display">\[
    \Pr[h(x_1) = y_1 ] = \sum_{y_2 = 0}^{p - 1} \Pr[h(x_1) = y_1, h(x_2)
= y_2] = \frac{1}{p}
\]</span></p>
<p>In a similar manner, we can construct a <span
class="math inline">\(k\)</span>-wise independent family: <span
class="math display">\[
    \mathcal{H_{k - 1}} = \{ p(x) = c_{k - 1} x^{k - 1} + c_{k - 2} x^{k
- 2} + ... + c_1 x_1 + c_0 \mid c_{k - 1}, ..., c_0 \in \mathbb{F}_p \}.
\]</span></p>
<p>Note that <span class="math inline">\(|\mathcal{H}| = p^{k}\)</span>.
For <span class="math inline">\(0 \le x_1 &lt; x_2 &lt; ... &lt; x_k
&lt; u\)</span>, and <span class="math inline">\(y_1, y_2, ..., y_k \in
\mathbb{F}_p\)</span>, there is a unique polynomial that goes through
the points <span class="math inline">\((x_1, y_1), (x_2, y_2), ...,
(x_k, y_k)\)</span>.</p>
<h2 id="key-sharing">Key-Sharing</h2>
<p>Suppose that we have <span
class="math inline">\(n\)</span>-candidates who knows some information
about the key and we require that only when no less than <span
class="math inline">\(k\)</span> of them aggragate their information can
they figure the actual key. No group of less than <span
class="math inline">\(k\)</span> candidates can achieve this. The way we
do it is as follows:</p>
<ol type="1">
<li>Select a large prime number <span
class="math inline">\(p\)</span>.<br />
</li>
<li>Select <span class="math inline">\(k+1\)</span> random numbers <span
class="math inline">\(y_0, y_1, ..., y_k\)</span> from <span
class="math inline">\([p-1]\)</span>.<br />
</li>
<li>Generate the unique polynomial <span
class="math inline">\(p(x)\)</span> with degree <span
class="math inline">\(k\)</span> that goes through <span
class="math inline">\((0, y_0), (1, y_1), ..., (k, y_k)\)</span>.<br />
</li>
<li>Inform the value of <span class="math inline">\(p(1)\)</span> to the
first person, <span class="math inline">\(p(2)\)</span> to the second
one, ... and <span class="math inline">\(p(n)\)</span> to the <span
class="math inline">\(n\)</span>-th person.</li>
</ol>
<p>If <span class="math inline">\(k - 1\)</span> people pool their keys
together, then there are <span class="math inline">\(p\)</span> possible
polynomials that goes through all their keys, each has different value
at point 0. The probability of guessing the correct key is given by
<span class="math inline">\(\frac{1}{p}\)</span>.</p>
<h1 id="reference">Reference</h1>
<p>[1]. CS 70. Discrete Mathematics and Probability Theory.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="Previous page" aria-label="Previous page" href="/page/44/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/44/">44</a><span class="page-number current">45</span><a class="page-number" href="/page/46/">46</a><span class="space">&hellip;</span><a class="page-number" href="/page/67/">67</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/46/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">WOW</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
