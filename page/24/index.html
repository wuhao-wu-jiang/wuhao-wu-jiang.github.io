<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="WOW">
<meta property="og:url" content="http://example.com/page/24/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/24/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>WOW</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">WOW</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">你生之前悠悠千載已逝<br>未來還會有千年沉寂的期待</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/05/17/Jaccard-Similarity/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/05/17/Jaccard-Similarity/" class="post-title-link" itemprop="url">Jaccard Similarity</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-05-17 21:41:06" itemprop="dateCreated datePublished" datetime="2019-05-17T21:41:06+10:00">2019-05-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-05-19 00:54:26" itemprop="dateModified" datetime="2019-05-19T00:54:26+10:00">2019-05-19</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>The Jaccard similarity measures the fraction of shared elements between set. In particular, given set <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, the Jaccard similarity between them is defined as<br />
<span class="math display">\[
J(A, B) = \frac{|A \cap B|}{|A \cup B|}
\]</span> The naive calculation of <span class="math inline">\(J(A, B)\)</span> has time complexity <span class="math inline">\(O(|A \cup B|)\)</span> by scanning all elements in the two sets once. Here we discuss how randomization might save time.</p>
<h2 id="lemma-one">Lemma One</h2>
<p>If we select an item <span class="math inline">\(x\)</span> uniformly at random from <span class="math inline">\(|A \cup B|\)</span>, then <span class="math inline">\(\Pr[x \in A \cap B] = \frac{|A \cap B|}{|A \cup B|}\)</span>.</p>
<p>Define the random variable<br />
<span class="math display">\[
X = \begin{cases}
1, \ if \ x \in \ A \cap B \\
0, \ otherwise
\end{cases}
\]</span></p>
<p>Then we see that <span class="math inline">\(X\)</span> is an unbiased estimator of <span class="math inline">\(J(A, B)\)</span>, i.e., <span class="math inline">\(E[X] = J(A, B)\)</span>.</p>
<p>Suppose that we have a sequence of i.i.d. copies of <span class="math inline">\(X\)</span>, denoted <span class="math inline">\(X_1, X_2, ..., X_k\)</span>, then the average <span class="math inline">\(\mu = \frac{1}{k} \sum_{i = 1}^k X_i\)</span> is also an unbiased estimator of <span class="math inline">\(J(A, B)\)</span>. Moreover, by law of large number, <span class="math inline">\(\mu \rightarrow J(A, B)\)</span> as <span class="math inline">\(k \rightarrow \infty\)</span>. The problem is, how many <span class="math inline">\(X_i\)</span>'s are enough.</p>
<p>The answer depends on a few factors:</p>
<ol type="1">
<li>Whether the value of the required error is relative to <span class="math inline">\(J(A, B)\)</span> or independent to <span class="math inline">\(J(A, B)\)</span>.</li>
<li>What is the tolerance of failure probability.</li>
</ol>
<p>In the following discussion we consider only the case of finding an estimator <span class="math inline">\(\mu\)</span> such that <span class="math inline">\(J(A, B) \in [\mu \pm \epsilon]\)</span> with probability at least <span class="math inline">\(1 - \delta\)</span>, where both <span class="math inline">\(\epsilon\)</span> and <span class="math inline">\(\delta\)</span> are given parameters. Then the convergence behavior with respect to the number of samples <span class="math inline">\(k\)</span> can be captured by Hoeffding inequality:<br />
<span class="math display">\[
\Pr[ |\mu - J(A, B)| \ge \epsilon] \le 2\exp \left( -\frac{2\epsilon^2}{k} \right) = \delta
\]</span></p>
<p>Solving the equation gives<br />
<span class="math display">\[
k = \frac{2}{\epsilon^2}\log \frac{2}{\delta}
\]</span></p>
<p>Or equivalent, when we interpret <span class="math inline">\(\epsilon\)</span> as the width of confidence interval, <span class="math display">\[
\epsilon = \sqrt \frac{\log \frac{2}{\delta} }{k}
\]</span> which has order <span class="math inline">\(O(\sqrt \frac{1}{k})\)</span>.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/04/05/Multiplicative-Weight-Updates/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/04/05/Multiplicative-Weight-Updates/" class="post-title-link" itemprop="url">Multiplicative Weight Updates</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-04-05 18:05:10" itemprop="dateCreated datePublished" datetime="2019-04-05T18:05:10+11:00">2019-04-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-12-14 17:48:44" itemprop="dateModified" datetime="2020-12-14T17:48:44+11:00">2020-12-14</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Consider a problem that might arises from many application scenarios. We have a sequence of <span class="math inline">\(T\)</span> binary variables indexed by time <span class="math inline">\(X_1, X_2, ..., X_T\)</span>, where <span class="math inline">\(X_t \in \{0, 1\}, \forall t \in [T]\)</span>. We try to predict the value of <span class="math inline">\(X_t\)</span>, such that we win <span class="math inline">\(1\)</span> dollar if our guess is correct and <span class="math inline">\(0\)</span> dollar otherwise.</p>
<p>We don't make decision on our own. Instead, we resort a group of <span class="math inline">\(n\)</span> experts. At each time <span class="math inline">\(t\)</span>, each expert <span class="math inline">\(i\)</span> gives a prediction <span class="math inline">\(p_i^t\)</span> of <span class="math inline">\(X_t\)</span>. Based on the experts' prediction, we make prediction our prediction <span class="math inline">\(p_A^t\)</span>. The value of <span class="math inline">\(X_t\)</span> is then revealed and we make a mistake if our prediction is wrong. The goal to minimize the number of mistakes.</p>
<h3 id="how-good-can-we-do">How Good Can We Do</h3>
<p>The first question is how good can we do? Define</p>
<ol type="1">
<li><span class="math inline">\(L_i^t:\)</span> the indicator variable of whether the expert <span class="math inline">\(i\)</span> makes a mistake at round <span class="math inline">\(t\)</span>.</li>
<li><span class="math inline">\(L_i = \sum_{t \in [T] } L_i^t:\)</span> the total number of mistakes expert <span class="math inline">\(i\)</span> makes, when <span class="math inline">\(T\)</span> is fixed.</li>
<li><span class="math inline">\(L_A:\)</span> the one made by our algorithm.</li>
</ol>
<p>Ideally, we would like achieve as few mistakes as<br />
<span class="math display">\[
    \sum_{t \in [T] } \min_{i \in [n]} L_i^t. 
\]</span></p>
<p>However, this is impossible. To see this, suppose <span class="math inline">\(X_t\)</span> is a sequence of independent Bernoulli random variable with probability <span class="math inline">\(0.5\)</span> equal to <span class="math inline">\(1\)</span>. No matter what strategy we use, the expected number of mistakes is always <span class="math inline">\(T / 2\)</span>. On the other hand, <span class="math inline">\(\sum_{t \in [T] } \min_{i \in [n]} L_i^t\)</span> could be <span class="math inline">\(0\)</span>.</p>
<p>Despite the negative result, there is hope to achieve as few mistakes as the best expert (up to some constant), that is<br />
<span class="math display">\[
O \left( \min_{i \in [n]} \sum_{t \in [T] } L_i^t \right) = O \left( \min_{i \in [n] } L_i \right). 
\]</span></p>
<h3 id="follow-the-majority">Follow the Majority</h3>
<p>We start with an easy case where there exists an expert who always gives the correct guess. Under this assumption, we can achieve <span class="math display">\[
\min_{i \in [n] } L_i + \log n
\]</span></p>
<p>mistakes. We simply keep track of a set of experts who do not make any mistake so far. Each time we make a decision, we follow the majority of the set.</p>
<blockquote>
<p>Algorithm 1. <strong>Follow the Majority</strong></p>
<ol type="1">
<li>Let <span class="math inline">\(E_0 \leftarrow \{ 1, 2, ..., n \}\)</span> be the set of all experts.<br />
</li>
<li>For <span class="math inline">\(t \leftarrow 1\)</span> to <span class="math inline">\(T\)</span><br />
</li>
<li><span class="math inline">\(\qquad\)</span> Let <span class="math inline">\(S\)</span> be the subset of <span class="math inline">\(E_{t - 1}\)</span> that predicts 0 at time <span class="math inline">\(t\)</span>.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> Let <span class="math inline">\(\bar S\)</span> be the subset of <span class="math inline">\(E_{t - 1}\)</span> that predicts 1 at time <span class="math inline">\(t\)</span>.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> If <span class="math inline">\(|S| &gt; |\bar S|\)</span>, then predict 0 (<span class="math inline">\(p_A^t \leftarrow 0\)</span>);<br />
</li>
<li><span class="math inline">\(\qquad\qquad\qquad\quad\)</span> else predict 1 (<span class="math inline">\(p_A^t \leftarrow 1\)</span>).<br />
</li>
<li><span class="math inline">\(\qquad\)</span> Reveal <span class="math inline">\(X_t\)</span>.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> If <span class="math inline">\(X_t = 0\)</span>, then <span class="math inline">\(E_t \leftarrow S\)</span>;<br />
</li>
<li><span class="math inline">\(\qquad\qquad\qquad\)</span> else <span class="math inline">\(E_t \leftarrow \bar S\)</span>.</li>
</ol>
</blockquote>
<p><em>Theorem. If there is a perfect expert, the algorithm </em>Follow the Majority* makes at most <span class="math inline">\(\log n\)</span> mistakes.*<br />
<em>Proof.</em> Let <span class="math inline">\(M\)</span> be the number of mistakes the algorithm makes. Each time it makes a mistake, the size of <span class="math inline">\(E_{t}\)</span> shrink by half. Hence, <span class="math display">\[
1 \le |E_T| \le |E_1| \frac{1}{2^M}  = \frac{n}{2^M}. 
\]</span></p>
<p>The first inequality follows from the existence of perfect expert. It concludes that <span class="math display">\[
M \le \log n.  
\]</span> <span class="math inline">\(\square\)</span></p>
<h3 id="follow-the-majority-with-reset">Follow the Majority With Reset</h3>
<p>We continue with the case without a perfect expert. By modifying the <em>Follow the Majority</em> a little, we can achieve <span class="math display">\[
\left( \min_{i \in [n] } L_i  + 1 \right) \cdot \log n
\]</span> mistakes. As before, we maintain a set of experts who do not make any mistake so far and we follow the majority of the set to make decisions.</p>
<blockquote>
<p>Algorithm 2. <strong>Follow the Majority With Reset</strong></p>
<ol type="1">
<li>Let <span class="math inline">\(E_0 \leftarrow \{ 1, 2, ..., n \}\)</span> be the set of all experts.<br />
</li>
<li>For <span class="math inline">\(t \leftarrow 1\)</span> to <span class="math inline">\(T\)</span><br />
</li>
<li><span class="math inline">\(\qquad\)</span> Let <span class="math inline">\(S\)</span> be the subset of <span class="math inline">\(E_{t - 1}\)</span> that predicts 0 at time <span class="math inline">\(t\)</span>.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> Let <span class="math inline">\(\bar S\)</span> be the subset of <span class="math inline">\(E_{t - 1}\)</span> that predicts 1 at time <span class="math inline">\(t\)</span>.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> If <span class="math inline">\(|S| &gt; |\bar S|\)</span>, then predict 0 (<span class="math inline">\(p_A^t \leftarrow 0\)</span>);<br />
</li>
<li><span class="math inline">\(\qquad\qquad\qquad\quad\)</span> else predict 1 (<span class="math inline">\(p_A^t \leftarrow 1\)</span>).<br />
</li>
<li><span class="math inline">\(\qquad\)</span> Reveal <span class="math inline">\(X_t\)</span>.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> If <span class="math inline">\(X_t = 0\)</span>, then <span class="math inline">\(E_t \leftarrow S\)</span>;<br />
</li>
<li><span class="math inline">\(\qquad\qquad\qquad\)</span> else <span class="math inline">\(E_t \leftarrow \bar S\)</span>.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> If <span class="math inline">\(E_t = \emptyset\)</span>, then reset <span class="math inline">\(E_t \leftarrow \{1, 2, ..., n\}\)</span>.</li>
</ol>
</blockquote>
<p><em>Theorem. If there isn't a perfect expert, the algorithm </em>Follow the Majority* makes at most <span class="math inline">\(\left( \min_{i \in [n] } L_i + 1 \right) \cdot \log n\)</span> mistakes.*<br />
<em>Proof.</em> Let <span class="math inline">\(M\)</span> be the number of mistakes the algorithm makes. As analysed before, between two consecutive resets of <span class="math inline">\(E_t\)</span>, the algorithm makes at most <span class="math inline">\(\log n\)</span> mistakes while the best expert makes at least one mistake. Therefore, <span class="math display">\[
\frac{M}{ \log n } \le \min_{i \in [n] } L_i + 1\implies M \le \left( \min_{i \in [n]}  L_i  + 1\right) \cdot \log n
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h3 id="follow-the-weighted-majority">Follow the Weighted Majority</h3>
<p>One drawback of the previous approach is that, the algorithm forgets the relative performance of the experts each time it resets <span class="math inline">\(E_t\)</span>. To fix this, we assign each expert <span class="math inline">\(i\)</span> a weight <span class="math inline">\(w_i^t\)</span> and we follow the weighted majority at time <span class="math inline">\(t\)</span>. This reduces the number of mistakes to <span class="math display">\[
    2.41 \cdot ( \min_{i \in [n]} L_i + \log n).
\]</span></p>
<blockquote>
<p>Algorithm 3. <strong>Follow the Weighted Majority</strong></p>
<ol type="1">
<li>Set <span class="math inline">\(w_i \leftarrow 1, \forall i \in [n].\)</span><br />
</li>
<li>For <span class="math inline">\(t \leftarrow 1\)</span> to <span class="math inline">\(T\)</span><br />
</li>
<li><span class="math inline">\(\qquad\)</span> Let <span class="math inline">\(S\)</span> be the set of experts who predict 0.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> Let <span class="math inline">\(\bar S\)</span> be the set of experts who predict 1.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> If <span class="math inline">\(\sum_{i \in S} w_i &gt; \sum_{i \in \bar S} w_i\)</span>, then predict 0 (<span class="math inline">\(p_A^t \leftarrow 0\)</span>);<br />
</li>
<li><span class="math inline">\(\qquad\qquad\qquad\qquad\qquad\qquad\)</span> else predict 1 (<span class="math inline">\(p_A^t \leftarrow 1\)</span>).<br />
</li>
<li><span class="math inline">\(\qquad\)</span> Reveal <span class="math inline">\(X_t\)</span>.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> For each expert <span class="math inline">\(i\)</span> who predicts wrong</li>
<li><span class="math inline">\(\qquad\qquad\)</span> <span class="math inline">\(w_i \leftarrow w_i / 2\)</span></li>
</ol>
</blockquote>
<p><strong><em>Analysis.</em></strong> Let <span class="math inline">\(w_i^t\)</span> be the weight of player <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span> and define <span class="math inline">\(W^t = \sum_{i = 1}^n w_i^t\)</span>. Each time we make a mistake, the experts who make wrong the prediction have sum of weight <span class="math inline">\(\ge \frac{1}{2} W^t\)</span>. Since their weights halve, we have <span class="math display">\[
W^{t + 1} \le W^t ( 1 - \frac{1}{2}\frac{1}{2}) = \frac{3}{4} W^t.
\]</span></p>
<p>Let <span class="math inline">\(M\)</span> be the number of mistakes the algorithm makes. It follows that <span class="math inline">\(\forall i \in [n]\)</span>, <span class="math display">\[
 \left( \frac{1}{2} \right)^{L_i} = w_i^T \le W^T \le \left( \frac{3}{4} \right)^M W_0 = \left( \frac{3}{4} \right)^M n,  
\]</span></p>
<p>which implies <span class="math display">\[
M \le  \frac{1}{ \log \frac{4}{3} } ( L_i + \log n) \le 2.41 \cdot (L_i + \log n).
\]</span></p>
<p><em>Remark:</em> it is not necessary to halve an expert's weight when it makes a mistake. We can decrease it by any factor <span class="math inline">\((1 - \epsilon)\)</span> for <span class="math inline">\(\epsilon \in (0, 1)\)</span>. In such case, we get <span class="math display">\[
\begin{aligned}
    &amp;\qquad (1- \epsilon)^{L_i} \le \left( 1 - \frac{1 - (1 - \epsilon)}{2} \right)^M n \\
    &amp;\implies L_i \cdot \ln (1 -\epsilon) \le M \ln \left( 1 - \frac{\epsilon}{ 2 } \right) + \ln n \\
    &amp;\implies M \le \frac{ L_i \ln \frac{1}{1 - \epsilon} + \ln n}{ \ln \frac{ 2 }{ 2 - \epsilon } }.
\end{aligned}
\]</span></p>
<p>Let <span class="math inline">\(x = \frac{1}{1 - \epsilon} &gt; 0\)</span>, then <span class="math inline">\(1 - \epsilon = \frac{1}{x}\)</span> and <span class="math inline">\(\frac{2 - \epsilon }{ 2 } = \frac{x + 1}{2x}\)</span>. Define <span class="math display">\[
y = \frac{ L_i \ln x + \ln n}{ \ln 2x - \ln ( x + 1  ) }.
\]</span></p>
<p>Then <span class="math display">\[
\begin{aligned}
    y&#39; \ge 0 
        &amp;\implies  \frac{L_i}{x} (\ln 2x - \ln ( x + 1  ) ) - \left( \frac{1}{x} - \frac{1}{x + 1} \right) (L_i \ln x + \ln n ) \ge 0 \\
        &amp;\implies  L_i(x + 1) (\ln 2x - \ln ( x + 1  ) ) - (L_i \ln x + \ln n ) \ge 0 \\
        &amp;\implies  (x + 1) (\ln 2x - \ln ( x + 1  ) ) - \ln x \ge \frac{\ln n}{L_i}
\end{aligned}
\]</span></p>
<p>It is not easy to compute a closed-form solution for <span class="math inline">\(x\)</span>. But observe that the function <span class="math inline">\((x + 1) (\ln 2x - \ln ( x + 1 ) ) - \ln x\)</span> equals to <span class="math inline">\(0\)</span> for <span class="math inline">\(x = 1\)</span> and is increasing for <span class="math inline">\(x &gt; 1\)</span>. Hence, there exists some <span class="math inline">\(x &gt; 1\)</span>, s.t., the value of the functions equal to <span class="math inline">\(\frac{ \ln n }{ L_i }\)</span>.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/MultiplicativeWeightUpdate/MultiplicativeWeightUpdate.png?raw=true" /></p>
<p><span class="math inline">\(\square\)</span></p>
<h3 id="multiplicative-weight-updates">Multiplicative Weight Updates</h3>
<p>We are in good shape so far. Let's extend the problem to more general settings. In this cases, the experts interact with the environment in round-robin fashion. At each round <span class="math inline">\(t\)</span>,</p>
<ol type="1">
<li>The expert <span class="math inline">\(i\)</span> performs action, termed <span class="math inline">\(a_i^t\)</span>.</li>
<li>The environment returns the loss of performing <span class="math inline">\(a_i^t\)</span>, denoted as <span class="math inline">\(l_i^t \in [0, 1]\)</span>.</li>
</ol>
<p>Although there is no restriction of the experts' actions and their losses, we can come up with some strategy the expected loss of which is almost as good as the best expert: <span class="math display">\[
    \min_{i \in [n] } L_i + 2 \sqrt{ T \ln n }, 
\]</span></p>
<p>where <span class="math inline">\(L_i \doteq \sum_{t \in [T] } l_i^t\)</span> is the loss of expert <span class="math inline">\(i\)</span>. This implies that the average expected loss converges at a rate of <span class="math inline">\(\sqrt \frac{1}{T}\)</span> to the best one.</p>
<blockquote>
<p>Algorithm 4. <strong>Multiplicative Weight Update</strong></p>
<ol type="1">
<li>Set <span class="math inline">\(w_i \leftarrow 1, \forall i \in [n].\)</span><br />
</li>
<li>For <span class="math inline">\(t \leftarrow 1\)</span> to <span class="math inline">\(T\)</span><br />
</li>
<li><span class="math inline">\(\qquad\)</span> Let <span class="math inline">\(W = \sum_{i \in [n] } w_i\)</span>.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> Follow action <span class="math inline">\(a_i^t\)</span> with probability <span class="math inline">\(w_i / W\)</span>.</li>
<li><span class="math inline">\(\qquad\)</span> For each expert <span class="math inline">\(i\)</span>:</li>
<li><span class="math inline">\(\qquad\qquad\)</span> <span class="math inline">\(w_i \leftarrow w_i \cdot (1 - \epsilon l_i^t)\)</span></li>
</ol>
</blockquote>
<p><strong><em>Analysis.</em></strong> Let <span class="math inline">\(l_A^t\)</span> be the loss of the algorithm at round <span class="math inline">\(t\)</span> and <span class="math inline">\(L_A \doteq \sum_{t \in [T] } l_A^t\)</span>. Let <span class="math inline">\(w_i^t\)</span> be the weight of expert <span class="math inline">\(i\)</span> and <span class="math inline">\(W^t\)</span> be the sum of weights at round <span class="math inline">\(t\)</span>. Then <span class="math display">\[
\mathbb{E} [ l_A^t ] = \sum_{i \in [n] } \frac{ \epsilon w_i^t l_i^t }{ W^t }. 
\]</span></p>
<p>By the update rule of the <span class="math inline">\(w_i\)</span>'s, we see <span class="math display">\[
W^{t + 1} = \sum_{i \in [n] } w_i^t (1 - \epsilon l_i^t) = W^t ( 1 - \epsilon \mathbb{E} [ l_A^t ] ) \le W^t \exp( - \epsilon \mathbb{E} [ l_A^t ] ). 
\]</span></p>
<p>By induction, we can write <span class="math display">\[
W^T \le W^1 \exp( - \sum_{t \in [T] } \epsilon \mathbb{E} [ l_A^t ] ) = n \cdot \exp( - \epsilon \mathbb{E} [ L_A ] ).
\]</span></p>
<p>To upper bound <span class="math inline">\(\mathbb{E} [ L_A ]\)</span>, we try to lower bound the value of <span class="math inline">\(n \cdot \exp( - \epsilon \mathbb{E} [ L_A ] )\)</span>. We uses that <span class="math inline">\(\forall i \in [n]\)</span>, <span class="math display">\[
    \prod_{t \in [T] } (1 - \epsilon l_i^t) = w_i^T \le W^T. 
\]</span></p>
<p>Using the fact that <span class="math inline">\(\ln(1 - \epsilon ) \ge \epsilon - \epsilon^2\)</span> for <span class="math inline">\(0 &lt; \epsilon &lt; 0.5\)</span>, we know that <span class="math inline">\(\forall i \in [n]\)</span>,</p>
<p><span class="math display">\[
\exp \left( - \sum_{i \in [T] } \epsilon l_i^t  - \sum_{i \in [T] } (\epsilon l_i^t)^2 \right) \le n \cdot \exp ( - \epsilon \mathbb{E} [ l_A^t ] ). 
\]</span></p>
<p>Taking the log, we get <span class="math display">\[
\mathbb{E} [ l_A^t ] \le \frac{1}{\epsilon } \ln n  + L_i + \epsilon \sum_{i \in [T] } (l_i^t)^2. 
\]</span></p>
<p>There are various ways to upper bound <span class="math inline">\(\sum_{i \in [T] } (l_i^t)^2\)</span>. Naively, this is at most <span class="math inline">\(T\)</span>. Hence, <span class="math display">\[
\mathbb{E} [ l_A^t ] \le \frac{1}{\epsilon } \ln n  + L_i + \epsilon T.  
\]</span></p>
<p>Setting <span class="math inline">\(\epsilon = \sqrt{ \frac{ \ln n}{T} }\)</span>, we get <span class="math display">\[
\mathbb{E} [ l_A^t ] \le L_i + 2 \sqrt{ T \ln n}.
\]</span></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<h4 id="last-updated-date-dec-14th-2020.">Last Updated Date: <strong>Dec 14th, 2020</strong>.</h4>
<h3 id="reference">Reference</h3>
<p>[1] Aaron Roth, “The Polynomial Weights Algorithm”, NETS 412: Algorithmic Game Theory,</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/03/24/Monotone-Class/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/24/Monotone-Class/" class="post-title-link" itemprop="url">Monotone Class</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-24 16:06:49" itemprop="dateCreated datePublished" datetime="2019-03-24T16:06:49+11:00">2019-03-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-04-02 02:14:05" itemprop="dateModified" datetime="2019-04-02T02:14:05+11:00">2019-04-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="theorem">Theorem</h1>
<p>If <span class="math inline">\(M\)</span> is a monotone class and <span class="math inline">\(R \subset M\)</span> is a ring, then <span class="math inline">\(M\)</span> contains the <span class="math inline">\(\sigma\)</span>-ring <span class="math inline">\(\sigma(R)\)</span> generated by <span class="math inline">\(R\)</span> and use the following lemma.</p>
<p><strong>Proof:</strong></p>
<p>Consider the monotone class <span class="math inline">\(M_0\)</span> generated by <span class="math inline">\(R\)</span>. By definition <span class="math inline">\(M_0 \subset M\)</span>. The goal is show that <span class="math inline">\(M_0\)</span> is a ring that contains <span class="math inline">\(R\)</span>.</p>
<h2 id="lemma">Lemma</h2>
<p>If <span class="math inline">\(M_0\)</span> is a ring, then it must be a <span class="math inline">\(\sigma\)</span>-ring.</p>
<p><em>Pf:</em> For each countable collection of sets <span class="math inline">\(( E_n )\)</span>, <span class="math inline">\(\cup_{n} E_n = \cup_{n} (\cup_{k = 1}^n E_k)\)</span>. Denote <span class="math inline">\(F_n = \cup_{k = 1}^n E_n\)</span>, and <span class="math inline">\(F = \cup_{n} E_n\)</span>. Clearly <span class="math inline">\(F_n \uparrow F\)</span>, which implies that <span class="math inline">\(F \subset M_0\)</span>.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<p>It immediately follows that <span class="math inline">\(M_0 \supset \sigma(R)\)</span>. Indeed, as <span class="math inline">\(\sigma(R)\)</span> itself is a monotone class and <span class="math inline">\(M_0\)</span> is the smallest monotone class that contains <span class="math inline">\(R\)</span>, we have <span class="math inline">\(\sigma(R) \supset M_0\)</span>. It concludes that <span class="math inline">\(M_0 = \sigma(R)\)</span>.</p>
<p>To show <span class="math inline">\(M_0\)</span> is a ring, we need to verify that <span class="math inline">\(E, F \in M_0\)</span>, <span class="math inline">\(E \cup F = M_0\)</span> and <span class="math inline">\(E \setminus F \in M_0\)</span>.</p>
<p>Define <span class="math inline">\(S_E = \{ F \in M_0 : E \cup F \in M_0, E \setminus F \in M_0 \}\)</span>, the collection of sets that satisfies the conditions. Note that <span class="math inline">\(S_E\)</span> is a monotone class.</p>
<ol type="1">
<li><p><span class="math inline">\((F_n) \subset S_E\)</span>, and <span class="math inline">\((F_n) \uparrow F\)</span>, then <span class="math inline">\(E \cup F = E \cup [\cup_n F_n] = \cup_n [E \cup F_n]\)</span>. By definition of <span class="math inline">\(S_E\)</span>, <span class="math inline">\(E \cup F_n \in M_0\)</span>. As <span class="math inline">\(F_n \uparrow\)</span> and <span class="math inline">\(M_0\)</span> is monotone, <span class="math inline">\(E \cup F \in M_0\)</span>. Hence <span class="math inline">\(F \in M_0\)</span>.</p></li>
<li><p><span class="math inline">\((F_n) \subset S_E\)</span>, and <span class="math inline">\((F_n) \uparrow F\)</span>, then <span class="math inline">\(E \setminus F = E \setminus [\cup_n F_n] = \cap_n [E \cap F_n] \in M_0\)</span>.</p></li>
</ol>
<p>We claim that for each <span class="math inline">\(E \in M_0\)</span>, it holds that <span class="math inline">\(F \in S_E\)</span> for any <span class="math inline">\(F \in M_0\)</span>, i.e., <span class="math inline">\(M_0 \subset S_E\)</span>. But this is equivalent to show <span class="math inline">\(E \in S_F\)</span>. Since <span class="math inline">\(M_0\)</span> is the smallest monotone class that contains <span class="math inline">\(R\)</span>, it suffices to prove <span class="math inline">\(R \subset S_F\)</span>. We need to utilize the following observation.</p>
<p><em>Let <span class="math inline">\(O \subset R\)</span>, then <span class="math inline">\(S_O \supset R\)</span>, which implies that <span class="math inline">\(S_O \supset M_0\)</span>, as <span class="math inline">\(S_O\)</span> is a monotone class.</em></p>
<p>Therefore, <span class="math inline">\(\forall F \in M_0\)</span>, <span class="math inline">\(R \subset S_F\)</span>.</p>
<p><span class="math inline">\(\blacksquare\)</span>.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/23/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/23/">23</a><span class="page-number current">24</span><a class="page-number" href="/page/25/">25</a><span class="space">&hellip;</span><a class="page-number" href="/page/42/">42</a><a class="extend next" rel="next" href="/page/25/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">125</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WOW</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
