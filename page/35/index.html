<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="WOW">
<meta property="og:url" content="http://example.com/page/35/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/35/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>WOW</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">WOW</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">你生之前悠悠千載已逝<br>未來還會有千年沉寂的期待</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/02/24/Eigenvalues-and-Eigenvectors/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/24/Eigenvalues-and-Eigenvectors/" class="post-title-link" itemprop="url">Eigenvalues, Eigenvectors and SVD</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-24 21:57:00" itemprop="dateCreated datePublished" datetime="2020-02-24T21:57:00+11:00">2020-02-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-03-19 11:27:33" itemprop="dateModified" datetime="2022-03-19T11:27:33+11:00">2022-03-19</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="eigenvector-and-eigenvalues">Eigenvector and Eigenvalues</h1>
<blockquote>
<p><strong>Theorem</strong>. Given a symmetric matrix <span class="math inline">\(A \in \mathbb{R}^{n \times n}\)</span> that is positive semi-definitive, there exists an orthogonal matrix <span class="math inline">\(V \in \mathbb{R}^{n \times n}\)</span>, and a diagonal matrix <span class="math inline">\(\Sigma \in \mathbb{R}^{n \times n}\)</span> with all entries non-negative, such that <span class="math display">\[
A = V \Sigma V^T. 
\]</span></p>
</blockquote>
<p>We need the following fact for the proof.</p>
<blockquote>
<p><strong>Fact.</strong> If a function <span class="math inline">\(f: S \rightarrow \mathbb{R}\)</span> is continuous on a closed set <span class="math inline">\(S\)</span>, then it achieves maximum value at some point of <span class="math inline">\(S\)</span>.</p>
</blockquote>
<p><strong>Proof.</strong> Consider the maximization problem: <span class="math display">\[
    \begin{aligned}
    &amp;\max &amp; \frac{1}{2} x^T A x \\
    &amp;s.t. &amp;  x^T x = 1
    \end{aligned}
\]</span></p>
<blockquote>
<p><em><strong>Question to ponder:</strong> Explain the geometric meaning of the term <span class="math inline">\(x^T A x\)</span>.</em></p>
</blockquote>
<p>The corresponding Lagrange function is given by <span class="math display">\[
    L(x, \lambda) = \frac{1}{2} x^T A x - \lambda (x^T x  - 1)
\]</span></p>
<p>Taking derivative with respect to <span class="math inline">\(x\)</span> gives <span class="math display">\[
    \frac{\partial L}{\partial x} = Ax - \lambda x. 
\]</span></p>
<p><strong><em>Existence of maximum solution:</em></strong> Note that <span class="math inline">\(\{ x : x^T x = 1 \}\)</span> is defined the boundary of the unit cycle, which is a closed set. Combined with the fact that <span class="math inline">\(f \doteq (1 / 2) \cdot x^T A x\)</span> is a continuous function (with respect to <span class="math inline">\(x\)</span>), it takes its maximum value at some point in <span class="math inline">\(\{ x : x^T x = 1 \}\)</span>. Denote this point <span class="math inline">\(v_1 \in \{ x : x^T x = 1 \}\)</span>.</p>
<p><strong><em>Gradient at the maximum point:</em></strong> At this point, it holds that <span class="math display">\[
    \frac{\partial L}{\partial x} \mid_{x = v_1} = Av_1 - \lambda v_1 = 0, 
\]</span></p>
<p>which implies that <span class="math inline">\(v_1\)</span> is an eigenvector of <span class="math inline">\(A\)</span>. Denote its corresponding eigenvalue <span class="math inline">\(\lambda_1\)</span>.</p>
<blockquote>
<p><em><strong>Question to ponder:</strong> Prove that <span class="math inline">\(\lambda_1\)</span> is the largest eigenvalue.</em></p>
</blockquote>
<p>After finding <span class="math inline">\(v_1\)</span>, consider a new optimization problem: <span class="math display">\[
    \begin{aligned}
    &amp;\max   &amp; \frac{1}{2} x^T A x \\
    &amp;s.t.   &amp;  x^T x = 1 \\
    &amp;       &amp;  v_1^T x = 0
    \end{aligned}
\]</span></p>
<p>That is, we want to find a new unit vector that is orthogonal to <span class="math inline">\(v_1\)</span> while maximizing <span class="math inline">\(\frac{1}{2} x^T A x\)</span>.</p>
<p><strong><em>Existence of maximum solution.</em></strong> By the lemma and the facts: 1. <span class="math inline">\(\{x : x^T x = 1\} \cap \{ x : v_1^T x = 0 \}\)</span> is closed.<br />
2. <span class="math inline">\(\frac{1}{2} x^T A x\)</span> is continuous.</p>
<p>Denote this maximum point <span class="math inline">\(v_2\)</span>. Now consider the new Lagrange function for the optimization <span class="math display">\[
    L(x, \lambda) = \frac{1}{2} x^T A x - \lambda (x^T x  - 1) - \beta(v_1^T x - 0).
\]</span></p>
<p><strong><em>Gradient at the maximum point:</em></strong> At this point, it holds that <span class="math display">\[
    \frac{\partial L}{\partial x} \mid_{x = v_2} = Av_2 - \lambda v_2 - \beta v_1 = 0.
\]</span></p>
<p>Left multiplying <span class="math inline">\(v_1^T\)</span> gives <span class="math display">\[
    (v_1^T A)v_2 - \lambda v_1^T v_2 - \beta v_1^T v_1 = (A v_1)^T v_2  - \beta = \lambda_1 v_1^T v_2 - \beta = -\beta = 0,
\]</span> where <span class="math inline">\(v_1^T A = (A v_1)^T\)</span> follows from the symmetry of <span class="math inline">\(A\)</span>, i.e., <span class="math inline">\(A = A^T\)</span>.</p>
<p>Therefore, <span class="math display">\[
    Av_2 - \lambda v_2 = 0.
\]</span></p>
<p>It follows that <span class="math inline">\(v_2\)</span> is an eigenvector of <span class="math inline">\(A\)</span>. Denote its associated eigenvalue <span class="math inline">\(\lambda_2\)</span>.</p>
<p>In a similar manner, we can define <span class="math display">\[
    \begin{aligned}
    &amp;\max   &amp; \frac{1}{2} x^T A x \\
    &amp;s.t.   &amp;  x^T x = 1 \\
    &amp;       &amp;  v_1^T x = 0 \\
    &amp;       &amp;  v_2^T x = 0 \\
    \end{aligned}
\]</span></p>
<p>There exists an optimal point <span class="math inline">\(v_3\)</span>. The derivative of Lagrange function at this point is <span class="math display">\[
    \frac{\partial L}{\partial x} \mid_{x = v_3} = Av_3 - \lambda v_3 - \beta_1 v_1 - \beta_2 v_2 = 0,
\]</span> for some parameters <span class="math inline">\(\lambda, \beta_1, \beta_2\)</span>. Left multiplying <span class="math inline">\(v_1^T\)</span> or <span class="math inline">\(v_2^T\)</span> gives <span class="math inline">\(\beta_1 = 0\)</span> and <span class="math inline">\(\beta_2 = 0\)</span> so that <span class="math inline">\(v_3\)</span> is an eigenvector of <span class="math inline">\(A\)</span>.</p>
<p>Following the procedure, we can find <span class="math inline">\(n\)</span> eigenvectors <span class="math inline">\(v_1, v_2, \ldots, v_n\)</span> of <span class="math inline">\(A\)</span>. Define <span class="math display">\[
    \Sigma =
        \begin{bmatrix}
            \lambda_1   &amp;           &amp;   \\
                        &amp;\lambda_2  &amp;   \\
                        &amp;           &amp;   \ldots \\
                        &amp;           &amp;      &amp; \lambda_n 
        \end{bmatrix}, 
    \qquad
    V =
        \begin{bmatrix}
            v_1, v_2, \ldots, v_n
        \end{bmatrix}.
\]</span></p>
<p>Then <span class="math display">\[
    A V = V \Sigma.
\]</span></p>
<p>Hence, <span class="math display">\[
    A = V \Sigma V^{-1} = V \Sigma V^T.
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h1 id="singular-vector-decomposition">Singular Vector Decomposition</h1>
<p>In general, a matrix <span class="math inline">\(A \in \mathbb{R}^{m \times n}\)</span> is considered a linear mapping from <span class="math inline">\(\mathbb{R}^n\)</span> to <span class="math inline">\(\mathbb{R}^m\)</span>. It takes a vector <span class="math inline">\(x \in \mathbb{R}^n\)</span> to a new one <span class="math inline">\(Ax \in \mathbb{R}^m\)</span>. We are interested in the following question.</p>
<blockquote>
<p>Is there a vector <span class="math inline">\(x\)</span>, whose length ratio, <span class="math display">\[
\max_{x \in \mathbb{R}^n } \frac{ \Vert Ax  \Vert }{ \Vert x \Vert }, 
\]</span> is maximized by the mapping?</p>
</blockquote>
<p>As <span class="math inline">\(\Vert x \Vert\)</span> is a number, <span class="math display">\[
    \frac{ \Vert Ax \Vert  }{ \Vert x \Vert } = \left\Vert A \frac{x}{\Vert x \Vert} \right\Vert .
\]</span></p>
<p>Hence, it suffices to consider unit vectors, and the following optimization problem: <span class="math display">\[
    \begin{aligned}
        &amp;\max &amp; \frac{1}{2} x^T A^T Ax \\
        &amp;s.t. &amp;  x^T x = 1
    \end{aligned}.
\]</span></p>
<p>In this case, the objective function is <span class="math inline">\(0.5 \cdot \Vert Ax \Vert^2 = 0.5 \cdot (Ax)^T (Ax) = 0.5 \cdot x^T A^T A x\)</span>.</p>
<p>Following similar process of previous section, we can find a set of eigenvectors <span class="math inline">\(v_1, v_2, \ldots, v_n\)</span> of <span class="math inline">\(A^T A\)</span>. Define <span class="math inline">\(U \in \mathbb{R}^{m \times n}\)</span> <span class="math display">\[
    U 
        = A V { \sqrt{\Sigma^{-1} } } 
        = AV 
        \begin{bmatrix}
        \sqrt { 1 / \lambda_1}  &amp;                       &amp; \\
                                &amp;\sqrt { 1 / \lambda_2} &amp; \\
                                &amp;                       &amp; \ldots \\
                                &amp;                       &amp; &amp;\sqrt {1/\lambda_n}
        \end{bmatrix}.
\]</span></p>
<p>Then <span class="math inline">\(U { \sqrt \Sigma } V^T = A\)</span>, which is called the <em>singular vector decomposition</em> of <span class="math inline">\(A\)</span>.</p>
<p>Finally, we can verify that the columns of <span class="math inline">\(U\)</span> are perpendicular: <span class="math inline">\(\forall i \neq j, i, j \in [n]\)</span>, <span class="math display">\[
    u_i^T u_j 
        = \left(\sqrt{\frac{1}{\lambda_i}} A V_i \right)^T 
            \left( \sqrt{\frac{1}{\lambda_j}} A V_j \right) 
        = \sqrt {\frac{1}{\lambda_i}} \sqrt{\frac{1}{\lambda_j}} v_i^T A^T A v_j  = 0,
\]</span> as <span class="math inline">\(v_i\)</span> and <span class="math inline">\(v_j\)</span> are orthogonal eigenvectors of <span class="math inline">\(A^T A\)</span>.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/02/20/Ellipsoid/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/20/Ellipsoid/" class="post-title-link" itemprop="url">Ellipsoid method</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-20 21:19:42" itemprop="dateCreated datePublished" datetime="2020-02-20T21:19:42+11:00">2020-02-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-02-22 22:39:05" itemprop="dateModified" datetime="2020-02-22T22:39:05+11:00">2020-02-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Ellipsoid method is a weakly polynomial algorithm for solving linear programming. The preliminary version was introduced by the Russian mathematician Shor in 1977 for general convex optimization problems. Then it was applied to linear programming by Khachyan in 1979 [1]. Before interior point method, it was the first polynomial time algorithm for LP.</p>
<h2 id="feasibility-implies-optimality">Feasibility implies Optimality</h2>
<p>Now, consider the primal LP: <span class="math display">\[
\mathcal{P}:  \qquad
\begin{aligned}
  &amp;\max   &amp;c^T x    &amp; \\
  &amp;s.t.   &amp;Ax \le b &amp; \\
  &amp;       &amp; x \ge 0 &amp;
\end{aligned}
\]</span></p>
<p>whose dual is given by <span class="math display">\[
\mathcal{D}:  \qquad
\begin{aligned}
  &amp;\min   &amp;y^Tb    \ \  &amp; \\
  &amp;s.t.   &amp;y^TA \ge c^T &amp; \\
  &amp;       &amp;y \ge 0 \ \  &amp;
\end{aligned}
\]</span></p>
<p>The ellipsoid does not optimize the primal directly. Instead, it try to return a feasible point <span class="math inline">\((x, y)\)</span> that satisfies the following constraints: <span class="math display">\[
\begin{aligned}
         c^T x &amp;= y^Tb  &amp; \\
         Ax    &amp;\le b   &amp; \\
          x    &amp;\ge 0       &amp; \\
         y^TA  &amp;\ge c^T &amp; \\
         y     &amp;\ge 0 \ \  &amp;
\end{aligned}
\]</span></p>
<p>By weak duality, if such point exists, then <span class="math inline">\(x\)</span> is the optimal solution for the primal program. (Note that, if there is no feasible point for the third program, the primal could be either infeasible or unbounded.)</p>
<h2 id="ellipsoid">Ellipsoid</h2>
<p>Ellipsoid is a unit ball that has been squashed or stretched along orthogonal directions. We illustrate this by an example in two dimension. The following picture shows an ellipse obtained by enlarging the unit ball by a facto of <span class="math inline">\(2\)</span> along the <span class="math inline">\(v_1\)</span> direction and squashing it ball by half along the <span class="math inline">\(v_2\)</span> direction, where <span class="math inline">\(v_1\)</span> and <span class="math inline">\(v_2\)</span> constitute an orthogonal base.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/Ellipsoid/EllipsoidMethod1.jpg" /></p>
<p>It is equivalent to first squash or stretch the ball along the directions of <span class="math inline">\(e_1, e_2\)</span>,</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/Ellipsoid/EllipsoidMethod2.jpg" /></p>
<p>then rotate the resulting ellipsoid to corresponding orthogonal directions.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/Ellipsoid/EllipsoidMethod3.jpg" /></p>
<p>The rotation can be done by left multiplying an orthogonal matrix <span class="math display">\[
V = [v_1, v_2]
\]</span></p>
<p>where <span class="math inline">\(v_1, v_2\)</span> are the orthogonal base for which the squash and stretch are performed.</p>
<p>To recover the unit ball, we can first perform the reverse rotation: <span class="math display">\[
x \leftarrow V^T x
\]</span></p>
<p>followed by a reverse scaling: <span class="math display">\[
x \leftarrow  
  \begin{bmatrix}
    1/2  &amp; \\
    &amp;  2
  \end{bmatrix} 
  x
\]</span></p>
<p>Note that the reverse rotation is represented by matrix <span class="math inline">\(V^T\)</span> as <span class="math inline">\(V V^T = I\)</span>. Therefore, the ellipsoid is denoted as <span class="math display">\[
  \left( 
  \begin{bmatrix}
    1/2  &amp; \\
    &amp;  2
  \end{bmatrix} 
  V^T x \right)^T
  \left( 
  \begin{bmatrix}
    1/2  &amp; \\
    &amp;  2
  \end{bmatrix} 
  V^T x \right) \le 1
\]</span></p>
<p>That is <span class="math display">\[
  x^T \left( V
  \begin{bmatrix}
    1/2  &amp; \\
    &amp;  2
  \end{bmatrix}^2 
  V^T \right) x  \le 1
\]</span></p>
<p>In general, an ellipsoid is represented by <span class="math display">\[
E(s, P) = \{ x : (x - s)^T P^{-1} (x - s) \le 1\}
\]</span></p>
<p>where <span class="math inline">\(s \in \mathcal{R}^n\)</span> is the center of the ellipsoid and <span class="math inline">\(P\)</span> is a positive semi-definite matrix.</p>
<p>Recall that a positive semi-definite matrix <span class="math inline">\(P\)</span> can be rewritten as <span class="math display">\[
P = V \Sigma V^T
\]</span> and <span class="math display">\[
P^{-1} = V \Sigma^{-1} V^T
\]</span></p>
<p>where <span class="math inline">\(V\)</span> is an orthogonal matrix and <span class="math inline">\(\Sigma\)</span> is a diagonal matrix. Geometrically, <span class="math inline">\(V\)</span> are the directions and <span class="math inline">\(\sqrt \Sigma\)</span> are the ratios of the squashes or stretches. If we define <span class="math inline">\(B = V \sqrt \Sigma\)</span>, then <span class="math inline">\(B^T = \sqrt \Sigma V^T\)</span>, <span class="math inline">\(B^{-1} = \sqrt \Sigma^{-1} V^T\)</span> and <span class="math inline">\(P = B B^T\)</span>, <span class="math inline">\(P^{-1} = (B^{-1} )^T B^{-1}\)</span>.</p>
<p>The representation can be viewed as merely a recipe for converting the ellipsoid back to the unit ball:</p>
<ol type="1">
<li>First perform a translation <span class="math inline">\(x \leftarrow (x - s)\)</span> so that the center of the ellipsoid is now the center.</li>
<li>Rotate the ellipsoid, such that its axes are aligned with <span class="math inline">\(e_1, e_2, ..., e_n\)</span>. This is done by multiplying the matrix <span class="math inline">\(V^T\)</span>: <span class="math inline">\(x \leftarrow V^T x\)</span>.</li>
<li>Squash or stretch along the axes <span class="math inline">\(e_1, e_2, ..., e_n\)</span>: <span class="math inline">\(x \leftarrow \sqrt \Sigma^{-1} x\)</span>.</li>
<li>Therefore, the linear transformation for the recovery is <span class="math display">\[
x \leftarrow B^{-1} (x - s)
\]</span></li>
</ol>
<p>Conversely, <span class="math inline">\(E(s, P) = E(s, V \sqrt \Sigma \sqrt \Sigma V^T)\)</span> tells us how to get the ellipsoid from the unit ball:</p>
<ol type="1">
<li>Scale unit ball along the axes <span class="math inline">\(e_1, e_2, .., e_n\)</span> by factors that <span class="math inline">\(\sqrt \Sigma_{1, 1}, \sqrt \Sigma_{2, 2}, ..., \sqrt \Sigma_{n, n}\)</span>.</li>
<li>Rotate the ellipsoid by matrix <span class="math inline">\(V\)</span>.</li>
<li>Move the ellipsoid by <span class="math inline">\(s\)</span>.</li>
</ol>
<p>That is, <span class="math inline">\(x \leftarrow V \sqrt \Sigma y + s\)</span> takes the unit ball <span class="math inline">\(\{ y : y^T y \le 1 \}\)</span> to the corresponding ellipsoid <span class="math inline">\(\{ x : (x - s)^T V \Sigma^{-1} V^T (x - s) \le 1 \}\)</span>.</p>
<h2 id="goal">Goal</h2>
<p>Now return to our discussion of ellipsoid method. Without lose of generality, we consider only the following problem:</p>
<p><em>Given <span class="math inline">\(F = \{x : Ax \le b\}\)</span>, output any <span class="math inline">\(x \in F\)</span> or report <span class="math inline">\(F = \emptyset\)</span>, where <span class="math inline">\(A \in \mathcal{R}^{m \times n}, x \in \mathcal{R}^n, b \in \mathcal{R}^m\)</span></em>.</p>
<p>We assume further that</p>
<ol type="1">
<li><p><span class="math inline">\(\exists R \in \mathcal{R}\)</span>, <span class="math inline">\(F \subset B(0, R)\)</span>. Besides, if <span class="math inline">\(F \neq \emptyset\)</span>, <span class="math inline">\(\exists r \in \mathcal{R}\)</span>, and <span class="math inline">\(t \in \mathcal{R}^n\)</span>, s.t., <span class="math inline">\(B(t, r) \subset F\)</span>. Here <span class="math inline">\(B(0, R) = \{ x : ||x||_2 \le R \}\)</span> and <span class="math inline">\(B(t, r) = \{ x : ||x - t||_2 \le r \}\)</span>.</p></li>
<li><p><em>Separation Oracle:</em> Given a vertex <span class="math inline">\(s \in \mathcal{R}^n\)</span>, the separation oracle is a mechanism that asserts</p>
<ul>
<li>either <span class="math inline">\(s \in F\)</span></li>
<li>or <span class="math inline">\(s \notin F\)</span> and returns a direction (which is a unit vector) <span class="math inline">\(d \in \mathcal{R}^n\)</span>, such that <span class="math inline">\(d^T s \ge d^T x\)</span> for <span class="math inline">\(\forall x \in F\)</span>.</li>
</ul></li>
</ol>
<p>The first assumption says that <span class="math inline">\(F\)</span> is neither too "large" nor too "small". Note that <span class="math inline">\(B(t, r) \subset F\)</span> also implies that <span class="math inline">\(F\)</span> has full dimension.</p>
<p>For LP, the separation is straightforward to implement: we just check whether <span class="math inline">\(Ac \ge b\)</span>. If so, then <span class="math inline">\(c \in F\)</span>. Otherwise, <span class="math inline">\(\exists i \in [m]\)</span>, such that the <span class="math inline">\(i\)</span>-th constraint is violated: <span class="math inline">\(A_{i,\cdot} c &gt; b_i\)</span>. Just return <span class="math inline">\(d^T = A_{i, \cdot}\)</span>.</p>
<p><strong><em>Question to ponder: the feasible region of an LP may not satisfy the first assumption? It is possible to reduce it to one satisfying the first assumption?</em></strong></p>
<h2 id="the-algorithm">The Algorithm</h2>
<p>The algorithm begins with a special ellipsoid <span class="math inline">\(E_0 = B(0, R)\)</span>. At each step, it queries the <em>separation oracle</em> and generates a smaller ellipsoid (with reduced volume). If <span class="math inline">\(F\)</span> is not empty, the ellipsoid at each step is guaranteed to contain it. The algorithm stops before the volume of the ellipsoid decreases below <span class="math inline">\(vol(B(t, r))\)</span>.</p>
<p>The algorithmic flow is shown below:</p>
<table style="width:53%;">
<colgroup>
<col style="width: 52%" />
</colgroup>
<tbody>
<tr class="odd">
<td style="text-align: left;">1. <span class="math inline">\(i = 0\)</span>.</td>
</tr>
<tr class="even">
<td style="text-align: left;">2. <span class="math inline">\(E_0 = B(0, R)\)</span>.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3. <em>While</em> <span class="math inline">\(vol(E_i(s_i, P_i)) \ge vol(B(t, r))\)</span>:</td>
</tr>
<tr class="even">
<td style="text-align: left;">4. <span class="math inline">\(\qquad\)</span> <em>if</em> <span class="math inline">\(s_i \in F\)</span>, output <span class="math inline">\(s_i\)</span>.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">5. <span class="math inline">\(\qquad\)</span> <em>else</em>,</td>
</tr>
<tr class="even">
<td style="text-align: left;">6. <span class="math inline">\(\qquad\)</span> <span class="math inline">\(\qquad\)</span> Obtain a direction <span class="math inline">\(d_i\)</span>, s.t., <span class="math inline">\(d_i^T s_i \ge d_i^T x\)</span> for <span class="math inline">\(x \in F\)</span>*.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">7. <span class="math inline">\(\qquad\)</span> <span class="math inline">\(\qquad\)</span> Calculate a ellipsoid <span class="math inline">\(E_{i + 1} \supset E_{i} \cap \{x : d_i^T s_i \ge d_i^T x \}\)</span>.</td>
</tr>
<tr class="even">
<td style="text-align: left;">8. <span class="math inline">\(\qquad\)</span> <span class="math inline">\(\qquad\)</span> <span class="math inline">\(i \leftarrow i + 1\)</span>.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">9. Output <span class="math inline">\(F = \emptyset\)</span>.</td>
</tr>
</tbody>
</table>
<p>For the one dimension case, it is nothing more than a variant of binary search.</p>
<h2 id="bounding-the-number-of-iterations">Bounding the Number of Iterations</h2>
<p>The main result that characterizes the running time is</p>
<p><strong><em>Theorem: It is guaranteed that for <span class="math inline">\(\forall i\)</span></em></strong>, <span class="math display">\[
\frac{vol( E_{i + 1} ) } {vol(E_i) } \le \exp \left( -\frac{1}{2 (n + 1) } \right) 
\]</span> <span class="math inline">\(\square\)</span>.</p>
<p><em>Corollary: the number of iterations of the ellipsoid method is bounded by</em> <span class="math display">\[
2n(n + 1) \ln \frac{R}{r}
\]</span> <span class="math inline">\(\square\)</span>.</p>
<p>To simplify the notation further, we write <span class="math inline">\(E_i = E(s, P)\)</span>, <span class="math inline">\(d_i = d\)</span> and <span class="math inline">\(E_{i + 1} = E(s&#39;, P&#39;)\)</span>. The key lemma for the theorem is:</p>
<p><em>Lemma: Given an ellipsoid <span class="math inline">\(E(s, P) = \{ x \in \mathcal{R}^n : (x - s)^T P^{-1} (x - s) \le 1\}\)</span> and the half space <span class="math inline">\(H(s, d) = \{ x \in \mathcal{R}^n : d^T (x - s)\le 0 \}\)</span>, we can find an ellipsoid <span class="math inline">\(E(s&#39;, P&#39;)\)</span>, such that</em></p>
<ol type="1">
<li><em><span class="math inline">\(E(s&#39;, P&#39;)\)</span> contains the intersection of <span class="math inline">\(E(s, P)\)</span> and <span class="math inline">\(H(s, d)\)</span> : <span class="math inline">\(E(c, P) \cap \{ x \in \mathcal{R}^n : d^T (x - s)\le 0 \}\)</span></em>.<br />
</li>
<li><em>The volume of <span class="math inline">\(E(s&#39;, P&#39;)\)</span> is at most <span class="math inline">\(\exp \left( -\frac{1}{2 (n + 1) } \right)\)</span> times that of <span class="math inline">\(E(s, P)\)</span></em>.</li>
</ol>
<p>In particular, <span class="math inline">\(s&#39;\)</span> and <span class="math inline">\(P&#39;\)</span> is given by <span class="math display">\[
\begin{aligned}
s&#39; &amp;= s - \frac{1}{n + 1} \frac{P d}{\sqrt{d^T P d} } \\
P&#39; &amp;= \frac{n^2}{n^2 - 1} \left( P - \frac{2}{n + 1} \frac{Pd}{\sqrt{d^T P d} } (\frac{Pd}{\sqrt{d^T P d} } )^T \right)
\end{aligned}
\]</span></p>
<p><em>Proof.</em></p>
<p>The transformation <span class="math inline">\(y = B^{-1} (x - s)\)</span> maps <span class="math inline">\(E(s, P)\)</span> to <span class="math inline">\(E(0， I)\)</span>, and <span class="math inline">\(\{x \in R^n: d^T B (B^{-1} (x - s)) \le 0\}\)</span> to <span class="math inline">\(H(0, B^T d) = \{y \in R^n: d^T B y \le 0\}\)</span>. Let <span class="math inline">\(e&#39; = \frac{B^T d}{\sqrt{d^T B B^T d} } = \frac{B^T d}{\sqrt{d^T P d} }\)</span> so that <span class="math inline">\(H(0, B^Td)\)</span> is equivalent to <span class="math inline">\(H(0, e&#39;)\)</span>.</p>
<p>It suffices to find an ellipsoid that contains <span class="math inline">\(E(0, I) \cap H(0, e&#39;)\)</span>. Then applying the reverse transformation <span class="math inline">\(x = By + s\)</span> will give us an ellipsoid that contains <span class="math inline">\(E(s, P) \cap H(s, d)\)</span>.</p>
<p>We can further reduce the problem to finding an ellipsoid that covers <span class="math inline">\(E(0, I) \cap H(0, e_1)\)</span> as we can recover the ellipsoid by rotating <span class="math inline">\(e_1\)</span> to <span class="math inline">\(e&#39;\)</span>.</p>
<p><strong><em>Claim.</em></strong> The ellipsoid that covers <span class="math inline">\(E(0,I) \cap H(0, e_1)\)</span> is given by <span class="math display">\[
E \left( -\frac{1}{n + 1}e_1, \frac{n^2}{n^2 - 1} (I - \frac{2}{n + 1}e_1 e_1^T) \right)
\]</span> and has minimum volume <span class="math inline">\(\exp ( -\frac{1}{2(n + 1)} )\)</span>.</p>
<p>To under the ellipsoid, we check how it transforms the unit ball to an ellipsoid:</p>
<ol type="1">
<li>It squashes the ball along the <span class="math inline">\(e_1\)</span> axis, by a factor of <span class="math inline">\(\sqrt{ \frac{n^2} {n^2 - 1} \frac{n - 1} {n + 1} } = \frac{n}{ n + 1 }\)</span>.</li>
<li>Then it stretches all other directions <span class="math inline">\(e_2, e_3, ..., e_n\)</span> by a factor of <span class="math inline">\(\sqrt \frac{n^2}{n^2 - 1}\)</span>.</li>
<li>Finally, move the center of the ellipsoid to <span class="math inline">\(-\frac{1}{n + 1}e_1\)</span>.</li>
</ol>
<p>Note that the ellipsoid has volume <span class="math inline">\((1 - \frac{1}{n + 1}) (1 + \frac{1}{n^2 -1} )^{(n - 1) / 2} \le e^{- \frac{1}{n + 1} + \frac{1}{n^2 -1} (n - 1) / 2} = e^{- \frac{1}{2(n + 1)} }\)</span>. This is also the ratio of the ellipsoid over that of the unit ball, whose value is 1.</p>
<p>Before we prove the claim, we show how to transform the ellipsoid back to <span class="math inline">\(E(s&#39;, P&#39;)\)</span> that covers <span class="math inline">\(E(s, P) \cap H(s, d)\)</span>. First, by symmetry, the ellipsoid that covers <span class="math inline">\(E(0, I) \cap H(0, e&#39;)\)</span> is given by <span class="math display">\[
 E(-\frac{1}{n + 1}e&#39;, \frac{n^2}{n^2 - 1} (I - \frac{2}{n + 1}e&#39; (e&#39;)^T) )
\]</span></p>
<p>Applying the mapping <span class="math inline">\(B y + s = x\)</span>: <span class="math display">\[
E(-\frac{1}{n + 1} e&#39;, \frac{n^2}{n^2 - 1} (I - \frac{2}{n + 1}e&#39; (e&#39;)^T) ) \rightarrow E(s - \frac{1}{n + 1} B^T e&#39;, \frac{n^2}{n^2 - 1} B (I - \frac{2}{n + 1}e&#39; (e&#39;)^T) B^T )
\]</span></p>
<p><strong>As linear transformation preserves the ratio of volumes, the ratio of the volume of the final ellipsoid over that of <span class="math inline">\(E(s, P)\)</span> is also <span class="math inline">\(\exp(- \frac{1}{2 (n + 1)} )\)</span>.</strong></p>
<p><strong><em>Question to ponder:</em></strong> 1. Show that <span class="math inline">\(\frac{n^2}{n^2 - 1} (I - \frac{2}{n + 1}e_1 e_1^T)\)</span> is positive definite. 2. Show that <span class="math inline">\(\left( \frac{n^2}{n^2 - 1} (I - \frac{2}{n + 1}e_1 e_1^T) \right)^{-1} = \frac{n^2 - 1}{n^2} I + \frac{2n + 2}{n^2} e_1 e_1^T\)</span>. 3. Show that <span class="math inline">\(\frac{n^2}{n^2 - 1} B (I - \frac{2}{n + 1}e&#39; (e&#39;)^T) B^T\)</span> is positive definite.</p>
<p><em>Proof of the claim</em>.</p>
<p>As both <span class="math inline">\(E(0,I)\)</span> and <span class="math inline">\(H(0, e_1)\)</span> are symmetric to <span class="math inline">\(e_1\)</span>, so should the ellipsoid covering the intersection of them. Therefore it should be of the form <span class="math display">\[
a_1 (x_1 - \lambda) + \sum_{i = 2}^n a_i x_i^2 \le 1
\]</span></p>
<p>where <span class="math inline">\(a_i\)</span>'s and <span class="math inline">\(\lambda\)</span> (<span class="math inline">\(0 &lt; \lambda &lt; 1\)</span>) are the parameters to be determined. The goal is to minimize its volume:</p>
<p><span class="math display">\[
\sqrt{\frac{1}{a_1} \prod_{i = 2}^n \frac{1}{a_i} } vol[ E(0, I) ]
\]</span></p>
<p>where <span class="math inline">\(vol[ E(0, I) ] = 1\)</span> is the volume of unit ball in <span class="math inline">\(R^n\)</span>. It is equivalent to maximize <span class="math display">\[
a_1 \prod_{i = 2}^n a_i
\]</span></p>
<p>As the ellipsoid covers <span class="math inline">\(E(0,I) \cap H(0, e_1)\)</span> and should has as small volume as possible, the points <span class="math inline">\(e_i\)</span> (<span class="math inline">\(i = 1, 2, ..., n\)</span>) should be on its boundary. Therefore,</p>
<p><span class="math display">\[
\begin{aligned}
a_1 (1 - \lambda)^2 + \sum_{i = 2}^n a_i 0^2 &amp;= 1 &amp;\rightarrow a_1(1 - \lambda)^2 = 1 &amp;\\
a_1 (0 - \lambda)^2 + a_i 1^2 &amp;= 1  &amp;\rightarrow a_i = 1 - a_1 \lambda^2  &amp;\quad  \forall i = 2, 3, ..., n  \\
\end{aligned}
\]</span></p>
<p>Replacing <span class="math inline">\(a_i\)</span> with <span class="math inline">\(1 - a_1 \lambda^2\)</span> and then <span class="math inline">\(a_1\)</span> with <span class="math inline">\(\frac{1}{(1 - \lambda)^2}\)</span>, the goal becomes</p>
<p><span class="math display">\[
\max \quad \frac{1}{(1 - \lambda)^2} \left[ 1 - \frac{\lambda^2}{(1 - \lambda)^2} \right]^{n - 1} 
\]</span></p>
<p>Substitute <span class="math inline">\(\frac{1}{1 - \lambda}\)</span> by a variable <span class="math inline">\(x &gt; 1\)</span>, and let <span class="math display">\[
f \doteq x^2 [1 - (x - 1)^2]^{n - 1}
\]</span></p>
<p>Its derivative is <span class="math display">\[
f&#39; = 2x [1 - (x - 1)^2]^{n - 1} - 2 (n - 1)(x - 1) x^2 [1 - (x - 1)^2]^{n - 2}
\]</span></p>
<p>Setting the derivative to zero, we obtain</p>
<p><span class="math display">\[
\begin{aligned}
&amp;[1 - (x - 1)^2] - (n - 1)(x - 1)x = 0 \\
&amp;\Rightarrow 1 - x^2 + 2x - 1- (n -1 )x^2 + (n -1 )x = 0 \\
&amp;\Rightarrow - n x^2 + (n + 1) x = 0 \\
&amp;\Rightarrow x = \frac{n + 1}{n}
\end{aligned}
\]</span></p>
<p>It follows that <span class="math inline">\(a_1 = (\frac{n + 1}{n})^2\)</span>, <span class="math inline">\(\lambda = \frac{1}{n + 1}\)</span> and <span class="math inline">\(a_i = \frac{n^2 - 1}{n^2}\)</span> for <span class="math inline">\(\forall i = 2, 3, ..., n\)</span>.</p>
<!-- Therefore, 
$$
c_1 = \left[ 
    \begin{matrix}
\frac{1}{n + 1} \\
 0 \\
  ...\\
0
\end{matrix}
\right] 
= \frac{1}{n + 1} e_1
$$
and 
$$
P_1^{-1} = \left[ 
\begin{matrix}
(\frac{n + 1}{n} )^2 &                       &   ...     \\
                    &   \frac{n^2 - 1}{n^2}  &   ...     \\
                    &                        &   ...     \\
                    &                        &   &\frac{n^2 - 1}{n^2}
\end{matrix}
\right] = \frac{n^2 - 1}{n^2} I + 2\frac{n + 1}{n^2} e_1 e_1^T \\
P_1 = \left[ 
\begin{matrix}
(\frac{n}{n + 1} )^2 &                       &   ...     \\
                    &   \frac{n^2}{n^2 - 1}  &   ...     \\
                    &                        &   ...     \\
                    &                        &   &\frac{n^2}{n^2 - 1}
\end{matrix}
\right] = \frac{n^2}{n^2 - 1} (I - \frac{2}{n + 1}e_1 e_1^T)
$$

The volume ratio between $E(c_1, P_1)$ and $E(0, I)$ is 

$$
\begin{aligned}
\sqrt{\frac{1}{a_1} \prod_{i = 2}^n \frac{1}{a_i} } 
&= \frac{n}{n + 1} \left[ \frac{n^2 }{n^2 - 1} \right]^{(n - 1) / 2} \\
&\le \exp \left( -\frac{1}{n + 1} + \frac{1}{2}\frac{n - 1}{n^2 - 1} \right) \\
&= \exp \left( -\frac{1}{2} \frac{1}{n + 1} \right)
\end{aligned}
$$ -->
<h2 id="reference">Reference</h2>
<ol type="1">
<li>Michel X. Goemans, 7. Lecture notes on the ellipsoid algorithm, 18.433: Combinatorial Optimization, MIT,</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/02/18/Determinant,%20Cross%20Product%20and%20Cramer's-Rule/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/18/Determinant,%20Cross%20Product%20and%20Cramer's-Rule/" class="post-title-link" itemprop="url">Determinant, Cross Product and Cramer's-Rule</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-18 23:36:52" itemprop="dateCreated datePublished" datetime="2020-02-18T23:36:52+11:00">2020-02-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-21 19:01:14" itemprop="dateModified" datetime="2020-04-21T19:01:14+10:00">2020-04-21</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="determinant"><strong><em>Determinant</em></strong></h3>
<p>When studying linear algebra, the determinant function <span class="math inline">\(\det(\cdot)\)</span> is a horrifying subject. We try to give a friendly approach to it in this article.</p>
<p>I think it is the study of the volume of the parallelotope specified by <span class="math inline">\(v_1, v_2, ... ,v_n \in \mathbb{R}^n\)</span> that gives it away. The parallelotope is defined as the set <span class="math display">\[
\left\{ \sum_{i \in [n]} \lambda_i v_i :  \lambda_i \in [0, 1], \forall i \in [n] \right\}
\]</span></p>
<p>Let's denote <span class="math inline">\(f(v_1, v_2, ... ,v_n) : \mathbb{R}^{n \times n} \rightarrow \mathbb{R}\)</span> the singed volume function, i.e., <span class="math inline">\(|f(v_1, v_2, ... ,v_n)|\)</span> gives the volume of the parallelotope. We will show how to determine the sign of <span class="math inline">\(f\)</span> later. At this point, we do not know how <span class="math inline">\(\det(\cdot)\)</span> is related to the volume. Therefore, we use the notation <span class="math inline">\(f\)</span> instead.</p>
<p>We show how to derive the formula of <span class="math inline">\(f\)</span> by its properties. The two key properties associated with volume are</p>
<ol type="1">
<li><p><span class="math inline">\(f\)</span> is multi-linear. Specially, it is a linear function in any dimension when other dimensions are fixed:</p>
<ul>
<li><p><span class="math inline">\(f(v_1, v_2, ..., cv_i, ... ,v_n)=cf(v_1, v_2, ... ,v_n)\)</span> for <span class="math inline">\(\forall i \in [n]\)</span> and <span class="math inline">\(c \in \mathbb{R}\)</span>. Geometrically, if we scale the <span class="math inline">\(i\)</span>-th vector <span class="math inline">\(v_i\)</span> by a factor <span class="math inline">\(c\)</span>, then the volume of the parallelotope should change by the same factor. <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/Determinant/Linearity1.jpg" /> In the above example, when <span class="math inline">\(v_2\)</span> is fixed, the area of the parallelogram is determined by its height, i.e., the projection of <span class="math inline">\(v_1\)</span> to the orthogonal direction of <span class="math inline">\(v_2\)</span>. When <span class="math inline">\(v_1\)</span> doubles, the length of its projection doubles.</p></li>
<li><p><span class="math inline">\(f(v_1, v_2, ..., v_i + u_i, ... ,v_n)= f(v_1, v_2, ..., v_i, ... ,v_n) + f(v_1, v_2, ..., u_i, ... ,v_n)\)</span>. <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/Determinant/Linearity2.jpg" /> In the above example, when <span class="math inline">\(v_2\)</span> is fixed, the projection to the orthogonal direction of <span class="math inline">\(v_2\)</span> are additive. In particular, denote <span class="math inline">\(\mathcal{P}(v_1)\)</span> the length of the projection of <span class="math inline">\(v_1\)</span> to the orthogonal direction of <span class="math inline">\(v_2\)</span>. Similarly we define <span class="math inline">\(\mathcal{P}(v_2)\)</span> and <span class="math inline">\(\mathcal{P}(v_1 + v_2)\)</span>. Then<br />
<span class="math display">\[
\mathcal{P}(v_1 + v_2) = \mathcal{P}(v_1) + \mathcal{P}(v_2)
\]</span></p></li>
<li><p>Note that the projection of two vector can cancel each other in some cases, in the sense that they points to different direction. <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/Determinant/Linearity4.jpg" /> In the above example, if we write <span class="math inline">\(v_1 = v_{1, 1} e_1 + v_{1, 2} e_2\)</span>, then <span class="math inline">\(\mathcal{P} (v_{1, 1} e_1)\)</span> and <span class="math inline">\(\mathcal{P} (v_{1,2} e_2)\)</span> points to opposite directions. This implies that we should give volume a sign. For example, we can define the direction pointed by purple vector points to be positive. The volume of the parallelogram increases if a vector's projection moves along this direction and decrease otherwise.</p></li>
</ul></li>
<li><p>If <span class="math inline">\(v_1, v_2, ..., v_n\)</span> are linearly independent, then the parallelotope is contained in a subspace with dimension smaller than <span class="math inline">\(n\)</span> and should have volume zero. <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/Determinant/NonIndependent.jpg" /> Intuitively, the parallelotope collapses to a lower dimension space. Examples include colinear vectors in two dimension case and the third vector lying in the hyperplane spanned by the other two in the three dimension case.<br />
Finally, we emphases an important case here: <span class="math display">\[
f(..., v_i,..., v_j, ... , ) = 0, \textbf{ if } v_i = v_j, \forall i, j \in [n], i \neq j
\]</span></p></li>
</ol>
<p>If we write <span class="math display">\[
v_i = v_{i, 1} e_1 + v_{i, 2} e_2 + ... + v_{i, n} e_n
\]</span></p>
<p>for all <span class="math inline">\(i \in [n]\)</span>, then by linearity <span class="math display">\[
\begin{aligned}
f(v_1, v_2, ..., v_n) 
    &amp;= f( v_{1, 1} e_1 + v_{1, 2} e_2 + ... + v_{1, n} e_n, \\
    &amp;\qquad v_{2, 1} e_1 + v_{2, 2} e_2 + ... + v_{2, n} e_n, \\
    &amp;\qquad ...\\
    &amp;\qquad v_{n, 1} e_1 + v_{n, 2} e_2 + ... + v_{n, n} e_n) \\
    &amp;= \sum_{k_1, k_2, ..., k_n \in [n]} v_{1, k_1} v_{2, k_2} ... v_{n, k_n} f(e_{k_1}, e_{k_2}, ..., e_{k_n}) 
\end{aligned}
\]</span></p>
<p>Note that if <span class="math inline">\(k_i = k_j\)</span> for <span class="math inline">\(i \neq j\)</span>, then <span class="math inline">\(f(e_{k_1}, e_{k_2}, ..., e_{k_n}) = 0\)</span>. Therefore, <span class="math display">\[
f(v_1, v_2, ..., v_n)  = \sum_{ k  \text{ is a permutation} } v_{1, k_1} v_{2, k_2} ... v_{n, k_n} f(e_{k_1}, e_{k_2}, ..., e_{k_n})
\]</span></p>
<p>We are almost done. It is left to determined the value of <span class="math inline">\(f(e_{k_1}, e_{k_2}, ..., e_{k_n})\)</span>, where <span class="math inline">\(k = (k_1, k_2, ..., k_n)\)</span> is a permutation of <span class="math inline">\((1, 2, ...., n)\)</span>. Here we claim that is purely determined by the value of <span class="math inline">\(f(e_1, e_2, ..., e_n)\)</span>. By conversion, we define <span class="math display">\[
f(e_1, e_2, ..., e_n) = 1
\]</span> Then we have the key lemma:</p>
<p><strong><em>Lemma</em></strong> <span class="math display">\[
f(e_{k_1}, e_{k_2}, ..., e_{k_n}) = -1
\]</span></p>
<p>if <span class="math inline">\({k_1}, {k_2}, ..., {k_n}\)</span> can be recovered to <span class="math inline">\(1, 2, ..., n\)</span> by odd number of neighboring swaps and <span class="math display">\[
f(e_{k_1}, e_{k_2}, ..., e_{k_n}) = 1
\]</span> if <span class="math inline">\({k_1}, {k_2}, ..., {k_n}\)</span> can be recovered to <span class="math inline">\(1, 2, ..., n\)</span> by even number of neighboring swaps.</p>
<p><em>Proof.</em> The key is to prove that we swap two neighboring vectors, then the sign of the volume change: <span class="math display">\[
f(e_{k_1}, e_{k_2}, ..., e_{k_{i } }, e_{k_{i + 1} }, ..., e_{k_n}) = -f(e_{k_1}, e_{k_2}, ..., e_{k_{i + 1 } }, e_{k_{i } }, ..., e_{k_n})
\]</span></p>
<p>This is because <span class="math display">\[
\begin{aligned}
    f(e_{k_1}, e_{k_2}, ..., e_{k_{i } } + e_{k_{i + 1} }, e_{k_{i } } + e_{k_{i + 1} }, ..., e_{k_n})  
        &amp;=
        f(e_{k_1}, e_{k_2}, ..., e_{k_{i } }, e_{k_{i + 1} }, ..., e_{k_n})\\
        &amp;\quad + 
        f(e_{k_1}, e_{k_2}, ..., e_{k_{i + 1 } }, e_{k_{i } }, ..., e_{k_n})
        \\
        &amp;= 0
\end{aligned}
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h3 id="cross-product"><strong><em>Cross Product</em></strong></h3>
<p>If we fix <span class="math inline">\(v_2, v_3, ..., v_n\)</span>, then <span class="math inline">\(\det(x, v_2, ..., v_n): \R^n \rightarrow \R\)</span> is a linear function. Then <span class="math display">\[
\begin{aligned}
    \det(x, v_2, ..., v_n) &amp;= \sum_{i = 1}^n \det(x_i e_i, v_2, ..., v_n) \\
    &amp;= \sum_{i = 1}^n x_i \det(e_i, v_2, ..., v_n)
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(x_i\)</span> is the i-th coordinator of <span class="math inline">\(x\)</span>. If we write <span class="math display">\[
d = \left&lt; det(e_1, v_2, ..., v_n), det(e_2, v_2, ..., v_n), ..., det(e_n, v_2, ..., v_n)\right&gt;
\]</span></p>
<p>Then <span class="math display">\[
\det(x, v_2, ..., v_n) = d \cdot x
\]</span></p>
<p>Indeed, in a similar manner, we can prove that for any <span class="math inline">\(h: \R^{n \times n} \rightarrow \R^n\)</span> linear function, there exists a vector <span class="math inline">\(\vec h\)</span>, such that <span class="math display">\[
h(x) = \vec h \cdot x
\]</span></p>
<p>Conventionally, <span class="math inline">\(d\)</span> is called the cross product of <span class="math inline">\(v_2, ..., v_n\)</span> is written as <span class="math display">\[
d = v_2 \times v_3 \times ... \times v_n
\]</span></p>
<p>It has some interesting properties:</p>
<ol type="1">
<li><p><span class="math inline">\(d\)</span> is perpendicular to the subspace spanned by <span class="math inline">\(v_2, ..., v_n\)</span>, as <span class="math inline">\(d \cdot v_i = \det(v_i, v_2, ..., v_n) = 0\)</span> for <span class="math inline">\(2 \le i \le n\)</span>.</p></li>
<li><p>For any <span class="math inline">\(x \in \R^n\)</span>, <span class="math inline">\(d \cdot x\)</span> gives the signed volume of the parallelotope spanned by <span class="math inline">\(x, v_2, ..., v_n\)</span>.</p>
<ul>
<li>When <span class="math inline">\(n = 2\)</span>, the length of <span class="math inline">\(d\)</span> equals to that of <span class="math inline">\(v_2\)</span>.</li>
<li>When <span class="math inline">\(n = 3\)</span>, the length of <span class="math inline">\(d\)</span> equals to the area of the parallelogram spanned by <span class="math inline">\(v_2, v_3\)</span>. Combined with the fact that <span class="math inline">\(d\)</span> is perpendicular to <span class="math inline">\(v_2, v_3\)</span>, we see why <span class="math inline">\(d \cdot x\)</span> gives the volume of the parallelotope spanned by <span class="math inline">\(x, v_2, v_3\)</span>: it takes the projection of <span class="math inline">\(x\)</span> to the direction that is perpendicular to <span class="math inline">\(v_2\)</span> and <span class="math inline">\(v_3\)</span>, scaled by a factor of the area spanned by <span class="math inline">\(v_2\)</span> and <span class="math inline">\(v_3\)</span>.<br />
</li>
</ul></li>
<li><p>The direction given of <span class="math inline">\(d\)</span> is given by right hand rule, when <span class="math inline">\(n = 2\)</span> or <span class="math inline">\(n = 3\)</span>.</p></li>
</ol>
<p><span class="math inline">\(\square\)</span></p>
<h3 id="cramers-rule"><strong><em>Cramer's Rule</em></strong></h3>
<p>Cramer's rule is a formula for solving linear equations. In particular, given an invertible matrix <span class="math inline">\(A \in \R^{n \times n}\)</span>, and vector <span class="math inline">\(b \in \R^n\)</span>, then the solution for the equation <span class="math display">\[
Ax = b
\]</span></p>
<p>is given by (<span class="math inline">\(\forall i \in [n]\)</span>), <span class="math display">\[
x_i = \frac{\det(A_i) }{\det (A)}
\]</span></p>
<p>where <span class="math inline">\(x_i\)</span> is the i-th coordinate of <span class="math inline">\(x\)</span> and <span class="math inline">\(A_i\)</span> is the matrix formed by replacing <span class="math inline">\(A\)</span>'s the <span class="math inline">\(i\)</span>-th column by column vector <span class="math inline">\(b\)</span>.</p>
<p>To understand the formula, we view <span class="math inline">\(A\)</span> as a mapping <span class="math inline">\(T: \R^n \rightarrow \R^n\)</span> that takes <span class="math inline">\(e_i (i \in [n])\)</span> to <span class="math inline">\(A[:,i]\)</span>, i.e., <span class="math display">\[
T(e_i) = A[:, i]
\]</span></p>
<p>where <span class="math inline">\(A[:, i]\)</span> is the i-th column of <span class="math inline">\(A\)</span>. The image of the hypercube <span class="math display">\[
\left\{ \sum_{i \in [n]} \lambda_i e_i :  \lambda_i \in [0, 1], \forall i \in [n] \right\}
\]</span></p>
<p>is given as <span class="math display">\[
\left\{ \sum_{i \in [n]} \lambda_i A[:, i] :  \lambda_i \in [0, 1], \forall i \in [n] \right\}
\]</span></p>
<p>Original the hypercube has volume 1. After the transformation it has volume <span class="math inline">\(\det(A)\)</span>. One interesting fact about linear transformation is that it preserves volumes ratio. Define <span class="math inline">\(\mathbb{V}(\cdot)\)</span> the volume of a parallelotope.</p>
<p><em>Fact.</em> For any parallelotope <span class="math inline">\(P\)</span>, its volume under transformation <span class="math inline">\(T\)</span> is given by <span class="math display">\[
\det(A) \mathbb{V}(P) = \mathbb{V}(T(P))
\]</span></p>
<p>Now, we rewrite the Cramer's rule as <span class="math display">\[
\det(A) x_i = \det(A_i)
\]</span></p>
<p>Its meaning is clear: there is a parallelotope <span class="math inline">\(P\)</span> whose volume is <span class="math inline">\(x_i\)</span> and after the transformation it has volume <span class="math inline">\(\det(A_i)\)</span>.</p>
<p>It is left to verify that the parallelotope indeed exists. We observe that <span class="math inline">\(\det(A_i)\)</span> can be viewed as the volume of the following parallelotope formed by <span class="math display">\[
\left\{ \sum_{j \in [n], j \neq i} \lambda_j A[:, j] +\lambda_i b_i:  \lambda_j \in [0, 1], \forall j, \lambda_i \in [0, 1] \right\}
\]</span></p>
<p>But this parallel0tope is the image of <span class="math display">\[
\left\{ \sum_{j \in [n], j \neq i} \lambda_j e_j +\lambda_i x_i:  \lambda_j \in [0, 1], \forall j, \lambda_i \in [0, 1] \right\}
\]</span></p>
<p>as <span class="math display">\[
\begin{aligned}
    &amp; T \left( \left\{ \sum_{j \in [n], j \neq i} \lambda_j e_j +\lambda_i x_i:  \lambda_j \in [0, 1], \forall j, \lambda_i \in [0, 1] \right\} \right) \\
    &amp;= \left\{ \sum_{j \in [n], j \neq i} \lambda_j T(e_j) +\lambda_i T(x_i):  \lambda_j \in [0, 1], \forall j, \lambda_i \in [0, 1] \right\} \\
    &amp;= \left\{ \sum_{j \in [n], j \neq i} \lambda_j A[:, j] +\lambda_i b_i:  \lambda_j \in [0, 1], \forall j, \lambda_i \in [0, 1] \right\}
\end{aligned}
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/34/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/34/">34</a><span class="page-number current">35</span><a class="page-number" href="/page/36/">36</a><span class="space">&hellip;</span><a class="page-number" href="/page/61/">61</a><a class="extend next" rel="next" href="/page/36/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">182</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WOW</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
