<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="WOW">
<meta property="og:url" content="http://example.com/page/17/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/17/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>WOW</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">WOW</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">你生之前悠悠千載已逝<br>未來還會有千年沉寂的期待</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/11/25/Releasing-Histogram-Privately/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/11/25/Releasing-Histogram-Privately/" class="post-title-link" itemprop="url">Releasing Histogram Privately</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-11-25 10:19:09 / Modified: 22:11:21" itemprop="dateCreated datePublished" datetime="2020-11-25T10:19:09+11:00">2020-11-25</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Given a set of <span class="math inline">\(n\)</span> elements <span class="math inline">\(S\)</span> that belongs to some finite domain <span class="math inline">\(\mathcal{X}= \{ x_1, x_2, ..., x_m \}\)</span>, we want to release the (normalized) histogram in a differentially private manner. Define <span class="math inline">\(\forall x_i \in \mathcal{X}\)</span>:</p>
<ol type="1">
<li><span class="math inline">\(F_S(x_i) \doteq\)</span> the number of times <span class="math inline">\(x_i\)</span> appears in <span class="math inline">\(S\)</span>;<br />
</li>
<li><span class="math inline">\(f_S(x_i) \doteq \frac{F_S(x_i) }{ |S| } = \frac{F_S(x_i) }{ n }\)</span>, the frequency of <span class="math inline">\(x_i\)</span> in <span class="math inline">\(S\)</span>.</li>
</ol>
<p>The (normalized) histogram of <span class="math inline">\(h_S\)</span> is a frequency vector: <span class="math display">\[
h_S \doteq \left&lt; f_S(x_1), f_S(x_2), ..., f_S(x_m) \right&gt; \in \mathbb{R}^m
\]</span></p>
<p>Consider another set <span class="math inline">\(S&#39;\)</span> obtained by replacing an element <span class="math inline">\(x_k\)</span> in <span class="math inline">\(S\)</span> to another element <span class="math inline">\(x_l\)</span>, such that</p>
<ol type="1">
<li><span class="math inline">\(F_{S&#39;} (x_k) = F_{S} (x_k) - 1\)</span>;</li>
<li><span class="math inline">\(F_{S&#39;} (x_l) = F_{S} (x_l) + 1\)</span>;</li>
<li><span class="math inline">\(F_{S&#39;} (x_i) = F_{S} (x_i), \forall i \notin \{k, l\}\)</span>.</li>
</ol>
<p>Let <span class="math inline">\(h_{S&#39;}\)</span> be the histogram of <span class="math inline">\(S&#39;\)</span>. Our goal is to design some mechanism <span class="math inline">\(M\)</span> that adds noise to the normalized so that the output distribution of <span class="math inline">\(M(h_S)\)</span> and <span class="math inline">\(M(h_{S&#39;})\)</span> are indistinguishable.</p>
<h3 id="naive-laplacian">Naive Laplacian</h3>
<p>One way is to add Laplacian noise directly to each dimension of the histogram. For any vector <span class="math inline">\(v \in \mathbb{R}^m\)</span>, <span class="math inline">\(M\)</span> outputs a new perturbed vector: <span class="math display">\[
M(v) \doteq v + L
\]</span></p>
<p>where <span class="math inline">\(L \doteq \left&lt; l_1, l_2, ..., l_m\right&gt;\)</span> and each <span class="math inline">\(l_i\)</span> is sampled independently from <span class="math inline">\(Lap( \frac{2 }{ n \epsilon } )\)</span>.</p>
<h4 id="privacy">Privacy</h4>
<p>We claim this mechanism is <span class="math inline">\((\epsilon, 0)\)</span>-differentially private. For <span class="math inline">\(u \in \mathbb{R}^n\)</span>, we have <span class="math display">\[
\begin{aligned}
    \frac{ p(M(h_S) = u) }{ p(M(h_{S&#39;}) = u) } 
        &amp;= \frac{ \prod_{i \in [m] } p( f_S (x_i) + l_i = u_i) }{ \prod_{i \in [m] } p( f_{S&#39;} (x_i) + l_i = u_i) } \\
        &amp;= \frac{ \prod_{i \in \{k, l\} } p( f_S (x_i) + l_i = u_i) }{ \prod_{i \in \{k, l\} } p( f_{S&#39;} (x_i) + l_i = u_i) } \\
        &amp;\le \exp( - (|u_k - f_S(x_k)| - |u_k - f_{S&#39;} (x_k) |) \frac{n\epsilon}{2} ) \\
        &amp;\quad \cdot \exp( - (|u_l - f_S(x_l)| - |u_l - f_{S&#39;} (x_l) |) \frac{n\epsilon}{2} ) \\
        &amp;\le \exp( |f_S(x_k) - f_{S&#39;} (x_k) | \frac{n\epsilon}{2} ) \cdot \exp( |f_S(x_l) - f_{S&#39;} (x_l) | \frac{n\epsilon}{2} ) \\
        &amp;= \exp( \frac{1}{n} \frac{ n \epsilon}{2} ) \cdot \exp( \frac{1}{n} \frac{n\epsilon}{2} ) \\
        &amp;= \exp( \epsilon).
\end{aligned}
\]</span></p>
<h4 id="accuracy">Accuracy</h4>
<p>We prove that <span class="math inline">\(|M(h_S) - h_S |_\infty = O (\frac{1}{ n \epsilon } \log \frac{m}{\delta})\)</span> with probability at least <span class="math inline">\(1 - \delta\)</span>.</p>
<p>Let <span class="math inline">\(b = \frac{2 }{ n \epsilon }\)</span>. For a failure probability <span class="math inline">\(\delta\)</span>, <span class="math display">\[
\Pr[ |f_S(x_i) + l_i - f_S(x_i) | \ge b \log \frac{m}{\delta} ] = \int_{ b \log \frac{m}{\delta} }^\infty \frac{1}{b} \exp( - x / b ) \ dx = \exp(- \log \frac{m}{\delta} ) = \frac{\delta}{m}
\]</span></p>
<p>By union bound, it holds that <span class="math display">\[
\Pr[ |M(h_S) - h_S |_\infty \ge b \log \frac{m}{\delta} ] \le \delta. 
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h3 id="rounding-small-values">Rounding Small Values</h3>
<p>When <span class="math inline">\(|\mathcal{X}| = m \gg n\)</span>, we could improve the release mechanism. As shown in the previous section, we would like to achieve error <span class="math inline">\(O(\frac{1}{n})\)</span>. This inspire to round the small frequencies (roughly <span class="math inline">\(O(\frac{1}{n})\)</span>) to zero. Of course, we should carry out this in a differentially private manner.</p>
<blockquote>
<p>Mechanism <span class="math inline">\(M\)</span><br />
<span class="math inline">\(===============================\)</span><br />
INPUT: a set <span class="math inline">\(S\)</span> of <span class="math inline">\(n\)</span> elements.<br />
OUTPUT: a histogram of <span class="math inline">\(S\)</span> in differentially private manner.<br />
<span class="math inline">\(------------------------\)</span><br />
For <span class="math inline">\(i \in [m]\)</span> do<br />
<span class="math inline">\(\qquad\)</span> If <span class="math inline">\(f_S(x_i) = 0\)</span>, then <span class="math inline">\(M(h_S)_i \leftarrow 0\)</span><br />
<span class="math inline">\(\qquad\)</span> Else<br />
<span class="math inline">\(\qquad\)</span> <span class="math inline">\(\qquad\)</span> <span class="math inline">\(M(h_S)_i \leftarrow f_S(x_i) + l_i\)</span>, where <span class="math inline">\(l_i \sim Lap(\frac{2}{n \epsilon} )\)</span>.<br />
<span class="math inline">\(\qquad\)</span> <span class="math inline">\(\qquad\)</span> If <span class="math inline">\(M(h_S)_i &lt; \frac{1}{n} +\frac{2 \log 2 / \delta }{ \epsilon n}\)</span>, then <span class="math inline">\(M(h_S)_i \leftarrow 0\)</span>.<br />
Release <span class="math inline">\(M(h_S) \doteq \left&lt; M(h_S)_1, M(h_S)_2, ... , M(h_S)_n \right&gt;\)</span><br />
<span class="math inline">\(------------------------\)</span></p>
</blockquote>
<h4 id="privacy-1">Privacy</h4>
<p>We claim this mechanism is <span class="math inline">\((\epsilon, \delta)\)</span>-differentially private.</p>
<ul>
<li><p>Case 1. If <span class="math inline">\(S\)</span> and <span class="math inline">\(S&#39;\)</span> have the same set of supports, i.e., <span class="math inline">\(f_S(x_i) &gt; 0 \leftrightarrow f_{S&#39;}(x_i) &gt; 0\)</span>, then <span class="math inline">\(M\)</span> is <span class="math inline">\((\epsilon, 0)\)</span> differentially private.</p></li>
<li><p>Case 2.</p>
<ol type="1">
<li><span class="math inline">\(F_{S} (x_k) = 1\)</span>, then <span class="math inline">\(F_{S&#39;} (x_k) = F_{S} (x_k) - 1 = 0\)</span>. For <span class="math inline">\(S&#39;\)</span>, it is guaranteed that <span class="math inline">\(M(h_{S&#39;})_k = 0\)</span>. For <span class="math inline">\(S\)</span>, as <span class="math inline">\(f_S(x_k) = \frac{1}{n}\)</span>, <span class="math display">\[
     \Pr[ M(h_S)_k \neq 0 ] = \Pr[ M(h_S)_k \neq M(h_{S&#39;})_k ] = \frac{\delta}{2}
 \]</span></li>
<li><span class="math inline">\(F_{S} (x_l) = 0\)</span>, then <span class="math inline">\(F_{S&#39;} (x_l) = F_{S} (x_l) + 1 = 1\)</span>. For <span class="math inline">\(S\)</span>, it is guaranteed that <span class="math inline">\(M(h_S)_k = 0\)</span>. For <span class="math inline">\(S&#39;\)</span>, by similar argument, we have <span class="math inline">\(\Pr[ M(h_{S&#39;})_k \neq 0 ] = \Pr[ M(h_S)_k \neq M(h_{S&#39;})_k ] = \frac{\delta}{2}\)</span>.</li>
</ol>
<p>There are three combinations such that either <span class="math inline">\(F_S(x_k) = 1\)</span> or <span class="math inline">\(F_{S} (x_l) = 0\)</span> holds, namely</p>
<ol type="1">
<li><span class="math inline">\(F_S(x_k) = 1, F_{S} (x_l) = 0\)</span>,</li>
<li><span class="math inline">\(F_S(x_k) = 1, F_{S} (x_l) &gt; 0\)</span>,</li>
<li><span class="math inline">\(F_S(x_k) &gt; 1, F_{S} (x_l) = 0\)</span>.</li>
</ol>
<p>We give a proof for the first case. The proofs for the other two are similar. Now, for <span class="math inline">\(\forall\)</span> measurable <span class="math inline">\(E \subset \mathbb{R}^n\)</span>, <span class="math display">\[
  \begin{aligned}
      \Pr[ M(h_S) \in E] 
          &amp;= \Pr[ M(h_S) \in E \mid M(h_S)_k = 0, M(h_{S&#39;})_l = 0] \\
          &amp;\ + \Pr[ M(h_S) \in E \mid M(h_S)_k \neq 0 \vee M(h_{S&#39;})_l \neq 0] \\
          &amp;\le \Pr[ M(h_S) \in E \mid M(h_S)_k = 0, M(h_{S&#39;})_l = 0] \\
          &amp;\ + \Pr[M(h_S)_k \neq 0 ] + \Pr[ M(h_{S&#39;})_l \neq 0] \\
          &amp;= \Pr[ M(h_{S&#39;}) \in E \mid M(h_S)_k = 0, M(h_{S&#39;})_l = 0] + \delta \\
          &amp;\le \Pr[ M(h_{S&#39;}) \in E] + \delta
  \end{aligned}
  \]</span></p></li>
</ul>
<h4 id="accuracy-1">Accuracy</h4>
<p>We prove that <span class="math inline">\(|M(h_S) - h_S |_\infty = O (\frac{1}{ n \epsilon } \log \frac{1}{\delta})\)</span> with probability at least <span class="math inline">\(1 - \delta\)</span>, if <span class="math inline">\(\delta \le \frac{1}{n}\)</span>.</p>
<ol type="1">
<li>If <span class="math inline">\(f_S(x_i) = 0\)</span>, then there is no error.<br />
</li>
<li>Otherwise, if <span class="math inline">\(M(h_S)_i\)</span> is not truncated, with probability at most <span class="math inline">\(\frac{\delta}{n}\)</span>, it <span class="math inline">\(|M(h_S)_i - f_S(x_i)|\le \frac{2\log 1 / \delta}{n\epsilon}\)</span>. If it is truncated, this will introduce an additional error of at most <span class="math inline">\(\frac{1}{n} +\frac{2 \log 2 / \delta }{ \epsilon n}\)</span>. The overall error is at most <span class="math inline">\(\frac{1}{n} +\frac{4 \log 2 / \delta }{ \epsilon n}\)</span>, which is <span class="math inline">\(O( \frac{ \log 1 / \delta }{ \epsilon n})\)</span> if <span class="math inline">\(\epsilon \le \log n\)</span>.</li>
</ol>
<!-- Let $b = \frac{2 }{ n \epsilon }$. For a failure probability $\delta$, 
$$
\Pr[ |f_S(x_i) + l_i - f_S(x_i) | \ge b \log \frac{m}{\delta} ] = \int_{ b \log \frac{m}{\delta} }^\infty \frac{1}{b} \exp( - x / b ) \ dx = \exp(- \log \frac{m}{\delta} ) = \frac{\delta}{m}
$$

By union bound, it holds that 
$$
\Pr[ |M(h_S) - h_S |_\infty \ge b \log \frac{m}{\delta} ] \le \delta. 
$$ -->
<p><span class="math inline">\(\square\)</span></p>
<h3 id="reference">Reference</h3>
<p>[1] S. Vadhan, “The Complexity of Differential Privacy,” in Tutorials on the Foundations of Cryptography, Y. Lindell, Ed. Cham: Springer International Publishing, 2017, pp. 347–450.</p>
<!-- Now, for $\forall$ measurable $E \subset \mathbb{R}^n$, define  
$$
    E_1 \doteq \{ v \in E : v_k = 0, v_l = 0 \}
$$
be the set of points with the $k$-th and $l$-th dimensions equal to 0. Let $E_2 = E \setminus E_1$. 
$$
\begin{aligned}
    \Pr[ M(h_S) \in E] &= \Pr[ M(h_S) \in E_1] + \Pr[ M(h_S) \in E_2] \\
    &= \Pr[ M(h_S) \in E_1 \mid M(h_S)_k = 0] \cdot \Pr[M(h_S)_k = 0] + \Pr[ M(h_S) \in E_2] \\
    &= \Pr[ M(h_S) \in E_1 \mid M(h_S)_k = 0] \cdot (1 - \frac{\delta}{2}) + \Pr[ M(h_S) \in E_2] \\
    &\le \Pr[ M(h_S) \in E_1 \mid M(h_S)_k = 0] \cdot (1 - \frac{\delta}{2}) + \Pr[ M(h_S)_k = 0]  \\
    &= \Pr[ M(h_S) \in E_1 \mid M(h_S)_k = 0] \cdot (1 - \frac{\delta}{2}) + \frac{\delta}{2}  \\
    &= \Pr[ M(h_{S'}) \in E_1 \mid M(h_{S'})_l = 0] \cdot (1 - \frac{\delta}{2}) + \frac{\delta}{2}  \\
    &\le \Pr[M(h_{S'}) \in E ] + \frac{\delta}{2}
\end{aligned}
$$

The last inequality follows from $\Pr[ M(h_{S'}) \in E_1 \mid M(h_{S'})_l = 0] = \Pr[ M(h_S) \in E_1 \mid M(h_S)_k = 0]$.  -->

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/11/23/Propose-Test-Release/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/11/23/Propose-Test-Release/" class="post-title-link" itemprop="url">Propose-Test-Release</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-23 21:53:14" itemprop="dateCreated datePublished" datetime="2020-11-23T21:53:14+11:00">2020-11-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-12-18 10:32:42" itemprop="dateModified" datetime="2020-12-18T10:32:42+11:00">2020-12-18</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Let <span class="math inline">\((\mathcal{X}, d)\)</span> be a metric space and <span class="math inline">\(q : \mathcal{X} \rightarrow \mathbb{R}\)</span> be a function defined on <span class="math inline">\(\mathcal{X}\)</span>. The metric <span class="math inline">\(d: \mathcal{X} \rightarrow \mathbb{N}\)</span> takes only integer values. For an <span class="math inline">\(x \in \mathcal{X}\)</span>, it neighbors an <span class="math inline">\(x&#39; \in \mathcal{X}\)</span>, termed <span class="math inline">\(x \sim x&#39;\)</span>, if <span class="math inline">\(d(x, x&#39;) = 1\)</span>.</p>
<p>Further, define the global sensitivity <span class="math inline">\(\Delta\)</span> of <span class="math inline">\(q\)</span> as: <span class="math display">\[
    \Delta \doteq \max_{x \sim x&#39; } | q(x) - q(x&#39;) |
\]</span></p>
<p>The Laplace mechanism <span class="math inline">\(M\)</span> of <span class="math inline">\(q\)</span> adds random noise <span class="math inline">\(N \sim Lap(\frac{\Delta}{\epsilon})\)</span> to the output of <span class="math inline">\(q\)</span>: <span class="math display">\[
M(x) \doteq q(x) + N
\]</span></p>
<p>where <span class="math inline">\(Lap(\frac{\Delta}{\epsilon})\)</span> is the Laplacian distribution with parameter <span class="math inline">\(\frac{\Delta}{\epsilon}\)</span>. It guarantees that if <span class="math inline">\(x \sim x&#39;\)</span>, the output distributions of <span class="math inline">\(M(x)\)</span> and <span class="math inline">\(M(x&#39;)\)</span> are indistinguishable in the sense that <span class="math inline">\(\forall S \subset \mathbb{R}\)</span>, if <span class="math inline">\(S\)</span> is measurable, <span class="math display">\[
\Pr[ M(x) \in S] \in [\exp(-\epsilon), \exp(\epsilon) ] \cdot \Pr[ M(x&#39;) \in S]
\]</span></p>
<p>The value of <span class="math inline">\(\Delta\)</span> could be large and is independent of an <span class="math inline">\(x \in \mathcal{X}\)</span>. We would like to investigate the possibility of adding a smaller noise than <span class="math inline">\(Lap(\frac{\Delta}{\epsilon})\)</span>.</p>
<p>For a fixed <span class="math inline">\(x\)</span>, we can define the local sensitivity with respect to <span class="math inline">\(x\)</span> as <span class="math display">\[
    \delta(x) \doteq \max_{x&#39; \sim x} | q(x) - q(x&#39;) |. 
\]</span></p>
<p>Here the maximum is over the neighbors of a fixed <span class="math inline">\(x\)</span>. The value between <span class="math inline">\(\Delta\)</span> and <span class="math inline">\(\delta(x)\)</span> is quite different.</p>
<blockquote>
<p>Example. Let * <span class="math inline">\(\mathcal{X} \doteq [0, 100]^3\)</span>.<br />
* <span class="math inline">\(d(x, x&#39;)\doteq \#\text{ different values between } x \text{ and } x&#39;\)</span>. * <span class="math inline">\(q(x) \doteq \min_{1 \le i &lt; j \le 3} |x_i - x_j|\)</span>, where <span class="math inline">\(x_i\)</span> is the <span class="math inline">\(i\)</span>-dimension of <span class="math inline">\(x\)</span>.</p>
<p>Then for the point <span class="math inline">\(x = (0, 0, 0) \in [0, 100]^3\)</span>, if <span class="math inline">\(x&#39; \sim x\)</span>, <span class="math inline">\(x&#39;\)</span> contains at least two zeros in some of its dimensions. Therefore, <span class="math inline">\(q(x&#39;) = 0\)</span> and <span class="math inline">\(\delta(x) = 0\)</span>. But for <span class="math inline">\(x = (0, 0, 100)\)</span>, it has a neighbor <span class="math inline">\(x&#39; = (0, 50, 100)\)</span>. Now <span class="math inline">\(q(x) = 0\)</span> but <span class="math inline">\(q(x&#39;) = 50\)</span>. So <span class="math inline">\(\Delta \ge \delta(x) \ge 50\)</span>.</p>
</blockquote>
<p>We are interested in whether adding smaller noise <span class="math inline">\(N \sim Lap(\frac{\delta(x) }{\epsilon})\)</span> to the output of <span class="math inline">\(q(x)\)</span> would preserve privacy: <span class="math display">\[
M(x) = q(x) + N
\]</span></p>
<p>It is not. In the previous example, <span class="math inline">\((0, 0, 0)\)</span> and <span class="math inline">\((0, 0, 100)\)</span> are neighbors. But for the former we add noise <span class="math inline">\(N \sim Lap(0)\)</span> and for the latter we add noise <span class="math inline">\(N \sim Lap(\frac{50}{\epsilon})\)</span>. So the output distributions of them are very different and this would lead to information leakage.</p>
<p>Perhaps, we should propose some fixed parameter <span class="math inline">\(\beta &gt; 0\)</span> (which could be much smaller than <span class="math inline">\(\Delta\)</span>), and add a noise <span class="math inline">\(N \sim Lap(\frac{\beta}{\epsilon})\)</span> for whatever <span class="math inline">\(x \in \mathcal{X}\)</span>. For a pair of neighboring <span class="math inline">\(x, x&#39;\)</span>, when <span class="math inline">\(|q(x) - q(x&#39;)| \le \beta\)</span>, then the distributions of <span class="math inline">\(q(x) + N\)</span> and <span class="math inline">\(q(x&#39;) + N\)</span> are indeed <span class="math inline">\((\epsilon, 0)\)</span> indistinguishable. The only concern is for the case where <span class="math inline">\(|q(x) - q(x&#39;)| &gt; \beta\)</span> and adding a noise <span class="math inline">\(N \sim Lap(\frac{\beta}{\epsilon})\)</span> fails to protect the privacy.</p>
<p>One simple remedy is simply to refuse to output <span class="math inline">\(q(x) + N\)</span> (or <span class="math inline">\(q(x) + N&#39;\)</span>). This should be done in a differentially private manner. Let <span class="math display">\[
\{ y \in \mathcal{X} : \delta(y) &gt; \beta \}
\]</span></p>
<p>be the set of points with local sensitivity greater than <span class="math inline">\(\beta\)</span>. For a fixed <span class="math inline">\(x\)</span>, define <span class="math inline">\(d(x, \{ y : \delta(y) &gt; \beta \})\)</span> be its distance to the set. It follows that for <span class="math inline">\(x \sim x&#39;\)</span>, <span class="math display">\[
|d(x, \{ y \in \mathcal{X} : \delta(y) &gt; \beta \}) - d(x&#39;, \{ y \in \mathcal{X} : \delta(y) &gt; \beta \})| \le 1.
\]</span></p>
<p>This motivates the following <em>propose-test-release</em> algorithm.</p>
<blockquote>
<ol type="1">
<li>Propose a bound <span class="math inline">\(\beta\)</span> on local sensitivity.<br />
</li>
<li>Compute <span class="math inline">\(\hat d \doteq d(x, \{ y \in \mathcal{X} : \delta(y) &gt; \beta \}) + Lap(1 / \epsilon)\)</span>.<br />
</li>
<li>If <span class="math inline">\(\hat d \le \frac{1}{\epsilon} \ln \frac{1}{\gamma}\)</span> then<br />
<span class="math inline">\(\qquad\)</span> output <span class="math inline">\(\bot\)</span>.</li>
<li>Else<br />
<span class="math inline">\(\qquad\)</span> output <span class="math inline">\(q(x) + Lap(\beta / \epsilon)\)</span>.</li>
</ol>
</blockquote>
<p><strong>Theorem.</strong> The algorithm is <span class="math inline">\((2\epsilon, \gamma / 2)\)</span> differentially private.</p>
<p><em>Proof.</em></p>
<p>First observe that for two neighboring <span class="math inline">\(x, x&#39;\)</span>, their probabilities of outputting <span class="math inline">\(\bot\)</span> are similar. <span class="math display">\[
 \Pr[ M(x) = \bot ] \le e^{ \epsilon} \cdot \Pr[ M(x&#39;) = \bot ] \\
 \Pr[ M(x) \neq \bot ] \le e^{ \epsilon} \cdot \Pr[ M(x&#39;) \neq \bot ]
\]</span></p>
<p>Now consider a measurable set <span class="math inline">\(S \subset \mathbb{R}\)</span>. <span class="math inline">\(M(x) \in S\)</span> is only possible when <span class="math inline">\(\hat d &gt; \frac{1}{\epsilon} \ln \frac{1}{\gamma}\)</span>:<br />
<span class="math display">\[
    \begin{aligned}
        \Pr[M(x) \in S] 
            &amp;= \Pr[ M(x) \in S \mid M(x) \neq \bot ] \cdot \Pr[ M(x) \neq \bot]
    \end{aligned}
  \]</span></p>
<p>We consider two cases.</p>
<ul>
<li><p>Case 1. When <span class="math inline">\(\delta(x) &gt; \beta\)</span>, then <span class="math inline">\(d(x, \{ y \in \mathcal{X} : \delta(y) &gt; \beta \}) = 0\)</span>. It follows that <span class="math display">\[
  \Pr[M(x) \in S] \le \Pr[M(x) \neq \bot ]  \le \frac{\gamma}{2}
\]</span></p></li>
<li><p>Case 2. When <span class="math inline">\(\delta(x) \le \beta\)</span>, it holds that <span class="math inline">\(|q(x) - q(x&#39;) |\le \beta\)</span> and <span class="math display">\[
      \Pr[ M(x) \in S \mid M(x) \neq \bot ] \le e^\epsilon \cdot \Pr[ M(x&#39;) \in S \mid M(x&#39;) \neq \bot ]
  \]</span> Therefore, <span class="math display">\[
  \begin{aligned}
      \Pr[M(x) \in S] 
          &amp;= \Pr[ M(x) \in S \mid M(x) \neq \bot ] \cdot \Pr[ M(x) \neq \bot] \\
          &amp;\le \Pr[ M(x) \in S \mid M(x) \neq \bot ] \cdot e^\epsilon \cdot \Pr[ M(x&#39;) \neq \bot] \\
          &amp;\le e^\epsilon \cdot \Pr[ M(x&#39;) \in S \mid M(x&#39;) \neq \bot ] \cdot e^\epsilon \cdot \Pr[ M(x&#39;) \neq \bot] \\
          &amp;= e^{2\epsilon} \Pr[ M(x&#39;) \in S].
  \end{aligned}
  \]</span></p></li>
</ul>
<p><span class="math inline">\(\blacksquare\)</span></p>
<h3 id="reference">Reference</h3>
<p>[1] S. Vadhan, “The Complexity of Differential Privacy,” in Tutorials on the Foundations of Cryptography, Y. Lindell, Ed. Cham: Springer International Publishing, 2017, pp. 347–450.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/11/19/PAC-Learning-From-Countable-Hypothesis-Family/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/11/19/PAC-Learning-From-Countable-Hypothesis-Family/" class="post-title-link" itemprop="url">PAC Learning From Countable Hypothesis Family</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-19 15:17:27" itemprop="dateCreated datePublished" datetime="2020-11-19T15:17:27+11:00">2020-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-03-27 11:22:12" itemprop="dateModified" datetime="2021-03-27T11:22:12+11:00">2021-03-27</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>We generalize the PAC learning problem of finding an hypothesis from a finite hypothesis family to the one from a countable hypothesis family.</p>
<h1 id="problem-setting">Problem Setting</h1>
<ol type="1">
<li><p><span class="math inline">\(\mathcal{X}:\)</span> the input space.</p></li>
<li><p><span class="math inline">\(\mathcal{Y} \doteq \{-1, 1\}:\)</span> the output space.</p></li>
<li><p><span class="math inline">\(\mathcal{Z} \doteq \mathcal{X} \times \mathcal{Y}:\)</span> the product space of <span class="math inline">\(\mathcal{X}\)</span> and <span class="math inline">\(\mathcal{Y}\)</span>.</p></li>
<li><p><span class="math inline">\(\mathcal{D}:\)</span> an unknown distribution defined on <span class="math inline">\(\mathcal{X} \times \mathcal{Y}\)</span>.</p></li>
<li><p><span class="math inline">\(\mathcal{H}:\)</span> an countable family of hypothesis, s.t., each <span class="math inline">\(h \in \mathcal{H}\)</span> is a function from <span class="math inline">\(\mathcal{X}\)</span> to <span class="math inline">\(\mathcal{Y}\)</span>.</p></li>
<li><p><span class="math inline">\(\ell: \mathcal{Y} \times \mathcal{Y} \rightarrow [0, 1]\)</span>, a loss function that takes two points in <span class="math inline">\(\mathcal{Y}\)</span> and outputs a value between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>.</p></li>
<li><p><span class="math inline">\(L_\mathcal{D} (h):\)</span> the expected loss of a hypothesis <span class="math inline">\(h\)</span> is defined as <span class="math display">\[
 L_\mathcal{D} (h) = \mathbb{E}_{ (x, y) \sim \mathcal{D} } [ \ell( h(x), y) ]
 \]</span></p>
<p>where <span class="math inline">\((x, y) \sim \mathcal{D}\)</span> implies that the pair <span class="math inline">\((x, y) \in \mathcal{Z}\)</span> is sampled according to the distribution <span class="math inline">\(\mathcal{D}\)</span>.</p></li>
<li><p><span class="math inline">\(h^* \doteq \arg\min_{h \in \mathcal{H} } L_\mathcal{D} (h):\)</span> the hypothesis that minimize the expected loss.</p></li>
<li><p><span class="math inline">\(\mu_h:\)</span> an alias for <span class="math inline">\(L_\mathcal{D} (h)\)</span>, when the distribution <span class="math inline">\(\mathcal{D}\)</span> discussed in the context is unique.</p></li>
<li><p><span class="math inline">\(B(\mu_h, \epsilon) \doteq \{ r \in \mathbb{R} : |r - \mu_h | &lt; \epsilon \}:\)</span> an open ball, which is an open interval in <span class="math inline">\(\mathbb{R}\)</span> centered at <span class="math inline">\(\mu_h\)</span> with length <span class="math inline">\(2 \epsilon\)</span>, where <span class="math inline">\(\epsilon &gt; 0\)</span>.</p></li>
<li><p><span class="math inline">\(S \sim \mathcal{D}^n:\)</span> a set of <span class="math inline">\(n\)</span> i.i.d samples drawn from <span class="math inline">\(\mathcal{D}\)</span>, where <span class="math inline">\(n \in \mathbb{N}^+\)</span> is some positive integer. In particular, when <span class="math inline">\(S \sim \mathcal{D}^n\)</span>, it can be represented as <span class="math display">\[
 S = \{ (x_1, y_1), (x_2, y_2), ..., (x_n, y_n) : (x_i, y_i) \sim \mathcal  {D}, \forall i \in [n] \}.
 \]</span> We also view <span class="math inline">\(S\)</span> as a point in <span class="math inline">\(\mathcal{Z}^n\)</span>.</p></li>
<li><p><span class="math inline">\(L_{S}(h) \doteq \frac{1}{ |S| } \sum_{ (x, y) \in S } \ell( h(x) , y ) :\)</span> the empirical loss of a hypothesis <span class="math inline">\(h\)</span> on a sample set <span class="math inline">\(S\)</span>.</p></li>
<li><p>Given a <span class="math inline">\(h \in \mathcal{H}\)</span>, its restriction on <span class="math inline">\(\mathcal{C} \subset \mathcal{X}\)</span> is a function <span class="math inline">\(h_S\)</span> defined on <span class="math inline">\(S\)</span>, such that <span class="math display">\[
h_\mathcal{C} (x) = h(x), \forall x \in \mathcal{C} 
\]</span></p></li>
<li><p>The restriction of <span class="math inline">\(\mathcal{H}\)</span> on <span class="math inline">\(\mathcal{C}\)</span> is the set of possible restriction of a function in <span class="math inline">\(\mathcal{H}\)</span> to <span class="math inline">\(\mathcal{C}\)</span> <span class="math display">\[
        \mathcal{H}_\mathcal{C}  = \{ h_\mathcal{C}  : \mathcal{C}  \rightarrow \mathcal{Y} : h \in \mathcal{H} \}
\]</span></p>
<p>As <span class="math inline">\(\mathcal{Y} = \{ -1, +1 \}\)</span>, the set of possible functions defined on <span class="math inline">\(\mathcal{C}\)</span> is bounded by <span class="math inline">\(2^{n}\)</span>. Hence, <span class="math display">\[
    |\mathcal{H}_\mathcal{C} | \le 2^{n}.
\]</span></p></li>
<li><p>The growth function <span class="math inline">\(\Pi_{\mathcal{H} } (n): \mathbb{N}^+ \rightarrow \mathbb{N}^+\)</span> of <span class="math inline">\(\mathcal{H}\)</span> is defined as <span class="math display">\[
   \Pi_{\mathcal{H} } (n) = \max_{\mathcal{C} \subset \mathcal{X}, |C| = n} | \mathcal{H}_\mathcal{C} |
   \]</span></p></li>
</ol>
<p>Ideally, we would like to find <span class="math inline">\(h^*\)</span>. The problem is difficult, as</p>
<ul>
<li>The space <span class="math inline">\(\mathcal{X} \times \mathcal{Y}\)</span> could be infinite.</li>
<li>The distribution <span class="math inline">\(\mathcal{D}\)</span> is unknown.</li>
</ul>
<p>To deal with the possibly infinite space <span class="math inline">\(\mathcal{X} \times \mathcal{Y}\)</span> and the unknown distribution <span class="math inline">\(\mathcal{D}\)</span>, we investigate <span class="math inline">\(\mathcal{H}\)</span> on a finite sample set <span class="math inline">\(S\)</span>. Due to the randomness inherited in sampling <span class="math inline">\(S\)</span>, we allow our solution to be approximate and to make error. For a given pair of parameters of <span class="math inline">\(\epsilon &gt; 0\)</span> and <span class="math inline">\(\delta &gt; 0\)</span>, we relax the goal to designing an <span class="math inline">\((\epsilon, \delta)\)</span>-learning algorithm <span class="math inline">\(A\)</span> that returns an <span class="math inline">\(h&#39;\)</span>, that is</p>
<blockquote>
<ul>
<li><span class="math inline">\(\epsilon\)</span>-approximate: <span class="math inline">\(\mu_{h&#39;} \le \mu_{h^*} + \epsilon\)</span>,<br />
</li>
<li>probably correct: <span class="math inline">\(A\)</span> return an <span class="math inline">\(h&#39;\)</span> that does not satisfies the above condition with probability at most <span class="math inline">\(\delta\)</span>.</li>
</ul>
</blockquote>
<p>Combined, <span class="math inline">\(A\)</span> should return an <span class="math inline">\(\epsilon\)</span>-approximate solution <span class="math inline">\(h&#39;\)</span> with probability at least <span class="math inline">\(1 - \delta\)</span>.</p>
<h1 id="the-algorithm">The Algorithm</h1>
<blockquote>
<p>An <span class="math inline">\((\epsilon, \delta)\)</span> approximate algorithm <span class="math inline">\(A\)</span><br />
1. Draw a set <span class="math inline">\(S\)</span> of <span class="math inline">\(n =\)</span> samples independently from <span class="math inline">\(\mathcal{D}\)</span>.<br />
2. Return an <span class="math inline">\(h&#39;\)</span> such that <span class="math display">\[
h&#39; = \arg\min_{h \in \mathcal{H} } L_{S} (h)
\]</span></p>
</blockquote>
<p>A key result of the algorithm states that <span class="math inline">\(L_S(h)\)</span> is a good approximation of <span class="math inline">\(\mu_h\)</span> for all <span class="math inline">\(h \in \mathcal{H}\)</span> simultaneously.</p>
<blockquote>
<p>Theorem. If <span class="math inline">\(n \ge\)</span>, then <span class="math display">\[
\Pr_{S \sim \mathcal{D}^n } [ \exists h \in \mathcal{H} : L_S(h) \notin B(\mu_h, \epsilon / 2 )  ] \le \delta
\]</span></p>
</blockquote>
<p>An immediate corollary is that <span class="math inline">\(h&#39;\)</span> is <span class="math inline">\(\epsilon\)</span>-approximate with probability at least <span class="math inline">\(1 - \delta\)</span>: <span class="math display">\[
\mu_{h&#39;} \le L_S(h&#39;) + \frac{\epsilon}{2} \le L_S(h^*) + \frac{\epsilon}{2} \le \mu_{h^*} + \epsilon.
\]</span></p>
<h2 id="proof-of-the-theorem">Proof of The Theorem</h2>
<p>The proof relies on a technique called double sampling. Alongside with <span class="math inline">\(S\)</span>, we create another sample set <span class="math inline">\(S&#39; \sim \mathcal{D}^n\)</span> independently, termed the "ghost sample". Let <span class="math display">\[
S = \{ (x_1, y_1), (x_2, y_2), ..., (x_n, y_n) \}
\]</span> and <span class="math display">\[
S&#39; = \{ (x_1&#39;, y_1&#39;), (x_2&#39;, y_2&#39;), ..., (x_n&#39;, y_n&#39;) \}.
\]</span></p>
<p>Then, we define</p>
<ol start="16" type="1">
<li><span class="math inline">\(\sigma:\)</span> a random swap that exchanges the <span class="math inline">\(i\)</span>-th (<span class="math inline">\(i \in [n]\)</span>) element of <span class="math inline">\(S\)</span> and <span class="math inline">\(S&#39;\)</span> independently with probability 0.5. Call the resulting sample sets <span class="math inline">\(\sigma S\)</span> and <span class="math inline">\(\sigma S&#39;\)</span>. Let <span class="math inline">\(\sigma S[i]\)</span> (<span class="math inline">\(\sigma S&#39;[i]\)</span>) be the <span class="math inline">\(i\)</span>-th element of <span class="math inline">\(\sigma S[i]\)</span> (<span class="math inline">\(\sigma S&#39;[i]\)</span>). So <span class="math display">\[
\Pr \left[ 
    \sigma S [i] = (x_i,  y_i) \wedge
    \sigma S&#39;[i] = (x_i&#39;, y_i&#39;)
 \right] = 0.5 \\
 \Pr \left[ 
    \sigma S [i] = (x_i&#39;, y_i&#39;) \wedge
    \sigma S&#39;[i] = (x_i,  y_i)
 \right] = 0.5
\]</span></li>
</ol>
<p>We use the gap of <span class="math inline">\(|L_{\sigma S} (h) - L_{\sigma S&#39;} (h)|\)</span> as a proxy of <span class="math inline">\(|L_S(h) - \mu_h|\)</span>. This enables us to focus on finite sets <span class="math inline">\(S\)</span> and <span class="math inline">\(S&#39;\)</span> without worrying about the infinite size of <span class="math inline">\(\mathcal{H}\)</span>.</p>
<p>For convenience, we use <span class="math inline">\(\underset{S}{\Pr}[\cdot]\)</span> (<span class="math inline">\(\underset{S&#39;}{\Pr}[\cdot]\)</span>) as shorthand for <span class="math inline">\(\underset{S \sim \mathcal{D}^n}{\Pr}[\cdot]\)</span> (<span class="math inline">\(\underset{S&#39; \sim \mathcal{D}^n}{\Pr}[\cdot]\)</span>). The road map of our proof is as follows.</p>
<blockquote>
<p>Lemma 1.<br />
<span class="math display">\[
\Pr_{S}[ \exists h : L_S(h) \notin B(\mu_h, \epsilon ) ] \le 2 \max_{S, S&#39; \in \mathcal{Z}^n } \Pr_\sigma \left[ \exists h : |L_{ \sigma S} (h) - L_{ \sigma S&#39; } (h) | \ge \frac{\epsilon}{2} \right]
\]</span></p>
</blockquote>
<p>On the left hand side of the inequality, the probability measures the event of a random set <span class="math inline">\(S\)</span> sampling from <span class="math inline">\(\mathcal{D}\)</span>. On the right hand side, we can pick a fixed pair of <span class="math inline">\(S\)</span> and <span class="math inline">\(S&#39;\)</span> that maximize <span class="math display">\[
\Pr_\sigma \left[ \exists h : |L_{ \sigma S} (h) - L_{ \sigma S&#39; } (h) | \ge \frac{\epsilon}{2} \right],
\]</span></p>
<p>and the probability measures the event of the random swap <span class="math inline">\(\sigma\)</span>. Fixing <span class="math inline">\(S\)</span> and <span class="math inline">\(S&#39;\)</span> significantly simplifies the structure of <span class="math inline">\(\mathcal{H}\)</span>. By Hoeffding inequality and union bound, we will prove that</p>
<blockquote>
<p>Lemma 2. For any fixed pair of <span class="math inline">\(S, S&#39; \in \mathcal{Z}^n\)</span>, <span class="math display">\[
\Pr_\sigma \left[ \exists h : |L_{ \sigma S} (h) - L_{ \sigma S&#39; } (h) | \ge \frac{\epsilon}{2} \right] \le 2 \Pi_\mathcal{H} (2n) \exp( - \frac{n^2 \epsilon^2 }{2} )
\]</span></p>
</blockquote>
<h3 id="proof-of-lemma-1."><strong>Proof of Lemma 1.</strong></h3>
<p>The proof of Lemma 1 consists of three steps.</p>
<h4 id="step-1"><strong>Step 1</strong></h4>
<blockquote>
<p><span class="math display">\[
\Pr_{S}[ \exists h : L_S(h) \notin B(\mu_h, \epsilon ) ] \le 2 \Pr_{S , S&#39;} [ \exists h : L_S (h) \notin B(\mu_h, \epsilon )  \wedge  L_{S&#39;} (h) \in B(\mu_h, \epsilon / 2)  ].
\]</span></p>
</blockquote>
<p><strong>Proof.</strong> By Hoeffding inequality, for a fixed <span class="math inline">\(h \in \mathcal{H}\)</span>, when <span class="math inline">\(n \ge \frac{2}{\epsilon^2} \ln 4\)</span> <span class="math display">\[
    \Pr_{S&#39;} [ L_{S&#39;} (h) \notin B(\mu_h, \epsilon / 2) ] \le 2 \exp \left(- 2 n \left( \frac{\epsilon }{ 2 } \right)^2 \right) = 2 \exp \left( - \frac{n \epsilon^2}{2} \right) \le \frac{1}{2}
\]</span></p>
<p>It follows that <span class="math display">\[
    \Pr_{S , S&#39;} [ \exists h : L_S (h) \notin B(\mu_h, \epsilon )  \wedge  L_{S&#39;} (h) \in B(\mu_h, \epsilon / 2)  ] 
        \ge 
    \frac{1}{2} \Pr_{S}[ \exists h : L_S(h) \notin B(\mu_h, \epsilon ) ]
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<p><strong>Remark:</strong> Mathematically, I don't know how to make prove this step rigorously. Suppose that for every <span class="math inline">\(i \in [n]\)</span>, we know that the events <span class="math inline">\(E_i\)</span> and <span class="math inline">\(F_i\)</span> are measurable and independent. If <span class="math inline">\(\Pr[ F_i ] \ge 1 / 2\)</span>, then <span class="math inline">\(\Pr[ E_i \wedge F_i ] \ge 1 / 2\)</span>. But, can we claim that <span class="math display">\[
    \Pr[ \cup (E_i \wedge F_i) ] \ge \frac{1}{2} \Pr[ \cup E_i ]. 
\]</span></p>
<h4 id="step-2"><strong>Step 2</strong></h4>
<blockquote>
<p><span class="math display">\[
\Pr_{S} [ \exists h : L_S (h) \notin B(\mu_h, \epsilon )  \wedge  L_{S&#39;} (h) \in B(\mu_h, \epsilon / 2) ] 
\le 
\Pr_{S, S&#39;} \left[ \exists h : |L_S (h) - L_{S&#39;} (h) | \ge \frac{\epsilon}{2} \right]
\]</span></p>
</blockquote>
<p><strong>Proof</strong>. Observe that <span class="math display">\[
    \{  \exists h : L_S (h) \notin B(\mu_h, \epsilon )  \wedge  L_{S&#39;} (h) \in B(\mu_h, \epsilon / 2)  \} 
        \subset 
    \left\{  \exists h : |L_S (h) - L_{S&#39;} (h) | \ge \frac{\epsilon}{2} \right\}. 
\]</span> By monotonicity of probability, we finish the proof.</p>
<p><span class="math inline">\(\square\)</span></p>
<h4 id="step-3"><strong>Step 3</strong></h4>
<blockquote>
<p><span class="math display">\[
\Pr_{S, S&#39; } \left[  \exists h : |L_S (h) - L_{S&#39;} (h) | \ge \frac{\epsilon}{2} \right] 
\le 
\max_{S, S&#39; \in \mathcal{Z}^n } \Pr_\sigma \left[ \exists h : |L_{ \sigma S} (h) - L_{ \sigma S&#39; } (h) | \ge \frac{\epsilon}{2} \right]
\]</span></p>
</blockquote>
<p><strong>Proof.</strong> We claim that <span class="math inline">\(\sigma S\)</span> and <span class="math inline">\(\sigma S&#39;\)</span> have the same joint distribution as <span class="math inline">\(S\)</span> and <span class="math inline">\(S&#39;\)</span> (if <span class="math inline">\(S, S&#39; \sim \mathcal{D}^n\)</span>). For points <span class="math inline">\(\forall Z, Z&#39; \in \mathcal{Z}^n\)</span>, by symmetry, it holds that <span class="math display">\[
\Pr_{S, S&#39;} [ S = Z, S&#39; = Z&#39;] = \Pr_{S, S&#39;, \sigma} [ \sigma S = Z, \sigma S&#39; = Z&#39;]
\]</span></p>
<p>The right hand side can be viewed as the successful probability of the following experiment:</p>
<ul>
<li>Sample independently <span class="math inline">\(S \sim \mathcal{D}^n\)</span> and <span class="math inline">\(S&#39; \sim \mathcal{D}^n\)</span>.<br />
</li>
<li>For each <span class="math inline">\(i \in [n]\)</span>, exchange the <span class="math inline">\(i\)</span>-th elements of <span class="math inline">\(S\)</span> and <span class="math inline">\(S&#39;\)</span> independently with probability <span class="math inline">\(0.5\)</span>.</li>
<li>After the random swap, <span class="math inline">\(\sigma S = Z\)</span> and <span class="math inline">\(\sigma S&#39; = Z&#39;\)</span>.</li>
</ul>
<p>Now, <span class="math inline">\(\forall \mathcal{E} \subset \mathcal{Z}^{2n}\)</span>, it holds that <span class="math display">\[
\begin{aligned}
    \Pr_{S, S&#39;} [ (S, S&#39;) \in \mathcal{E} ] 
        &amp;= \Pr_{S, S&#39;, \sigma} [ (\sigma S, \sigma S&#39;) \in \mathcal{E} ] \\
        &amp;= \mathbb{E}_{S, S&#39;} [ \Pr_\sigma [(\sigma S, \sigma S&#39;) \in \mathcal{E} ] \mid S, S&#39; ] \\
        &amp;\le \max_{S, S&#39; \in \mathcal{Z}^n } \Pr_\sigma [(\sigma S, \sigma S&#39;) \in \mathcal{E} ]
\end{aligned}
\]</span></p>
<p>Replacing <span class="math inline">\(\mathcal{E}\)</span> with the set <span class="math inline">\(\{Z, Z&#39; \in \mathcal{Z}^n : \exists h : |L_Z (h) - L_{Z&#39;} (h) | \ge \frac{\epsilon}{2} \}\)</span> finishes the proof.</p>
<p><span class="math inline">\(\square\)</span></p>
<!-- *Remark of the proof of step 1.* If we define 
$$
\mathcal{H}(S, \epsilon) \doteq \{ h \in \mathcal{H} :L_S(h) \notin B(\mu_h, \epsilon ) \}.
$$
*which is the set of hypothesis whose empirical loss on $S$ is $\epsilon$ more than its expectation. Then,* 
$$
\begin{aligned}
    \Pr_{S} [ \exists h : L_S(h) \notin B(\mu_h, \epsilon ) ] \cdot \frac{1}{2} 
    &= \Pr_{S } [ \mathcal{H}(S, \epsilon) \neq \emptyset ] \cdot \frac{1}{2} \\
    &\le \Pr_{S } [ \mathcal{H}(S, \epsilon) \neq \emptyset] \\
    & \ \ \cdot \Pr_{S, S' } [ \exists h \in \mathcal{H}(S, \epsilon) : L_{S'} (h) \in B(\mu_h, \epsilon / 2 ) \mid \mathcal{H}(S, \epsilon) \neq \emptyset ] \\
    &= \Pr_{S, S' } [ \exists h : L_S (h) \notin B(\mu_h, \epsilon )  \wedge L_{S'} (h) \in B(\mu_h, \epsilon / 2 )  ]
\end{aligned}
$$

*Note that the event $\mathcal{H}(S, \epsilon) \neq \emptyset$ is equivalent to the one* 
$$
\cup_{h \in \mathcal{H} } \{ L_S(h) \notin B(\mu_h, \epsilon ) \} 
$$

*For a fixed $h \in \mathcal{H}$, the event $\{ L_S(h) \notin B(\mu_h, \epsilon ) \}$ is measurable when $S$ consists of a finite number of i.i.d samples from $\mathcal{D}$. If $\mathcal{H}$ consists of countable number of $h$, then $\cup_{h \in \mathcal{H} } \{ L_S(h) \notin B(\mu_h, \epsilon ) \}$ is a countable union and should be measurable.*  -->
<h3 id="proof-of-lemma-2."><strong>Proof of Lemma 2.</strong></h3>
<p>Let <span class="math display">\[
S = \{ (x_1, y_1), (x_2, y_2), ..., (x_n, y_n) \}
\]</span> and <span class="math display">\[
S&#39; = \{ (x_1&#39;, y_1&#39;), (x_2&#39;, y_2&#39;), ..., (x_n&#39;, y_n&#39;) \}.
\]</span> be a pair of fixed sample sets. Define the set <span class="math inline">\(\mathcal{C} = \{ x_1, x_2, ..., x_n, x_1&#39;, x_2&#39;, ..., x_n&#39; \} \subset \mathcal{X}\)</span> (with duplicates removed). The size of <span class="math inline">\(\mathcal{C}\)</span> is bounded by <span class="math inline">\(2n\)</span> and therefore the size of restriction of <span class="math inline">\(\mathcal{H}\)</span> on <span class="math inline">\(\mathcal{C}\)</span> is bounded by <span class="math inline">\(\Pi_\mathcal{H} (2n)\)</span>.</p>
<p>First, fix a hypothesis <span class="math inline">\(h\)</span>. For all <span class="math inline">\(i \in [n]\)</span>, define <span class="math inline">\(a_i = |\ell( h( x_i ), y_i) - \ell( h( x_i&#39; ), y_i&#39; ) | \le 1\)</span> and let <span class="math inline">\(V_i \in \{-1, 1\}\)</span> be a random variable with equal probability: <span class="math display">\[
\Pr[ V_i = -1 ] = \Pr[ V_i = 1] = 0.5
\]</span></p>
<p>If we apply a random swap <span class="math inline">\(\sigma\)</span> to <span class="math inline">\((S, S&#39;)\)</span>, then <span class="math inline">\(L_{ \sigma S} (h_S) - L_{ \sigma S&#39; } (h_S)\)</span> has the same distribution as <span class="math inline">\(\sum_{i \in [n] } \frac{1}{n} a_i V_i\)</span>. Since <span class="math display">\[
\mathbb{E} \left[ \sum_{i \in [n] } \frac{1}{n} a_i V_i \right] = \sum_{i \in [n] } \frac{1}{n} a_i \mathbb{E}[ V_i ] = 0,
\]</span></p>
<p>by Hoeffding inequality, <span class="math display">\[
\begin{aligned}
    \Pr_\sigma \left[ |L_{ \sigma S} (h) - L_{ \sigma  S&#39; } (h) | \ge \frac{\epsilon}{2} \right] 
        &amp;= \Pr \left[ \left| \sum_{i \in [n] } \frac{1}{n} a_i V_i - 0 \right| \ge \frac{\epsilon}{2} \right] \\
        &amp;\le 2 \exp \left( - \frac{ 2 }{  \sum_{i \in [n] } a_i^2 } \left( \frac{n \epsilon}{2} \right)^2 \right)  \\
        &amp;\le 2 \exp \left( - \frac{n^2 \epsilon^2 }{2} \right)
\end{aligned}
\]</span></p>
<p>The last inequality follows from that <span class="math inline">\(\sum_{i \in [n] } a_i^2 \le n\)</span>.</p>
<p>Since for each <span class="math inline">\(h \in \mathcal{H}\)</span>, it has the same behavior on <span class="math inline">\(\mathcal{C}\)</span> as some function in <span class="math inline">\(\mathcal{H}_\mathcal{C}\)</span>. We can apply union bound on <span class="math inline">\(\mathcal{H}_\mathcal{C}\)</span>. <span class="math display">\[
\Pr_\sigma \left[ \exists h : |L_{ \sigma S} (h) - L_{ \sigma  S&#39; } (h) | \ge \frac{\epsilon}{2} \right] \le 2 |\mathcal{H}_\mathcal{C} | \exp \left( - \frac{n^2 \epsilon^2 }{2} \right) \le 2 \Pi_\mathcal{H} (2n) \exp \left( - \frac{n^2 \epsilon^2 }{2} \right)
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h1 id="reference">Reference</h1>
<p>[1] Ethan Fetaya, "Lecture 02 - Introduction to Statistical Learning Theory", Weizmann Institute of Science, 2016</p>
<p>[2].R. Schapire and D. Bieber, “Lecture 05 - COS 511: Theoretical Machine Learning,”, Princeton University, 2013</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/16/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/16/">16</a><span class="page-number current">17</span><a class="page-number" href="/page/18/">18</a><span class="space">&hellip;</span><a class="page-number" href="/page/56/">56</a><a class="extend next" rel="next" href="/page/18/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">167</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WOW</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
