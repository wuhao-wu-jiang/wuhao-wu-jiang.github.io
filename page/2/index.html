<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Helvetica:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.24.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js" defer></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="WOW">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/2/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/2/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>WOW</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">WOW</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">你生之前悠悠千載已逝<br>未來還會有千年沉寂的期待</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">200</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/09/23/Local-Sensitivity-Lower-Bound/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | WOW">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/09/23/Local-Sensitivity-Lower-Bound/" class="post-title-link" itemprop="url">Local Sensitivity Lower Bound</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-09-23 17:20:45" itemprop="dateCreated datePublished" datetime="2023-09-23T17:20:45-04:00">2023-09-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-04-11 16:40:43" itemprop="dateModified" datetime="2024-04-11T16:40:43-04:00">2024-04-11</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <blockquote>
<p><strong>Theorem.</strong> Let <span class="math inline">\(q :
\mathcal{X} \rightarrow \mathbb{R}\)</span> be a real-valued query and
<span class="math inline">\(M : \mathcal{X} \rightarrow Y\)</span> be an
<span class="math inline">\((\varepsilon,  \delta
)\)</span>-differentially private mechanism. Then 1. For every <span
class="math inline">\(x_0 ∼ x_1 \in \mathcal{X}\)</span>, at least one
of the following holds <span class="math display">\[
\Pr\left[ |M(x_0) − q(x_0)| &lt; \frac{|q(x_0) − q(x_1)|}{2} \right]
\le
\frac{1 +  \delta}
{1 + e^{−\varepsilon}}
= \frac{1}{2} + O( \delta  + \varepsilon).
\]</span> <span class="math display">\[
\Pr\left[ |M(x_1) − q(x_1)| &lt; \frac{|q(x_0) − q(x_1)|}{2} \right]
\le
\frac{1 +  \delta}
{1 + e^{−\varepsilon}}
= \frac{1}{2} + O( \delta  + \varepsilon). \\
\]</span></p>
</blockquote>
<blockquote>
<p><strong>Corollary.</strong> For every <span class="math inline">\(x
\in \mathcal{X}\)</span>, there is some <span
class="math inline">\(x&#39;\)</span> at Hamming distance at most <span
class="math inline">\(1\)</span> from <span
class="math inline">\(x\)</span> such that <span class="math display">\[
\Pr\left[ |M(x&#39;) − q(x&#39;)| &lt; \frac{LS_q(x)}{2} \right]
\le
\frac{1 +  \delta}
{1 + e^{−\varepsilon}}
= \frac{1}{2} + O( \delta  + \varepsilon). \\
\]</span></p>
</blockquote>
<p><strong>Proof.</strong> Let <span class="math display">\[
    \begin{align*}
        G_b
            &amp;= \left\{ y \in \mathbb{R} : |y − q(x_b)| &lt; |q(x_0)
− q(x_1)| \right\},
        \quad \forall b \in \{0, 1\}, \\
        p   &amp;= \min \{ \Pr[ M(x_0) \in G_0 ], \Pr[ M(x_1) \in G_1 ]
\}.
    \end{align*}
\]</span> To shed light on the final inequality, assume first that <span
class="math inline">\(M(x_0)\)</span> and <span
class="math inline">\(M(x_1)\)</span> have identical distributions. Then
<span class="math inline">\(M(x_0) \in G_0\)</span> and <span
class="math inline">\(M(x_1) \in G_1\)</span> are mutually disjoint
events, and therefore at least one of them has probability at most <span
class="math inline">\(1 / 2\)</span>.</p>
<p>In general, since <span class="math inline">\(M(x_0)\)</span> and
<span class="math inline">\(M(x_1)\)</span> have similar distributions,
we should expect similar results. We present two ways of deriving
it.</p>
<p>First, <span class="math display">\[
    \begin{align*}
        2 \cdot p
        &amp;\le \Pr[ M(x_0) \in G_0 ] + \Pr[ M(x_1) \in G_1 ] \\
        &amp;\le \Pr[ M(x_0) \in G_0 ] + e^\varepsilon \Pr[ M(x_0) \in
G_1 ] + \delta \\
        &amp;\le \Pr[ M(x_0) \in G_0 ] + e^\varepsilon \big(1 - \Pr[
M(x_0) \in G_0 ]\big) + \delta \\
        &amp;= e^\varepsilon + \delta + (1 - e^\varepsilon) \cdot \Pr[
M(x_0) \in G_0 ].
    \end{align*}
\]</span></p>
<p>Similarly, we have <span class="math inline">\(2 \cdot p \le
e^\varepsilon + \delta + (1 - e^\varepsilon) \cdot \Pr[ M(x_1) \in G_1
]\)</span>. It follows that <span class="math display">\[
    2 \cdot p \le e^\varepsilon + \delta + (1 - e^\varepsilon) \cdot p
    \Longleftrightarrow
    p \le \frac{e^\varepsilon + \delta}{e^\varepsilon + 1}.
\]</span></p>
<p>Second Proof: <span class="math display">\[
    \begin{align*}
        1 − p
            &amp;\ge \Pr[ M(x_0) \notin G_0 ] \\
            &amp;\ge \Pr[ M(x_0) \in G_1] \\
            &amp;\ge e^{− \varepsilon} \cdot \Pr[ M(x_1) \in G_1 ]
−  \delta \\
            &amp;\ge e^{− \varepsilon} \cdot p −  \delta.
    \end{align*}
\]</span> Solving, we deduce that <span class="math inline">\(p \le (1
+  \delta ) / (1 + e^{−\varepsilon})\)</span>.</p>
<p>Third Proof: there is an alternative proof, which is quite close the
proof of packing lower bound. <span class="math display">\[
    \begin{aligned}
        1   &amp;\ge \Pr[ M(x_0) \in G_0 ] + \Pr[ M(x_0) \in G_1]\\
            &amp;\ge \Pr[ M(x_0) \in G_0 ] + e^{− \varepsilon} \cdot
(\Pr[ M(x_1) \in G_1 ] −  \delta)\\
            &amp;\ge (1 + e^{− \varepsilon}) \cdot p −  e^{−
\varepsilon} \cdot \delta.
    \end{aligned}
\]</span> It concludes that <span class="math display">\[
    p \le \frac{e^\varepsilon + \delta}{e^\varepsilon + 1}.
\]</span></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<h1 id="reference">Reference</h1>
<ol type="1">
<li>Vadhan, Salil. “The Complexity of Differential Privacy.” 2017.
https://doi.org/10.1007/978-3-319-57048-8_7.</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/06/16/Sub-Exponential-Random-Variable/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | WOW">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/06/16/Sub-Exponential-Random-Variable/" class="post-title-link" itemprop="url">Sub-Exponential Random Variable</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-06-16 13:35:04" itemprop="dateCreated datePublished" datetime="2023-06-16T13:35:04-04:00">2023-06-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-11-22 14:59:27" itemprop="dateModified" datetime="2024-11-22T14:59:27-05:00">2024-11-22</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <blockquote>
<p><strong>Theorem (Sub-exponential properties).</strong> Let <span
class="math inline">\(X\)</span> be a random variable. Then the
following properties are equivalent; the parameters <span
class="math inline">\(K_i &gt; 0\)</span> appearing in these properties
differ from each other by at most an absolute constant factor. 1. The
tails of <span class="math inline">\(X\)</span> satisfy <span
class="math display">\[
\Pr \{ |X| \ge t \} \le 2 \exp( − t / K_1 ), \quad  \forall t \ge 0.
      \]</span> 2. The moments of <span class="math inline">\(X\)</span>
satisfy <span class="math display">\[
\Vert X \Vert_{L_p} = ( \mathbb{E} |X|^p )^{1/p}
\le
K_1 \cdot \sqrt[p]{2 p \cdot \Gamma (p)}
= K_2 p, \quad \forall p \ge 1.
      \]</span> 3. The MGF of <span class="math inline">\(|X|\)</span>
satisfies <span class="math display">\[
\mathbb{E} \exp( \lambda |X| ) \le \exp( K_3 \lambda ),
\quad
\forall \lambda, \, \text{ s.t., } \, 0 \le \lambda \le 1 / K_3.
      \]</span> 4. The MGF of <span class="math inline">\(|X|\)</span>
is bounded at some point, namely <span class="math display">\[
\mathbb{E} \exp( |X| / K_4 ) \le 2.
      \]</span> 5. Moreover, if <span class="math inline">\(\mathbb{E} X
= 0\)</span> then properties 1 - 4 are also equivalent to the following
property: The MGF of <span class="math inline">\(X\)</span> satisfies
<span class="math display">\[
\mathbb{E} \exp( \lambda X ) \le \exp( K_5^2 \lambda^2 ),
\quad
\forall \lambda, \, \text{ s.t., } \, | \lambda | \le 1/K_5.
      \]</span></p>
</blockquote>
<p><strong>Proof.</strong></p>
<p><span class="math inline">\(1 \rightarrow 2:\)</span> <span
class="math display">\[
    \begin{aligned}
        \Vert X \Vert_{L_p}^p
            &amp;= \mathbb{E}|X|^p \\
            &amp;= \int_{0}^\infty \Pr[ |X|^p \ge t ] \, dt \\
            &amp;= \int_{0}^\infty \Pr[ |X| \ge t^{1 / p} ] \, dt \\
            &amp;\le \int_{0}^\infty 2 \exp(− t^{1 / p} / K_1) \, dt
            &amp; u \doteq t^{1 / p} / K_1 \\
            &amp;\le \int_{0}^\infty 2 K_1^p \cdot p \cdot u^{p - 1}
\exp(− u ) \, du \\
            &amp;= 2 K_1^p \cdot p \cdot \Gamma (p).
    \end{aligned}
\]</span> Noting that <span class="math inline">\(\Gamma(p) \le
p^p\)</span> proves property 2.</p>
<p><span class="math inline">\(2 \rightarrow 3:\)</span> By monotone
convergence theorem, we have <span class="math display">\[
    \begin{aligned}
        \mathbb{E} \exp( \lambda |X|)
            &amp;= \mathbb{E} \left( \sum_{n \in \N} \frac{\lambda^n
|X|^n}{n!}\right) \\
            &amp;= 1 + \sum_{n \in \N^+} \frac{\lambda^n \mathbb{E}
|X|^n}{n!} \\
            &amp;\le 1 + \sum_{n \in \N^+} \frac{\lambda^n \cdot 2 K_1^n
\cdot n \cdot \Gamma(n)}{n!}
            &amp; \text{ since }\, \mathbb{E} |X|^n \le 2 K_1^n \cdot n
\cdot \Gamma(n) \\
            &amp;\le 1 + 2 \cdot \sum_{n \in \N^+} \lambda^n K_1^n \\
            &amp;= 1 + \frac{2 \lambda K_1}{1 - \lambda K_1}
            &amp; \text{ provided that }\, \lambda K_1 &lt; 1 \\
            &amp;= \frac{1 + \lambda K_1}{1 - \lambda K_1} \\
            &amp;\le e^{ 3 K_1 \lambda }
            &amp; \text{ provided that }\, \lambda K_1 \in [0, 4 / 5].
    \end{aligned}
\]</span></p>
<p><span class="math inline">\(3 \rightarrow 4:\)</span></p>
<p>It is trivial to prove property 4 by setting <span
class="math inline">\(\lambda = 1 / K_3\)</span> in property 3.</p>
<p><span class="math inline">\(4 \rightarrow 1:\)</span> <span
class="math display">\[
    \begin{aligned}
         \Pr \{ |X| \ge t \}
            &amp;=  \Pr \{ e^{|X| / K_4} \ge e^{t / K_4} \} \\
            &amp;\le \frac{\mathbb{E} e^{|X| / K_4}}{e^{t / K_4}} \\
            &amp;\le 2 \exp(−t / K_4),
            &amp;\forall t \ge 0.
    \end{aligned}
\]</span></p>
<p><span class="math inline">\(2 \rightarrow 5:\)</span> By monotone
convergence theorem, we have <span class="math display">\[
    \begin{aligned}
        \mathbb{E} \exp( \lambda X)
            &amp;= \mathbb{E} \left( \sum_{n \in \N} \frac{\lambda^n
X^n}{n!}\right) \\
            &amp;= 1 + \mathbb{E} (\lambda X) + \mathbb{E} \left(
\sum_{n \in \N} \frac{\lambda^n X^n}{n!}\right) \\
            &amp;= 1 + \mathbb{E} \left( \sum_{n \ge 2} \frac{\lambda^n
X^n}{n!}\right) \\
            &amp;\le 1 + \mathbb{E} \left( \sum_{n \ge 2}
\frac{\lambda^n |X|^n}{n!}\right) \\
            &amp;= 1 + \sum_{n \ge 2} \frac{\lambda^n \mathbb{E}
|X|^n}{n!} \\
            &amp;\le 1 + \sum_{n \ge 2} \frac{\lambda^n \cdot 2 K_1^n
\cdot n \cdot \Gamma(n)}{n!}
            &amp; \text{ since }\, \mathbb{E} |X|^n \le 2 K_1^n \cdot n
\cdot \Gamma(n) \\
            &amp;\le 1 + 2 \cdot \sum_{n \ge 2} \lambda^n K_1^n \\
            &amp;= 1 + \frac{2 \lambda^2 K_1^2}{1 - \lambda K_1}
            &amp; \text{ provided that }\, \lambda K_1 &lt; 1 \\
            &amp;= 1 + 4 \lambda^2 K_1^2
            &amp; \text{ provided that }\, \lambda K_1 \le 1 / 2 \\
            &amp;\le e^{ 4 K_1^2 \lambda^2 }.
    \end{aligned}
\]</span></p>
<p><span class="math inline">\(5 \rightarrow 2:\)</span> Taking <span
class="math inline">\(\lambda = 1 / K_5\)</span> and <span
class="math inline">\(\lambda = - 1 / K_5\)</span> gives <span
class="math display">\[
    \begin{aligned}
        \mathbb{E}\exp( X / K_5 ) \le \exp( 1 ),
        \qquad
        \mathbb{E}\exp( - X / K_5 ) \le \exp( 1 ),
    \end{aligned}
\]</span> Further, for each <span class="math inline">\(x \in
\R\)</span>, and <span class="math inline">\(p &gt; 0\)</span>, since
<span class="math inline">\(|x| / p \le 1 + |x / p| \le e^{|x| /
p}\)</span>, it holds that <span class="math display">\[
    |x|^p / p^p \le e^{|x|} \le e^x + e^{-x},
    \quad
    \Longleftrightarrow
    \quad
    |x / K_5|^p / p^p \le e^{|x / K_5|} \le e^{x / K_5} + e^{- x / K_5}.
\]</span> It follows that <span class="math display">\[
    \mathbb{E} \left[ |X / K_5|^p / p^p \right]
        \le \mathbb{E} \left[ e^{X / K_5} \right]
        + \mathbb{E} \left[ e^{- X / K_5} \right]
        \le 2,
\]</span> i.e., <span class="math display">\[
      \mathbb{E} \left[ |X|^p \right] \le 2 \cdot p^p \cdot K_5^p.
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<p>A random variable <span class="math inline">\(X\)</span> that
satisfies one of the equivalent properties 1 - 5 in previous theorem is
called a <strong><em>sub-exponential random variable</em></strong>.</p>
<blockquote>
<p><strong>Definition (Sub-Exponential Norm).</strong> The
sub-exponential norm of <span class="math inline">\(X\)</span>, denoted
<span class="math inline">\(\Vert X \Vert_{\psi_1}\)</span>, is defined
to be the smallest <span class="math inline">\(K_3\)</span> in property
3. In other words, <span class="math display">\[    
\Vert X \Vert_{\psi_1} = \inf \{t &gt; 0: \mathbb{E}\exp(|X|/t) \le 2
\}.
\]</span></p>
</blockquote>
<blockquote>
<p><strong>Lemma (Sub-gaussian squared is sub-exponential).</strong> A
random variable <span class="math inline">\(X\)</span> is sub-gaussian
if and only if <span class="math inline">\(X^2\)</span> is
sub-exponential. Moreover, <span class="math display">\[  
\Vert X^2 \Vert_{\psi_1} = \Vert X \Vert_{\psi_2}^2.
  \]</span></p>
</blockquote>
<p><strong>Proof.</strong> By definition we have <span
class="math display">\[
\begin{align*}
    \Vert X^2   \Vert_{\psi_1}
        &amp;\doteq \inf \{t &gt; 0: \mathbb{E}\exp(|X|^2/t) \le 2 \}.
\\
    \Vert X \Vert_{\psi_2}
        &amp;\doteq \inf \{t &gt; 0: \mathbb{E}\exp(|X|^2/t^2) \le 2 \}.
\end{align*}
\]</span> Hence the claim follows.</p>
<p><span class="math inline">\(\square\)</span></p>
<blockquote>
<p><strong>Lemma (The product of sub-gaussians is
sub-exponential).</strong> Let <span class="math inline">\(X\)</span>
and <span class="math inline">\(Y\)</span> be sub-gaussian random
variables. Then <span class="math inline">\(XY\)</span> is
sub-exponential. Moreover, <span class="math display">\[
\Vert XY \Vert_{\psi_1} \le \Vert X \Vert_{\psi_2} \Vert Y
\Vert_{\psi_2}.
  \]</span></p>
</blockquote>
<p><strong>Proof.</strong> Assume that <span class="math inline">\(\Vert
X \Vert_{\psi_2} = a\)</span>, and <span class="math inline">\(\Vert Y
\Vert_{\psi_2} = b.\)</span> Then by definition, we have <span
class="math display">\[
\begin{aligned}
    \mathbb{E}\exp( |X|^2 / a^2 ) \le 2, \\
    \mathbb{E}\exp( |Y|^2 / b^2 ) \le 2.
\end{aligned}
\]</span> Further <span class="math display">\[
\begin{aligned}
    \mathbb{E} \left[
        \exp ( | X Y | / (a \cdot b) )
    \right]
    &amp;\le \mathbb{E} \left[
        \exp \bigg( \frac{1}{2} \cdot (X^2 / a^2 + Y^2 / b^2) \bigg)
    \right] \\
    &amp;\le \mathbb{E} \left[
        \exp \bigg( \frac{1}{2} \cdot (X^2 / a^2 ) \bigg)
        \cdot
        \exp \bigg( \frac{1}{2} \cdot (Y^2 / b^2) \bigg)
    \right] \\
    &amp;\le \mathbb{E} \left[
        \frac{1}{2} \cdot \left( \exp \bigg( \frac{1}{2} \cdot (X^2 /
a^2 ) \bigg) \right)^2
        +
        \frac{1}{2} \cdot \left( \exp \bigg( \frac{1}{2} \cdot (Y^2 /
b^2) \bigg) \right)^2
    \right] \\
    &amp;\le \frac{1}{2} \cdot \left( 2 + 2 \right)
    = 2.
\end{aligned}
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<blockquote>
<p><strong>Theorem (Centering).</strong> Given sub-exponential random
variables <span class="math inline">\(X\)</span>, it holds that <span
class="math display">\[
\Vert X − \mathbb{E} X \Vert_{\psi_1} \le C \Vert X \Vert_{\psi_1}.
\]</span></p>
</blockquote>
<p><strong>Proof.</strong> Since <span class="math inline">\(\Vert \cdot
\Vert_{\psi_1}\)</span> is a norm, it holds that <span
class="math display">\[
    \begin{aligned}
        \Vert X − \mathbb{E} X \Vert_{\psi_1}
            &amp;\le \Vert X \Vert_{\psi_1}
            + \Vert \mathbb{E} X \Vert_{\psi_1},
    \end{aligned}
\]</span> it suffices to bound <span class="math inline">\(\Vert
\mathbb{E} X \Vert_{\psi_1}\)</span>. Define <span
class="math inline">\(t = |\mathbb{E} X| / \ln 2\)</span>. Then <span
class="math display">\[
    \mathbb{E} \left[ \exp \left( |\mathbb{E} X| / t \right) \right]
        = \mathbb{E} \left[ \exp \left( \ln 2 \right) \right]
        = 2.
\]</span> Therefore, <span class="math display">\[
    \begin{aligned}
        \Vert \mathbb{E} X \Vert_{\psi_1}
            &amp;= \frac{1}{\ln 2} \cdot |\mathbb{E} X | \\
            &amp;\le \frac{1}{\ln 2} \cdot \mathbb{E} |X| \\
            &amp;= \frac{\Vert X \Vert_{\psi_1}}{\ln 2} \cdot \mathbb{E}
\left[ |X| / \Vert X \Vert_{\psi_1} \right] \\
            &amp;\le \frac{\Vert X \Vert_{\psi_1}}{\ln 2} \cdot \left(
                1 + \mathbb{E} \left[ \frac{|X|}{\Vert X \Vert_{\psi_1}}
\right] + \frac{1}{2!} \cdot \mathbb{E} \left[ \left( \frac{|X|}{\Vert X
\Vert_{\psi_1}} \right)^2 \right] + \frac{1}{3!} \cdot \mathbb{E} \left[
\left( \frac{|X|}{\Vert X \Vert_{\psi_1}} \right)^3 \right] + \cdots
            \right) \\
            &amp;\stackrel{(a)}{=} \frac{1}{\ln 2} \cdot \mathbb{E}
\left[ \exp \left( \frac{|X|}{\Vert X \Vert_{\psi_1}} \right) \right] \\
            &amp;= 2 \cdot \frac{ \Vert X \Vert_{\psi_1} }{\ln 2},
    \end{aligned}
\]</span> where <span class="math inline">\((a)\)</span> follows from
monotone convergence theorem.</p>
<p><span class="math inline">\(\square\)</span></p>
<blockquote>
<p><strong>Theorem (Bernstein’s Inequality).</strong> Let <span
class="math inline">\(X_1, \ldots, X_n\)</span> be independent mean-zero
sub-exponential random variables. Then, for every <span
class="math inline">\(t \ge 0\)</span>, we have <span
class="math display">\[
\Pr \left[ \sum_{i \in [n]} X_i \ge t \right]
\le 2 \exp \left( − c \min
\left(
\frac{t^2}{\sum_{i \in [n]} \Vert X_i \Vert_{\psi_1}^2},
\frac{t}{\max_{i \in [n]} \Vert X_i \Vert_{\psi_1}}
\right)
\right),
\]</span> where <span class="math inline">\(c &gt; 0\)</span> is an
absolute constant.</p>
</blockquote>
<p><strong>Proof.</strong> Let <span class="math inline">\(\lambda &gt;
0\)</span>. Since the <span class="math inline">\(K_i\)</span> in each
property in Theorem 1 differs by at most an absolute constant, and by
property (5) , when $ $ for some absolute constant <span
class="math inline">\(c\)</span>, it holds that <span
class="math display">\[
    \begin{aligned}
        \Pr \left[ \sum_{i \in [n]} X_i \ge t \right]
            \le \frac{
                \prod_{i \in [n]} \mathbb{E} \exp \left( \lambda \cdot
X_i \right)
            }{
                 \exp \left( \lambda \cdot t \right)
            }
            \le \exp \left( \sum_{i \in [n]} \lambda^2 \cdot c^* \cdot
\Vert X_i \Vert_{\psi_1}^2 - \lambda \cdot t \right),
    \end{aligned}
\]</span> where <span class="math inline">\(c^* = 1 / c&#39;\)</span>.
The RHS is minimized for <span class="math display">\[
    \lambda = \min \left\lbrace
        \frac{t}{
            2 \cdot c^* \cdot \sum_{i \in [n]} \Vert X_i
\Vert_{\psi_1}^2
        }
        ,\quad
        \frac{ c&#39; }{ \max_{i \in [n]}
            \Vert X_i \Vert_{\psi_1}
        }
    \right\rbrace,
\]</span> which gives <span class="math display">\[
    \begin{aligned}
        \Pr \left[ \sum_{i \in [n]} X_i \ge t \right]
            \le \exp \left(
                \sum_{i \in [n]} \lambda^2 \cdot c^* \cdot \Vert X_i
\Vert_{\psi_1}^2 - \lambda \cdot t
            \right).
    \end{aligned}
\]</span> When <span class="math inline">\(\lambda = \frac{t}{
            2 \cdot c^* \cdot \sum_{i \in [n]} \Vert X_i
\Vert_{\psi_1}^2
        } \le \frac{ c&#39; }{
           \max_{i \in [n]}  \Vert X_i \Vert_{\psi_1}
        },\)</span> we have <span class="math display">\[
    \sum_{i \in [n]} \lambda^2 \cdot c^* \cdot \Vert X_i
\Vert_{\psi_1}^2 - \lambda \cdot t
        = \frac{t^2}{
            4 \cdot c^* \cdot \sum_{i \in [n]} \Vert X_i
\Vert_{\psi_1}^2
        } - \frac{t^2}{
            2 \cdot c^* \cdot \sum_{i \in [n]} \Vert X_i
\Vert_{\psi_1}^2
        }
        = - \frac{t^2}{
            4 \cdot c^* \cdot \sum_{i \in [n]} \Vert X_i
\Vert_{\psi_1}^2
        }.
\]</span> When <span class="math inline">\(\lambda = \frac{ c&#39; }{
           \max_{i \in [n]}  \Vert X_i \Vert_{\psi_1}
        }
        \le \frac{t}{
            2 \cdot c^* \cdot \sum_{i \in [n]} \Vert X_i
\Vert_{\psi_1}^2
        },\)</span> we have <span class="math display">\[
\begin{aligned}
    \sum_{i \in [n]} \lambda^2 \cdot c^* \cdot \Vert X_i
\Vert_{\psi_1}^2 - \lambda \cdot t
        &amp;= \left(
            \frac{ c&#39; }{
                \max_{i \in [n]} \Vert X_i \Vert_{\psi_1}
            }
        \right)^2 \cdot \sum_{i \in [n]} c^* \cdot \Vert X_i
\Vert_{\psi_1}^2
        - \left(
            \frac{ c&#39; }{
                \max_{i \in [n]} \Vert X_i \Vert_{\psi_1}
            }
        \right) t \\
        &amp;\le \left(
            \frac{ c&#39; }{
                \max_{i \in [n]} \Vert X_i \Vert_{\psi_1}
            }
        \right)
        \cdot
        \frac{t}{
            2 \cdot c^* \cdot \sum_{i \in [n]} \Vert X_i
\Vert_{\psi_1}^2
        }
        \cdot \sum_{i \in [n]} c^* \cdot \Vert X_i \Vert_{\psi_1}^2
        - \left(
            \frac{ c&#39; }{
                \max_{i \in [n]} \Vert X_i \Vert_{\psi_1}
            }
        \right) t \\
        &amp;= - \frac{ c&#39; t }{
                2 \cdot \max_{i \in [n]} \Vert X_i \Vert_{\psi_1}
            }.
\end{aligned}
\]</span> It concludes that <span class="math display">\[
    \begin{aligned}
        \Pr \left[ \sum_{i \in [n]} X_i \ge t \right]
            &amp;\le \exp \left(
                \max \left\lbrace
                    - \frac{t^2}{
                        4 \cdot c^* \cdot \sum_{i \in [n]} \Vert X_i
\Vert_{\psi_1}^2
                    },
                    \,
                    - \frac{ c&#39; t }{
                        2 \cdot \max_{i \in [n]} \Vert X_i
\Vert_{\psi_1}
                    }
                \right\rbrace
            \right) \\
            &amp;= \exp \left(
                - \min \left\lbrace
                    \frac{t^2}{
                        4 \cdot c^* \cdot \sum_{i \in [n]} \Vert X_i
\Vert_{\psi_1}^2
                    },
                    \,
                    \frac{ c&#39; t }{
                        2 \cdot \max_{i \in [n]} \Vert X_i
\Vert_{\psi_1}
                    }
                \right\rbrace
            \right).
    \end{aligned}
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h1 id="reference">Reference</h1>
<p>[1] <em>R. Vershynin, "High-Dimensional Probability: An Introduction
with Applications in Data Science." in Cambridge Series in Statistical
and Probabilistic Mathematics. Cambridge: Cambridge University Press,
2018. doi: 10.1017/9781108231596.</em></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/06/14/Sub-Gaussian-Random-Variable/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | WOW">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/06/14/Sub-Gaussian-Random-Variable/" class="post-title-link" itemprop="url">Sub-Gaussian Random Variable</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-06-14 14:27:59" itemprop="dateCreated datePublished" datetime="2023-06-14T14:27:59-04:00">2023-06-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-11-25 14:43:54" itemprop="dateModified" datetime="2024-11-25T14:43:54-05:00">2024-11-25</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <blockquote>
<p><strong>Definition (Sub-Gaussian Random Variable).</strong> A random
variable <span class="math inline">\(X\)</span> is called a sub-gaussian
random variable, if it exhibits one of the following equivalent
properties: let <span class="math inline">\(K_i &gt; 0, i \in
[5]\)</span> be absolute constants.<br />
1. The tails of <span class="math inline">\(X\)</span> satisfy <span
class="math display">\[
\Pr[|X| \ge t]
\le 2 \exp \left(− \frac{t^2}{K_1^2} \right), \quad  \forall t \ge 0.
      \]</span> 2. The moments of <span class="math inline">\(X\)</span>
satisfy <span class="math display">\[
\Vert X \Vert_{L^p}
= ( \mathbb{E}|X|^p )^{1/p}
\le K_1 \sqrt[p]{p \cdot \Gamma(p / 2)}
\le
K_2 \sqrt{p},
\quad \forall p \ge 1.
      \]</span> 3. The MGF of <span class="math inline">\(X^2\)</span>
satisfies <span class="math display">\[
\mathbb{E} \exp(\lambda^2 X^2)
\le \exp(K_3^2 \lambda^2)
\quad \forall \lambda \, \text{ s.t. }, \, |\lambda| \le 1 / K_3 .
      \]</span> 4. The MGF of <span class="math inline">\(X^2\)</span>
is bounded at some point, namely <span class="math display">\[
\mathbb{E} \exp(X^2 / K_4^2) \le 2.
      \]</span><br />
5. Moreover, if <span class="math inline">\(\mathbb{E} [ X ] =
0\)</span> then properties 1 - 4 are also equivalent to the following
property. The MGF of <span class="math inline">\(X\)</span>
satisfies<br />
<span class="math display">\[
\mathbb{E} \exp(\lambda X) \le \exp(K_5^2 \lambda^2)
\quad \forall \lambda \in \R.
      \]</span></p>
</blockquote>
<p><strong>Proof.</strong></p>
<p><span class="math inline">\(1 \rightarrow 2:\)</span></p>
<p><span class="math display">\[
    \begin{aligned}
        \mathbb{E} \big[ |X|^p \big]
            &amp;= \int_0^\infty \Pr\big[ |X|^p \ge t \big] \, d t \\
            &amp;= \int_0^\infty \Pr\big[ |X| \ge t^{1 / p} \big] \, d t
\\
            &amp;\le \int_0^\infty 2 \cdot  \exp \left(− \frac{t^{2/
p}}{K_1^2} \right) \, d t     &amp; u = t^{2/p} / K_1^2 \rightarrow t =
K_1^p u^{p / 2} \\
            &amp;= \int_0^\infty 2 \cdot K_1^p \cdot (p / 2) \cdot u^{p
/ 2 - 1} e^{-u} \, d u \\
            &amp;= K_1^p \cdot p \cdot \Gamma(p / 2)
    \end{aligned}
\]</span></p>
<p>Applying the Stirling's approximation of <span
class="math inline">\(\Gamma(x) \le x^x\)</span>, and taking the <span
class="math inline">\(p\)</span> root of both sides given <span
class="math display">\[
        \mathbb{E} \big[ |X|^p \big] \le K_1 \cdot \sqrt[p]{p} \cdot
\sqrt{p / 2}.
\]</span></p>
<p><span class="math inline">\(2 \rightarrow 3:\)</span> By monotone
convergence theorem, <span class="math display">\[
    \begin{aligned}
        \mathbb{E} \exp(\lambda^2 X^2)
            &amp;= \mathbb{E} \left( 1 + \sum_{n \in \N^+}
\frac{\lambda^{2n} X^{2n}}{ n! } \right) \\
            &amp;= 1 + \sum_{n \in \N^+} \mathbb{E} \left(
\frac{\lambda^{2n} X^{2n}}{ n! } \right) \\
            &amp;\le 1 + \sum_{n \in \N^+} \frac{ ( \lambda^2 K_1^2 )^n
\cdot 2n \cdot \Gamma(n) }{ n! }
            &amp;  \text{since } \mathbb{E} |X|^{2n} \le K_1^{2n} \cdot
2 n \cdot \Gamma(2n / 2) \\
            &amp;\le 1 + 2 \cdot \sum_{n \in \N^+} (\lambda^2 K_1^2 )^n
\\
            &amp;= 1 + \frac{2 K_1^2 \lambda^2}{1 - K_1^2 \lambda^2}
&amp;  \text{provided that } K_1^2 \lambda^2 &lt; 1 \\
            &amp;= \frac{1 +  K_1^2 \lambda^2}{1 - K_1^2 \lambda^2}  \\
            &amp;= \exp(3 \cdot K_1^2 \lambda^2), &amp;  \frac{1 + x}{1
- x} \le e^{3x}, \, \forall x \in [0, 4 / 5].
    \end{aligned}
\]</span></p>
<p><span class="math inline">\(3 \rightarrow 4:\)</span> Taking <span
class="math inline">\(\lambda = 1 / K_3\)</span> in property 3 proves
property 4.</p>
<p><span class="math inline">\(4 \rightarrow 1:\)</span> By Markov's
inequality, we have <span class="math display">\[
    \begin{aligned}
        \Pr[|X| \ge t]
            &amp;= \Pr[X^2 / K_4^2 \ge t^2 / K_4^2] \\
            &amp;= \Pr[\exp (X^2 / K_4^2 ) \ge \exp( t^2 / K_4^2 )] \\
            &amp;\le \frac{ \mathbb{E} \exp(X^2 / K_4^2) }{ \exp( t^2 /
K_4^2 ) } \\
            &amp;\le 2 \exp( - t^2 / K_4^2 ).
    \end{aligned}
\]</span></p>
<p><span class="math inline">\(3 \rightarrow 5\)</span> (when <span
class="math inline">\(|\lambda| \cdot K_3 \le 1\)</span>): Since <span
class="math inline">\(e^x \le x + e^{x^2}, \forall x \in R\)</span>, we
have <span class="math display">\[
    \begin{aligned}
        \mathbb{E} \exp(\lambda X)
            &amp;\le \mathbb{E} \left( \lambda X + \exp(\lambda^2 X^2)
\right) \\
            &amp;= \mathbb{E} \left( \exp(\lambda^2 X^2) \right) \\
            &amp;\le \exp(K_3^2 \lambda^2).
    \end{aligned}
\]</span></p>
<p><span class="math inline">\(4 \rightarrow 5\)</span> (when <span
class="math inline">\(|\lambda| \cdot K_3 \ge 1\)</span>): Since <span
class="math inline">\(\lambda X \le (X^2 / K_3^2 + \lambda^2 \cdot
K_3^2) / 2\)</span>, we have <span class="math display">\[
    \begin{aligned}
        \mathbb{E} \exp(\lambda X)
            &amp;\le \mathbb{E} \exp \left( \frac{X^2 / K_3^2 +
\lambda^2 \cdot K_3^2}{2} \right) \\
            &amp;= \exp \left( \frac{\lambda^2 \cdot K_3^2}{2} \right)
\cdot \mathbb{E} \exp \left( \frac{X^2 / K_3^2 }{2} \right) \\
            &amp;\le \exp \left( \frac{\lambda^2 \cdot K_3^2}{2} \right)
\exp \left( \frac{1}{2} \right) \\
            &amp; \exp \left( \lambda^2 \cdot K_3^2 \right),
    \end{aligned}
\]</span> where the final inequality follows as <span
class="math inline">\(\lambda^2 K_3^2 \ge 1\)</span>.</p>
<p><span class="math inline">\(5 \rightarrow 1:\)</span> When <span
class="math inline">\(\lambda &gt; 0\)</span>, <span
class="math display">\[
    \begin{aligned}
        \Pr[X \ge t]
            &amp;= \Pr[ \exp(\lambda X) \ge \exp(\lambda t) ] \\
            &amp;\le \exp(- \lambda t) \cdot \mathbb{E} \exp(\lambda X)
\\
            &amp;\le \exp( - \lambda t + K_5^2 \lambda^2 ) \\
            &amp;= \exp \left( - \frac{t^2}{4 K_5^2} \right)
            &amp; \text{ choosing } \lambda = 1 / (2 K_5^2).
    \end{aligned}
\]</span> When <span class="math inline">\(\lambda &lt; 0\)</span>,
<span class="math display">\[
    \begin{aligned}
        \Pr[X \le -t]
            &amp;= \Pr[ \exp(\lambda X) \ge \exp(\lambda t) ] \\
            &amp;\le \exp(- \lambda t) \cdot \mathbb{E} \exp(\lambda X)
\\
            &amp;\le \exp( - \lambda t + K_5^2 \lambda^2 ) \\
            &amp;= \exp \left( - \frac{t^2}{4 K_5^2} \right)
            &amp; \text{ choosing } \lambda = 1 / (2 K_5^2).
    \end{aligned}
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<blockquote>
<p><strong>Remark.</strong> If <span class="math display">\[
\mathbb{E} \exp(\lambda X) \le \exp(K_5^2 \lambda^2)
\quad \forall \lambda \in \R,
\]</span> then it holds that <span class="math display">\[
\mathbb{E} [ X ] = 0, \quad \text{ and } \quad \mathbb{E} [ |X|^k ] \in
O(k!), \, \forall k \in \mathbb{N}^+.
\]</span></p>
</blockquote>
<p><strong>Proof.</strong> Since <span
class="math inline">\(\exp(|\lambda X|) \le \exp(-\lambda X) +
\exp(\lambda X)\)</span>, it holds that <span
class="math inline">\(\exp(|\lambda X|)\)</span> is integrable and <span
class="math display">\[
    \mathbb{E} \exp(|\lambda X|)
        \le 2 \cdot \exp(K_5^2 \lambda^2).
\]</span> It follows that <span class="math inline">\(\mathbb{E}
\exp(|X|) \in O(1)\)</span>. Since <span class="math inline">\(|X|^k \le
k! \cdot \exp(|X|)\)</span>, it is integrable and <span
class="math display">\[
    \mathbb{E} |X|^k \in O(k!).
\]</span></p>
<p>Further, as for each <span class="math inline">\(n \in
\mathbb{N}\)</span>, it holds that <span class="math display">\[
    \sum_{k = 0}^n \frac{\lambda^k X^k}{k!}
        \le \sum_{k = 0}^n \frac{|\lambda|^k |X|^k}{k!}
        \le \exp(|\lambda X|),
\]</span> by dominated convergence theorem, we have <span
class="math display">\[
    1 + \lambda \mathbb{E}[X] + \frac{\lambda^2}{2} \mathbb{E}[X^2] +
\sum_{k = 3}^\infty \frac{\lambda^k \mathbb{E}[X^k] }{k!}
        = \mathbb{E} \exp(\lambda X)
        \le \exp(K_5^2 \lambda^2)
        = 1 + K_5^2 \lambda^2 + \sum_{k = 2}^\infty \frac{
(K_5\lambda)^{2k} }{k!}.
\]</span> When <span class="math inline">\(|\lambda| &lt; 1\)</span> and
<span class="math inline">\(\lambda \rightarrow 0\)</span>, clearly
<span class="math display">\[
    \sum_{k = 2}^\infty \frac{ (K_5\lambda)^{2k} }{k!} \in o(\lambda^2).
\]</span></p>
<p>Observe that <span class="math display">\[
    \frac{\lambda^k \mathbb{E}[X^k] }{k!}
        \le \frac{\lambda^k \mathbb{E}[|X|^k] }{k!}
        \in O(\lambda^k).
\]</span> Therefore, <span class="math display">\[
    \left| \sum_{k = 3}^\infty \frac{\lambda^k \mathbb{E}[X^k] }{k!}
\right|
        \in O(\lambda^3) \in o(\lambda^2).
\]</span> Hence, <span class="math display">\[
    \lambda \mathbb{E}[X] + \frac{\lambda^2}{2} \mathbb{E}[X^2] +
o(\lambda^2)
        \le K_5^2 \lambda^2 + o(\lambda^2).
\]</span></p>
<p>Taking <span class="math inline">\(\lambda &gt; 0\)</span> and
letting <span class="math inline">\(\lambda \rightarrow 0\)</span> gives
<span class="math inline">\(\mathbb{E}[X] \le 0\)</span>.</p>
<p>Taking <span class="math inline">\(\lambda &lt; 0\)</span> and
letting <span class="math inline">\(\lambda \rightarrow 0\)</span> gives
<span class="math inline">\(\mathbb{E}[X] \ge 0\)</span>.</p>
<p>It concludes that <span class="math inline">\(\mathbb{E} [ X ] =
0\)</span>, and therefore <span class="math inline">\(\mathbb{E}[X^2]
\le 2 K_5^2\)</span>.</p>
<p><span class="math inline">\(\square\)</span></p>
<blockquote>
<p><strong>Definition.</strong> The sub-gaussian norm of <span
class="math inline">\(X\)</span>, denoted <span
class="math inline">\(\Vert X \Vert_{\psi_2}\)</span>, is defined to be
the smallest <span class="math inline">\(K_4\)</span> in property 4,
i.e., <span class="math display">\[
\Vert X \Vert_{\psi_2}
= \inf \{ t &gt; 0: \mathbb{E} \exp( X^2 / t^2) \le  2 \}.
\]</span></p>
</blockquote>
<p>We first show that <span class="math inline">\(\mathbb{E} \exp( X^2 /
\Vert X \Vert_{\psi_2}^2) \le  2\)</span>. Let <span
class="math inline">\(t_1, t_2, t_3, \ldots\)</span> be a decreasing
sequence such that <span class="math inline">\(t_i - \Vert X
\Vert_{\psi_2} \le 1 / k\)</span>. Then by monotone convergence theorem,
we have <span class="math display">\[
    \mathbb{E} \exp( X^2 / \Vert X \Vert_{\psi_2}^2)
        = \mathbb{E} \lim_{i \rightarrow \infty} \exp( X^2 / t_i^2 )
        = \lim_{i \rightarrow \infty} \mathbb{E} \exp( X^2 / t_i^2 )
        \le 2.
\]</span></p>
<p>We restate the previous theorem in terms of the sub-gaussian
norm.</p>
<ol type="1">
<li><span class="math inline">\(\Pr (|X| \ge t) \le  2 \exp( −c t^2 /
\Vert X \Vert_{\psi_2} ),  \quad \forall t \ge 0\)</span>;</li>
<li><span class="math inline">\(\Vert X  \Vert_{L_p} \le  C \sqrt{p}
\Vert X \Vert_{\psi_2}, \quad \forall p \ge 1\)</span></li>
<li><span class="math inline">\(\mathbb{E} \exp(X^2 / \Vert X
\Vert_{\psi_2} ) \le  2\)</span>;</li>
<li>if <span class="math inline">\(\mathbb{E} [ X ] = 0\)</span> then
<span class="math inline">\(\mathbb{E} \exp( \lambda X) \le \exp( C
\lambda^2 \Vert X \Vert_{\psi_2} ) , \quad \forall \lambda \in
\R\)</span>.</li>
</ol>
<p>Here <span class="math inline">\(C, c &gt; 0\)</span> are absolute
constants.</p>
<blockquote>
<p><strong>Theorem.</strong> <span class="math inline">\(\Vert \cdot
\Vert_{\psi_2}\)</span> is a norm on the space of sub-gaussian random
variables.</p>
</blockquote>
<p><strong>Proof.</strong> Let <span class="math inline">\(X\)</span>
and <span class="math inline">\(Y\)</span> be sub-gaussian random
variables, and <span class="math inline">\(a = \Vert X
\Vert_{\psi_2},  b = \Vert Y \Vert_{\psi_2}\)</span>. Then <span
class="math display">\[
    \begin{aligned}
        \mathbb{E} \exp \left( \frac{X + Y}{a + b} \right)^2
            &amp;= \mathbb{E} \exp \left( \frac{X}{a} \cdot \frac{a}{a +
b} + \frac{Y}{b} \cdot \frac{b}{a + b} \right)^2  \\
            &amp;\le \mathbb{E} \left[ \frac{a}{a + b} \exp \left(
\frac{X}{a}  \right)^2
            + \frac{b}{a + b} \cdot  \exp \left( \frac{Y}{b} \right)^2
\right]
            \le  2.
    \end{aligned}
\]</span> Hence, <span class="math display">\[
    \Vert X + Y \Vert_{\psi_2}  
        \le a + b
        = \Vert X \Vert_{\psi_2} + \Vert Y \Vert_{\psi_2}.
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<blockquote>
<p><strong>Theorem</strong> (Sums of independent sub-gaussians) Let
<span class="math inline">\(X_1, \ldots, X_N\)</span> be independent
mean-zero sub-gaussian random variables. Then <span
class="math inline">\(\sum_{i \in [N]} X_i\)</span> is also a
sub-gaussian random variable, and <span class="math display">\[
\left\Vert \sum_{i \in [N]} X_i \right\Vert_{\psi_2}^2
\le C \cdot \sum_{i \in [N]} \Vert X \Vert_{\psi_2}^2
\]</span> where <span class="math inline">\(C\)</span> is an absolute
constant.</p>
</blockquote>
<p><strong>Proof.</strong> <span class="math display">\[
    \begin{aligned}
        \mathbb{E} \exp \left( \lambda \sum_{i \in [N]} X_i \right)
            &amp;= \prod_{i \in [N]} \mathbb{E} \exp \left( \lambda  X_i
\right) \\
            &amp;\le \prod_{i \in [N]} \exp \left( C \lambda^2 \Vert X_i
\Vert_{\psi_2}^2 \right)
            = \exp \left( \sum_{i \in [N]} C \lambda^2 \Vert X_i
\Vert_{\psi_2}^2 \right).
    \end{aligned}
\]</span> Hence, <span class="math inline">\(\sum_{i \in [N]}
X_i\)</span> is sug-gaussian, and <span class="math inline">\(\Vert X_i
\Vert_{\psi_2}^2 \in O( \sum_{i \in [N]} \Vert X_i \Vert_{\psi_2}^2
)\)</span>.</p>
<p><span class="math inline">\(\square\)</span></p>
<blockquote>
<p><strong>Theorem (General Hoeffding Inequality).</strong> Let <span
class="math inline">\(X_1, \ldots, X_N\)</span> be independent mean-zero
sub-gaussian random variables. Then, <span class="math display">\[
\Pr \left( \left| \sum_{i \in [N]} X_i \right| \ge t \right)
\le 2 \exp \left( − \frac{c t^2}{\sum_{i \in [N]} \Vert X
\Vert_{\psi_2}^2} \right),
\quad t \ge 0.
\]</span></p>
</blockquote>
<p><strong>Proof.</strong> This can be viewed as a corollary as the
previous theorem.</p>
<p><span class="math inline">\(\square\)</span></p>
<blockquote>
<p><strong>Theorem (Khintchine’s inequality)</strong> Let <span
class="math inline">\(X_1, \ldots, X_N\)</span> be independent
sub-gaussian random variables with zero means and unit variances, and
let <span class="math inline">\(a = (a_1,\ldots,a_N) \in \R^N\)</span>.
Then for every <span class="math inline">\(p \in [2, \infty)\)</span> we
have <span class="math display">\[
\Vert a \Vert_2
\le  \left\Vert \sum_{i \in [N]} a_i X_i \right\Vert_{L_p}
\le  C K \sqrt{p} \Vert a \Vert_2
\]</span> where <span class="math inline">\(K = \max_i \Vert X_i
\Vert_{\psi_2}\)</span> and <span class="math inline">\(C\)</span> is an
absolute constant.</p>
</blockquote>
<p><strong>Proof.</strong> First, since <span class="math inline">\(p
\ge 2\)</span>, we have <span class="math display">\[
    \begin{aligned}
        \left\Vert \sum_{i \in [N]} a_i X_i \right\Vert_{L_p}
            &amp;\ge \left\Vert \sum_{i \in [N]} a_i X_i
\right\Vert_{L_2} \\
            &amp;= \left( \mathbb{E} \left[ \left( \sum_{i \in [N]} a_i
X_i \right)^2 \right] \right)^{1 / 2} \\
            &amp;= \left( \sum_{i, j \in [N]} \mathbb{E} \left[ a_i a_j
X_i X_j \right] \right)^{1 / 2}
            = \Vert a \Vert_2.
    \end{aligned}
\]</span></p>
<p>Let <span class="math inline">\(X \doteq \sum_{i \in [N]} a_i
X_i\)</span>. Then <span class="math display">\[
    \Vert X \Vert_{\psi_2}^2
        \le \sum_{i \in [n]} \Vert a_i X_i \Vert_{\psi_2}^2
        = \sum_{i \in [n]} a_i^2 \cdot \Vert X_i \Vert_{\psi_2}^2
        \le K^2 \cdot \Vert a \Vert_2^2.
\]</span> It follows that <span class="math display">\[
    \mathbb{E} [ |X|^p ]
        \in O( \sqrt{p} \cdot \Vert X \Vert_{\psi_2}  )
        \subseteq O( \sqrt{p} \cdot K \cdot \Vert a \Vert_2 ).
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<blockquote>
<p><strong>Theorem (Centering).</strong> If <span
class="math inline">\(X\)</span> is a sub-gaussian random variable then
<span class="math inline">\(X − \mathbb{E} [ X ]\)</span> is
sub-gaussian too and <span class="math display">\[
\Vert X − \mathbb{E} [ X ] \Vert_{\psi_2}
\le C \Vert X \Vert_{\psi_2},
\]</span> where <span class="math inline">\(C\)</span> is an absolute
constant.</p>
</blockquote>
<p><strong>Proof.</strong> Since <span class="math inline">\(\Vert \cdot
\Vert_{\psi_2}\)</span> is a norm, <span class="math display">\[
    \Vert X − \mathbb{E} [ X ] \Vert_{\psi_2}
        \le \Vert X \Vert_{\psi_2} + \Vert \mathbb{E} [ X ]
\Vert_{\psi_2}.
\]</span> It remains to bound the second term. By definition, we have
<span class="math display">\[
    \mathbb{E} \left[ \exp \left( \frac{(\mathbb{E} [ X ])^2}{ \big( (1
/ \ln 2)^{1 / 2} \cdot\mathbb{E} [ X ] \big)^2} \right) \right] = 2,
\]</span> Therefore, <span class="math display">\[
    \begin{aligned}
        \Vert \mathbb{E} [ X ] \Vert_{\psi_2}
            &amp;= \frac{1}{\sqrt{\ln 2}} \cdot \mathbb{E} [ X ]
            \le \frac{1}{\sqrt{\ln 2}} \cdot \mathbb{E} | X |
            \in O( \Vert X \Vert_{\psi_2} ).
    \end{aligned}
\]</span> <span class="math inline">\(\square\)</span></p>
<h1 id="reference">Reference</h1>
<p>[1] <em>R. Vershynin, High-Dimensional Probability: An Introduction
with Applications in Data Science. in Cambridge Series in Statistical
and Probabilistic Mathematics. Cambridge: Cambridge University Press,
2018.</em></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="Previous page" aria-label="Previous page" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/67/">67</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">WOW</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
