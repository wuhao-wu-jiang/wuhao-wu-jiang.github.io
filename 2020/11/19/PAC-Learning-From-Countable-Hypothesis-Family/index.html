<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="We generalize the PAC learning problem of finding an hypothesis from a finite hypothesis family to the one from a countable hypothesis family. Problem Setting  \(\mathcal{X}:\) the input space. \(">
<meta property="og:type" content="article">
<meta property="og:title" content="PAC Learning From Countable Hypothesis Family">
<meta property="og:url" content="http://example.com/2020/11/19/PAC-Learning-From-Countable-Hypothesis-Family/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:description" content="We generalize the PAC learning problem of finding an hypothesis from a finite hypothesis family to the one from a countable hypothesis family. Problem Setting  \(\mathcal{X}:\) the input space. \(">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-11-19T04:17:27.000Z">
<meta property="article:modified_time" content="2021-03-27T00:22:12.964Z">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2020/11/19/PAC-Learning-From-Countable-Hypothesis-Family/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>PAC Learning From Countable Hypothesis Family | WOW</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">WOW</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">你生之前悠悠千載已逝<br>未來還會有千年沉寂的期待</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/11/19/PAC-Learning-From-Countable-Hypothesis-Family/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          PAC Learning From Countable Hypothesis Family
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-19 15:17:27" itemprop="dateCreated datePublished" datetime="2020-11-19T15:17:27+11:00">2020-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-03-27 11:22:12" itemprop="dateModified" datetime="2021-03-27T11:22:12+11:00">2021-03-27</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>We generalize the PAC learning problem of finding an hypothesis from a finite hypothesis family to the one from a countable hypothesis family.</p>
<h1 id="problem-setting">Problem Setting</h1>
<ol type="1">
<li><p><span class="math inline">\(\mathcal{X}:\)</span> the input space.</p></li>
<li><p><span class="math inline">\(\mathcal{Y} \doteq \{-1, 1\}:\)</span> the output space.</p></li>
<li><p><span class="math inline">\(\mathcal{Z} \doteq \mathcal{X} \times \mathcal{Y}:\)</span> the product space of <span class="math inline">\(\mathcal{X}\)</span> and <span class="math inline">\(\mathcal{Y}\)</span>.</p></li>
<li><p><span class="math inline">\(\mathcal{D}:\)</span> an unknown distribution defined on <span class="math inline">\(\mathcal{X} \times \mathcal{Y}\)</span>.</p></li>
<li><p><span class="math inline">\(\mathcal{H}:\)</span> an countable family of hypothesis, s.t., each <span class="math inline">\(h \in \mathcal{H}\)</span> is a function from <span class="math inline">\(\mathcal{X}\)</span> to <span class="math inline">\(\mathcal{Y}\)</span>.</p></li>
<li><p><span class="math inline">\(\ell: \mathcal{Y} \times \mathcal{Y} \rightarrow [0, 1]\)</span>, a loss function that takes two points in <span class="math inline">\(\mathcal{Y}\)</span> and outputs a value between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>.</p></li>
<li><p><span class="math inline">\(L_\mathcal{D} (h):\)</span> the expected loss of a hypothesis <span class="math inline">\(h\)</span> is defined as <span class="math display">\[
 L_\mathcal{D} (h) = \mathbb{E}_{ (x, y) \sim \mathcal{D} } [ \ell( h(x), y) ]
 \]</span></p>
<p>where <span class="math inline">\((x, y) \sim \mathcal{D}\)</span> implies that the pair <span class="math inline">\((x, y) \in \mathcal{Z}\)</span> is sampled according to the distribution <span class="math inline">\(\mathcal{D}\)</span>.</p></li>
<li><p><span class="math inline">\(h^* \doteq \arg\min_{h \in \mathcal{H} } L_\mathcal{D} (h):\)</span> the hypothesis that minimize the expected loss.</p></li>
<li><p><span class="math inline">\(\mu_h:\)</span> an alias for <span class="math inline">\(L_\mathcal{D} (h)\)</span>, when the distribution <span class="math inline">\(\mathcal{D}\)</span> discussed in the context is unique.</p></li>
<li><p><span class="math inline">\(B(\mu_h, \epsilon) \doteq \{ r \in \mathbb{R} : |r - \mu_h | &lt; \epsilon \}:\)</span> an open ball, which is an open interval in <span class="math inline">\(\mathbb{R}\)</span> centered at <span class="math inline">\(\mu_h\)</span> with length <span class="math inline">\(2 \epsilon\)</span>, where <span class="math inline">\(\epsilon &gt; 0\)</span>.</p></li>
<li><p><span class="math inline">\(S \sim \mathcal{D}^n:\)</span> a set of <span class="math inline">\(n\)</span> i.i.d samples drawn from <span class="math inline">\(\mathcal{D}\)</span>, where <span class="math inline">\(n \in \mathbb{N}^+\)</span> is some positive integer. In particular, when <span class="math inline">\(S \sim \mathcal{D}^n\)</span>, it can be represented as <span class="math display">\[
 S = \{ (x_1, y_1), (x_2, y_2), ..., (x_n, y_n) : (x_i, y_i) \sim \mathcal  {D}, \forall i \in [n] \}.
 \]</span> We also view <span class="math inline">\(S\)</span> as a point in <span class="math inline">\(\mathcal{Z}^n\)</span>.</p></li>
<li><p><span class="math inline">\(L_{S}(h) \doteq \frac{1}{ |S| } \sum_{ (x, y) \in S } \ell( h(x) , y ) :\)</span> the empirical loss of a hypothesis <span class="math inline">\(h\)</span> on a sample set <span class="math inline">\(S\)</span>.</p></li>
<li><p>Given a <span class="math inline">\(h \in \mathcal{H}\)</span>, its restriction on <span class="math inline">\(\mathcal{C} \subset \mathcal{X}\)</span> is a function <span class="math inline">\(h_S\)</span> defined on <span class="math inline">\(S\)</span>, such that <span class="math display">\[
h_\mathcal{C} (x) = h(x), \forall x \in \mathcal{C} 
\]</span></p></li>
<li><p>The restriction of <span class="math inline">\(\mathcal{H}\)</span> on <span class="math inline">\(\mathcal{C}\)</span> is the set of possible restriction of a function in <span class="math inline">\(\mathcal{H}\)</span> to <span class="math inline">\(\mathcal{C}\)</span> <span class="math display">\[
        \mathcal{H}_\mathcal{C}  = \{ h_\mathcal{C}  : \mathcal{C}  \rightarrow \mathcal{Y} : h \in \mathcal{H} \}
\]</span></p>
<p>As <span class="math inline">\(\mathcal{Y} = \{ -1, +1 \}\)</span>, the set of possible functions defined on <span class="math inline">\(\mathcal{C}\)</span> is bounded by <span class="math inline">\(2^{n}\)</span>. Hence, <span class="math display">\[
    |\mathcal{H}_\mathcal{C} | \le 2^{n}.
\]</span></p></li>
<li><p>The growth function <span class="math inline">\(\Pi_{\mathcal{H} } (n): \mathbb{N}^+ \rightarrow \mathbb{N}^+\)</span> of <span class="math inline">\(\mathcal{H}\)</span> is defined as <span class="math display">\[
   \Pi_{\mathcal{H} } (n) = \max_{\mathcal{C} \subset \mathcal{X}, |C| = n} | \mathcal{H}_\mathcal{C} |
   \]</span></p></li>
</ol>
<p>Ideally, we would like to find <span class="math inline">\(h^*\)</span>. The problem is difficult, as</p>
<ul>
<li>The space <span class="math inline">\(\mathcal{X} \times \mathcal{Y}\)</span> could be infinite.</li>
<li>The distribution <span class="math inline">\(\mathcal{D}\)</span> is unknown.</li>
</ul>
<p>To deal with the possibly infinite space <span class="math inline">\(\mathcal{X} \times \mathcal{Y}\)</span> and the unknown distribution <span class="math inline">\(\mathcal{D}\)</span>, we investigate <span class="math inline">\(\mathcal{H}\)</span> on a finite sample set <span class="math inline">\(S\)</span>. Due to the randomness inherited in sampling <span class="math inline">\(S\)</span>, we allow our solution to be approximate and to make error. For a given pair of parameters of <span class="math inline">\(\epsilon &gt; 0\)</span> and <span class="math inline">\(\delta &gt; 0\)</span>, we relax the goal to designing an <span class="math inline">\((\epsilon, \delta)\)</span>-learning algorithm <span class="math inline">\(A\)</span> that returns an <span class="math inline">\(h&#39;\)</span>, that is</p>
<blockquote>
<ul>
<li><span class="math inline">\(\epsilon\)</span>-approximate: <span class="math inline">\(\mu_{h&#39;} \le \mu_{h^*} + \epsilon\)</span>,<br />
</li>
<li>probably correct: <span class="math inline">\(A\)</span> return an <span class="math inline">\(h&#39;\)</span> that does not satisfies the above condition with probability at most <span class="math inline">\(\delta\)</span>.</li>
</ul>
</blockquote>
<p>Combined, <span class="math inline">\(A\)</span> should return an <span class="math inline">\(\epsilon\)</span>-approximate solution <span class="math inline">\(h&#39;\)</span> with probability at least <span class="math inline">\(1 - \delta\)</span>.</p>
<h1 id="the-algorithm">The Algorithm</h1>
<blockquote>
<p>An <span class="math inline">\((\epsilon, \delta)\)</span> approximate algorithm <span class="math inline">\(A\)</span><br />
1. Draw a set <span class="math inline">\(S\)</span> of <span class="math inline">\(n =\)</span> samples independently from <span class="math inline">\(\mathcal{D}\)</span>.<br />
2. Return an <span class="math inline">\(h&#39;\)</span> such that <span class="math display">\[
h&#39; = \arg\min_{h \in \mathcal{H} } L_{S} (h)
\]</span></p>
</blockquote>
<p>A key result of the algorithm states that <span class="math inline">\(L_S(h)\)</span> is a good approximation of <span class="math inline">\(\mu_h\)</span> for all <span class="math inline">\(h \in \mathcal{H}\)</span> simultaneously.</p>
<blockquote>
<p>Theorem. If <span class="math inline">\(n \ge\)</span>, then <span class="math display">\[
\Pr_{S \sim \mathcal{D}^n } [ \exists h \in \mathcal{H} : L_S(h) \notin B(\mu_h, \epsilon / 2 )  ] \le \delta
\]</span></p>
</blockquote>
<p>An immediate corollary is that <span class="math inline">\(h&#39;\)</span> is <span class="math inline">\(\epsilon\)</span>-approximate with probability at least <span class="math inline">\(1 - \delta\)</span>: <span class="math display">\[
\mu_{h&#39;} \le L_S(h&#39;) + \frac{\epsilon}{2} \le L_S(h^*) + \frac{\epsilon}{2} \le \mu_{h^*} + \epsilon.
\]</span></p>
<h2 id="proof-of-the-theorem">Proof of The Theorem</h2>
<p>The proof relies on a technique called double sampling. Alongside with <span class="math inline">\(S\)</span>, we create another sample set <span class="math inline">\(S&#39; \sim \mathcal{D}^n\)</span> independently, termed the "ghost sample". Let <span class="math display">\[
S = \{ (x_1, y_1), (x_2, y_2), ..., (x_n, y_n) \}
\]</span> and <span class="math display">\[
S&#39; = \{ (x_1&#39;, y_1&#39;), (x_2&#39;, y_2&#39;), ..., (x_n&#39;, y_n&#39;) \}.
\]</span></p>
<p>Then, we define</p>
<ol start="16" type="1">
<li><span class="math inline">\(\sigma:\)</span> a random swap that exchanges the <span class="math inline">\(i\)</span>-th (<span class="math inline">\(i \in [n]\)</span>) element of <span class="math inline">\(S\)</span> and <span class="math inline">\(S&#39;\)</span> independently with probability 0.5. Call the resulting sample sets <span class="math inline">\(\sigma S\)</span> and <span class="math inline">\(\sigma S&#39;\)</span>. Let <span class="math inline">\(\sigma S[i]\)</span> (<span class="math inline">\(\sigma S&#39;[i]\)</span>) be the <span class="math inline">\(i\)</span>-th element of <span class="math inline">\(\sigma S[i]\)</span> (<span class="math inline">\(\sigma S&#39;[i]\)</span>). So <span class="math display">\[
\Pr \left[ 
    \sigma S [i] = (x_i,  y_i) \wedge
    \sigma S&#39;[i] = (x_i&#39;, y_i&#39;)
 \right] = 0.5 \\
 \Pr \left[ 
    \sigma S [i] = (x_i&#39;, y_i&#39;) \wedge
    \sigma S&#39;[i] = (x_i,  y_i)
 \right] = 0.5
\]</span></li>
</ol>
<p>We use the gap of <span class="math inline">\(|L_{\sigma S} (h) - L_{\sigma S&#39;} (h)|\)</span> as a proxy of <span class="math inline">\(|L_S(h) - \mu_h|\)</span>. This enables us to focus on finite sets <span class="math inline">\(S\)</span> and <span class="math inline">\(S&#39;\)</span> without worrying about the infinite size of <span class="math inline">\(\mathcal{H}\)</span>.</p>
<p>For convenience, we use <span class="math inline">\(\underset{S}{\Pr}[\cdot]\)</span> (<span class="math inline">\(\underset{S&#39;}{\Pr}[\cdot]\)</span>) as shorthand for <span class="math inline">\(\underset{S \sim \mathcal{D}^n}{\Pr}[\cdot]\)</span> (<span class="math inline">\(\underset{S&#39; \sim \mathcal{D}^n}{\Pr}[\cdot]\)</span>). The road map of our proof is as follows.</p>
<blockquote>
<p>Lemma 1.<br />
<span class="math display">\[
\Pr_{S}[ \exists h : L_S(h) \notin B(\mu_h, \epsilon ) ] \le 2 \max_{S, S&#39; \in \mathcal{Z}^n } \Pr_\sigma \left[ \exists h : |L_{ \sigma S} (h) - L_{ \sigma S&#39; } (h) | \ge \frac{\epsilon}{2} \right]
\]</span></p>
</blockquote>
<p>On the left hand side of the inequality, the probability measures the event of a random set <span class="math inline">\(S\)</span> sampling from <span class="math inline">\(\mathcal{D}\)</span>. On the right hand side, we can pick a fixed pair of <span class="math inline">\(S\)</span> and <span class="math inline">\(S&#39;\)</span> that maximize <span class="math display">\[
\Pr_\sigma \left[ \exists h : |L_{ \sigma S} (h) - L_{ \sigma S&#39; } (h) | \ge \frac{\epsilon}{2} \right],
\]</span></p>
<p>and the probability measures the event of the random swap <span class="math inline">\(\sigma\)</span>. Fixing <span class="math inline">\(S\)</span> and <span class="math inline">\(S&#39;\)</span> significantly simplifies the structure of <span class="math inline">\(\mathcal{H}\)</span>. By Hoeffding inequality and union bound, we will prove that</p>
<blockquote>
<p>Lemma 2. For any fixed pair of <span class="math inline">\(S, S&#39; \in \mathcal{Z}^n\)</span>, <span class="math display">\[
\Pr_\sigma \left[ \exists h : |L_{ \sigma S} (h) - L_{ \sigma S&#39; } (h) | \ge \frac{\epsilon}{2} \right] \le 2 \Pi_\mathcal{H} (2n) \exp( - \frac{n^2 \epsilon^2 }{2} )
\]</span></p>
</blockquote>
<h3 id="proof-of-lemma-1."><strong>Proof of Lemma 1.</strong></h3>
<p>The proof of Lemma 1 consists of three steps.</p>
<h4 id="step-1"><strong>Step 1</strong></h4>
<blockquote>
<p><span class="math display">\[
\Pr_{S}[ \exists h : L_S(h) \notin B(\mu_h, \epsilon ) ] \le 2 \Pr_{S , S&#39;} [ \exists h : L_S (h) \notin B(\mu_h, \epsilon )  \wedge  L_{S&#39;} (h) \in B(\mu_h, \epsilon / 2)  ].
\]</span></p>
</blockquote>
<p><strong>Proof.</strong> By Hoeffding inequality, for a fixed <span class="math inline">\(h \in \mathcal{H}\)</span>, when <span class="math inline">\(n \ge \frac{2}{\epsilon^2} \ln 4\)</span> <span class="math display">\[
    \Pr_{S&#39;} [ L_{S&#39;} (h) \notin B(\mu_h, \epsilon / 2) ] \le 2 \exp \left(- 2 n \left( \frac{\epsilon }{ 2 } \right)^2 \right) = 2 \exp \left( - \frac{n \epsilon^2}{2} \right) \le \frac{1}{2}
\]</span></p>
<p>It follows that <span class="math display">\[
    \Pr_{S , S&#39;} [ \exists h : L_S (h) \notin B(\mu_h, \epsilon )  \wedge  L_{S&#39;} (h) \in B(\mu_h, \epsilon / 2)  ] 
        \ge 
    \frac{1}{2} \Pr_{S}[ \exists h : L_S(h) \notin B(\mu_h, \epsilon ) ]
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<p><strong>Remark:</strong> Mathematically, I don't know how to make prove this step rigorously. Suppose that for every <span class="math inline">\(i \in [n]\)</span>, we know that the events <span class="math inline">\(E_i\)</span> and <span class="math inline">\(F_i\)</span> are measurable and independent. If <span class="math inline">\(\Pr[ F_i ] \ge 1 / 2\)</span>, then <span class="math inline">\(\Pr[ E_i \wedge F_i ] \ge 1 / 2\)</span>. But, can we claim that <span class="math display">\[
    \Pr[ \cup (E_i \wedge F_i) ] \ge \frac{1}{2} \Pr[ \cup E_i ]. 
\]</span></p>
<h4 id="step-2"><strong>Step 2</strong></h4>
<blockquote>
<p><span class="math display">\[
\Pr_{S} [ \exists h : L_S (h) \notin B(\mu_h, \epsilon )  \wedge  L_{S&#39;} (h) \in B(\mu_h, \epsilon / 2) ] 
\le 
\Pr_{S, S&#39;} \left[ \exists h : |L_S (h) - L_{S&#39;} (h) | \ge \frac{\epsilon}{2} \right]
\]</span></p>
</blockquote>
<p><strong>Proof</strong>. Observe that <span class="math display">\[
    \{  \exists h : L_S (h) \notin B(\mu_h, \epsilon )  \wedge  L_{S&#39;} (h) \in B(\mu_h, \epsilon / 2)  \} 
        \subset 
    \left\{  \exists h : |L_S (h) - L_{S&#39;} (h) | \ge \frac{\epsilon}{2} \right\}. 
\]</span> By monotonicity of probability, we finish the proof.</p>
<p><span class="math inline">\(\square\)</span></p>
<h4 id="step-3"><strong>Step 3</strong></h4>
<blockquote>
<p><span class="math display">\[
\Pr_{S, S&#39; } \left[  \exists h : |L_S (h) - L_{S&#39;} (h) | \ge \frac{\epsilon}{2} \right] 
\le 
\max_{S, S&#39; \in \mathcal{Z}^n } \Pr_\sigma \left[ \exists h : |L_{ \sigma S} (h) - L_{ \sigma S&#39; } (h) | \ge \frac{\epsilon}{2} \right]
\]</span></p>
</blockquote>
<p><strong>Proof.</strong> We claim that <span class="math inline">\(\sigma S\)</span> and <span class="math inline">\(\sigma S&#39;\)</span> have the same joint distribution as <span class="math inline">\(S\)</span> and <span class="math inline">\(S&#39;\)</span> (if <span class="math inline">\(S, S&#39; \sim \mathcal{D}^n\)</span>). For points <span class="math inline">\(\forall Z, Z&#39; \in \mathcal{Z}^n\)</span>, by symmetry, it holds that <span class="math display">\[
\Pr_{S, S&#39;} [ S = Z, S&#39; = Z&#39;] = \Pr_{S, S&#39;, \sigma} [ \sigma S = Z, \sigma S&#39; = Z&#39;]
\]</span></p>
<p>The right hand side can be viewed as the successful probability of the following experiment:</p>
<ul>
<li>Sample independently <span class="math inline">\(S \sim \mathcal{D}^n\)</span> and <span class="math inline">\(S&#39; \sim \mathcal{D}^n\)</span>.<br />
</li>
<li>For each <span class="math inline">\(i \in [n]\)</span>, exchange the <span class="math inline">\(i\)</span>-th elements of <span class="math inline">\(S\)</span> and <span class="math inline">\(S&#39;\)</span> independently with probability <span class="math inline">\(0.5\)</span>.</li>
<li>After the random swap, <span class="math inline">\(\sigma S = Z\)</span> and <span class="math inline">\(\sigma S&#39; = Z&#39;\)</span>.</li>
</ul>
<p>Now, <span class="math inline">\(\forall \mathcal{E} \subset \mathcal{Z}^{2n}\)</span>, it holds that <span class="math display">\[
\begin{aligned}
    \Pr_{S, S&#39;} [ (S, S&#39;) \in \mathcal{E} ] 
        &amp;= \Pr_{S, S&#39;, \sigma} [ (\sigma S, \sigma S&#39;) \in \mathcal{E} ] \\
        &amp;= \mathbb{E}_{S, S&#39;} [ \Pr_\sigma [(\sigma S, \sigma S&#39;) \in \mathcal{E} ] \mid S, S&#39; ] \\
        &amp;\le \max_{S, S&#39; \in \mathcal{Z}^n } \Pr_\sigma [(\sigma S, \sigma S&#39;) \in \mathcal{E} ]
\end{aligned}
\]</span></p>
<p>Replacing <span class="math inline">\(\mathcal{E}\)</span> with the set <span class="math inline">\(\{Z, Z&#39; \in \mathcal{Z}^n : \exists h : |L_Z (h) - L_{Z&#39;} (h) | \ge \frac{\epsilon}{2} \}\)</span> finishes the proof.</p>
<p><span class="math inline">\(\square\)</span></p>
<!-- *Remark of the proof of step 1.* If we define 
$$
\mathcal{H}(S, \epsilon) \doteq \{ h \in \mathcal{H} :L_S(h) \notin B(\mu_h, \epsilon ) \}.
$$
*which is the set of hypothesis whose empirical loss on $S$ is $\epsilon$ more than its expectation. Then,* 
$$
\begin{aligned}
    \Pr_{S} [ \exists h : L_S(h) \notin B(\mu_h, \epsilon ) ] \cdot \frac{1}{2} 
    &= \Pr_{S } [ \mathcal{H}(S, \epsilon) \neq \emptyset ] \cdot \frac{1}{2} \\
    &\le \Pr_{S } [ \mathcal{H}(S, \epsilon) \neq \emptyset] \\
    & \ \ \cdot \Pr_{S, S' } [ \exists h \in \mathcal{H}(S, \epsilon) : L_{S'} (h) \in B(\mu_h, \epsilon / 2 ) \mid \mathcal{H}(S, \epsilon) \neq \emptyset ] \\
    &= \Pr_{S, S' } [ \exists h : L_S (h) \notin B(\mu_h, \epsilon )  \wedge L_{S'} (h) \in B(\mu_h, \epsilon / 2 )  ]
\end{aligned}
$$

*Note that the event $\mathcal{H}(S, \epsilon) \neq \emptyset$ is equivalent to the one* 
$$
\cup_{h \in \mathcal{H} } \{ L_S(h) \notin B(\mu_h, \epsilon ) \} 
$$

*For a fixed $h \in \mathcal{H}$, the event $\{ L_S(h) \notin B(\mu_h, \epsilon ) \}$ is measurable when $S$ consists of a finite number of i.i.d samples from $\mathcal{D}$. If $\mathcal{H}$ consists of countable number of $h$, then $\cup_{h \in \mathcal{H} } \{ L_S(h) \notin B(\mu_h, \epsilon ) \}$ is a countable union and should be measurable.*  -->
<h3 id="proof-of-lemma-2."><strong>Proof of Lemma 2.</strong></h3>
<p>Let <span class="math display">\[
S = \{ (x_1, y_1), (x_2, y_2), ..., (x_n, y_n) \}
\]</span> and <span class="math display">\[
S&#39; = \{ (x_1&#39;, y_1&#39;), (x_2&#39;, y_2&#39;), ..., (x_n&#39;, y_n&#39;) \}.
\]</span> be a pair of fixed sample sets. Define the set <span class="math inline">\(\mathcal{C} = \{ x_1, x_2, ..., x_n, x_1&#39;, x_2&#39;, ..., x_n&#39; \} \subset \mathcal{X}\)</span> (with duplicates removed). The size of <span class="math inline">\(\mathcal{C}\)</span> is bounded by <span class="math inline">\(2n\)</span> and therefore the size of restriction of <span class="math inline">\(\mathcal{H}\)</span> on <span class="math inline">\(\mathcal{C}\)</span> is bounded by <span class="math inline">\(\Pi_\mathcal{H} (2n)\)</span>.</p>
<p>First, fix a hypothesis <span class="math inline">\(h\)</span>. For all <span class="math inline">\(i \in [n]\)</span>, define <span class="math inline">\(a_i = |\ell( h( x_i ), y_i) - \ell( h( x_i&#39; ), y_i&#39; ) | \le 1\)</span> and let <span class="math inline">\(V_i \in \{-1, 1\}\)</span> be a random variable with equal probability: <span class="math display">\[
\Pr[ V_i = -1 ] = \Pr[ V_i = 1] = 0.5
\]</span></p>
<p>If we apply a random swap <span class="math inline">\(\sigma\)</span> to <span class="math inline">\((S, S&#39;)\)</span>, then <span class="math inline">\(L_{ \sigma S} (h_S) - L_{ \sigma S&#39; } (h_S)\)</span> has the same distribution as <span class="math inline">\(\sum_{i \in [n] } \frac{1}{n} a_i V_i\)</span>. Since <span class="math display">\[
\mathbb{E} \left[ \sum_{i \in [n] } \frac{1}{n} a_i V_i \right] = \sum_{i \in [n] } \frac{1}{n} a_i \mathbb{E}[ V_i ] = 0,
\]</span></p>
<p>by Hoeffding inequality, <span class="math display">\[
\begin{aligned}
    \Pr_\sigma \left[ |L_{ \sigma S} (h) - L_{ \sigma  S&#39; } (h) | \ge \frac{\epsilon}{2} \right] 
        &amp;= \Pr \left[ \left| \sum_{i \in [n] } \frac{1}{n} a_i V_i - 0 \right| \ge \frac{\epsilon}{2} \right] \\
        &amp;\le 2 \exp \left( - \frac{ 2 }{  \sum_{i \in [n] } a_i^2 } \left( \frac{n \epsilon}{2} \right)^2 \right)  \\
        &amp;\le 2 \exp \left( - \frac{n^2 \epsilon^2 }{2} \right)
\end{aligned}
\]</span></p>
<p>The last inequality follows from that <span class="math inline">\(\sum_{i \in [n] } a_i^2 \le n\)</span>.</p>
<p>Since for each <span class="math inline">\(h \in \mathcal{H}\)</span>, it has the same behavior on <span class="math inline">\(\mathcal{C}\)</span> as some function in <span class="math inline">\(\mathcal{H}_\mathcal{C}\)</span>. We can apply union bound on <span class="math inline">\(\mathcal{H}_\mathcal{C}\)</span>. <span class="math display">\[
\Pr_\sigma \left[ \exists h : |L_{ \sigma S} (h) - L_{ \sigma  S&#39; } (h) | \ge \frac{\epsilon}{2} \right] \le 2 |\mathcal{H}_\mathcal{C} | \exp \left( - \frac{n^2 \epsilon^2 }{2} \right) \le 2 \Pi_\mathcal{H} (2n) \exp \left( - \frac{n^2 \epsilon^2 }{2} \right)
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h1 id="reference">Reference</h1>
<p>[1] Ethan Fetaya, "Lecture 02 - Introduction to Statistical Learning Theory", Weizmann Institute of Science, 2016</p>
<p>[2].R. Schapire and D. Bieber, “Lecture 05 - COS 511: Theoretical Machine Learning,”, Princeton University, 2013</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/11/13/Advanced-Composition/" rel="prev" title="Advanced Composition">
      <i class="fa fa-chevron-left"></i> Advanced Composition
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/11/23/Propose-Test-Release/" rel="next" title="Propose-Test-Release">
      Propose-Test-Release <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#problem-setting"><span class="nav-number">1.</span> <span class="nav-text">Problem Setting</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#the-algorithm"><span class="nav-number">2.</span> <span class="nav-text">The Algorithm</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#proof-of-the-theorem"><span class="nav-number">2.1.</span> <span class="nav-text">Proof of The Theorem</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#proof-of-lemma-1."><span class="nav-number">2.1.1.</span> <span class="nav-text">Proof of Lemma 1.</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#step-1"><span class="nav-number">2.1.1.1.</span> <span class="nav-text">Step 1</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#step-2"><span class="nav-number">2.1.1.2.</span> <span class="nav-text">Step 2</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#step-3"><span class="nav-number">2.1.1.3.</span> <span class="nav-text">Step 3</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#proof-of-lemma-2."><span class="nav-number">2.1.2.</span> <span class="nav-text">Proof of Lemma 2.</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#reference"><span class="nav-number">3.</span> <span class="nav-text">Reference</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">141</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WOW</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
