<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.24.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="We generalize the PAC learning problem of finding an hypothesis from a finite hypothesis family to the one from a countable hypothesis family. Problem Setting  \(\mathcal{X}:\) the input space.">
<meta property="og:type" content="article">
<meta property="og:title" content="PAC Learning From Countable Hypothesis Family">
<meta property="og:url" content="http://example.com/2020/11/19/PAC-Learning-From-Countable-Hypothesis-Family/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:description" content="We generalize the PAC learning problem of finding an hypothesis from a finite hypothesis family to the one from a countable hypothesis family. Problem Setting  \(\mathcal{X}:\) the input space.">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-11-19T20:17:27.000Z">
<meta property="article:modified_time" content="2021-03-27T00:22:12.000Z">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/2020/11/19/PAC-Learning-From-Countable-Hypothesis-Family/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2020/11/19/PAC-Learning-From-Countable-Hypothesis-Family/","path":"2020/11/19/PAC-Learning-From-Countable-Hypothesis-Family/","title":"PAC Learning From Countable Hypothesis Family"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>PAC Learning From Countable Hypothesis Family | WOW</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">WOW</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">你生之前悠悠千載已逝<br>未來還會有千年沉寂的期待</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#problem-setting"><span class="nav-number">1.</span> <span class="nav-text">Problem Setting</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#the-algorithm"><span class="nav-number">2.</span> <span class="nav-text">The Algorithm</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#proof-of-the-theorem"><span class="nav-number">2.1.</span> <span class="nav-text">Proof of The Theorem</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#proof-of-lemma-1."><span class="nav-number">2.1.1.</span> <span class="nav-text">Proof of Lemma 1.</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#step-1"><span class="nav-number">2.1.1.1.</span> <span class="nav-text">Step 1</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#step-2"><span class="nav-number">2.1.1.2.</span> <span class="nav-text">Step 2</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#step-3"><span class="nav-number">2.1.1.3.</span> <span class="nav-text">Step 3</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#proof-of-lemma-2."><span class="nav-number">2.1.2.</span> <span class="nav-text">Proof of Lemma 2.</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#reference"><span class="nav-number">3.</span> <span class="nav-text">Reference</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">200</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/11/19/PAC-Learning-From-Countable-Hypothesis-Family/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="PAC Learning From Countable Hypothesis Family | WOW">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          PAC Learning From Countable Hypothesis Family
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-11-19 15:17:27" itemprop="dateCreated datePublished" datetime="2020-11-19T15:17:27-05:00">2020-11-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2021-03-26 20:22:12" itemprop="dateModified" datetime="2021-03-26T20:22:12-04:00">2021-03-26</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>We generalize the PAC learning problem of finding an hypothesis from
a finite hypothesis family to the one from a countable hypothesis
family.</p>
<h1 id="problem-setting">Problem Setting</h1>
<ol type="1">
<li><p><span class="math inline">\(\mathcal{X}:\)</span> the input
space.</p></li>
<li><p><span class="math inline">\(\mathcal{Y} \doteq \{-1,
1\}:\)</span> the output space.</p></li>
<li><p><span class="math inline">\(\mathcal{Z} \doteq \mathcal{X} \times
\mathcal{Y}:\)</span> the product space of <span
class="math inline">\(\mathcal{X}\)</span> and <span
class="math inline">\(\mathcal{Y}\)</span>.</p></li>
<li><p><span class="math inline">\(\mathcal{D}:\)</span> an unknown
distribution defined on <span class="math inline">\(\mathcal{X} \times
\mathcal{Y}\)</span>.</p></li>
<li><p><span class="math inline">\(\mathcal{H}:\)</span> an countable
family of hypothesis, s.t., each <span class="math inline">\(h \in
\mathcal{H}\)</span> is a function from <span
class="math inline">\(\mathcal{X}\)</span> to <span
class="math inline">\(\mathcal{Y}\)</span>.</p></li>
<li><p><span class="math inline">\(\ell: \mathcal{Y} \times \mathcal{Y}
\rightarrow [0, 1]\)</span>, a loss function that takes two points in
<span class="math inline">\(\mathcal{Y}\)</span> and outputs a value
between <span class="math inline">\(0\)</span> and <span
class="math inline">\(1\)</span>.</p></li>
<li><p><span class="math inline">\(L_\mathcal{D} (h):\)</span> the
expected loss of a hypothesis <span class="math inline">\(h\)</span> is
defined as <span class="math display">\[
L_\mathcal{D} (h) = \mathbb{E}_{ (x, y) \sim \mathcal{D} } [ \ell( h(x),
y) ]
\]</span></p>
<p>where <span class="math inline">\((x, y) \sim \mathcal{D}\)</span>
implies that the pair <span class="math inline">\((x, y) \in
\mathcal{Z}\)</span> is sampled according to the distribution <span
class="math inline">\(\mathcal{D}\)</span>.</p></li>
<li><p><span class="math inline">\(h^* \doteq \arg\min_{h \in
\mathcal{H} } L_\mathcal{D} (h):\)</span> the hypothesis that minimize
the expected loss.</p></li>
<li><p><span class="math inline">\(\mu_h:\)</span> an alias for <span
class="math inline">\(L_\mathcal{D} (h)\)</span>, when the distribution
<span class="math inline">\(\mathcal{D}\)</span> discussed in the
context is unique.</p></li>
<li><p><span class="math inline">\(B(\mu_h, \epsilon) \doteq \{ r \in
\mathbb{R} : |r - \mu_h | &lt; \epsilon \}:\)</span> an open ball, which
is an open interval in <span class="math inline">\(\mathbb{R}\)</span>
centered at <span class="math inline">\(\mu_h\)</span> with length <span
class="math inline">\(2 \epsilon\)</span>, where <span
class="math inline">\(\epsilon &gt; 0\)</span>.</p></li>
<li><p><span class="math inline">\(S \sim \mathcal{D}^n:\)</span> a set
of <span class="math inline">\(n\)</span> i.i.d samples drawn from <span
class="math inline">\(\mathcal{D}\)</span>, where <span
class="math inline">\(n \in \mathbb{N}^+\)</span> is some positive
integer. In particular, when <span class="math inline">\(S \sim
\mathcal{D}^n\)</span>, it can be represented as <span
class="math display">\[
S = \{ (x_1, y_1), (x_2, y_2), ..., (x_n, y_n) : (x_i, y_i) \sim
\mathcal  {D}, \forall i \in [n] \}.
\]</span> We also view <span class="math inline">\(S\)</span> as a point
in <span class="math inline">\(\mathcal{Z}^n\)</span>.</p></li>
<li><p><span class="math inline">\(L_{S}(h) \doteq \frac{1}{ |S| }
\sum_{ (x, y) \in S } \ell( h(x) , y ) :\)</span> the empirical loss of
a hypothesis <span class="math inline">\(h\)</span> on a sample set
<span class="math inline">\(S\)</span>.</p></li>
<li><p>Given a <span class="math inline">\(h \in \mathcal{H}\)</span>,
its restriction on <span class="math inline">\(\mathcal{C} \subset
\mathcal{X}\)</span> is a function <span
class="math inline">\(h_S\)</span> defined on <span
class="math inline">\(S\)</span>, such that <span
class="math display">\[
h_\mathcal{C} (x) = h(x), \forall x \in \mathcal{C}
\]</span></p></li>
<li><p>The restriction of <span
class="math inline">\(\mathcal{H}\)</span> on <span
class="math inline">\(\mathcal{C}\)</span> is the set of possible
restriction of a function in <span
class="math inline">\(\mathcal{H}\)</span> to <span
class="math inline">\(\mathcal{C}\)</span> <span class="math display">\[
        \mathcal{H}_\mathcal{C}  = \{ h_\mathcal{C}  :
\mathcal{C}  \rightarrow \mathcal{Y} : h \in \mathcal{H} \}
\]</span></p>
<p>As <span class="math inline">\(\mathcal{Y} = \{ -1, +1 \}\)</span>,
the set of possible functions defined on <span
class="math inline">\(\mathcal{C}\)</span> is bounded by <span
class="math inline">\(2^{n}\)</span>. Hence, <span
class="math display">\[
    |\mathcal{H}_\mathcal{C} | \le 2^{n}.
\]</span></p></li>
<li><p>The growth function <span class="math inline">\(\Pi_{\mathcal{H}
} (n): \mathbb{N}^+ \rightarrow \mathbb{N}^+\)</span> of <span
class="math inline">\(\mathcal{H}\)</span> is defined as <span
class="math display">\[
   \Pi_{\mathcal{H} } (n) = \max_{\mathcal{C} \subset \mathcal{X}, |C| =
n} | \mathcal{H}_\mathcal{C} |
   \]</span></p></li>
</ol>
<p>Ideally, we would like to find <span
class="math inline">\(h^*\)</span>. The problem is difficult, as</p>
<ul>
<li>The space <span class="math inline">\(\mathcal{X} \times
\mathcal{Y}\)</span> could be infinite.</li>
<li>The distribution <span class="math inline">\(\mathcal{D}\)</span> is
unknown.</li>
</ul>
<p>To deal with the possibly infinite space <span
class="math inline">\(\mathcal{X} \times \mathcal{Y}\)</span> and the
unknown distribution <span class="math inline">\(\mathcal{D}\)</span>,
we investigate <span class="math inline">\(\mathcal{H}\)</span> on a
finite sample set <span class="math inline">\(S\)</span>. Due to the
randomness inherited in sampling <span class="math inline">\(S\)</span>,
we allow our solution to be approximate and to make error. For a given
pair of parameters of <span class="math inline">\(\epsilon &gt;
0\)</span> and <span class="math inline">\(\delta &gt; 0\)</span>, we
relax the goal to designing an <span class="math inline">\((\epsilon,
\delta)\)</span>-learning algorithm <span
class="math inline">\(A\)</span> that returns an <span
class="math inline">\(h&#39;\)</span>, that is</p>
<blockquote>
<ul>
<li><span class="math inline">\(\epsilon\)</span>-approximate: <span
class="math inline">\(\mu_{h&#39;} \le \mu_{h^*} +
\epsilon\)</span>,<br />
</li>
<li>probably correct: <span class="math inline">\(A\)</span> return an
<span class="math inline">\(h&#39;\)</span> that does not satisfies the
above condition with probability at most <span
class="math inline">\(\delta\)</span>.</li>
</ul>
</blockquote>
<p>Combined, <span class="math inline">\(A\)</span> should return an
<span class="math inline">\(\epsilon\)</span>-approximate solution <span
class="math inline">\(h&#39;\)</span> with probability at least <span
class="math inline">\(1 - \delta\)</span>.</p>
<h1 id="the-algorithm">The Algorithm</h1>
<blockquote>
<p>An <span class="math inline">\((\epsilon, \delta)\)</span>
approximate algorithm <span class="math inline">\(A\)</span><br />
1. Draw a set <span class="math inline">\(S\)</span> of <span
class="math inline">\(n =\)</span> samples independently from <span
class="math inline">\(\mathcal{D}\)</span>.<br />
2. Return an <span class="math inline">\(h&#39;\)</span> such that <span
class="math display">\[
h&#39; = \arg\min_{h \in \mathcal{H} } L_{S} (h)
\]</span></p>
</blockquote>
<p>A key result of the algorithm states that <span
class="math inline">\(L_S(h)\)</span> is a good approximation of <span
class="math inline">\(\mu_h\)</span> for all <span
class="math inline">\(h \in \mathcal{H}\)</span> simultaneously.</p>
<blockquote>
<p>Theorem. If <span class="math inline">\(n \ge\)</span>, then <span
class="math display">\[
\Pr_{S \sim \mathcal{D}^n } [ \exists h \in \mathcal{H} : L_S(h) \notin
B(\mu_h, \epsilon / 2 )  ] \le \delta
\]</span></p>
</blockquote>
<p>An immediate corollary is that <span
class="math inline">\(h&#39;\)</span> is <span
class="math inline">\(\epsilon\)</span>-approximate with probability at
least <span class="math inline">\(1 - \delta\)</span>: <span
class="math display">\[
\mu_{h&#39;} \le L_S(h&#39;) + \frac{\epsilon}{2} \le L_S(h^*) +
\frac{\epsilon}{2} \le \mu_{h^*} + \epsilon.
\]</span></p>
<h2 id="proof-of-the-theorem">Proof of The Theorem</h2>
<p>The proof relies on a technique called double sampling. Alongside
with <span class="math inline">\(S\)</span>, we create another sample
set <span class="math inline">\(S&#39; \sim \mathcal{D}^n\)</span>
independently, termed the "ghost sample". Let <span
class="math display">\[
S = \{ (x_1, y_1), (x_2, y_2), ..., (x_n, y_n) \}
\]</span> and <span class="math display">\[
S&#39; = \{ (x_1&#39;, y_1&#39;), (x_2&#39;, y_2&#39;), ..., (x_n&#39;,
y_n&#39;) \}.
\]</span></p>
<p>Then, we define</p>
<ol start="16" type="1">
<li><span class="math inline">\(\sigma:\)</span> a random swap that
exchanges the <span class="math inline">\(i\)</span>-th (<span
class="math inline">\(i \in [n]\)</span>) element of <span
class="math inline">\(S\)</span> and <span
class="math inline">\(S&#39;\)</span> independently with probability
0.5. Call the resulting sample sets <span class="math inline">\(\sigma
S\)</span> and <span class="math inline">\(\sigma S&#39;\)</span>. Let
<span class="math inline">\(\sigma S[i]\)</span> (<span
class="math inline">\(\sigma S&#39;[i]\)</span>) be the <span
class="math inline">\(i\)</span>-th element of <span
class="math inline">\(\sigma S[i]\)</span> (<span
class="math inline">\(\sigma S&#39;[i]\)</span>). So <span
class="math display">\[
\Pr \left[
    \sigma S [i] = (x_i,  y_i) \wedge
    \sigma S&#39;[i] = (x_i&#39;, y_i&#39;)
\right] = 0.5 \\
\Pr \left[
    \sigma S [i] = (x_i&#39;, y_i&#39;) \wedge
    \sigma S&#39;[i] = (x_i,  y_i)
\right] = 0.5
\]</span></li>
</ol>
<p>We use the gap of <span class="math inline">\(|L_{\sigma S} (h) -
L_{\sigma S&#39;} (h)|\)</span> as a proxy of <span
class="math inline">\(|L_S(h) - \mu_h|\)</span>. This enables us to
focus on finite sets <span class="math inline">\(S\)</span> and <span
class="math inline">\(S&#39;\)</span> without worrying about the
infinite size of <span class="math inline">\(\mathcal{H}\)</span>.</p>
<p>For convenience, we use <span
class="math inline">\(\underset{S}{\Pr}[\cdot]\)</span> (<span
class="math inline">\(\underset{S&#39;}{\Pr}[\cdot]\)</span>) as
shorthand for <span class="math inline">\(\underset{S \sim
\mathcal{D}^n}{\Pr}[\cdot]\)</span> (<span
class="math inline">\(\underset{S&#39; \sim
\mathcal{D}^n}{\Pr}[\cdot]\)</span>). The road map of our proof is as
follows.</p>
<blockquote>
<p>Lemma 1.<br />
<span class="math display">\[
\Pr_{S}[ \exists h : L_S(h) \notin B(\mu_h, \epsilon ) ] \le 2 \max_{S,
S&#39; \in \mathcal{Z}^n } \Pr_\sigma \left[ \exists h : |L_{ \sigma S}
(h) - L_{ \sigma S&#39; } (h) | \ge \frac{\epsilon}{2} \right]
\]</span></p>
</blockquote>
<p>On the left hand side of the inequality, the probability measures the
event of a random set <span class="math inline">\(S\)</span> sampling
from <span class="math inline">\(\mathcal{D}\)</span>. On the right hand
side, we can pick a fixed pair of <span class="math inline">\(S\)</span>
and <span class="math inline">\(S&#39;\)</span> that maximize <span
class="math display">\[
\Pr_\sigma \left[ \exists h : |L_{ \sigma S} (h) - L_{ \sigma S&#39; }
(h) | \ge \frac{\epsilon}{2} \right],
\]</span></p>
<p>and the probability measures the event of the random swap <span
class="math inline">\(\sigma\)</span>. Fixing <span
class="math inline">\(S\)</span> and <span
class="math inline">\(S&#39;\)</span> significantly simplifies the
structure of <span class="math inline">\(\mathcal{H}\)</span>. By
Hoeffding inequality and union bound, we will prove that</p>
<blockquote>
<p>Lemma 2. For any fixed pair of <span class="math inline">\(S, S&#39;
\in \mathcal{Z}^n\)</span>, <span class="math display">\[
\Pr_\sigma \left[ \exists h : |L_{ \sigma S} (h) - L_{ \sigma S&#39; }
(h) | \ge \frac{\epsilon}{2} \right] \le 2 \Pi_\mathcal{H} (2n) \exp( -
\frac{n^2 \epsilon^2 }{2} )
\]</span></p>
</blockquote>
<h3 id="proof-of-lemma-1."><strong>Proof of Lemma 1.</strong></h3>
<p>The proof of Lemma 1 consists of three steps.</p>
<h4 id="step-1"><strong>Step 1</strong></h4>
<blockquote>
<p><span class="math display">\[
\Pr_{S}[ \exists h : L_S(h) \notin B(\mu_h, \epsilon ) ] \le 2 \Pr_{S ,
S&#39;} [ \exists h : L_S (h) \notin B(\mu_h, \epsilon
)  \wedge  L_{S&#39;} (h) \in B(\mu_h, \epsilon / 2)  ].
\]</span></p>
</blockquote>
<p><strong>Proof.</strong> By Hoeffding inequality, for a fixed <span
class="math inline">\(h \in \mathcal{H}\)</span>, when <span
class="math inline">\(n \ge \frac{2}{\epsilon^2} \ln 4\)</span> <span
class="math display">\[
    \Pr_{S&#39;} [ L_{S&#39;} (h) \notin B(\mu_h, \epsilon / 2) ] \le 2
\exp \left(- 2 n \left( \frac{\epsilon }{ 2 } \right)^2 \right) = 2 \exp
\left( - \frac{n \epsilon^2}{2} \right) \le \frac{1}{2}
\]</span></p>
<p>It follows that <span class="math display">\[
    \Pr_{S , S&#39;} [ \exists h : L_S (h) \notin B(\mu_h, \epsilon
)  \wedge  L_{S&#39;} (h) \in B(\mu_h, \epsilon / 2)  ]
        \ge
    \frac{1}{2} \Pr_{S}[ \exists h : L_S(h) \notin B(\mu_h, \epsilon ) ]
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<p><strong>Remark:</strong> Mathematically, I don't know how to make
prove this step rigorously. Suppose that for every <span
class="math inline">\(i \in [n]\)</span>, we know that the events <span
class="math inline">\(E_i\)</span> and <span
class="math inline">\(F_i\)</span> are measurable and independent. If
<span class="math inline">\(\Pr[ F_i ] \ge 1 / 2\)</span>, then <span
class="math inline">\(\Pr[ E_i \wedge F_i ] \ge 1 / 2\)</span>. But, can
we claim that <span class="math display">\[
    \Pr[ \cup (E_i \wedge F_i) ] \ge \frac{1}{2} \Pr[ \cup E_i ].
\]</span></p>
<h4 id="step-2"><strong>Step 2</strong></h4>
<blockquote>
<p><span class="math display">\[
\Pr_{S} [ \exists h : L_S (h) \notin B(\mu_h, \epsilon
)  \wedge  L_{S&#39;} (h) \in B(\mu_h, \epsilon / 2) ]
\le
\Pr_{S, S&#39;} \left[ \exists h : |L_S (h) - L_{S&#39;} (h) | \ge
\frac{\epsilon}{2} \right]
\]</span></p>
</blockquote>
<p><strong>Proof</strong>. Observe that <span class="math display">\[
    \{  \exists h : L_S (h) \notin B(\mu_h, \epsilon
)  \wedge  L_{S&#39;} (h) \in B(\mu_h, \epsilon / 2)  \}
        \subset
    \left\{  \exists h : |L_S (h) - L_{S&#39;} (h) | \ge
\frac{\epsilon}{2} \right\}.
\]</span> By monotonicity of probability, we finish the proof.</p>
<p><span class="math inline">\(\square\)</span></p>
<h4 id="step-3"><strong>Step 3</strong></h4>
<blockquote>
<p><span class="math display">\[
\Pr_{S, S&#39; } \left[  \exists h : |L_S (h) - L_{S&#39;} (h) | \ge
\frac{\epsilon}{2} \right]
\le
\max_{S, S&#39; \in \mathcal{Z}^n } \Pr_\sigma \left[ \exists h : |L_{
\sigma S} (h) - L_{ \sigma S&#39; } (h) | \ge \frac{\epsilon}{2} \right]
\]</span></p>
</blockquote>
<p><strong>Proof.</strong> We claim that <span
class="math inline">\(\sigma S\)</span> and <span
class="math inline">\(\sigma S&#39;\)</span> have the same joint
distribution as <span class="math inline">\(S\)</span> and <span
class="math inline">\(S&#39;\)</span> (if <span class="math inline">\(S,
S&#39; \sim \mathcal{D}^n\)</span>). For points <span
class="math inline">\(\forall Z, Z&#39; \in \mathcal{Z}^n\)</span>, by
symmetry, it holds that <span class="math display">\[
\Pr_{S, S&#39;} [ S = Z, S&#39; = Z&#39;] = \Pr_{S, S&#39;, \sigma} [
\sigma S = Z, \sigma S&#39; = Z&#39;]
\]</span></p>
<p>The right hand side can be viewed as the successful probability of
the following experiment:</p>
<ul>
<li>Sample independently <span class="math inline">\(S \sim
\mathcal{D}^n\)</span> and <span class="math inline">\(S&#39; \sim
\mathcal{D}^n\)</span>.<br />
</li>
<li>For each <span class="math inline">\(i \in [n]\)</span>, exchange
the <span class="math inline">\(i\)</span>-th elements of <span
class="math inline">\(S\)</span> and <span
class="math inline">\(S&#39;\)</span> independently with probability
<span class="math inline">\(0.5\)</span>.</li>
<li>After the random swap, <span class="math inline">\(\sigma S =
Z\)</span> and <span class="math inline">\(\sigma S&#39; =
Z&#39;\)</span>.</li>
</ul>
<p>Now, <span class="math inline">\(\forall \mathcal{E} \subset
\mathcal{Z}^{2n}\)</span>, it holds that <span class="math display">\[
\begin{aligned}
    \Pr_{S, S&#39;} [ (S, S&#39;) \in \mathcal{E} ]
        &amp;= \Pr_{S, S&#39;, \sigma} [ (\sigma S, \sigma S&#39;) \in
\mathcal{E} ] \\
        &amp;= \mathbb{E}_{S, S&#39;} [ \Pr_\sigma [(\sigma S, \sigma
S&#39;) \in \mathcal{E} ] \mid S, S&#39; ] \\
        &amp;\le \max_{S, S&#39; \in \mathcal{Z}^n } \Pr_\sigma [(\sigma
S, \sigma S&#39;) \in \mathcal{E} ]
\end{aligned}
\]</span></p>
<p>Replacing <span class="math inline">\(\mathcal{E}\)</span> with the
set <span class="math inline">\(\{Z, Z&#39; \in \mathcal{Z}^n :  \exists
h : |L_Z (h) - L_{Z&#39;} (h) | \ge \frac{\epsilon}{2} \}\)</span>
finishes the proof.</p>
<p><span class="math inline">\(\square\)</span></p>
<!-- *Remark of the proof of step 1.* If we define 
$$
\mathcal{H}(S, \epsilon) \doteq \{ h \in \mathcal{H} :L_S(h) \notin B(\mu_h, \epsilon ) \}.
$$
*which is the set of hypothesis whose empirical loss on $S$ is $\epsilon$ more than its expectation. Then,* 
$$
\begin{aligned}
    \Pr_{S} [ \exists h : L_S(h) \notin B(\mu_h, \epsilon ) ] \cdot \frac{1}{2} 
    &= \Pr_{S } [ \mathcal{H}(S, \epsilon) \neq \emptyset ] \cdot \frac{1}{2} \\
    &\le \Pr_{S } [ \mathcal{H}(S, \epsilon) \neq \emptyset] \\
    & \ \ \cdot \Pr_{S, S' } [ \exists h \in \mathcal{H}(S, \epsilon) : L_{S'} (h) \in B(\mu_h, \epsilon / 2 ) \mid \mathcal{H}(S, \epsilon) \neq \emptyset ] \\
    &= \Pr_{S, S' } [ \exists h : L_S (h) \notin B(\mu_h, \epsilon )  \wedge L_{S'} (h) \in B(\mu_h, \epsilon / 2 )  ]
\end{aligned}
$$

*Note that the event $\mathcal{H}(S, \epsilon) \neq \emptyset$ is equivalent to the one* 
$$
\cup_{h \in \mathcal{H} } \{ L_S(h) \notin B(\mu_h, \epsilon ) \} 
$$

*For a fixed $h \in \mathcal{H}$, the event $\{ L_S(h) \notin B(\mu_h, \epsilon ) \}$ is measurable when $S$ consists of a finite number of i.i.d samples from $\mathcal{D}$. If $\mathcal{H}$ consists of countable number of $h$, then $\cup_{h \in \mathcal{H} } \{ L_S(h) \notin B(\mu_h, \epsilon ) \}$ is a countable union and should be measurable.*  -->
<h3 id="proof-of-lemma-2."><strong>Proof of Lemma 2.</strong></h3>
<p>Let <span class="math display">\[
S = \{ (x_1, y_1), (x_2, y_2), ..., (x_n, y_n) \}
\]</span> and <span class="math display">\[
S&#39; = \{ (x_1&#39;, y_1&#39;), (x_2&#39;, y_2&#39;), ..., (x_n&#39;,
y_n&#39;) \}.
\]</span> be a pair of fixed sample sets. Define the set <span
class="math inline">\(\mathcal{C} = \{ x_1, x_2, ..., x_n, x_1&#39;,
x_2&#39;, ..., x_n&#39; \} \subset \mathcal{X}\)</span> (with duplicates
removed). The size of <span class="math inline">\(\mathcal{C}\)</span>
is bounded by <span class="math inline">\(2n\)</span> and therefore the
size of restriction of <span class="math inline">\(\mathcal{H}\)</span>
on <span class="math inline">\(\mathcal{C}\)</span> is bounded by <span
class="math inline">\(\Pi_\mathcal{H} (2n)\)</span>.</p>
<p>First, fix a hypothesis <span class="math inline">\(h\)</span>. For
all <span class="math inline">\(i \in [n]\)</span>, define <span
class="math inline">\(a_i = |\ell( h( x_i ), y_i) - \ell( h( x_i&#39; ),
y_i&#39; ) | \le 1\)</span> and let <span class="math inline">\(V_i \in
\{-1, 1\}\)</span> be a random variable with equal probability: <span
class="math display">\[
\Pr[ V_i = -1 ] = \Pr[ V_i = 1] = 0.5
\]</span></p>
<p>If we apply a random swap <span class="math inline">\(\sigma\)</span>
to <span class="math inline">\((S, S&#39;)\)</span>, then <span
class="math inline">\(L_{ \sigma S} (h_S) - L_{ \sigma  S&#39; }
(h_S)\)</span> has the same distribution as <span
class="math inline">\(\sum_{i \in [n] } \frac{1}{n} a_i V_i\)</span>.
Since <span class="math display">\[
\mathbb{E} \left[ \sum_{i \in [n] } \frac{1}{n} a_i V_i \right] =
\sum_{i \in [n] } \frac{1}{n} a_i \mathbb{E}[ V_i ] = 0,
\]</span></p>
<p>by Hoeffding inequality, <span class="math display">\[
\begin{aligned}
    \Pr_\sigma \left[ |L_{ \sigma S} (h) - L_{ \sigma  S&#39; } (h) |
\ge \frac{\epsilon}{2} \right]
        &amp;= \Pr \left[ \left| \sum_{i \in [n] } \frac{1}{n} a_i V_i -
0 \right| \ge \frac{\epsilon}{2} \right] \\
        &amp;\le 2 \exp \left( - \frac{ 2 }{  \sum_{i \in [n] } a_i^2 }
\left( \frac{n \epsilon}{2} \right)^2 \right)  \\
        &amp;\le 2 \exp \left( - \frac{n^2 \epsilon^2 }{2} \right)
\end{aligned}
\]</span></p>
<p>The last inequality follows from that <span
class="math inline">\(\sum_{i \in [n] } a_i^2 \le n\)</span>.</p>
<p>Since for each <span class="math inline">\(h \in
\mathcal{H}\)</span>, it has the same behavior on <span
class="math inline">\(\mathcal{C}\)</span> as some function in <span
class="math inline">\(\mathcal{H}_\mathcal{C}\)</span>. We can apply
union bound on <span
class="math inline">\(\mathcal{H}_\mathcal{C}\)</span>. <span
class="math display">\[
\Pr_\sigma \left[ \exists h : |L_{ \sigma S} (h) - L_{ \sigma  S&#39; }
(h) | \ge \frac{\epsilon}{2} \right] \le 2 |\mathcal{H}_\mathcal{C} |
\exp \left( - \frac{n^2 \epsilon^2 }{2} \right) \le 2 \Pi_\mathcal{H}
(2n) \exp \left( - \frac{n^2 \epsilon^2 }{2} \right)
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h1 id="reference">Reference</h1>
<p>[1] Ethan Fetaya, "Lecture 02 - Introduction to Statistical Learning
Theory", Weizmann Institute of Science, 2016</p>
<p>[2].R. Schapire and D. Bieber, “Lecture 05 - COS 511: Theoretical
Machine Learning,”, Princeton University, 2013</p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2020/11/13/Advanced-Composition/" rel="prev" title="Advanced Composition">
                  <i class="fa fa-angle-left"></i> Advanced Composition
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2020/11/23/Propose-Test-Release/" rel="next" title="Propose-Test-Release">
                  Propose-Test-Release <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">WOW</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
