<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.24.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="We discuss a toy model of probably approximately correct (PAC) learning [1]. The setting focuses on a \(d\)-dimension Boolean hypercube \(\{0, 1\}^d\) and a set of functions \(\mathcal{H} &#x3D; \{ h : \{">
<meta property="og:type" content="article">
<meta property="og:title" content="PAC Learning Basic">
<meta property="og:url" content="http://example.com/2020/11/12/PAC-learning/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:description" content="We discuss a toy model of probably approximately correct (PAC) learning [1]. The setting focuses on a \(d\)-dimension Boolean hypercube \(\{0, 1\}^d\) and a set of functions \(\mathcal{H} &#x3D; \{ h : \{">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/PAC-Learning.png?raw=true">
<meta property="article:published_time" content="2020-11-12T21:06:55.000Z">
<meta property="article:modified_time" content="2021-11-09T10:28:44.000Z">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/PAC-Learning.png?raw=true">


<link rel="canonical" href="http://example.com/2020/11/12/PAC-learning/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2020/11/12/PAC-learning/","path":"2020/11/12/PAC-learning/","title":"PAC Learning Basic"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>PAC Learning Basic | WOW</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">WOW</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">你生之前悠悠千載已逝<br>未來還會有千年沉寂的期待</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#reference"><span class="nav-number">1.</span> <span class="nav-text">Reference</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">200</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/11/12/PAC-learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="PAC Learning Basic | WOW">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          PAC Learning Basic
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-11-12 16:06:55" itemprop="dateCreated datePublished" datetime="2020-11-12T16:06:55-05:00">2020-11-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2021-11-09 05:28:44" itemprop="dateModified" datetime="2021-11-09T05:28:44-05:00">2021-11-09</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>We discuss a toy model of probably approximately correct (PAC)
learning [1]. The setting focuses on a <span
class="math inline">\(d\)</span>-dimension Boolean hypercube <span
class="math inline">\(\{0, 1\}^d\)</span> and a set of functions <span
class="math inline">\(\mathcal{H} = \{ h : \{0, 1\}^d \rightarrow \{0, 1
\} \}\)</span>. A function <span class="math inline">\(h \in
\mathcal{H}\)</span> is called a hypothesis or a concept, which assigns
each vertex in the hypercube a label 0 or 1.</p>
<p>The goal of PAC learning is to learn an unknown hypothesis, denoted
as <span class="math inline">\(h^* \in \mathcal{H}\)</span>, from a
dataset, which consists of <span class="math inline">\(n\)</span> points
<span class="math inline">\(X_1, X_2, \ldots, X_n \in \{0,
1\}^n\)</span> sampled independently from an unknown distribution <span
class="math inline">\(D\)</span> (over the hypercube), as well as their
labels <span class="math inline">\(Y_1 = h^*(X_1), Y_2 = h^*(X_2),
\ldots, Y_n = h^*(X_n)\)</span>.</p>
<p>We can state the algorithm for PAC learning in just one sentence.</p>
<blockquote>
<p>Output any hypothesis <span class="math inline">\(h&#39; \in
\mathcal{H}\)</span> that is consistent with the sampled dataset, i.e.,
<span class="math display">\[
h&#39;(X_i) = Y_i, \qquad \forall i \in [n]
\]</span></p>
</blockquote>
<p>Such an hypothesis always exists, as <span
class="math inline">\(h^*\)</span> satisfies this constraint. We have
the classic PAC learning theorem.</p>
<blockquote>
<p><strong><em>Theorem.</em></strong> Let <span class="math inline">\(X
\in \{0, 1\}^n\)</span> be a random point sampled from the unknown
distribution, then for a given <span class="math inline">\(\delta \in
(0, 1)\)</span>, <span class="math display">\[
\Pr[ h&#39;(X) \neq h^*(X)] \ge \sqrt{ \log |\mathcal{H}| + \log \frac{
1 }{ \delta } \over 2n}
\]</span> with probability at most <span
class="math inline">\(\delta\)</span>.</p>
</blockquote>
<p>The PAC learning theorem states that the probability that <span
class="math inline">\(h&#39;\)</span> mislabels a point is bounded by
<span class="math inline">\(\sqrt{ \log |\mathcal{H}| + \log ( 1  /
\delta ) \over 2n}\)</span>.</p>
<p><em>Proof.</em> Consider some fixed <span class="math inline">\(h \in
\mathcal{H}\)</span>. For convenience, we rewrite <span
class="math display">\[
    \Pr[ h(X) \neq h^*(X)] = \mu_h.
\]</span></p>
<p>Denote <span class="math inline">\(Z_i\)</span> the indicator
variable of whether <span class="math inline">\(h\)</span> mislabels
<span class="math inline">\(X_i\)</span>, i.e., <span
class="math display">\[
    Z_i = \begin{cases}
        0, \qquad \text{ if } h(X_i) = Y_i \\
        1, \qquad \text{ if } h(X_i) \neq Y_i
    \end{cases}
\]</span></p>
<p>By definition, <span class="math inline">\(\mathbb{E}[Z_i]\)</span>
is an unbiased estimator of <span class="math inline">\(\mu_h\)</span>.
Further, denote <span class="math inline">\(\hat \mu_h\)</span> the
empirical mean of <span class="math inline">\(Z_i\)</span>'s <span
class="math display">\[
    \hat \mu_h \doteq \frac{1}{n} \sum_{i \in [n] } Z_i.
\]</span></p>
<p>Note that for the outputted <span
class="math inline">\(h&#39;\)</span>, <span class="math inline">\(\hat
\mu_{h&#39;} = 0\)</span>.</p>
<p>By Hoeffding inequality, for any <span
class="math inline">\(\delta&#39; &gt; 0\)</span>, <span
class="math display">\[
    \Pr \left[ \hat \mu_h \le \mu_h - \sqrt{ \frac{ \log ( 1 /
\delta&#39;) }{2n} } \right] \le \delta&#39;.
\]</span></p>
<p>By union bound, the probability that <span class="math display">\[
    \exists h \in \mathcal{H}, \hat \mu_h \ge \mu_h - \sqrt{ \frac{ \log
( 1 / \delta&#39;) }{2n} }
\]</span></p>
<p>is bounded by <span class="math inline">\(| \mathcal{H} |
\delta&#39;\)</span>. By setting <span class="math inline">\(\delta&#39;
= \frac{\delta}{ | \mathcal{H} | }\)</span>, it is guaranteed that with
probability at most <span class="math inline">\(\delta\)</span>, <span
class="math display">\[
    0 = \hat \mu_{h&#39; } \le \mu_{h&#39;} -  \sqrt{ \log |\mathcal{H}|
+ \log ( 1 / \delta) \over 2n}.
\]</span></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<p>The previous theorem can be improved with the <span
class="math inline">\(\sqrt{ \cdot }\)</span> removed. The key here is
that the selected <span class="math inline">\(h&#39;\)</span> is
error-free on the samples.</p>
<blockquote>
<p><strong><em>Theorem.</em></strong> Let <span class="math inline">\(X
\in \{0, 1\}^n\)</span> be a random point sampled from the unknown
distribution, then for a given <span class="math inline">\(\delta \in
(0, 1)\)</span>, <span class="math display">\[
\Pr[ h&#39;(X) \neq h^*(X)] \ge { \log |\mathcal{H}| + \log \frac{ 1 }{
\delta } \over n}
\]</span> with probability at most <span
class="math inline">\(\delta\)</span>.</p>
</blockquote>
<p><em>Proof.</em> Consider some fixed <span class="math inline">\(h \in
\mathcal{H}\)</span>. For convenience, we rewrite <span
class="math display">\[
    \Pr[ h(X) \neq h^*(X)] = \mu_h.
\]</span></p>
<p>We will prove that if <span class="math inline">\(\mu_h \ge { \log
|\mathcal{H}| + \log \frac{ 1 }{ \delta } \over n}\)</span>, then <span
class="math inline">\(h\)</span>'s probability of being selected is very
low.</p>
<p>Denote <span class="math inline">\(Z_i\)</span> the indicator
variable of whether <span class="math inline">\(h\)</span> mislabels
<span class="math inline">\(X_i\)</span>, i.e., <span
class="math display">\[
    Z_i = \begin{cases}
        0, \qquad \text{ if } h(X_i) = Y_i \\
        1, \qquad \text{ if } h(X_i) \neq Y_i
    \end{cases}
\]</span></p>
<p>By definition, <span class="math inline">\(\Pr[Z_i = 1] =
\mu_h\)</span>. Therefore, <span class="math display">\[
    \begin{aligned}
        \Pr[ Z_1 = 0 \wedge Z_2 = 0 \wedge \ldots \wedge Z_n = 0] = (1 -
\mu_h)^n \le \exp(- \mu_h n) = \frac{\delta}{ |\mathcal{H} | }
    \end{aligned}
\]</span></p>
<p>Taking union bound over all possible <span
class="math inline">\(h\)</span> gives the desired result.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<p><strong><em>Caveat.</em></strong> <em>In both theorem, we see a <span
class="math inline">\(\log \mathcal{H}\)</span> term in the failure
probability, which is due to the use of union bound and can be roughly
considered as the complexity of the hypothesis family. It is tempting to
think that this could be avoid as follows.</em></p>
<blockquote>
<p>For the outputted <span class="math inline">\(h&#39;\)</span>, <span
class="math inline">\(Z_1, \ldots, Z_n\)</span> are i.i.d samples.
Therefore, the probability of all of them being <span
class="math inline">\(0\)</span> is give by<br />
<span class="math display">\[
(1 - \mu_{h&#39;} )^n \le \exp( - \mu_{h&#39;} n).
  \]</span><br />
Bounding this probability by <span class="math inline">\(\delta\)</span>
gives <span class="math inline">\(\mu_{h&#39;} \le \frac{ \log ( 1 /
\delta ) } {n}\)</span>.</p>
</blockquote>
<p><em>The argument is wrong. For the outputted <span
class="math inline">\(h&#39;\)</span>, the <span
class="math inline">\(Z_1, \ldots, Z_n\)</span> are not i.i.d samples,
as <span class="math inline">\(h&#39;\)</span> is selected according to
<span class="math inline">\(Z_1, \ldots, Z_n\)</span> and depends on
them.</em></p>
<p><em>To make it more concrete, suppose that there is an <span
class="math inline">\(h\)</span>, such that <span
class="math inline">\(\mu_h = \frac{ \log ( 1 / \delta ) } {n}\)</span>.
Consider the following experiment</em></p>
<blockquote>
<ol type="1">
<li>Sample <span class="math inline">\(n\)</span> points independently
the distribution <span class="math inline">\(D\)</span>.<br />
</li>
<li>Pick an <span class="math inline">\(h&#39;\)</span> that makes no
prediction error on the samples.</li>
</ol>
</blockquote>
<p><em>If we repeat the experiment <span
class="math inline">\(N\)</span> times for some positive integer <span
class="math inline">\(N\)</span>, then the fixed <span
class="math inline">\(h\)</span> makes no mistake in roughly <span
class="math inline">\((1 - \delta) N\)</span> of the experiments and
constitutes an candidate of <span class="math inline">\(h&#39;\)</span>.
However, on the other roughly <span class="math inline">\(\delta
N\)</span> experiments, where <span class="math inline">\(h\)</span>
makes prediction error, it is no longer considered as the candidate of
<span class="math inline">\(h&#39;\)</span>. The selection procedure of
<span class="math inline">\(h&#39;\)</span> ignores bad event of <span
class="math inline">\(h\)</span> automatically.</em></p>
<p><em>We could also investigate the following example. Let <span
class="math inline">\(h^* = h_0\)</span>. There are also other two
hypothesis <span class="math inline">\(h_1\)</span> and <span
class="math inline">\(h_2\)</span>. Let <span
class="math inline">\(S\)</span> be the sample space. It holds that</em>
<span class="math display">\[
    |h_1(x) - h^*(x) | = \begin{cases}
        2 \epsilon, \forall x \in S \setminus S_{h_1} \\
        0,\ \       \forall x \in S_{h_1}
    \end{cases}
\]</span> <span class="math display">\[
    |h_2(x) - h^*(x) | = \begin{cases}
        2 \epsilon, \forall x \in S \setminus S_{h_2} \\
        0,\ \       \forall x \in S_{h_2}
    \end{cases}
\]</span> <em>Moreover, <span class="math inline">\(\Pr[S_{h_1}] =
\Pr[S_{h_2} ] = \delta\)</span>. How, if we get a sample in <span
class="math inline">\(S_{h_1}\)</span>, then we can output <span
class="math inline">\(h&#39;\)</span> as <span
class="math inline">\(h_0\)</span> or <span
class="math inline">\(h_1\)</span>, since both of them make no error
when <span class="math inline">\(x \in S_{h_1}\)</span>. Similarly, if
<span class="math inline">\(x \in S_{h_2}\)</span>, we can output either
<span class="math inline">\(h_0\)</span> or <span
class="math inline">\(h_2\)</span>. We call <span
class="math inline">\(S_{h_1}\)</span> and <span
class="math inline">\(S_{h_2}\)</span> the bad areas. When <span
class="math inline">\(x\)</span> is in the bad area of any hypothesis,
we can't distinguish this hypothesis from the true hypothesis. That is
why we need to use union bound to bound the total probabilities of these
bad areas.</em></p>
<div style="text-align:center">
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/PAC-Learning.png?raw=true" width="400" height="340" /></p>
</div>
<h3 id="reference">Reference</h3>
<p>[1] Leslie G. Valiant. A theory of the learnable. Communications of
the ACM, 27(11):1134-1142, 1984. 6</p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2020/11/06/Gaussian-Distribution/" rel="prev" title="Gaussian Distribution">
                  <i class="fa fa-angle-left"></i> Gaussian Distribution
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2020/11/13/Advanced-Composition/" rel="next" title="Advanced Composition">
                  Advanced Composition <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">WOW</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
