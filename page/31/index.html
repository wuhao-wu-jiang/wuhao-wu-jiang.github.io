<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Helvetica:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.24.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js" defer></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="WOW">
<meta property="og:url" content="http://example.com/page/31/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/31/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/31/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>WOW</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">WOW</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">你生之前悠悠千載已逝<br>未來還會有千年沉寂的期待</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">201</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/11/02/Randomized-Response/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | WOW">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/11/02/Randomized-Response/" class="post-title-link" itemprop="url">Randomized Response</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-11-02 10:41:39" itemprop="dateCreated datePublished" datetime="2020-11-02T10:41:39-05:00">2020-11-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2020-11-09 01:26:31" itemprop="dateModified" datetime="2020-11-09T01:26:31-05:00">2020-11-09</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>In the setting of randomized response, there is a coordinator and a
set of <span class="math inline">\(n\)</span> players each having a
secrete bit <span class="math inline">\(x_i \in \{0, 1\}\)</span>.
Instead of sending <span class="math inline">\(x_i\)</span> to the
coordinator directly, the player sends a randomly perturbed version
<span class="math inline">\(X_i\)</span>, such that <span
class="math display">\[
X_i =
\begin{cases}
    x_i, \qquad \text{with probability } 0.5 + \epsilon \\
    \bar{ x}_i, \qquad \text{with probability } 0.5 - \epsilon \\
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(\epsilon \in [0, 0.5]\)</span> and
<span class="math inline">\(\bar{x}_i = 1 - x_i\)</span>. If <span
class="math inline">\(\epsilon = 0\)</span>, then the response from play
<span class="math inline">\(i\)</span> is totally random. On the other
hand, if <span class="math inline">\(\epsilon = 0.5\)</span>, there
isn't noise in <span class="math inline">\(X_i\)</span>.</p>
<p>The coordinator would like to estimate the ratio of <span
class="math inline">\(1\)</span>'s among the <span
class="math inline">\(x_i\)</span>'s. Let <span class="math display">\[
\bar{X} = \frac{1}{n} \sum_{i \in [n] } X_i.
\]</span></p>
<p>Denote <span class="math inline">\(\mu = \frac{1}{n} \sum_{i \in [n]
} x_i\)</span> the true ratio. Now <span class="math display">\[
\begin{aligned}
    \mathbb{E} [ \bar{X} ] &amp;= \frac{1}{n} \sum_{i \in [n] }
\mathbb{E}[ X_i ] \\
                            &amp;= \frac{1}{n} \sum_{i \in [n] } [ (0.5
+ \epsilon) x_i + (0.5 - \epsilon )\bar{x}_i ] \\
                            &amp;= \frac{1}{n} \sum_{i \in [n] } [ 2
\epsilon x_i  + (0.5 - \epsilon) (x_i + \bar{x}_i) ] \\
                            &amp;= \frac{1}{n} \sum_{i \in [n] } [ 2
\epsilon x_i  + (0.5 - \epsilon)  ] \\
                            &amp;= \frac{1 - 2\epsilon }{2n}  +
2\epsilon \mu
\end{aligned}
\]</span></p>
<p>and <span class="math display">\[
\begin{aligned}
    \mathbb{Var} [ \bar{X} ] = \frac{1}{n} \sum_{i \in [n] }
\mathbb{Var}[ X_i ]
                            \le \frac{1}{4n}
\end{aligned}
\]</span></p>
<p>Hence, <span class="math display">\[
\mu = \mathbb{E}[ \frac{1}{2\epsilon} (\bar X + \frac{2\epsilon -
1}{2n}) ]
\]</span></p>
<p>and <span class="math inline">\(\hat \mu \doteq \frac{1}{2\epsilon}
(\bar X + \frac{2\epsilon - 1}{2n})\)</span> is an unbiased estimator of
<span class="math inline">\(\mu\)</span>. As <span
class="math display">\[
\mathbb{Var}[ \hat \mu ] = \frac{1}{4 \epsilon^2 } \mathbb{Var}[\bar{X}
] \le \frac{1}{16 n \epsilon^2}
\]</span></p>
<p>By Chebyshev's inequality, <span class="math display">\[
\Pr[ |\hat \mu - \mu | \ge \sqrt{2} \cdot \frac{1 }{4\epsilon \sqrt{n} }
] \le \frac{ \mathbb{Var}[ \hat \mu ] }{ ( \sqrt{2} \cdot \frac{1 }{4
\epsilon \sqrt{n} } )^2 } = \frac{1}{2}
\]</span></p>
<p>Or we can apply Hoeffding inequality to show that, with probability
at least <span class="math inline">\(1 - \delta\)</span>, <span
class="math display">\[
|\bar{X} - \mathbb{E} [ \bar{X} ] | \le \sqrt{ \frac{\log
\frac{2}{\delta} }{2n} }
\]</span></p>
<p>i.e., <span class="math display">\[
|\hat \mu - \mu | = \frac{1}{2 \epsilon} |\bar{X} - \mathbb{E} [ \bar{X}
] | \le \frac{1}{ 2 \epsilon } \sqrt{ \frac{\log \frac{2}{\delta} }{2n}
}
\]</span></p>
<p>which is much tighter than Chebyshev inequality.</p>
<p>Finally, observe that to get a meaningful estimate <span
class="math inline">\(\hat \mu\)</span>, we require that <span
class="math inline">\(\frac{ 1 }{\epsilon \sqrt{n} } \le 1\)</span>,
i.e., <span class="math inline">\(n \in
\Omega(\frac{1}{\epsilon^2})\)</span> or <span
class="math inline">\(\epsilon \in \Omega( \frac{1}{ \sqrt{n} }
)\)</span>.</p>
<p><span class="math inline">\(\square\)</span></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/10/27/Twin-Drive-or-Not/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | WOW">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/10/27/Twin-Drive-or-Not/" class="post-title-link" itemprop="url">Twin Drive or Not?</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-10-27 16:15:03" itemprop="dateCreated datePublished" datetime="2020-10-27T16:15:03-04:00">2020-10-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2020-11-05 19:08:17" itemprop="dateModified" datetime="2020-11-05T19:08:17-05:00">2020-11-05</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>In this article, we introduce differential privacy. We start with a
story of information leakage.</p>
<h3 id="twin-drive-or-not">Twin Drive or Not</h3>
<p>Celestial Being is a private military organization with superior
technology. It has four advanced machines. The most powerful one is the
Gundam 00.</p>
<p>The Gundam 00 is about to engage the enemy.</p>
<div style="text-align:center">
<p><img src="https://lh5.googleusercontent.com/-9AOc-O5bdRk/S_mZxjf1DWI/AAAAAAAACvs/uXI0SvAMqWc/s640/5.jpg" width="500" height="250" /></p>
</div>
<p>Due to maintenance, Gundam 00 is not always equipped with two engines
(known as <strong><em>twin drive system</em></strong>). With probability
<strong><em>0.5</em></strong>, it uses one drive. We use <span
class="math inline">\(T =  (1, 1)\)</span> to denote the status of
equipping with the twin drive system, and <span class="math inline">\(S
= (1, 0)\)</span> (or <span class="math inline">\((0, 1)\)</span>) for
status of single drive. Let <span class="math inline">\(X\)</span> be a
random variable that indicates drive status. Therefore, <span
class="math display">\[
\Pr[ X = T ] = 0.5, \\
\Pr[ X = S ] = 0.5.  
\]</span></p>
<div style="text-align:center">
<p><img src="https://knolly.files.wordpress.com/2009/03/00gundamdrive1.jpg" width="500" height="250" /></p>
</div>
<p>Raiser sword is one of Gundam 00 most powerful weapon. The energy
level of the Raiser sword, denote as <span
class="math inline">\(Y\)</span>, is a random variable in <span
class="math inline">\([0, 100]\)</span>, whose distribution, denoted as
<span class="math inline">\(\Pr[\cdot \mid X]\)</span>, depends on the
drive status. Thus, <span class="math inline">\(\Pr[Y = y \mid X =
T]\)</span> (or <span class="math inline">\(\Pr[Y = y \mid X =
S]\)</span>) is the probability that <span
class="math inline">\(Y\)</span> equals to <span
class="math inline">\(y\)</span> conditioned on <span
class="math inline">\(X = T\)</span> (<span class="math inline">\(X =
S\)</span>). Specifically, <span class="math display">\[
\Pr[\cdot \mid T] \sim B(100, 0.81) \\
\Pr[\cdot \mid S] \sim B(100, 0.09)
\]</span></p>
<p>where <span class="math inline">\(B(n, p)\)</span> denotes a binomial
distribution. The expected energy level is <span
class="math inline">\(81\)</span> with <em>twin drive system</em>,
compared to only <span class="math inline">\(9\)</span> with single
drive. This is called "<strong><em>squaring</em></strong>" phenomenon of
<em>twin drive</em>.</p>
<div style="text-align:center">
<p><img src="https://vignette.wikia.nocookie.net/gundam/images/8/84/Raiser_sword.png/revision/latest?cb=20101124151429" width="500" height="250" /></p>
</div>
<p>Now suppose that you're the enemy pilot of a mobile suit with just
average performance. Before you start dog fighting with Gundam 00, you
will be attacked by the 00's long-range raiser sword (you have not seen
00 yet). Luckily, you survive the raiser sword attack. Now you need to
make a decision. If 00 is equipped with twin drive, there is zero chance
that you can win the dog fight. The best choice is to leave the battle.
Otherwise, you can outperform 00 and you would like to engage it.</p>
<div style="text-align:center">
<p><img src="https://blogimg.goo.ne.jp/user_image/79/da/c198b8cf829b5f7f7dd507d40bb39ba5.jpg" width="500" height="250" /></p>
</div>
<p>Since you have just been attacked by the raiser sword, you have an
observation of its energy level <span class="math inline">\(y\)</span>.
By Bayes' theorem, <span class="math display">\[
\begin{aligned}
\Pr[ X = T \mid Y = y] = \frac{ \Pr[Y = y \mid X = T] \cdot \Pr[X = T]
}{ \Pr[Y = y \mid X = T] \cdot \Pr[X = T] + \Pr[Y = y \mid X = S] \cdot
\Pr[X = S] }
\\
\\
\Pr[ X = S \mid Y = y] = \frac{ \Pr[Y = y \mid X = S] \cdot \Pr[X = S]
}{ \Pr[Y = y \mid X = T] \cdot \Pr[X = T] + \Pr[Y = y \mid X = S] \cdot
\Pr[X = S] }
\end{aligned}
\]</span></p>
<p>Substituting with <span class="math inline">\(\Pr[X = S] = \Pr[X = T]
= 0.5\)</span>, we get <span class="math display">\[
\begin{aligned}
\Pr[ X = T \mid Y = y] = \frac{ \Pr[Y = y \mid X = T]  }{ \Pr[Y = y \mid
X = T]  + \Pr[Y = y \mid X = S] }
\\
\\
\Pr[ X = S \mid Y = y] = \frac{ \Pr[Y = y \mid X = S]  }{ \Pr[Y = y \mid
X = T]  + \Pr[Y = y \mid X = S] }
\end{aligned}
\]</span></p>
<p>The distributions <span class="math inline">\(B(100, 0.09)\)</span>
and <span class="math inline">\(B(100, 0.81)\)</span> are plotted
together below.</p>
<p><img
src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/B-100-0.09-vs-B-100-0.81.png?raw=true" /></p>
<p>Immediately, you can draw some conclusions based on single value of
<span class="math inline">\(y\)</span>, such as</p>
<ol type="1">
<li>If <span class="math inline">\(y = 10\)</span>, it is likely 00 has
only one drive.<br />
</li>
<li>If <span class="math inline">\(y = 75\)</span>, it is likely 00 has
twin drive.</li>
</ol>
<p>Or you can conclude based on the range of <span
class="math inline">\(y\)</span>, such as</p>
<ol type="1">
<li>If <span class="math inline">\(y \in [0, 20]\)</span>, it is likely
00 has single drive.</li>
<li>If <span class="math inline">\(y \in [70, 90]\)</span>, it is likely
00 has twin drive.</li>
</ol>
<p>Before the observation of <span class="math inline">\(y\)</span>, as
<span class="math inline">\(\Pr[X = S] = \Pr[X = T] = 0.5\)</span>, you
have only random guess over the engine status of 00. After the
observation, you might be much more confident about your guess, even
though the energy level of the raiser sword is a random variable.</p>
<p>Why does this happen? Because the two distributions are
well-separated. They are far from each other. Further, the prior
probabilities <span class="math inline">\(\Pr[X = S]\)</span> and <span
class="math inline">\(\Pr[X = T]\)</span> play important roles. If you
know <span class="math inline">\(\Pr[X = S] = 10^{-10}\)</span>, even if
you observe an energy level of <span class="math inline">\(y =
10\)</span>, you had better not engage Gundam 00. You know it could be
just a trap!</p>
<h3 id="formal-definition">Formal Definition</h3>
<p>Database managers face similar scenarios in privacy protection. We
know define the setting for differential privacy. We view a dataset
<span class="math inline">\(D\)</span> as a table of <span
class="math inline">\(n\)</span> rows, each of which comes from a domain
<span class="math inline">\(\mathcal{X}\)</span>. Hence <span
class="math inline">\(D \in \mathcal{X}^n\)</span>. Instead of releasing
the dataset directly, the manager runs a randomized algorithm <span
class="math inline">\(A: \mathcal{X}^n \rightarrow \mathcal{Y}\)</span>
on <span class="math inline">\(D\)</span>, and outputs <span
class="math inline">\(Y = A(D) \in \mathcal{Y}\)</span>. Here <span
class="math inline">\(\mathcal{Y}\)</span> is called the co-domain of
<span class="math inline">\(A\)</span> and does not necessarily equal to
<span class="math inline">\(\mathcal{X}^n\)</span>. Note that the output
distribution of <span class="math inline">\(A\)</span> may depend on the
input <span class="math inline">\(D\)</span>. Further, for simplicity of
discussion, we believe a uniform prior distribution over datasets in
<span class="math inline">\(\mathcal{X}^n\)</span>.</p>
<p>In the Gundam 00's story, <span class="math inline">\(\mathcal{X} =
\{0, 1\}^2\)</span>, and <span class="math inline">\(\mathcal{Y} = [0,
100]\)</span>.</p>
<p>Suppose there is another dataset <span
class="math inline">\(D&#39;\)</span> that differs only one row from
<span class="math inline">\(D\)</span>. The algorithm <span
class="math inline">\(A\)</span> is said to be differentially private if
a malicious user is unlikely to distinguish the input to <span
class="math inline">\(A\)</span> between <span
class="math inline">\(D\)</span> and <span
class="math inline">\(D&#39;\)</span>, by merely observing <span
class="math inline">\(A\)</span>'s output. Simply put, the conditional
distributions of <span class="math inline">\(\Pr[\cdot \mid X =
D]\)</span> and <span class="math inline">\(\Pr[\cdot \mid X =
D&#39;]\)</span> should be similar, where <span
class="math inline">\(X\)</span> is a variable that denotes the input
dataset.</p>
<p>We observe in the previous section that, if the distributions are
well separated, then we can infer the underlying input with high
confidence when the output value takes specific values or lies in
certain ranges.</p>
<p>There are many ways to characterize the closeness of two
distributions. We introduce the one proposed in [1].</p>
<blockquote>
<p>Algorithm <span class="math inline">\(A\)</span> is called <span
class="math inline">\((\epsilon, \delta)\)</span> differentially
private, if for any pair of neighboring datasets <span
class="math inline">\(D\)</span> and <span
class="math inline">\(D&#39;\)</span> (the ones that differ in only one
row), and for any (measurable) subset <span
class="math inline">\(\mathcal{R} \subset \mathcal{Y}\)</span>, it holds
that <span class="math display">\[
\Pr[Y \in \mathcal{R} \mid X = D ] \le \exp(\epsilon) \cdot \Pr[Y \in
\mathcal{R} \mid X = D&#39; ]+ \delta
\]</span></p>
</blockquote>
<p>In other words, we can't find a subset <span
class="math inline">\(\mathcal{R}\)</span>, with which we can
distinguish <span class="math inline">\(D\)</span> and <span
class="math inline">\(D&#39;\)</span> with high confidence. In the
previous example, such <span class="math inline">\(\mathcal{R}\)</span>
exists. E.g., <span class="math inline">\(R = [70, 90]\)</span>. If
<span class="math inline">\(Y\)</span> lies in <span
class="math inline">\(\mathcal{R}\)</span>, we can infer that Gundam 00
is likely to have twin drive.</p>
<h3 id="hypothesis-testing">Hypothesis Testing</h3>
<p>There is alternative view of <span class="math inline">\((\epsilon,
0)\)</span> differential privacy as hypothesis testing. Suppose that we
know the underlying dataset is either <span
class="math inline">\(D\)</span> or <span
class="math inline">\(D&#39;\)</span> with equal probability. After
observing the output of <span class="math inline">\(A\)</span>, we need
to decide which hypothesis of the following holds: <span
class="math display">\[
H_0: \text{ the dataset if } D \\
H_1: \text{ the dataset if } D&#39;
\]</span></p>
<p>Assume that we adopt a fixed strategy:</p>
<ol type="1">
<li>First we choose a fixed subset <span
class="math inline">\(\mathcal{R} \subset \mathcal{Y}\)</span>,</li>
<li>If <span class="math inline">\(Y \in \mathcal{R}\)</span>, we choose
to accept <span class="math inline">\(H_0\)</span>,</li>
<li>Otherwise, we accept <span class="math inline">\(H_1\)</span>.</li>
</ol>
<p>There are two kinds of errors we can make. The type I error is the
one when the true hypothesis is <span class="math inline">\(H_0\)</span>
and we accept <span class="math inline">\(H_1\)</span>. Conversely, type
II error is the one when the true hypothesis is <span
class="math inline">\(H_1\)</span> and we accept <span
class="math inline">\(H_0\)</span>. Let <span
class="math inline">\(p\)</span> and <span
class="math inline">\(q\)</span> be the probabilities we make type I and
II errors respectively. The following theorem holds</p>
<blockquote>
<p>Algorithm A is <span class="math inline">\((\epsilon, 0)\)</span>
differentially private then</p>
<ol type="1">
<li><span class="math inline">\(\frac{1}{1 + \exp(\epsilon) } \le q \le
\frac{1}{1 + \exp(-\epsilon) }\)</span><br />
</li>
<li><span class="math inline">\(\frac{1}{1 + \exp(\epsilon) } \le p \le
\frac{1}{1 + \exp(-\epsilon) }\)</span></li>
</ol>
</blockquote>
<p><em>Proof.</em> By definition, <span class="math display">\[
\begin{aligned}
    q   &amp;= \Pr[ X = D \mid  Y \in \bar{\mathcal{R}} ] \\
        &amp;= \frac{ \Pr[  Y \in \bar{\mathcal{R}} \mid X = D ] \Pr[X =
D ] }{ \Pr[  Y \in \bar{\mathcal{R}} \mid X = D ] \Pr[X = D ] + \Pr[  Y
\in \bar{\mathcal{R}} \mid X = D&#39; ] \Pr[X = D&#39; ] } \\
        &amp;= \frac{ \Pr[  Y \in \bar{\mathcal{R}} \mid X = D ]  }{
\Pr[  Y \in \bar{\mathcal{R}} \mid X = D ]  + \Pr[  Y \in
\bar{\mathcal{R}} \mid X = D&#39; ]  }
\end{aligned}
\]</span></p>
<p>As <span class="math inline">\(A\)</span> is <span
class="math inline">\((\epsilon, 0)\)</span> differentially private, it
holds that <span class="math display">\[
\Pr[  Y \in \bar{\mathcal{R}} \mid X = D&#39; ] \le \exp(\epsilon) \cdot
\Pr[  Y \in \bar{\mathcal{R}} \mid X = D ]
\]</span> and <span class="math display">\[
\Pr[  Y \in \bar{\mathcal{R}} \mid X = D ] \le \exp(\epsilon) \cdot
\Pr[  Y \in \bar{\mathcal{R}} \mid X = D&#39; ]
\]</span></p>
<p>therefore, <span class="math display">\[
\frac{1}{1 + \exp(\epsilon) } \le q \le \frac{1}{1 + \exp(-\epsilon) }
\]</span></p>
<p>By symmetry, we also have <span class="math display">\[
\frac{1}{1 + \exp(\epsilon) } \le p \le \frac{1}{1 + \exp(-\epsilon) }
\]</span></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<h3 id="reference">Reference</h3>
<p>[1] C. Dwork and A. Roth, “The Algorithmic Foundations of
Differential Privacy,” Foundations and Trends in Theoretical Computer
Science, vol. 9, no. 3–4, pp. 211–407, 2013<br />
[2] L. Wasserman and S. Zhou, “A statistical framework for differential
privacy,” arXiv:0811.2501 [math, stat], Oct. 2009, Accessed: Oct. 27,
2020.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/10/26/Norm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | WOW">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/10/26/Norm/" class="post-title-link" itemprop="url">Norm</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-10-26 22:17:18" itemprop="dateCreated datePublished" datetime="2020-10-26T22:17:18-04:00">2020-10-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-03-31 06:54:40" itemprop="dateModified" datetime="2022-03-31T06:54:40-04:00">2022-03-31</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="norm-and-unit-ball">Norm and Unit Ball</h1>
<p>A norm <span class="math inline">\(\Vert \cdot \Vert:\mathbb{R}^n
\rightarrow \mathbb{R}\)</span> is a function that satisfies the
following properties:</p>
<ol type="1">
<li><p>Positive definite: <span class="math inline">\(\Vert x \Vert = 0
\rightarrow x = \vec 0\)</span>,</p></li>
<li><p>Nonnegative:<span class="math inline">\(\Vert x \Vert \ge
0\)</span> for any <span class="math inline">\(x \in
\mathbb{R}^n\)</span>,</p></li>
<li><p>Absolutely homogeneous: <span class="math inline">\(\Vert k
x\Vert = |k| \cdot \Vert x \Vert\)</span>, for any <span
class="math inline">\(x \in \mathbb{R}^n, k \in
\mathbb{R}\)</span>,</p></li>
<li><p>Subadditive (triangle inequality): <span
class="math inline">\(\Vert x + y \Vert \le \Vert x \Vert + \Vert y
\Vert\)</span>, for any <span class="math inline">\(x \in \mathbb{R}^n,
y \in \mathbb{R}^n\)</span>.</p></li>
</ol>
<blockquote>
<p><strong>Theorem.</strong> Given properties 1-3, property 4 is
equivalent to</p>
<ol start="5" type="1">
<li>The region <span class="math inline">\(\{ x \in \mathbb{R}^n: \Vert
x \Vert \le 1\}\)</span> is convex.</li>
</ol>
</blockquote>
<p><strong>Proof.</strong> The proof is straightforward.</p>
<p><span class="math inline">\(5 \rightarrow 4:\)</span> If <span
class="math inline">\(x = \vec 0\)</span> or <span
class="math inline">\(\vec y = 0\)</span>, then 4 holds trivially.
Otherwise, suppose that <span class="math inline">\(x, y \neq \vec
0\)</span>. Then <span class="math display">\[
    \begin{aligned}
        \Vert x + y \Vert \le \Vert x \Vert + \Vert y \Vert
        \Longleftrightarrow
        \left\Vert \frac{ \Vert x \Vert }{ \Vert x \Vert + \Vert y \Vert
} \frac{ x }{ \Vert x \Vert } + \frac{ \Vert x \Vert }{ \Vert x \Vert +
\Vert y \Vert } \frac{ y }{ \Vert y \Vert } \right\Vert
        \le 1.
    \end{aligned}
\]</span></p>
<p>As <span class="math inline">\(\left\Vert \frac{ x }{ \Vert x \Vert }
\right\Vert =1\)</span>, <span class="math inline">\(\left\Vert \frac{ y
}{ \Vert y \Vert } \right\Vert  = 1\)</span> and <span
class="math inline">\(\frac{ \Vert x \Vert }{ \Vert x \Vert + \Vert y
\Vert } + \frac{ \Vert y \Vert }{ \Vert x \Vert + \Vert y \Vert } =
1\)</span>, the second inequality follows exactly from condition 5.</p>
<p><span class="math inline">\(4 \rightarrow 5:\)</span> Let <span
class="math inline">\(x, y \in \mathbb{R}^n, \Vert x \Vert \le 1, \Vert
y \Vert \le 1\)</span> and <span class="math inline">\(a, b \ge
0\)</span>, <span class="math inline">\(a + b = 1\)</span>. Then <span
class="math display">\[
    \left\Vert ax + by \right\Vert
    \le
    \left\Vert ax \right\Vert + \left\Vert by \right\Vert
    = a\Vert x \Vert + b\Vert y \Vert = 1
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h1 id="induced-norm">Induced Norm</h1>
<p>To illustrate a deeper connection between property 4 and 5, we first
show how a norm can be induced by a convex and symmetric region centered
at the origin <span class="math inline">\(O\)</span>. Let the boundary
of the region as <span class="math inline">\(E\)</span>. We are going to
induce a norm by <span class="math inline">\(E\)</span>, denoted as
<span class="math inline">\(\Vert \cdot \Vert_E\)</span>.</p>
<p>First, we define</p>
<ol type="1">
<li><span class="math inline">\(\Vert x \Vert_E = 1, \forall x \in
E\)</span>.</li>
</ol>
<p>For any other vector <span class="math inline">\(x \notin E\)</span>,
consider the ray initiated from the origin and with the same direction
as <span class="math inline">\(x\)</span>. Denote its intersection point
with <span class="math inline">\(E\)</span> as <span
class="math inline">\(x_E\)</span>. Suppose that <span
class="math inline">\(x = a \cdot x_E\)</span> for some <span
class="math inline">\(a \in \mathbb{R}_+\)</span>. Then we define</p>
<ol start="2" type="1">
<li><span class="math inline">\(\Vert x \Vert_E = a \Vert x_E \Vert_E =
a\)</span>.</li>
</ol>
<p>Indeed, if we write the <span class="math inline">\(\Vert \cdot
\Vert_2\)</span> as the <span class="math inline">\(\ell_2\)</span>
norm, then the value of <span class="math inline">\(a\)</span> is given
by <span class="math inline">\(\frac{ \Vert x \Vert_2 } { \Vert x_E
\Vert_2 }\)</span>. Clearly, by definition, <span
class="math inline">\(\Vert \cdot \Vert_2\)</span> is positive definite
and non-negative. To prove that it is absolutely homogeneous, <span
class="math inline">\(\forall k \in \mathbb{R}\)</span>, <span
class="math display">\[
    \Vert k x \Vert = \Vert k ax_E \Vert_E.
\]</span></p>
<p>If <span class="math inline">\(k \ge 0\)</span>, we have <span
class="math inline">\(\Vert k ax_E\Vert_E = ka \Vert x_E \Vert_E =
ka\)</span>. Otherwise, if <span class="math inline">\(k &lt;
0\)</span>, <span class="math display">\[
    \Vert k x \Vert = \Vert k ax_E\Vert_E = \Vert -k a (-x_E)\Vert_E =
-k a \Vert (-x_E)\Vert_E.
\]</span></p>
<p>By symmetry of <span class="math inline">\(E\)</span> (with respect
to the origin <span class="math inline">\(O\)</span>), <span
class="math inline">\(\Vert (-x_E)\Vert_E = \Vert x_E \Vert_E =
1\)</span>. Therefore, <span class="math display">\[
    \Vert k x \Vert = |k|a.
\]</span></p>
<p>Finally, we have a graphical verification of triangle inequality. Let
<span class="math inline">\(v, u \in \mathbb{R}^n\)</span>, which
intersect with <span class="math inline">\(E\)</span> at <span
class="math inline">\(v_E\)</span> and <span
class="math inline">\(u_E\)</span> respectively. If <span
class="math inline">\(\Vert v\Vert_E &lt; 1\)</span> (<span
class="math inline">\(\Vert u\Vert_E &lt; 1\)</span>), then we can
extend it along its direction to get its intersection with <span
class="math inline">\(E\)</span>. Let <span class="math inline">\(c =
\Vert v\Vert_E\)</span> and <span class="math inline">\(d = \Vert u
\Vert_E\)</span>, then</p>
<ol type="1">
<li><span class="math inline">\(v = c \cdot v_E\)</span>,</li>
<li><span class="math inline">\(u = d \cdot u_E\)</span>.</li>
</ol>
<p>Let <span class="math inline">\(w = v + u = c \cdot v_E + d \cdot
u_E\)</span>. Let <span class="math inline">\(p\)</span> be the
intersection between <span class="math inline">\(w\)</span> and the line
segment between <span class="math inline">\(v\)</span> and <span
class="math inline">\(u\)</span>. It is easy to verify that <span
class="math display">\[
    p = \frac{c}{c + d} v_E + \frac{d}{ c + d} u_E
\]</span></p>
<p>By convexity of the region bounded by <span
class="math inline">\(E\)</span>, <span class="math display">\[
    \Vert p\Vert_E \le 1
\]</span></p>
<p>It concludes that <span class="math inline">\(\Vert w\Vert_E = \Vert
c v_E + d u_E \Vert_E \le c + d = \Vert v\Vert_E + \Vert u
\Vert_E\)</span>.</p>
<!-- <img src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/Induced-Norm.png?raw=true" style="zoom: 67%;" /> -->
<p><img
src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/Induced-Norm.png?raw=true" /></p>
<h3 id="application"><strong>Application</strong></h3>
<p>The idea discussed above significantly simplifies the proof of
Minkowski inequality.</p>
<p>The <span class="math inline">\(p\)</span>-norm (<span
class="math inline">\(p \ge 1\)</span>) on <span
class="math inline">\(\mathbb{R}^n\)</span> is given as <span
class="math display">\[
    \Vert x \Vert _p = \left( \sum_{i \in [n]} |x_i|^p
\right)^\frac{1}{p}
\]</span></p>
<p>Clearly, <span class="math inline">\(p\)</span>-norm is positive
definite, nonnegative, absolutely homogeneous. It is left to verify
triangle inequality, which is known as Minkowski inequality for the case
of <span class="math inline">\(p\)</span>-norm. This is equivalent to
show that <span class="math display">\[
    \{ x \in \mathbb{R}^n : \Vert x \Vert_p \le 1 \}
\]</span></p>
<p>is convex. The trick here is that <span class="math inline">\(\Vert x
\Vert_p \le 1\)</span> is equivalent to <span
class="math inline">\((\Vert x \Vert_p)^p \le 1\)</span>. Hence, <span
class="math display">\[
    \{ x \in \mathbb{R}^n : \Vert x \Vert_p \le 1 \}
    =
    \left\{ x \in \mathbb{R}^n : \sum_{i \in [n]} |x_i|^p  \le 1
\right\}.
\]</span></p>
<p>The convexity of this set follows directly from the point-wise
convexity of the function <span class="math inline">\(f(t) =
t^p\)</span>.</p>
<p><span class="math inline">\(\square\)</span></p>
<p><strong><em>Remark:</em></strong> To appreciate how concise the above
proof is, we also give one traditional proof here, which consists of
three steps.</p>
<h2 id="youngs-inequality"><strong>Young's Inequality</strong></h2>
<blockquote>
<p><strong>Theorem.</strong> For <span class="math inline">\(a, b &gt;
0\)</span>, <span class="math inline">\(p, q &gt; 0\)</span>, s.t.,
<span class="math inline">\(\frac{1}{p} + \frac{1}{q} = 1\)</span>, it
holds that <span class="math display">\[
ab \le \frac{a^p}{p} + \frac{b^q}{q}
\]</span></p>
</blockquote>
<p><strong>Proof.</strong> Via the concavity of <span
class="math inline">\(y = \ln x, x &gt; 0\)</span>, we see <span
class="math display">\[
    \ln a + \ln b
        = \frac{1}{p} \ln a^p + \frac{1}{q} \ln b^q
        \le \ln \left( \frac{a^p}{p} + \frac{b^q}{q} \right).
\]</span> <span class="math inline">\(\square\)</span></p>
<h2 id="holders-inequality"><strong>Holder's Inequality</strong></h2>
<blockquote>
<p><strong>Theorem.</strong> For <span class="math inline">\(x, y \in
\mathbb{R}^n\)</span>, <span class="math inline">\(p, q &gt; 0\)</span>,
s.t., <span class="math inline">\(\frac{1}{p} + \frac{1}{q} =
1\)</span>, it holds that <span class="math display">\[
\sum_{i \in [n]} |x_i| |y_i| \le \Vert x \Vert_p \Vert y \Vert_q
\]</span></p>
</blockquote>
<p><strong>Proof.</strong> The inequality is trivial if <span
class="math inline">\(x = \vec 0\)</span> or <span
class="math inline">\(y = \vec 0\)</span>. Otherwise, let <span
class="math inline">\(u = x / \Vert x \Vert_p\)</span> and <span
class="math inline">\(v = y / \Vert y \Vert_q\)</span>. It is easy to
see that <span class="math inline">\(\Vert u \Vert_p = \Vert v \Vert_q =
1\)</span>, and it remains to prove <span class="math display">\[
    \sum_{i \in [n]} |u_i| |v_i| \le 1
\]</span></p>
<p>Applying Young's Inequality, we have <span class="math display">\[
    \sum_{i \in [n]} |u_i| |v_i|
        = \sum_{i \in [n]} \left( \frac{ |u_i|^p }{p}  +
\frac{|v_i|^q}{q} \right)
        = \frac{1}{p} + \frac{1}{q} = 1.
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h2 id="minkowski-inequality"><strong>Minkowski Inequality</strong></h2>
<blockquote>
<p>For <span class="math inline">\(x, y \in \mathbb{R}^n\)</span>, <span
class="math inline">\(p \ge 1\)</span>, it holds that <span
class="math display">\[
\Vert x + y \Vert_p \le \Vert x \Vert_p + \Vert y \Vert_p
\]</span></p>
</blockquote>
<p><strong>Proof.</strong> The inequality is trivial if <span
class="math inline">\(x = \vec 0\)</span> or <span
class="math inline">\(y = \vec 0\)</span>. Otherwise, assume that <span
class="math inline">\(x &gt; 0\)</span> and <span
class="math inline">\(y &gt; 0\)</span>. Now</p>
<p><span class="math display">\[
    \Vert x + y \Vert_p^p = \sum_{i \in [n]} |x_i + y_i|^p = \sum_{i \in
[n]} [ x_i (x_i + y_i)^{p - 1} + y_i (x_i + y_i)^{p - 1} ]
\]</span></p>
<p>Let <span class="math inline">\(q = \frac{p}{p - 1}\)</span>. Then
<span class="math inline">\(\frac{1}{p} + \frac{1}{q} = 1\)</span>. By
Holder's inequality, <span class="math display">\[
    \begin{aligned}
        \sum_{i \in [n]} x_i (x_i + y_i)^{p - 1}
        &amp;\le \Vert x \Vert_p ( \sum_{i \in [n]} (x_i + y_i)^{(p -
1)q} )^{ \frac{1}{q} } \\
        &amp;= \Vert x \Vert_p ( \sum_{i \in [n]} (x_i + y_i)^{ p } )^{
\frac{p - 1}{ p } } \\
        &amp;= \Vert x \Vert_p (\Vert x + y \Vert_p)^{p - 1}
    \end{aligned}
\]</span></p>
<p>Similarly, we have <span class="math display">\[
\sum_{i \in [n]} y_i (x_i + y_i)^{p - 1} \le \Vert y \Vert_p (\Vert x +
y \Vert_p)^{p - 1}
\]</span></p>
<p>Putting the inequalities together, <span class="math display">\[
\Vert x + y \Vert_p^p \le \Vert x \Vert_p (\Vert x + y \Vert_p)^{p - 1}
+ \Vert y \Vert_p (\Vert x + y \Vert_p)^{p - 1}
\]</span></p>
<p>We finish the proof by dividing both side with <span
class="math inline">\((\Vert x + y \Vert_p)^{p - 1}\)</span>.</p>
<p><span class="math inline">\(\square\)</span></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="Previous page" aria-label="Previous page" href="/page/30/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/30/">30</a><span class="page-number current">31</span><a class="page-number" href="/page/32/">32</a><span class="space">&hellip;</span><a class="page-number" href="/page/67/">67</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/32/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">WOW</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
