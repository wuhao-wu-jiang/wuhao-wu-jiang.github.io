<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
<meta property="og:type" content="website">
<meta property="og:title" content="WOW">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>WOW</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">WOW</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/10/20/Peeling/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/10/20/Peeling/" class="post-title-link" itemprop="url">Peeling</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-10-20 21:41:54" itemprop="dateCreated datePublished" datetime="2020-10-20T21:41:54+11:00">2020-10-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-10-23 11:24:43" itemprop="dateModified" datetime="2020-10-23T11:24:43+11:00">2020-10-23</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Let $Z_1, Z_2, …, Z_n$ be i.i.d. copies of random variable $Z$ on $[0, 1]$. Let  </p>
<ol>
<li><p>$\mu_k \doteq \frac{1}{k} \sum_{i = 1}^k Z_i$ for $1 \le k \le n$,   </p>
</li>
<li><p>$\mu = \mathbb{E}[Z]$,   </p>
</li>
<li><p>$M_k$ be the event such that<br> $$</p>
<pre><code> M_k \doteq \left\&#123; \mu_k + \sqrt&#123; \frac&#123; \log \frac&#123;1&#125;&#123;\delta&#125; &#125;&#123;2 k&#125; &#125; \le \mu \right\&#125;,
</code></pre>
<p> $$<br> where $0 &lt; \delta &lt; 1$.</p>
</li>
</ol>
<p>We are interested in bounding the probability of<br>$$<br>\Pr[ \cup_{k = 1}^n M_k ].<br>$$</p>
<h3 id="Hoeffding-Inequality"><a href="#Hoeffding-Inequality" class="headerlink" title="Hoeffding Inequality"></a>Hoeffding Inequality</h3><p>We first prove a bound of<br>$$<br>\Pr[ \cup_{k = 1}^n M_k ] \le n \delta<br>$$<br>by Hoeffding inequality. </p>
<p><strong><em>Hoeffding Inequality.</em></strong>  <em>For a fixed integer $s$, let $Z_1, Z_2, …, Z_s$ be i.i.d. copies of a random variable $Z$ on $[0, 1]$. For any $r &gt; 0$</em><br>$$<br>\Pr[ \mu - \mu_s  \ge r] \le \exp(- 2 s r^2 ). \<br>\<br>$$ </p>
<p>Applying Hoeffding inequality with $s = k$, $r = \sqrt{ \frac{ \log \frac{1}{\delta} }{2 k} }$, we get<br>$$<br>\Pr[ M_k ] \le \delta.<br>$$ </p>
<p>By sub-additivity of probability,<br>$$<br>\Pr[ \cup_{k = 1}^n M_k ] \le \sum_{k = 1}^n \Pr[M_k] = n \delta.<br>$$</p>
<p>To make the bound meaningful, we require that $\delta \le \frac{1}{n}$.</p>
<h3 id="Beyond-The-Naive-Union-Bound"><a href="#Beyond-The-Naive-Union-Bound" class="headerlink" title="Beyond The Naive Union Bound"></a>Beyond The Naive Union Bound</h3><p>In this section, we avoid using union bound over $n$ events and improve the $\Pr[ \cup_{k = 1}^n M_k ]$ to<br>$$<br>\Pr[ \cup_{k = 1}^n M_k ] \le ( \log_\frac{1}{\alpha} n  + 1 ) \cdot \delta^\alpha,<br>$$</p>
<p>where $\alpha$ is any real number that satisfies $0 &lt; \alpha &lt; 1$. </p>
<p>As a sanity check, suppose $\delta = \frac{1}{n}$ and $\alpha = \frac{1}{2}$. The two bounds we have are </p>
<ol>
<li><p> $$<br> \Pr[ \cup_{k = 1}^n M_k ] \le n \delta = 1,<br> $$<br> which is trivial.</p>
</li>
<li><p> $$<br> \begin{aligned}</p>
<pre><code> ( \log_\frac&#123;1&#125;&#123;\alpha&#125; n  + 1 ) \cdot \delta^\alpha 
 &amp;= (\log_2 n + 1) \cdot &#123;1 \over \sqrt n&#125; 
</code></pre>
<p> \end{aligned}<br> $$</p>
</li>
</ol>
<p>The proof relies on a strengthened version of <em>Hoeffding inequality.</em>  </p>
<p><strong><em>Fact [1].</em></strong>  <em>For a fixed integer $s$, let $Z_1, Z_2, …, Z_s$ be i.i.d. copies of a random variable $Z$ on $[0, 1]$. For any $r &gt; 0$</em><br>$$<br>\Pr[ \exists t \le s : \quad t \cdot \mu - t \cdot \mu_t  \ge r] \le \exp(- \frac{2 r^2}{s} ). \<br>\<br>$$ </p>
<p><em>Proof.</em> We divide the $M_k$’s into $\lfloor \log_\frac{1}{\alpha} n \rfloor + 1$ groups. For integer $0 \le j \le \lfloor \log_\frac{1}{\alpha} n \rfloor$, define<br>$$<br>\begin{aligned}<br>    B_j &amp;\doteq \cup_{n \cdot \alpha^{j + 1} &lt; k \le  n \cdot \alpha^j } M_k \<br>        &amp;= \left{ \exists \quad n \cdot \alpha^{j + 1} &lt; k \le  n \cdot \alpha^j, \mu_k + \sqrt{ \frac{ \log \frac{1}{\delta} }{2 k} } \le \mu \right} \<br>        &amp;= \left{ \exists \quad n \cdot \alpha^{j + 1} &lt; k \le  n \cdot \alpha^j, k \cdot \mu_k + \sqrt{ \frac{  k \log \frac{1}{\delta} }{2} } \le k \cdot \mu \right} \<br>        &amp;\subset \left{ \exists \quad n \cdot \alpha^{j + 1} &lt; k \le  n \cdot \alpha^j, k \cdot \mu_k + \sqrt{ \frac{  n \cdot \alpha^{j + 1} \log \frac{1}{\delta} }{2} } \le k \cdot \mu \right} \<br>\end{aligned}<br>$$</p>
<p>Applying Fact [1] with $s = \lfloor n \cdot \alpha^j \rfloor &lt; n \cdot \alpha^j$, $r = \sqrt{ \frac{ n \cdot \alpha^{j + 1} \log \frac{1}{\delta} }{2  } }$, and by monotonicity of probability, we get<br>$$<br>\Pr[B_j] \le \exp( - \frac{  n \cdot \alpha^{j + 1} \log \frac{1}{\delta} }{2} \frac{ 2 }{ n \cdot \alpha^j } ) = \delta^{ \alpha }.<br>$$</p>
<p>Summing over all possible values of $j$, we get<br>$$<br>\Pr[ \cup_{j = 0}^{ \lfloor \log_\frac{1}{\alpha} n \rfloor } B_j] \le  \sum_{j = 0}^{ \lfloor \log_\frac{1}{\alpha} n \rfloor } \Pr[B_j] \le( \log_\frac{1}{\alpha} n  + 1 ) \cdot \delta^\alpha.<br>$$</p>
<p><em>Remark:</em> The first inequality still follows from union bound. However the number of events is now bounded by $\log_\frac{1}{\alpha} n  + 1$ instead of $n$. This comes with a cost of increasing $\delta$ to $\delta^\alpha$. </p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] S. Lattimore, “Bandit Algorithms,”<br>[2] S. Bubeck, “Bandits Games and Clustering Foundations,” </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/10/15/Stochastic-Multi-Armed-Bandits/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/10/15/Stochastic-Multi-Armed-Bandits/" class="post-title-link" itemprop="url">Stochastic Multi-Armed Bandits</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-10-15 23:26:43" itemprop="dateCreated datePublished" datetime="2020-10-15T23:26:43+11:00">2020-10-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-10-21 15:15:01" itemprop="dateModified" datetime="2020-10-21T15:15:01+11:00">2020-10-21</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>The multi-arm bandit problem (MAB) models a casino with $k$ machines, where the reward of each machine is controlled by a fixed and unknown distribution. The player (agent) observes independent random rewards from generated from the distribution of a machine each time it pulls its arm. Because of limited budget, the player can only play the machines $T$ times. The goal of the player is to maximize its expected gain.</p>
<p>There is an inherent exploration-exploitation nature of the problem. The player has to explore what is a good machine while simultaneously exploits what seems to be a good machine. </p>
<div style="text-align:center"><img src="https://jmichaux.github.io/assets/week6/octopus-bandit.jpeg" /></div>


<h3 id="Formulation"><a href="#Formulation" class="headerlink" title="Formulation"></a>Formulation</h3><p>We study the restricted case where the reward distribution of each machine is bounded on $[0, 1]$. Define </p>
<ol>
<li>$D_i:$ the reward distribution on $[0, 1]$ of the $i$-th machine, where $i \in [k]$,</li>
<li>$\mu_i:$ the expected reward of the $i$-th machine, where $i \in [k]$,</li>
<li>$\mu^* = \max_{i \in [k]} \mu_i$,</li>
<li>$i^*:$ the index of the machine with highest expected reward,</li>
<li>$\Delta_i = \mu^* - \mu_i$.</li>
</ol>
<p>Let $\vec Y_i$ be the random reward vector whose elements are i.i.d. random variables from $D_i$: </p>
<ol start="6">
<li>$\vec Y_i = (Y_{i, 1}, Y_{i, 2}, …, Y_{i, T})$</li>
</ol>
<p>Denote $Y$ be the matrix of the random variables</p>
<ol start="7">
<li>$$<br> Y = \begin{bmatrix}<pre><code> \vec Y_1 \\
 \vec Y_2 \\
 ... \\
 \vec Y_k
</code></pre>
 \end{bmatrix}<br>$$</li>
</ol>
<p>Each time the player pulls the arm, it observes one random variable from the matrix. Specially, let</p>
<ol start="8">
<li>$I_t:$ the machine played at the $t$-th trial,</li>
<li> $N_i(t):$ the number of times the machine $i$ is played up to trial $t$.</li>
</ol>
<p>Before trial $t$, the number of random variables observed in $\vec Y_{I_t}$ is $N_{I_t} (t - 1)$. At trial $t$, a new random variable in $\vec Y_{I_t}$ is observed, and $N_{I_t} (t) = N_{I_t} (t - 1) + 1$. Hence, the newly observed random variable is $Y_{I_t, N_{I_t} (t)}$. For convenience, we define </p>
<ol start="11">
<li> $X_{t} \doteq Y_{I_t, N_{I_t} (t)}:$ the rewards obtained at the $t$-th trial. </li>
</ol>
<div style="text-align:center">
<img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/StochasticMultiArmBandit.png" width="500" height="250" />
</div>


<p>When the player chooses a machine $I_t$ on trial $t$, it is based on the history of his play, which consists of his past decisions, and the corresponding observed rewards:</p>
<ol>
<li> $H_t: { (I_1, X_1), (I_2, X_2), …, (I_{t -1}, X_{t - 1}) }$ the history up to trial $t$. </li>
</ol>
<p>The strategy the player uses at trial $t$ is considered as a functions from $H_t$ to $[k]$: </p>
<ol start="11">
<li>$\phi_t: H_t \rightarrow [k]$ a function that chooses a machine based on the history at trial $t$</li>
</ol>
<p>We define the policy as the strategies the player uses over all trials:</p>
<ol start="12">
<li>$\phi = (\phi_1, \phi_2, …, \phi_T):$ policy, the strategy for the pulling arms by the player</li>
</ol>
<p>The goal is to find a policy that maximizes the expected rewards, or equivalently, the one that minimizes the expected regret<br>$$ \small<br>\mathbb{R}(\phi) = T \cdot \mu^* - \mathbb{E}[\sum_{t = 1}^T X_t ]<br>$$</p>
<p>By definition of $N_i(t)$’s, we have $\sum_{i = 1}^k N_i(T) = T$. Then the regret can be written as<br>$$<br>\mathbb{R}(\phi) = \mathbb{E}[\sum_{i = 1}^k N_i(T)] \cdot \mu^* - \sum_{i = 1}^k \mathbb{E}[N_i(T) ] \cdot \mu_i = \sum_{i : \Delta_i &gt; 0} \mathbb{E}[N_i(T) ] \cdot \Delta_i<br>$$</p>
<h3 id="The-Upper-Confidence-Bound-UCB-Algorithm"><a href="#The-Upper-Confidence-Bound-UCB-Algorithm" class="headerlink" title="The Upper Confidence Bound (UCB) Algorithm"></a>The Upper Confidence Bound (UCB) Algorithm</h3><p>When making decision at trial $t$, a good indicator of a machine’s performance is its empirical reward:<br>$$<br>\hat \mu_{i, N_i(t - 1)} \doteq  \sum_{\tau = 1}^{N_i(t - 1) } \frac{1}{ N_i(t - 1) } Y_{i, \tau}<br>$$</p>
<p>But this might not reflect the true value of its expectation $\mu_i$ because of sampling variation. The UCB algorithm takes the variation into consideration. </p>
<p><strong><em>Fact.</em></strong> <em>Hoeffding Inequality.</em> <em>Let $Z_1, Z_2, …, Z_s$ be i.i.d. copies of random variable $Z$ on $[a, b]$. Then</em><br>$$<br>\Pr[ \frac{1}{s} \sum_{\tau = 1}^s Z_\tau - E[Z] \ge r] \le \exp(- \frac{2 s r^2}{(b - a)^2 } )<br>$$<br><em>where r &gt; 0</em>. </p>
<p>Now, consider a <strong>fixed</strong> $s$ ($1 \le s \le T$) and a failure probability $\delta &gt; 0$.  Applying Hoeffding inequality with $Z_1 = Y_{i, 1}, Z_2 = Y_{i, 2}, …, Z_s = Y_{i, s}$, $a = 0, b = 1$ and $r = \sqrt { \log \frac{1}{\delta} \over 2  s }$, we get<br>$$ \small<br>\Pr \left[ \hat \mu_{i, s} - \mu_i \ge \sqrt { \log \frac{1}{\delta} \over 2  s } \right] \le \delta<br>$$</p>
<p>Similarly, by applying Hoeffding inequality with $Z_1 = -Y_{i, 1}, Z_2 = -Y_{i, 2}, …, Z_s = -Y_{i, s}$, $a = -1, b = 0$ and $r = \sqrt { \log \frac{1}{\delta} \over 2  s }$, we have<br>$$ \small<br>\Pr \left[ \mu_i - \hat \mu_{i, s} \ge \sqrt { \log \frac{1}{\delta} \over 2  s } \right] \le \delta<br>$$</p>
<p>Inspired by this, the UCB defines the upper and lower bounds for the expected reward of the $i$-th machine as follows:<br>$$ \small<br>UB_i ( t ) \doteq \hat \mu_{i, N_i(t - 1)} + \sqrt { \log t^\alpha \over 2  N_i(t - 1) } \<br>LB_i ( t ) \doteq \hat \mu_{i, N_i(t - 1)} - \sqrt { \log t^\alpha \over 2  N_i(t - 1) } \<br>$$<br>where $\alpha &gt; 0$ is a parameter to be set. By convention here that if $N_i(t - 1) = 0$, $\sqrt { \log t^\alpha \over 2  N_i(t - 1) } = \infty$. </p>
<p>The UCB algorithms chooses just the machine with highest upper bound. The lower bound is needed for its analysis. </p>
<blockquote>
<p><strong><em>UCB algorithm</em></strong>  </p>
<ol>
<li>For $t \leftarrow 1$ to $T$ do    </li>
<li>$\qquad$ Choose $I_t = \arg \max_{i \in [k] } UB_i ( t )$   </li>
<li>$\qquad$ Observe a reward $X_t$  </li>
</ol>
</blockquote>
<p>Intuitively, there are two cases when $UB_i ( t )$ is high:</p>
<ol>
<li>The value $\mu_i$ is high;</li>
<li>The $i$-th machine is under-explored.</li>
</ol>
<p><strong><em>Caveat:</em> <em>The reader might start to think that at trial $t$, it holds that $\Pr[\mu_i \ge UB_i(t) ]$ (or $\Pr[\mu_i \le LB_i(t) ]$) is bounded by $\frac{1}{t^\alpha}$, according to Hoeffding inequality. It is not. Hoeffding inequality requires the number of samples to be a fixed number. On the other hand, $N_i(t - 1)$ is a random variable that depends on the history of the game. We will discuss this later.</em></strong></p>
<p>The following theorem states that the expected regret of UCB algorithm grows logarithmically with $T$. </p>
<p><strong><em>Theorem.</em></strong> <em>If $\alpha &gt; 2$, the regret of the UCB algorithm is bounded by</em><br>$$ \small<br>\mathbb{R}(\phi) \le  \log T \cdot ( \sum_{i : \Delta_i &gt; 0 } \frac{2 \alpha }{\Delta_i } ) + \frac{\alpha}{ \alpha - 2 } \sum_{i : \Delta_i &gt; 0 } \Delta_i<br>$$</p>
<p><em>Proof:</em></p>
<p>We will show that for $i : \Delta_i &gt; 0$,<br>$$ \small<br>\mathbb{E} [n_{i, T}] \le \frac{ \alpha \log T }{ \Delta_i^2} + \frac{\alpha}{\alpha - 2}<br>$$</p>
<p>The key for the proof relies on a sufficient condition that the $i$-th machine will not be chosen at trial $t$: </p>
<blockquote>
<p>if the following events happen at trial $t$, machine $i$ will not be chosen:</p>
<ol>
<li>$A_t: 2 \sqrt { \alpha \log t \over 2  N_i(t - 1) } \le \Delta_i$  </li>
<li>$B_t: UB_{ i^* } ( t ) &gt; \mu^*$  </li>
<li>$C_t: \mu_i &gt; LB_i ( t )$</li>
</ol>
</blockquote>
<p>This condition essentially prevents $UB_i(t)$ from exceeding $\mu^*$ while assures $UB_{i^*}(t)$ is higher than $\mu^*$. </p>
<p>$$ \small<br>UB_i ( t ) = LB_i ( t ) + 2 \sqrt { \alpha \log t \over 2  N_i(t - 1) } &lt; \mu_i + \Delta_i = \mu^* &lt; UB_{ i^* } ( t )<br>$$</p>
<p>Let $\beta = \lceil \frac{2 \alpha \log T}{\Delta_i^2}  \rceil$. Note that  $A_t = { N_i(t - 1) \ge  \frac{2 \alpha \log t}{\Delta_i^2} }  \subset {  N_i(t - 1) \ge \beta }$. Now,<br>$$<br>{I_t = i } \subset \overline{ A_t \cap B_t \cap C_t } = \bar A_t \cup \bar B_t \cup \bar C_t<br>$$</p>
<p>and<br>$$<br>\begin{array}{ll}<br>    \mathbb{E}[n_{i, T}]    &amp;=  \mathbb{E}[ \sum_{t = 1}^T \mathfrak{1} {I_t = i} ]  \<br>                            &amp;=  \mathbb{E} [ \sum_{t = 1}^T \mathfrak{1} {I_t = i, \bar A_t }+ \sum_{t = 1}^T \mathfrak{1} {I_t = i, A_t } ]  \<br>                            &amp;\le  \mathbb{E} [ \sum_{t = 1}^T \mathfrak{1} {I_t = i, \  N_i(t) &lt; \beta } ] + \sum_{t = 1}^T \mathbb{E} [\mathfrak{1} {I_t = i, A_t } ]  \<br>                            &amp;\le \beta + \sum_{t = \beta + 1}^T \Pr[ {I_t = i} \cap A_t ] \<br>                            &amp;\le \beta + \sum_{t = \beta + 1}^T ( \Pr[ \bar B_t \cap A_t ] + \Pr[ \bar C_t \cap A_t ] ) \<br>                            &amp;\le \beta + \sum_{t = \beta + 1}^T ( \Pr[ \bar B_t ] + \Pr[ \bar C_t ] ) \<br>\end{array}<br>$$</p>
<p>It is non-trivial to bound $\Pr[\bar B_t]$. For a fixed $1 \le s \le t - 1$, define the event<br>$$<br>M_s : \frac{1}{s} \sum_{\tau = 1}^s Y_{i^*, \tau} + \sqrt{ \frac{\alpha \log t}{2 s} } \le \mu^*<br>$$</p>
<p>Since $s$ is fixed, by Hoeffding inequality, $\Pr[M_s] \le \frac{1}{t^\alpha}$. Then<br>$$ \small<br>\begin{aligned}<br>    \bar B_t = \left{ \mu_{ {i^*}, N_{i^*} (t - 1)} + \sqrt { \alpha \log t \over 2  N_{i^*} (t - 1) }  \le \mu^* \right} \subset \cup_{s = 1}^{t - 1} M_s<br>\end{aligned}<br>$$</p>
<p>and<br>$$<br>\Pr[ \bar B_t ] \le \Pr[ \cup_{s = 1}^{t - 1} M_s ] \le \sum_{s = 1}^{t - 1} \Pr[M_s] &lt; t^{\alpha - 1}<br>$$</p>
<p>and<br>$$<br>\sum_{t = \beta + 1}^T \Pr[ \bar B_t ] &lt; \sum_{t = \beta + 1}^T t^{\alpha - 1} &lt; \int_{t = 1}^\infty \frac{1}{ x^{\alpha - 1} } dx  = \frac{1}{\alpha - 2} x^{-(\alpha - 2)} \mid_{t = 1}^\infty  = \frac{1}{\alpha - 2}<br>$$</p>
<p>Similarly, we have<br>$$<br>\sum_{t = \beta + 1}^T \Pr[ \bar C_t ] &lt; \frac{1}{\alpha - 2}<br>$$</p>
<p>Finally,<br>$$<br>\begin{aligned} \small<br>    \mathbb{E} [n_{i, T}]<br>                &amp;\le \beta + \frac{2}{\alpha - 2} \<br>                &amp;\le \frac{2 \alpha \log T}{\Delta_i^2} + 1 + \frac{2}{\alpha - 2} \<br>                &amp;= \frac{2 \alpha \log T}{\Delta_i^2} + \frac{\alpha }{\alpha - 2}<br>\end{aligned}<br>$$</p>
<p><strong><em>Remark:</em></strong> <em>Can we bound  $\Pr[ \bar B_t ]$ as follows:</em><br>$$<br>\begin{array}{ll}<br>    \Pr[\bar B_t] &amp;= \sum_{\tau = 1}^{t - 1} \Pr[UB_{ i^* } ( t ) &lt; \mu^* \mid n_{i^*, t} = \tau] \cdot \Pr[n_{i^*, t} = \tau]\<br>    &amp;= \sum_{\tau = 1}^{t - 1} \frac{1}{t^\alpha} \cdot \Pr[n_{i^*, t} = \tau] \<br>    &amp;= \frac{1}{t^\alpha}<br>\end{array}<br>$$</p>
<p>When we know $n_{i^*, t} = \tau$ for some $\tau$, the $n_{i^*, t}$ rewards from machine $i^*$ can’t be viewed as independent samples. E.g., if $t$ is large, the best machines has much larger expected reward than others, and $n_{i^*, t}$ is very small compared to $t$. Then it is likely machine $i^*$ generates bad rewards in the history. The reward sequence of $i^*$ can’t be viewed as a sequence of independent samples from distribution $D_{i^*}$.</p>
<p>$\blacksquare$</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] D. Katselis, B. Miranda, and H. Hu, “Lecture 8: Multi-Armed Bandits”, ECE586 MDPs and Reinforcement Learning, Spring 2019, University of Illinois at Urbana-Champaign.<br>[2] S. Bubeck and N. Cesa-Bianchi, “Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems,” arXiv:1204.5721 [cs, stat], Nov. 2012, Accessed: Oct. 19, 2020. </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/06/21/Median-of-Mean/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/21/Median-of-Mean/" class="post-title-link" itemprop="url">Median-of-Mean</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-06-21 21:23:19 / Modified: 21:54:42" itemprop="dateCreated datePublished" datetime="2020-06-21T21:23:19+10:00">2020-06-21</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Suppose that we have an algorithm $A$ that estimates the mean $E[Y]$ of a random variable $Y$ within some specified range $r$ with probability $\rho &gt; \frac{1}{2}$. We can derive a new algorithm $A^*$ from $A$ that boosts the successful probability to $1 - \delta$, as follows: </p>
<blockquote>
<ol>
<li>Repeat $A$ for $m = \frac{1}{2 (\rho - 0.5)^2 } \ln \frac{1}{\delta}$ times. </li>
<li>Take the median of the $m$ outputs.   </li>
</ol>
</blockquote>
<p>To prove it, define the indicator random variable<br>$$<br>X_i = \begin{cases}<br>    1, \text{ if the } i \text{-th output of } A \text{ is within the range } r \<br>    0, \text{otherwise}<br>\end{cases}<br>$$</p>
<p>for $1 \le i \le m$. Then $E[X_i] = \rho &gt; 0.5$.<br>Let $\mu = E \left[\sum_{i = 1}^m X_i \right] = m\rho$.  </p>
<p>By Hoeffding’s inequality, for $\lambda &gt; 0<br>$,<br>$$<br>\Pr \left[ \left| \sum_{i = 1}^m X_i - \mu \right| \ge \lambda \right] \le \exp \left(- \frac{2\lambda^2}{m} \right)<br>$$</p>
<p>Replacing $\lambda$ with $\mu - 0.5m$, and $m$ with $m = \frac{1}{2 (\rho - 0.5)^2 }\ln \frac{1}{\delta}$, we get<br>$$<br>\begin{aligned}<br>    \Pr \left[ \sum_{i = 1}^m X_i \le 0.5m \right] &amp;\le \Pr \left[ \left| \sum_{i = 1}^m X_i - \mu \right| \ge m(\rho - 0.5) \right] \<br>    &amp;\le \exp \left(- 2m(\rho - 0.5)^2 \right) \<br>    &amp;= \delta<br>\end{aligned}<br>$$</p>
<p>Note that if more than half of $A$ outputs are correct, then the output of $A^*$ is correct. This happens with probability at least $1 - \delta$.  </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/06/18/Entropy-and-Message-Transmission/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/18/Entropy-and-Message-Transmission/" class="post-title-link" itemprop="url">Entropy and Message Transmission</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-06-18 20:26:03" itemprop="dateCreated datePublished" datetime="2020-06-18T20:26:03+10:00">2020-06-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-07-01 11:06:27" itemprop="dateModified" datetime="2020-07-01T11:06:27+10:00">2020-07-01</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>We discuss another application that sheds light on meaning of entropy, the message transmission problem. In this model, a sender transmits a message to the receiver through a channel. In real world, the channel could be an optical fiber, a wireless channel,  a hard disk etc. In the final application, the computer that writes and reads information from the hard disk is both the sender and the receiver. </p>
<p>In real world the channel is not perfect and the message transmitted is distorted by noise. It is natural to ask whether the message can be transmitted accurately under the noise, i.e., whether the receiver can recover the noisy message. </p>
<p>To study the problem, we need a mathematical model for both the channel and the noise. We focus on the simplest binary channel with bits of 0 and 1. The noise causes the bits to flip and is modelled by the distribution on the bit-flips.  We study the simplest one that flips each bit independently with some identical probability $p &lt; 0.5$. For a message with length $n$, the number of bit flips follows a Binomial distribution $B(n, p)$. We call such channel a <em>binary symmetric channel</em>. </p>
<p>To protect the message against noise, a naïve way is to send the each bit multiple times. For example, if the sender wants to send a bit 1, it sends $10$ copies of $1$ as $1111111111$.  The receiver decides that the bit sent is 1, if the majority of the $10$ bits it receives is 1. </p>
<p>Could it be improved?  Repeating each bit may not be the mot efficient way against the noise. In general, if the sender wants to send a message of $k$ bits, it can convert it into a new message of $n$ bits and sends the new one.  The receiver considers the $n$ bits received as a whole, and try to recover the $k$-bit message the sender wants to send.</p>
<p>We call the method used by the sender to convert the original message the <em>encoding function</em>, and the one used by the receiver to recover the message the  <em>decoding function.</em> </p>
<p><strong><em>Definition.</em></strong> A $(k, n)$ encoding function $\text{Enc}: {0, 1}^k \rightarrow {0, 1}^n$ and a $(k, n)$ decoding function $\text{Dec}: {0, 1}^n \rightarrow {0, 1}^k$, where $n \ge k$. </p>
<p>Since the noise flips the bits randomly, it is impossible to have an encoding function and a decoding function without error (unless $p = 0$). Instead, we aim to control the  probability of error within some specified threshold $\delta$. To achieve this, we add redundancy to the message and encode a $k$-bit one into an $n$-bit one. Now, $n - k$ is the amount of redundancy introduced. We would like to make $n - k$ as small as possible. On the other hand, the value of $n-k$ should positively related to $p$. The larger $p$ is, the noisier the channel is and the larger $n - k$ should be. </p>
<p>For fixed $\delta$ and $p$, the <em>Shannon’s Theorem</em> says that the smallest possible value of $n - k$ we can achieve is roughly $n\mathbf{H}(p)$. Intuitively, $\mathbf{H}(p)$ is the amount of randomness the noise exerts on each bit. Therefore $1 - \mathbf{H}(p)$ is the maximum amount of information we can transmit by one bit. </p>
<p>Before we proceed, we prove the following lemma. </p>
<p><strong><em>Lemma 1</em></strong><br>For $q \in \mathbb{R}, q \le 1 / 2$ and $n \in \mathbb{N}$,  it hold that<br>$$<br>\begin{aligned}<br>    \sum_{i = 0}^{\lfloor q n \rfloor} \binom{n}{i}<br>    &amp;\le 2^{ n \mathbf{H} ( q)  + \log \frac{n + 1}{2} }<br>\end{aligned}<br>$$</p>
<p><strong><em>Proof.</em></strong><br>$$<br>\begin{aligned}<br>    \sum_{i = 0}^{\lfloor q n \rfloor} \binom{n}{i}<br>    &amp;\le \frac{n + 1}{2} \binom{n }{\lfloor q n \rfloor }  \<br>    &amp;\le \frac{n + 1}{2} 2^{ n \mathbf{H} \left( { \lfloor q n \rfloor } / { n } \right) } \<br>    &amp;\le 2^{ n \mathbf{H} ( q)  + \log \frac{n + 1}{2} }<br>\end{aligned}<br>$$</p>
<p>The first inequality follows from  that $\binom{n}{i}$ is increasing for $i \le n / 2$ and that the summation is over at most $(n + 1) /2$ terms. The last one follows from that $\mathbf{H}(x)$ is increasing for $x \le 1 / 2$ and that ${ \lfloor q n \rfloor } / { n } \le {  q n } / { n } = q &lt; 1/2$.</p>
<p>$\blacksquare$</p>
<p><strong><em>Shannon’s Theorem</em></strong><br>Given a binary symmetric channel with flip probability $p &lt; 1 / 2$ and for any any $\epsilon, \delta &gt; 0$, when $n$ is large enough,  </p>
<ol>
<li>if $k \le  n (1 - \mathbf{H}(p) - \epsilon)$, there exist $(k, n)$ encoding and decoding functions such that the receiver fails to obtain the correct message with probability at most $2\delta$.   </li>
<li>$\nexists (k, n)$ encoding and decoding functions with $k \ge n (1 - \mathbf{H}(p) + \epsilon)$ such that the decoding is correctly is at most $\delta$ for a $k$-bit input message chosen uniformly at random. </li>
</ol>
<p><strong><em>Proof of 1.</em></strong> </p>
<p><strong>Intuition.</strong>  When an $n$-bit message $s$ is transmitted through the channel, the number of flipped bits is roughly $np$. As $p &lt; {1} / {2}$, we can find a $\lambda &gt; 0$ such that $p + \lambda &lt; {1} / {2}$.  Let $R$ be the received $n$-bit message and define $d(s, R)$ the number of different bits between $s$ and $R$, i.e., the Hamming distance between $s$ and $R$. Given $s$ and $p$, let $\mathfrak{D}(s, p)$ be the distribution of $R$ on ${0, 1}^n$.</p>
<p>By Hoeffding’s inequality, it holds that<br>$$<br>\Pr_{R \sim \mathfrak{D}(s, p) } [ |d(s, R) - pn | \ge \lambda n] \le \exp(- 2 \lambda^2 n).<br>$$</p>
<p>Define the $(p + \lambda)n$ ball centered $s$ as<br>$$<br>B_{s, (p + \lambda)n} \doteq { r \in {0, 1}^n : d(s, r) &lt; (p + \lambda)n }.<br>$$</p>
<p>The the Hoeffding’s inequality implies that for large enough $n$, we have<br>$$<br>\Pr_{R \sim \mathfrak{D}(s, p) } [ R \notin B_{s, (p + \lambda)n}] \le \delta.<br>$$</p>
<p>That is, with probability at most $\delta$, the received message fall outside the ball $B_{s, (p + \lambda)n}$. This motivates to decode each message in $B_{s, (p + \lambda)n}$ as the original message the sender wants to send. </p>
<p>Further, by Lemma 1, the size of $B_{s, (p + \lambda) n}$ is bounded by<br>$$<br>\begin{aligned}<br>    \sum_{i = 0}^{\lfloor (p + \lambda) n \rfloor} \binom{n}{i}<br>    &amp;\le 2^{ n \mathbf{H} ( p + \lambda)  + \log \frac{n + 1}{2} }<br>\end{aligned}<br>$$</p>
<p>Therefore, the maximum number of non-overlapped balls we can pack into the message space ${0, 1}^n$ is<br>$$<br>\frac{2^n}{ 2^{ n \mathbf{H} ( p + \lambda)  + \log \frac{n + 1}{2} }  } = 2^{ n (1 - \mathbf{H} ( p + \lambda) - \frac{1}{n} \log \frac{n + 1}{2})   }<br>$$</p>
<p>When $n$ is large enough, this is at least $2^{ n (1 - \mathbf{H} ( p ) - \epsilon) }$. </p>
<p><em>Remark: Hoeffding’s inequality is an overkill. Chebyshev’s inequality suffices for this proof.</em></p>
<p><strong>Designing Encoding and Decoding Functions.</strong></p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/Entropy/Balls.png"></p>
<p>This motivates one to design of encoding and decoding function as follows: find a set of messages $s_1, s_2, …, s_{2^k} \in {0, 1}^n$, such that<br>$$<br>B_{s_1, (p + \lambda)n}, B_{s_2, (p + \lambda)n}, …, B_{s_{2^k} , (p + \lambda)n}<br>$$</p>
<p>are disjoint balls, and assign the messages in ${0, 1}^k$ to the ones in ${ s_i }‘s$ one by one. If the sending want to send $i$, it sends $s_i$. On receiving a message $r$, the receiver determines which ball $r$ belongs to. The probability of decoding error is at most $\delta$.</p>
<p><em>Question to ponder: can we find such a set efficiently, such that</em><br>$$<br>B_{s_1, (p + \lambda)n}, B_{s_2, (p + \lambda)n}, …, B_{s_{2^k} , (p + \lambda)n}<br>$$<br><em>are disjoint?</em>  </p>
<p><strong>Finding the Codewords.</strong></p>
<p>It is left to find a set of satisfactory $s_1, s_2, …, s_{2^k} \in {0, 1}^n$. The method we show here does not find a set of non-overlapped balls. Instead it aims to find a set such that </p>
<blockquote>
<p>if $s_i$ is transmitted, then the probability received message $r$ falls into the another ball, i.e., $r \in B_{s_{j} , (p + \lambda)n}$ ($j \neq i$),  is less than $\delta$.  </p>
</blockquote>
<p>The property implies that the overlap between $B_{s_{i} , (p + \lambda)n}$ and $\cup_{j \neq i} B_{s_{j} , (p + \lambda)n}$ is less than $\delta$ (measured by probability). To formalize the statement, define the random variable $S$ to be the message sent and $R$ to be the one received. Given that $S = s_i$ is sent, the conditional probability of receiving $R = r$ is<br>$$<br>\Pr_{R \sim \mathfrak{D}(s_i, p) } [R = r \mid S = s_i] = p^{d(s_i,r)} (1 - p)^{1 - d(s_i, r)}<br>$$</p>
<p>To goal is to prove that it holds for all $i$,<br>$$<br>\Pr_{R \sim \mathfrak{D}(s_i, p) } [R \in \cup_{j \neq i} B_{s_{j} , (p + \lambda)n } \mid S = s_i] = \sum_{r \in \cup_{j \neq i} B_{s_{j} , (p + \lambda)n} } p_r \le \delta<br>$$</p>
<p>Then , by union bound, it holds that<br>$$<br>\begin{aligned}<br>\Pr_{R \sim \mathfrak{D}(s_i, p) }  [ R \text{ is not recovered correctly} \mid S = s_i]<br>    &amp;= \Pr_{R \sim \mathfrak{D}(s_i, p) }  [ R \notin B_{s_i, (p + \lambda)n}  \vee  R \in \cup_{j \neq i} B_{s_{j} , (p + \lambda)n}  \mid S = s_i] \<br>    &amp;\le \Pr_{R \sim \mathfrak{D}(s_i, p) }  [ R \notin B_{s_i, (p + \lambda)n}   \mid S = s_i]  + \Pr[ R \in \cup_{j \neq i} B_{s_{j} , (p + \lambda)n}  \mid S = s_i] \<br>    &amp;\le 2 \delta<br>\end{aligned}<br>$$<br>That is, $s_i$ is transmitted and decoded correctly with probability at least $1 - 2 \delta$. </p>
<p>In what follows, we will prove the following claim:</p>
<p><strong>Claim 1</strong>. <em>If we generate $2^{k + 1}$ codewords uniformly at random from ${0, 1}^n$, then in  expectation</em><br>$$<br>\underset{ {s_1, s_2, …,s_{2^{k + 1} } \sim \mathbf{U}({0, 1}^n) } } {\mathbb{E} }  \left[ \sum_{i = 1}^{2^{k + 1} }  \Pr_{R \sim \mathfrak{D}(s_i, p) } [R \in \cup_{j \neq i} B_{s_{j} , (p + \lambda)n } \mid S = s_i] \right] \le  2^k \delta<br>$$</p>
<p>Claim 1 implies that there exits a set of codewords $s_1, s_2, …, s_{2^{k + 1} }$ with<br>$$<br>\sum_{i = 1}^{2^{k + 1} } \Pr_{R \sim \mathfrak{D}(s_i, p) } [R \in \cup_{j \neq i} B_{s_{j} , (p + \lambda)n } \mid S = s_i]    \le 2^k \delta<br>$$</p>
<p>If we send each $s_i$ with probability $1 / 2^k$, then the expected error probability is already $\delta$. But we can have a stronger result: we can find a set of $2^k$ codewords, such that for each $i$,<br>$$<br>\Pr_{R \sim \mathfrak{D}(s_i, p) } [R \in \cup_{j \neq i} B_{s_{j} , (p + \lambda)n } \mid S = s_i] \le 2 \delta<br>$$</p>
<p>W.L.O.G., suppose that $s_1, s_2, …, s_{2^k}$ are the ones with the smallest $\Pr_{R \sim \mathfrak{D}(s_i, p) } [R \in \cup_{j \neq i} B_{s_{j} , (p + \lambda)n } \mid S = s_i]$ ‘s, it must be that<br>$$<br>\Pr_{R \sim \mathfrak{D}(s_i, p) } [R \in \cup_{j \neq i} B_{s_{j} , (p + \lambda)n } \mid S = s_i]  \le \frac{2^k \delta }{2^k } = \delta<br>$$</p>
<p><strong><em>Proof of Claim 1</em></strong>. By Lemma 1, for a fixed $r$, the number of  strings $s \in {0, 1}^n$ such that $d(s, r) &lt; (p + \lambda) n$ is bounded by<br>$$<br>\begin{aligned}<br>    \sum_{k = 0}^{\lfloor (p + \lambda) n \rfloor} \binom{n}{k}<br>        &amp;\le \frac{n + 1}{2} 2^{ n \mathbf{H} ( p + \lambda) }<br>\end{aligned}<br>$$</p>
<p>If a message $s$ is picked uniformly at random from ${0, 1}^n$, the probability such that<br>$$<br>\Pr_{s \sim \mathbf{U}({0, 1}^n) } [d(s, r) &lt; (p + \lambda) n ] \le \frac{n + 1}{2^{n + 1} } 2^{ n \mathbf{H} \left(  p + \lambda \right) }<br>$$</p>
<p>By union bound,<br>$$<br>\begin{aligned}<br>    \Pr_{s_1, s_2, …,s_{2^{k + 1} } \sim \mathbf{U}({0, 1}^n) } [ r \in \cup_{j \neq i} B_{s_{j} , (p + \lambda)n}  ]<br>    &amp;&lt; 2^k \frac{n + 1}{2^{n + 1} } 2^{ n \mathbf{H}( p + \lambda) }  \<br>    &amp;= 2^{ k + \log (n + 1) +  n \mathbf{H} ( p + \lambda) - n - 1 }<br>\end{aligned}<br>$$</p>
<p>As $k \le n(1 - \mathbf{H}(p) - \epsilon)$, when $n$ is sufficient large, it follows<br>$$<br>\begin{aligned}<br>     \Pr_{s_1, s_2, …,s_{2^{k + 1} } \sim \mathbf{U}({0, 1}^n) } [ r \in \cup_{j \neq i} B_{s_{j} , (p + \lambda)n}  ]<br>        &lt; 2^{ \log \frac{n + 1}{2} +  n ( \mathbf{H} ( p + \lambda) - \mathbf{H} ( p) - \delta) }<br>        \le \frac{\delta}{2}<br>\end{aligned}<br>$$</p>
<p>Therefore,<br>$$<br>\begin{aligned}<br>    &amp;\underset{ {s_1, s_2, …,s_{2^{k + 1} } \sim \mathbf{U}({0, 1}^n) } } {\mathbb{E} } \left[ \Pr_{R \sim \mathfrak{D}(s_i, p) } [R \in \cup_{j \neq i} B_{s_{j} , (p + \lambda)n } \mid S = s_i] \right] \<br>    &amp;= \sum_{r \in {0, 1}^n }     \Pr_{s_1, s_2, …,s_{2^{k + 1} } \sim \mathbf{U}({0, 1}^n) } [ r \in \cup_{j \neq i} B_{s_{j} , (p + \lambda)n}  ] \cdot  \Pr_{R \sim \mathfrak{D}(s_i, p) } [ R = r \mid S = s_i] \<br>    &amp;\le \frac{\delta}{2}<br>\end{aligned}<br>$$</p>
<p>and<br>$$<br>\underset{ {s_1, s_2, …,s_{2^{k + 1} } \sim \mathbf{U}({0, 1}^n) } } {\mathbb{E} }  \left[ \sum_{i = 1}^{2^{k + 1} }  \Pr_{R \sim \mathfrak{D}(s_i, p) } [R \in \cup_{j \neq i} B_{s_{j} , (p + \lambda)n } \mid S = s_i] \right] \le 2^{k + 1} \frac{\delta}{2} = 2^k \delta<br>$$</p>
<p>$\blacksquare$</p>
<p><strong><em>Proof of 2.</em></strong>  </p>
<p>The difficulty here is to prove that the claim holds for arbitrary $(k, n)$ encoding and decoding functions. The proof relies on an important property:</p>
<blockquote>
<p>the decoding function $\text{Dec}$ is a function on ${0, 1}^n$</p>
</blockquote>
<p>For any $r \in {0, 1}^n$, there is a unique output $\text{Dec}(r) \in {0, 1}^k$. The decoding function needs to decide the unique message ${0, 1}^n$ the sender want to send. </p>
<p>Now, define<br>$$<br>S_i \doteq { r \in {0, 1}^n :  r \text{ is decoded correctly if } s_i \text{ is sent}   }<br>$$</p>
<p>The $S_i$’s are non-overlapped and we have,<br>$$<br>\cup_{i = 1}^{2^k} S_i \subset {0, 1 }^n<br>$$</p>
<p>If $s_i$ is sent, then by Hoeffding inequality, with probability at least $1 - \exp(- 2\lambda^2 n)$, the received message $R$ is likely to fall into a ring centered at $s_i$:<br>$$<br>\text{ring} (s_i) \doteq { r \in {0, 1}^n : |d(r, s_i) - pn |&lt; \lambda n }<br>$$</p>
<p>Finally, if the messages $s_1, s_2, …, s_{2^k}$ are sent uniformly at random, i.e., $i \sim \mathbf{U}[1, 2^k]$, then<br>$$<br>\begin{aligned}<br>    \Pr[ R \text{ is decoded correctly}]   &amp;=  \sum_{i = 1}^{2^k} \sum_{r \in S_i } \Pr_{R \sim \mathfrak{D}(s_i, p) } [R = r \mid S = s_i] \Pr_{i \sim \mathbf{U}[1, 2^k]} [ S = s_i] \<br>        &amp;=  \frac{1}{2^k} \sum_{i = 1}^{2^k} \sum_{r \in S_i } \Pr_{R \sim \mathfrak{D}(s_i, p) } [R = r \mid S = s_i]<br>\end{aligned}<br>$$</p>
<p>Observed that $S_i \subset \text{ring} (s_i) \cup (S_i \cap \text{ring} (s_i) )$, we get</p>
<p>$$<br>\begin{aligned}<br> &amp;\Pr[ R \text{ is decoded correctly}] \<br>        &amp;\le \frac{1}{2^k}  \sum_{i = 1}^{2^k} \left( \sum_{r \notin \text{ring} (s_i)  } \Pr_{R \sim \mathfrak{D}(s_i, p) } [R = r \mid S = s_i]  +\sum_{r \in S_i \cap \text{ring} (s_i) } \Pr_{R \sim \mathfrak{D}(s_i, p) } [R = r \mid S = s_i] \right) \<br>        &amp;\le \frac{1}{2^k}  \sum_{i = 1}^{2^k} \left( \exp( -2\lambda^2n) +\sum_{r \in S_i \cap \text{ring} (s_i) } \Pr_{R \sim \mathfrak{D}(s_i, p) } [R = r \mid S = s_i] \right)<br>\end{aligned}<br>$$</p>
<p>Note that for $r \in S_i \cap \text{ring} (s_i)$, as $p &lt; 1 / 2$, it holds that<br>$$<br>\Pr_{R \sim \mathfrak{D}(s_i, p) } [R = r \mid S = s_i] \le p^{ \lceil(p - \lambda) n \rceil} (1 - p)^{ n - \lceil(p - \lambda) n \rceil }<br>$$</p>
<p>We obtain</p>
<p>$$<br>\begin{aligned}<br>        &amp;\Pr[ R \text{ is decoded correctly}] \<br>        &amp;\le \exp( -2\lambda^2n) +  \frac{1}{2^k}  \sum_{i = 1}^{2^k} \sum_{r \in S_i \cap \text{ring} (s_i) } p^{ \lceil(p - \lambda) n \rceil} (1 - p)^{ n - \lceil(p - \lambda) n \rceil } \<br>        &amp;\le \exp( -2\lambda^2n) +  \frac{1}{2^k}  \sum_{i = 1}^{2^k} \sum_{r \in S_i \cap \text{ring} (s_i) } p^{ (p - \lambda) n } (1 - p)^{ n - (p - \lambda) n  } \<br>        &amp;= \exp( -2\lambda^2n) +  p^{ (p - \lambda) n } (1 - p)^{ n - (p - \lambda) n  }  \sum_{i = 1}^{2^k} \sum_{r \in S_i \cap \text{ring} (s_i) } \frac{1}{2^k}  \<br>        &amp;= \exp( -2\lambda^2n) +   p^{ pn } (1 - p)^{ n - pn } \left(\frac{ 1 - p}{ p} \right)^{\lambda n} 2^{n - k}\<br>        &amp;= \exp( -2\lambda^2n) +  2^{n - k - n \mathbf{H}(p)}  \left(\frac{ 1 - p}{ p} \right)^{\lambda n}<br>\end{aligned}<br>$$</p>
<p>Conditioning on that $k \ge n (1 - \mathbf{H}(p) + \delta)$,<br>$$<br>\Pr[ R \text{ is decoded correctly}] \le \exp( -2\lambda^2n) +  2^{- n (\delta + \lambda \log \frac{ 1 - p}{ p} ) }<br>$$</p>
<p>By choosing sufficient small $\lambda$ and large enough $n$, $\Pr[ R \text{ is decoded correctly}]$ can be arbitrary small.  </p>
<p>$\blacksquare$</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] M. Mitzenmacher and E. Upfal, Probability and computing: an introduction to randomized algorithms and probabilistic analysis. New York: Cambridge University Press, 2005.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/06/07/Entropy-and-Compression/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/07/Entropy-and-Compression/" class="post-title-link" itemprop="url">Entropy and Compression</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-06-07 12:24:22" itemprop="dateCreated datePublished" datetime="2020-06-07T12:24:22+10:00">2020-06-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-07-13 23:57:00" itemprop="dateModified" datetime="2020-07-13T23:57:00+10:00">2020-07-13</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>One interpretation of entropy of a random variable is as a measure of how many unbiased, independent random bits in expectation we can extract from the random variable. Another one comes from compression of a sequence.</p>
<p>Assume that the sequence studied (denoted as $s$) is a binary one. It consists of a concatenation of the outcomes of $n$ independent Bernoulli random variables. Without lose of generality, we assume that each bit comes up $1$ with probability $p \le { 1 / 2 }$. This is one of the simplest models of a sequence. </p>
<p>The fact that sequence could be a biased one makes it possible to represent it by a new sequence with shorter length in expectation. For example, suppose that $p = \frac{1}{4}$, then for a pair of consecutive bits, it have   </p>
<ol>
<li>probability $\frac{1}{16}$ of being $11$,   </li>
<li>probability $\frac{3}{16}$ of being $01$, </li>
<li>probability $\frac{3}{16}$ of being $10$,</li>
<li>probability $\frac{9}{16}$ of being $00$.  </li>
</ol>
<p>If we use $111$ to represent $11$, $110$ to represent $01$, $10$ to represent $10$, and $0$ to represent $00$,  then the expected number of representation bits per pair is<br>$$<br>\begin{array}{r}<br>    3 \cdot \frac{1}{16} + 3 \cdot \frac{3}{16} + 2 \cdot  \frac{3}{16} + 1 \cdot  \frac{9}{16}<br>    = \frac{27}{16}<br>    &lt; 2<br>\end{array}<br>$$</p>
<p>In general, compression is not limited to the way described above. We call the rule with which we compress a string <em>a compression function</em>. </p>
<h3 id="Compression-Function"><a href="#Compression-Function" class="headerlink" title="Compression Function"></a><strong><em>Compression Function</em></strong></h3><p><em>Let $S = {0, 1}^n$ be the set of binary sequence of length $n$, and $T = { 0, 1}^+$ the set of binary sequence of any positive length. A compression function $h: S \rightarrow T$ is an injective (one-to-one) function from $S$ to $T$.</em>    </p>
<p>In other words, each $s \in S$ is assigned a unique non-empty sequence (of arbitrary length) by $h$. </p>
<p>Observe that the size of $S$ is $2^n$. On the other hand, the number of sequences with length less than $n$ is $\sum_{i = 1}^{n - 1} 2^{i} = 2^n - 1 &lt; 2^n$. For any $h$, it is impossible for $h$ to map every $s \in S$ to a sequence with length less than $n$. Under adversarial input, $h$ can not compress at all.</p>
<p>The hope is that when there is a distribution $\mathfrak{D}$ on $S$, the expected length of the compressed sequences would be small:<br>$$<br>\mathbf{E} [ |h(s)| ] = \sum_{s \in S} p_s \cdot |h(s)|<br>$$</p>
<p>To illustrate the meaning of entropy, we study a simple case where $\mathfrak{D}$ is the joint distribution of $n$ <em>i.i.d.</em> Bernoulli random variables that come up $1$ with probability $p \le { 1 / 2 }$ (by symmetry, the claim holds for the case of $p &gt; { 1 / 2 }$).</p>
<p>The following theorem formalizes how good a compression function we can find. </p>
<h3 id="Entropy-as-Lower-Bound-and-Upper-Bound"><a href="#Entropy-as-Lower-Bound-and-Upper-Bound" class="headerlink" title="Entropy as Lower Bound and Upper Bound"></a><strong><em>Entropy as Lower Bound and Upper Bound</em></strong></h3><p><em>Theorem.</em></p>
<ol>
<li>$\forall \delta &gt; 0$, $\exists$ a compression $h$ and integer $N &gt; 0$, s.t., $\forall n \ge N$, it holds that<br>$$<br>\mathbf{E}[ |h(s)| ] \le (1 + \delta) n \mathbf{H}(p)<br>$$</li>
<li>$\forall \delta &gt; 0$, $\exists$ integer $N &gt; 0$, s.t., $\forall n \ge N$, it holds that for any compression $h$,<br> $$<pre><code> \mathbf&#123;E&#125;[ |h(s)| ] \ge (1 - \delta) n \mathbf&#123;H&#125;(p)
</code></pre>
 $$</li>
</ol>
<p><em>Intuitively, the entropy $\mathbf{H}(p)$ is the measure of the average number of bits in expectation we need after compression to represent a Bernoulli random variable that comes up $1$ with probability $p$.</em> </p>
<p><em>The high level idea of the proof is that, with high probability, the number of ones in a $s \in S$ is roughly $np$. There are roughly $2^{n\mathbf{H}(p)}$ such sequences. Therefore, we can use $n \mathbf{H}(p)$ bits to represent each sequence.</em></p>
<p><strong><em>Proof.</em></strong> The claim is trivially true if $p = { 1 / 2 }$. Otherwise, $p &lt; { 1 / 2 }$. We can pick some $\epsilon &gt; 0$, such that $p + \epsilon &lt; { 1 / 2 }$. Further, if $n$ is large enough,  $np + n\epsilon \le n / 2 - 1$. Hence, we may assume that $\lceil np + n\epsilon \rceil \le n / 2$ . </p>
<p>Denote $Z$ be the number of ones in the string $s$. By Hoeffding Inequality, it holds that<br>$$<br>\Pr[ |Z - np| \ge n\epsilon ] \le \exp(-2n \epsilon^2)<br>$$</p>
<p>By the fact that $Z$ takes only integer values, we have<br>$$<br>\Pr[Z \ge \lceil np + n\epsilon \rceil] \le \exp(-2 n \epsilon^2 )<br>$$</p>
<p>We use the first bit output of $h$ as a flag. For a string $s$ with $Z \ge \lceil np + n\epsilon \rceil$, we set the first bit to $0$ and then output the same sequence, i.e., $h(s) = 0s$. In such case we do not compress the string at all and use $n + 1$ bits to represent it. </p>
<p>We set the first bit output to $1$ if $Z &lt; \lceil np + n \epsilon \rceil \le n / 2$.  The number of such sequences is bounded by<br>$$<br>\sum_{k = 0}^{\lceil np + n\epsilon \rceil - 1} \binom{n}{k} \le  \frac{n}{2} \binom{n}{\lceil np + n\epsilon \rceil - 1 } \le \frac{n}{2} 2^{ n \cdot \mathbf{H} \left( \frac{ \lceil np + n\epsilon \rceil - 1 }{n} \right) } \le \frac{n}{2} 2^{ n \mathbf{H} \left( p + \epsilon  \right) }<br>$$</p>
<p>The first inequality holds because $\binom{n}{k}$ increases for $k &lt; n / 2$ and that the summation is over $\lceil np + n \epsilon \rceil \le n / 2$ terms. The last inequality holds since $(\lceil np + n\epsilon \rceil - 1) / n \le ( np + n\epsilon ) / n = p + \epsilon &lt; 1 / 2$ and $\mathbf{H}( \cdot )$ is a increasing function in the range $[0, 1/2]$. </p>
<p>We compress these sequences by representing each of them with a unique sequence of at most<br>$$<br>\begin{array}{rl}<br>    \log \left[ (n / 2) \cdot  2^{ n \cdot\mathbf{H} \left( p + \epsilon  \right) } \right]<br>    = n \cdot\mathbf{H} \left( p + \epsilon  \right)  + \log n -1<br>\end{array}<br>$$</p>
<p>bits. Considering the leading flag bit 1 (to indicate the sequence is a compressed one), we output at most $n \mathbf{H} \left( p + \epsilon  \right)  + \log n$ bits for sequences with $Z &lt; \lceil np + n \epsilon \rceil$. This can be written as $\left[ \mathbf{H} \left( p + \epsilon  \right)  + (1 / n) \cdot (\log n - 1) \right] n$ bits and is smaller than<br>$$<br>(1 + \delta /{2} ) \cdot \mathbf{H} (p) \cdot n<br>$$</p>
<p>is $\epsilon$ is smaller enough and $n$ is large enough.</p>
<p>We are almost done with the proof. It is left to consider sequences with $Z \ge \lceil np + n \epsilon \rceil$. For those sequence, we don’t compress them and and set the leading flag bit to 0. The outputs for those sequences consist of at most $1 + n$ bits. However, by Hoeffding inequality, such sequences do not appear frequently and the expected output length can be made arbitrary small.</p>
<p>Specifically, $\forall \delta &gt; 0$, we can find large enough $N$, such that $\forall n &gt; N$, it holds  </p>
<p>$$<br>(n + 1 ) \cdot \exp(-2 n \epsilon^2 ) \le n \cdot (\delta / 2)  \cdot  \mathbf{H}(p)<br>$$</p>
<p>Then, in expectation, the bits outputted by $h$ is at most<br>$$<br>\begin{aligned}<br>    &amp;(n + 1) \cdot \exp(-2 n \epsilon^2 ) + [n \cdot \mathbf{H} \left( p + \epsilon  \right)   + \log n ] \cdot [ 1 - \exp(-2 n \epsilon^2 ) ] \<br>    \le&amp; n \cdot (\delta / 2)  \cdot  \mathbf{H}(p) + [ n \cdot \mathbf{H} \left( p + \epsilon  \right)   + \log n ]\<br>    \le&amp; n \cdot (\delta / 2)  \cdot  \mathbf{H}(p)  +  (1 + \delta /{2} ) \cdot \mathbf{H} (p) \cdot n\<br>    \le&amp; \left(  1 + \delta \right) \cdot \mathbf{H}(p) \cdot n<br>\end{aligned}<br>$$</p>
<p>To prove the lower bound, first we need the following lemma.</p>
<p><strong><em>Lemma.</em></strong> <em>for $s_1, s_2 \in S$, if $s_1$ has more ones than $s_2$, i.e., $\Pr(s_1) \ge \Pr(s_2)$, then the $h$ that minimizes the expected output length $\mathbf{E}[ |h(s)| ]$ should assign $s_1$ a sequence at most as long as $s_2$, i.e., $|h(s_1)| \le |h(s_2)|$.</em> </p>
<p><em>Proof</em>. Otherwise, if we swap the output sequences of $h(s_1)$ and $h(s_2)$, we lower value of  $\mathbf{E}[ |h(s)| ]$.  </p>
<p>$\square$</p>
<p>Further, consider the number of $s \in S$ with $\lfloor np - n \epsilon \rfloor$ ones,<br>$$<br>\begin{aligned}<br>\binom{n}{\lfloor np - n\epsilon \rfloor }<br>    &amp;\ge \frac{1}{n + 1} 2^{ n \cdot \mathbf{H} \left( { \lfloor np - n\epsilon \rfloor } / { n} \right) } \<br>    &amp;\ge \frac{1}{n + 1} 2^{ n \cdot \mathbf{H}( { (np - n\epsilon - 1) } / {n} )} \<br>    &amp;\ge 2^{ \lfloor n \cdot \mathbf{H}( p - \epsilon -1 / n) -  \log (n + 1)  \rfloor }<br>\end{aligned}<br>$$</p>
<p>Let $k = \lfloor n \cdot \mathbf{H}( p - \epsilon -1 / n) - \log (n + 1)  \rfloor$. For large enough $n$, it holds that<br>$$<br>k \ge (1 - \delta / 2) \cdot n \cdot \mathbf{H}(p)<br>$$</p>
<p>Further, since<br>$$<br>\sum_{i = 1}^{  k - 1  } 2^i \le \sum_{i = 0}^{  k - 1  } 2^i = 2^{  k } - 1 &lt; 2^k,<br>$$</p>
<p>there are strictly less than $2^k$ distinct binary sequences with length at most $k - 1$. </p>
<p>Therefore, for the set of $s \in S$ with $\lfloor np - n\epsilon \rfloor$ ones, at least one of them has output length at least $k$. </p>
<p>By the previous lemma, all sequences with more than $\lfloor np - n\epsilon \rfloor$ ones has length at least $k$. </p>
<p>Denote $Z$ be the number of ones in the string $s$. By Hoeffding Inequality, it holds that<br>$$<br>\Pr[ |Z - np| \ge n\epsilon ] \le \exp(-2n \epsilon^2)<br>$$</p>
<p>By the fact that $Z$ takes only integer values, we have<br>$$<br>\Pr[Z \le \lfloor np - n\epsilon \rfloor] \le \exp(-2 n \epsilon^2 )<br>$$</p>
<p>The expected output length of the sequences with more than $\lfloor np - n\epsilon \rfloor$ ones is at least<br>$$<br>\begin{aligned}<br>    &amp;[ 1 - \exp(-2n\epsilon^2) ] \cdot k \<br>    =&amp;[ 1 - \exp(-2n\epsilon^2) ] \cdot  (1 - \delta / 2) \cdot n \cdot \mathbf{H}(p)<br>\end{aligned}<br>$$</p>
<p>This is at least $(1 - \delta) \cdot n \cdot \mathbf{H}(p)$ when $n$ is large enough. </p>
<p>$\blacksquare$</p>
<h3 id="Huffman-Code"><a href="#Huffman-Code" class="headerlink" title="Huffman Code"></a><strong><em>Huffman Code</em></strong></h3><p>In this section, we show that the upper bound can be achieved by Huffman code. </p>
<blockquote>
<p><em>$\forall \delta &gt; 0$, $\exists$ a compression $h$ and integer $N &gt; 0$, s.t., $\forall n \ge N$, it holds that</em><br> $$<br>   \mathbf{E}[ |h(s)| ] \le (1 + \delta) n \mathbf{H}(p)<br>   $$</p>
</blockquote>
<p>We begin with an important property of Huffman Code. Suppose that we have an alphabet $\mathbb{U}$ such that probability associated with each element in $\mathbb{U}$ is $2^{-l}$ for some integer $l$. Then $\exists h$, such that<br>$$<br>   \mathbf{E}_{X \in \mathbb{U} } [ |h(X)| ] =  n \mathbf{H}(X)<br>$$</p>
<p>For example, if $\mathbb{U} = {0, 1, 2, 3 }$ and the distribution $p = { 0.5, 0.25, 0.125, 0.125 }$, then we can have the following encoding </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/Entropy/Encoding.png"></p>
<p>The expected coding length is<br>$$<br>0.5 \cdot 1 + 0.25 \cdot 2 + 2 \cdot 0.125 \cdot 3 = 1.75<br>$$</p>
<p>which is exactly the entropy of the random variable. </p>
<p>In general, if we have a random variable $X$, we can round down its probability to the nearest integer negative power of $2$. The expected code length is given by<br>$$<br>\sum_{i } p_i \left\lceil \log \frac{1}{p_i} \right\rceil \le \mathbf{H}(p) + 1<br>$$</p>
<p>Intuitively, the $\left\lceil \log \frac{1}{p_i} \right\rceil$ has enough slot to accommodate all elements with probabilities $p_i$’s. </p>
<p>In particular, we view ${0, 1}^n$ as a large alphabet $\mathbf{\Sigma }$. The alphabet has entropy $n \cdot \mathbf{H}(p)$. We can have a encoding such that the expected output length is at most $n \cdot \mathbf{H}(p) + 1$. For large enough $n$, this is at most $(1 + \delta) n \cdot \mathbf{H}(p)$. </p>
<h3 id="Relative-Entropy-and-Mutual-Information"><a href="#Relative-Entropy-and-Mutual-Information" class="headerlink" title="Relative Entropy and Mutual Information"></a><strong><em>Relative Entropy and Mutual Information</em></strong></h3><h4 id="Relative-Entropy"><a href="#Relative-Entropy" class="headerlink" title="Relative Entropy"></a>Relative Entropy</h4><p>Given a distribution $p$, we mistaken it as a distribution $q$, the expected coding length is roughly<br>$$<br>\sum_i p_i \log \frac{1}{q_i}<br>$$</p>
<p>The discrepancy between the optimal coding is given by<br>$$<br>D(p || q) = \sum_i p_i \log \frac{1}{q_i} - \sum_i p_i \log \frac{1}{p_i} = \sum_i p_i \log \frac{p_i}{q_i}<br>$$</p>
<p>By definition, we know that this gap is always non-negative. We can prove it rigorously algebraically. We show two different approaches here. </p>
<ol>
<li>By that $f(x) = x \log x$ is convex for $x \ge 0$, we have<br>$$<br>\begin{aligned}<pre><code>D(p || q) &amp;= \sum_i p_i \log \frac&#123;p_i&#125;&#123;q_i&#125; \\
&amp;= \sum_i q_i \cdot \frac&#123;p_i&#125;&#123;q_i&#125; \log \frac&#123;p_i&#125;&#123;q_i&#125; \\
&amp;\ge \left( \sum_i q_i \cdot \frac&#123;p_i&#125;&#123;q_i&#125; \right) \log \left( \sum_i q_i \cdot \frac&#123;p_i&#125;&#123;q_i&#125; \right) \\
&amp;= 0
</code></pre>
\end{aligned}<br>$$</li>
<li>By that $f(x) = -\log x$ is convex (for $x \ge 0$ ), we have<br>$$<br>\begin{aligned}<pre><code>D(p || q) &amp;= \sum_i - p_i \log \frac&#123;q_i&#125;&#123;p_i&#125; \\
&amp;\ge  -\log \left( \sum_i p_i \cdot \frac&#123;q_i&#125;&#123;p_i&#125; \right) \\
&amp;= 0
</code></pre>
\end{aligned}<br>$$</li>
</ol>
<h4 id="Mutual-Information"><a href="#Mutual-Information" class="headerlink" title="Mutual Information"></a>Mutual Information</h4><p>Given two random variable, the mutual information between them is defined as<br>$$<br>I(X; Y) = I(Y; X) = \mathbb{E}_{p(x, y) } \left[ \log \frac{ p(x, y)}{p(x) p(y) } \right]<br>$$</p>
<p>If we know $p(x,y)$ we use in expectation $\mathbb{E}_{p(x, y) } \left[ \log \frac{1} { p(x, y)} \right]$ to describe them. If we know only $p(x)$ and $p(y)$, the mutual information measured the bits we waste.</p>
<p>$$<br>\begin{aligned}<br>    &amp;\sum p(x, y) \log \frac{ p(x, y)}{p(x) p(y) } \<br>    =&amp;  \sum p(x, y) \log \frac{ 1 }{p(x)} \<br>    &amp;+  \sum p(x, y) \log \frac{ 1 }{p(y)} \<br>    &amp;-  \sum p(x, y) \log \frac{ 1 }{p(x, y)} \<br>    =&amp; \mathbf{H} ( X ) + \mathbf{H} ( Y ) - \mathbf{H} ( X, Y ) \<br>    =&amp;\sum p(x, y) \log \frac{ p(x | y)}{p(x)  } \<br>    =&amp; \mathbf{H} ( X ) - \mathbf{H} ( X \mid Y) \<br>    =&amp;\sum p(x, y) \log \frac{ p(x | y)}{ p(x) }  \<br>    =&amp; \mathbf{H} ( Y ) - \mathbf{H} ( X \mid Y) \<br>\end{aligned}<br>$$</p>
<p><strong><em>Lemma.</em></strong><br>$$<br>\mathbf{I}(X; Y) \ge 0<br>$$</p>
<p><strong><em>Proof.</em></strong><br>$$<br>\mathbf{I}(X; Y) = D( p(x, y) \mid p(x) p(y) ) \ge 0<br>$$</p>
<p>Or<br>$$<br>\begin{aligned}<br>    \sum p(x, y) \log \frac{ p(x, y)}{p(x) p(y) }<br>    &amp;= -\sum p(x, y) \log \frac{p(x) p(y) }{ p(x, y)} \<br>    &amp;\ge - \log \sum p(x, y) \frac{p(x) p(y) }{ p(x, y)} \<br>    &amp;=0<br>\end{aligned}<br>$$</p>
<p>$\blacksquare$</p>
<p><strong><em>Corollary</em></strong><br>$$<br>\mathbf{H} ( Y ) - \mathbf{H} ( X \mid Y) = \mathbf{H} ( X ) - \mathbf{H} ( X \mid Y) \ge 0<br>$$</p>
<p>$\blacksquare$</p>
<p><strong><em>Definition</em></strong> Conditional Relative Entropy<br>$$<br>\begin{aligned}<br>    \mathbf{D}( p(y \mid x) || q(y \mid x) ) &amp;\doteq  \mathbb{E}<em>{p(x, y) } \left[ \log \frac{ p(Y \mid X) }{ q(Y \mid X) }  \right]\<br>    &amp;=\sum</em>{x}  \sum_{ y } p(y \mid x) \log \frac{ p(y \mid x) }{ q(y \mid x) }<br>\end{aligned}<br>$$</p>
<p><strong><em>Lemma.</em></strong> Relative entropy $\mathbf{D}( p || q )$ is convex in the pair $(p, q)$: if there are two distribution pairs $(p_1, q_1)$ and $(p_2, q_2)$, then .<br>$$<br>\mathbf{D}( \lambda p_1 + (1 - \lambda) p_2 || \lambda q_1 + (1 - \lambda_1) q_2 ) \le \lambda \mathbf{D}( p_1 ||  q_1 ) + (1 - \lambda) \mathbf{D}( p_2 ||  q_2 )<br>$$</p>
<p><strong><em>Proof.</em></strong><br>For any fix value $x$, it holds that<br>$$<br>\begin{aligned}<br>    &amp;[ \lambda p_1(x) + (1 - \lambda) p_2(x) ] \log \frac{ \lambda p_1(x) + (1 - \lambda) p_2(x) }{ \lambda q_1(x) + (1 - \lambda) q_2(x) } \<br>    &amp;=-[ \lambda p_1(x) + (1 - \lambda) p_2(x) ] \log \frac { \lambda q_1(x) + (1 - \lambda) q_2(x) } { \lambda p_1(x) + (1 - \lambda) p_2(x) } \<br>    &amp;= -[ \lambda p_1(x) + (1 - \lambda) p_2(x) ] \log \left( \frac { \lambda p_1(x)  } { \lambda p_1(x) + (1 - \lambda) p_2(x) } \frac { \lambda q_1(x) } { \lambda p_1(x)  } + \frac { (1 - \lambda) p_2(x)  } { \lambda p_1(x) + (1 - \lambda) p_2(x) } \frac { (1 - \lambda) q_2(x) } { (1 - \lambda) p_2(x)  } \right) \<br>    &amp;\le -\lambda p_1(x) \log   \frac { \lambda q_1(x) } { \lambda p_1(x)  } - (1 - \lambda) p_2(x) \log \frac { (1 - \lambda) q_2(x) } { (1 - \lambda) p_2(x)  }<br>\end{aligned}<br>$$</p>
<p>$\blacksquare$</p>
<h3 id="Chain-Rules"><a href="#Chain-Rules" class="headerlink" title="Chain Rules"></a><strong><em>Chain Rules</em></strong></h3><p>Let $X_1, X_2, …, X_n$ be random variables whose density function is $p(x_1, x_2, …, x_n)$, then   </p>
<ol>
<li><p>$\mathbf{H}(X_1, X_2, …, X_n) = \sum_{i = 1}^n \mathbf{H}(X_i \mid X_1, …, X_{i - 1})$<br> <strong><em>Proof.</em></strong><br> $$<br> \begin{aligned}</p>
<pre><code> \mathbf&#123;H&#125;(X_1, X_2, ..., X_n) 
     &amp;= \sum_&#123;x_1, x_2, ..., x_n&#125; p(x_1, x_2, ..., x_n)  \log \frac&#123;1&#125;&#123;\prod_&#123;i = 1&#125;^n p(x_i \mid x_1, ..., x_&#123;i - 1&#125;)  &#125;  \\
     &amp;= \sum_&#123;x_1, x_2, ..., x_n&#125; p(x_1, x_2, ..., x_n) \sum_&#123;i = 1&#125;^n \log \frac&#123;1&#125;&#123; p(x_i \mid x_1, ..., x_&#123;i - 1&#125;)  &#125;  \\
     &amp;=\sum_&#123;i = 1&#125;^n \mathbf&#123;H&#125;(X_i \mid X_1, ..., X_&#123;i - 1&#125;) \\
</code></pre>
<p> \end{aligned}<br> $$  </p>
<p> <strong><em>Corollary</em></strong><br> $$<br> \mathbf{H} ( X_1, X_2, …, X_n) = \sum_{i = 1}^n \mathbf{H}(X_i \mid X_1, …, X_{i - 1}) \le \sum_{i = 1}^n \mathbf{H}(X_i)<br> $$</p>
<p> $\blacksquare$</p>
</li>
<li><p>$\mathbf{I}(X_1, X_2, …, X_n; Y) = \sum_{i = 1}^n \mathbf{I}(X_i ; Y\mid X_1, …, X_{i - 1})$<br> <strong><em>Proof.</em></strong><br> $$<br> \begin{aligned}</p>
<pre><code> \mathbf&#123;I&#125;(X_1, X_2, ..., X_n; Y)
 &amp;=  \mathbf&#123;H&#125;(X_1, X_2, ..., X_n) -  \mathbf&#123;H&#125;(X_1, X_2, ..., X_n \mid Y) \\
 &amp;= \sum_&#123;i = 1&#125;^n \mathbf&#123;H&#125;(X_i \mid X_1, ..., X_&#123;i - 1&#125;)  - \sum_&#123;i = 1&#125;^n \mathbf&#123;H&#125;(X_i \mid X_1, ..., X_&#123;i - 1&#125;, Y) \\
 &amp;= \sum_&#123;i = 1&#125;^n \mathbf&#123;I&#125;(X_i ; Y\mid X_1, ..., X_&#123;i - 1&#125;) \\
</code></pre>
<p> \end{aligned}<br> $$  </p>
</li>
<li><p>$\mathbf{D}( p(x, y) || q(x, y) ) = \mathbf{D}( p(x) || q(x) ) + \mathbf{D}( p(y \mid x) || q(y \mid x) )$<br><strong><em>Proof.</em></strong><br>$$<br> \begin{aligned}</p>
<pre><code> \mathbf&#123;D&#125;( p(x, y) || q(x, y) ) 
 &amp;= \sum_&#123;x, y&#125; p(x, y) \log \frac&#123; p(x) p(y \mid x) &#125;&#123;q(x) q (y \mid x) &#125;
 \\
 &amp;= \sum_&#123;x, y&#125; p(x, y) \log \frac&#123; p(x)  &#125;&#123;q(x) &#125; + \sum_&#123;x, y&#125; p(x, y) \log \frac&#123;  p(y \mid x) &#125;&#123;  q (y \mid x) &#125;
 \\
 &amp;= \mathbf&#123;D&#125;( p(x) || q(x) ) + \mathbf&#123;D&#125;( p(y \mid x) || q(y \mid x) )
</code></pre>
<p> \end{aligned}<br> $$</p>
</li>
</ol>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference."></a>Reference.</h3><p>[1]M. Mitzenmacher and E. Upfal, Probability and computing: an introduction to randomized algorithms and probabilistic analysis. New York: Cambridge University Press, 2005.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/06/01/Entropy-and-Random-Bits/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/01/Entropy-and-Random-Bits/" class="post-title-link" itemprop="url">Entropy and Random Bits</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-06-01 00:16:09" itemprop="dateCreated datePublished" datetime="2020-06-01T00:16:09+10:00">2020-06-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-07-14 00:15:12" itemprop="dateModified" datetime="2020-07-14T00:15:12+10:00">2020-07-14</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="Entropy"><a href="#Entropy" class="headerlink" title="Entropy"></a>Entropy</h4><p>The entropy of a random variable $X$ is defined as<br>$$<br>\mathbf{H}[X] = \mathbb{E} \left[ \log_2 \frac{1}{\Pr[X] } \right]<br>$$</p>
<p>Here we adopt the convention that $0 \log 0 = 0$, as $\lim_{x \rightarrow 0^+} x \log x = \lim_{x \rightarrow \infty} \frac{1 }{ x } \log \frac{1 }{ x } = 0$. </p>
<p>The entropy is oblivious to the specific values $X$ takes and is only sensitive to the probabilities with which $X$ takes these values.</p>
<blockquote>
<p>Example.  </p>
<ol>
<li>$X_1 = \begin{cases}<br>e^{1000}, \text{with probability 0.5} \ 0, \text{with probability 0.5}<br>\end{cases}$      </li>
<li>$X_2 = \begin{cases}<br>1, \text{with probability 0.5} \ -1, \text{with probability 0.5}<br>\end{cases}$  </li>
</ol>
</blockquote>
<p>By definition, both<br>$$<br>\mathbf{H}[X_1] = \mathbf{H}[X_2] = 0.5 \log_2 2 + 0.5 \log_2 2 = 1<br>$$</p>
<p>We also notice that the entropy of a random variable may not reflect the whether a random variable is concentrated at its mean or not. </p>
<p>The binary entropy function $\mathbf{H}(p)$ of a Bernoulli random variable $X$ that takes value $1$ with probability $p$ is<br>$$<br>\begin{aligned}<br>    \mathbf{H}(p) = &amp;p \log_2 \frac{1}{p} + (1 - p) \log_2 \frac{1}{1 - p} \<br>    = &amp;-p \log_2 p - (1 - p) \log_2 (1 - p)<br>\end{aligned}<br>$$</p>
<p>By concavity of $\log_2(\cdot )$, we know that<br>$$<br>\begin{aligned}<br>    \mathbf{H}(p)<br>    &amp;\le \log_2 \left( p \frac{1}{p} + (1 - p) \frac{1}{1 - p} \right)<br>    &amp;= 1<br>\end{aligned}<br>$$</p>
<p>The equality holds when $p = 0.5$. </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/Entropy/Entropy.png"></p>
<p>Some interesting values:</p>
<ul>
<li>$p = 0.5$, $\mathbf{H}(p) = 1$</li>
<li>$p = 0.2/0.8$, $\mathbf{H}(p) \approx 0.7$</li>
<li>$p = 0.1/0.9$, $\mathbf{H}(p) \approx 0.5$</li>
</ul>
<p><strong><em>Lemma.</em></strong> Given a discrete range $\mathcal{U}$, the entropy of a random variable $X$ defined on $\mathcal{U}$ is maximized when $X$ has uniform distribution, i.e.,<br>$$<br>\mathbf{H} (X) \le \log |\mathcal{U}|<br>$$</p>
<p><strong><em>Proof.</em></strong><br>$$<br>\begin{aligned}<br>    \mathbf{H} (X)<br>        &amp;= \sum_{x} p(x) \log \frac{1}{p(x) } \<br>        &amp;\le  \log \sum_{x} p(x) \frac{1}{p(x) } \<br>        &amp;= \log |\mathcal{U}|<br>\end{aligned}<br>$$</p>
<p>The inequality holds with equality only when $p(x) = 1/ |\mathcal{U}|$. </p>
<p>$\blacksquare$</p>
<p><strong><em>Lemma.</em></strong> Let $p(x)$ and $q(x)$ be two distributions and $\lambda \in [0, 1]$, then<br>$$<br>\mathbf{H} (\lambda p(x) + (1 - \lambda) q(x) ) \ge \lambda \mathbf{H}(p(x) ) + (1 - \lambda) \mathbf{H} (q(x) )<br>$$</p>
<p><strong><em>Proof.</em></strong><br>$$<br>\begin{aligned}<br>    \lambda \mathbf{H}(p(x) ) + (1 - \lambda) \mathbf{H} (q(x) )<br>        &amp;= \sum_{x} \left( \lambda p(x) \log \frac{1}{p(x)} + (1 - \lambda) q(x) \log \frac{1}{q(x) }  \right) \<br>        &amp;= (  \lambda p(x) + (1 - \lambda) q(x) )\sum_{x} \left( \frac{ \lambda p(x) }{  \lambda p(x) + (1 - \lambda) q(x) } \log \frac{1}{p(x)} + \frac{(1 - \lambda) q(x) }{ \lambda p(x) + (1 - \lambda) q(x) } \log \frac{1}{q(x) }  \right) \<br>        &amp;\le \sum_{x} ( \lambda p(x) + (1 - \lambda) q(x) ) \log \frac{1}{ \lambda p(x) + (1 - \lambda) q(x) } \<br>        &amp;= \mathbf{H} ( \lambda p(x) + (1 - \lambda) q(x) )<br>\end{aligned}<br>$$</p>
<p>$\blacksquare$</p>
<p><strong><em>Lemma.</em></strong> For two independent random variables $X$ and $Y$, we have<br>$$<br>\mathbb{E} \left[ \log_2 \frac{1}{\Pr[X + Y] } \right] = \mathbb{E} \left[ \log_2 \frac{1}{\Pr[X] } \right] + \mathbb{E} \left[ \log_2 \frac{1}{\Pr[Y] } \right]<br>$$</p>
<p>i.e.,<br>$$<br>\mathbf{H}[X + Y] = \mathbf{H}[X] + \mathbf{H}[Y]<br>$$</p>
<p><strong><em>Proof.</em></strong> We prove it for the case of discrete random variables.<br>$$<br>\begin{array}{rrl}<br>    &amp;\mathbb{E} \left[ \log_2 \frac{1}{\Pr[X + Y] }  \right]<br>    &amp;= \sum_{x, y} p(x, y) \log_2 \frac{1}{p(x, y)} \<br>    &amp;&amp;= \sum_{x, y} p(x) p(y) \left( \log_2 \frac{1}{p(x)} + \log_2 \frac{1}{p(y) } \right) \<br>    &amp;&amp;= \sum_{x} p(x) \sum_{y} p(y) \log_2 \frac{1}{p(x)} + \sum_{y} p(y) \sum_{x} p(x) \log_2 \frac{1}{p(y) } \<br>    &amp;&amp;= \mathbb{E} \left[ \log_2 \frac{1}{\Pr[X] } \right] + \mathbb{E} \left[ \log_2 \frac{1}{\Pr[Y] } \right]<br>\end{array}<br>$$<br>$\blacksquare$</p>
<p><strong><em>Definition.</em></strong> Given random variable $X$ and $Y$, the joint entropy $\mathbf{H}(X, Y)$ with a distribution $p(x, y)$ is defined as<br>   $$<br>    \mathbf{H}(X,Y) = \mathbb{E}\left[ \log \frac{1}{p(x, y)} \right]<br>   $$<br>   When $X$ and $Y$ are discrete random variables, it is equivalent to<br>   $$<br>    \mathbf{H}(X,Y) = \sum_{x \in \mathcal{X} } \sum_{y \in \mathcal{Y} } p(x, y) \log \frac{1}{p(x, y) }.<br>   $$</p>
<p><strong><em>Definition.</em></strong> The conditional entropy $\mathbf{H}(Y \mid X)$ with a distribution $p(x, y)$ is defined as<br>   $$<br>   \begin{aligned}<br>       \mathbf{H}(Y \mid X)<br>        &amp;= \sum_{x \in \mathcal{X} } p(x) \cdot \mathbf{H} (Y \mid X = x) \<br>        &amp;= \sum_{x \in \mathcal{X} } p(x) \cdot \sum_{y \in \mathcal{Y} } p(y \mid x) \log \frac{1}{p(y \mid x) } \<br>        &amp;= \sum_{x \in \mathcal{X} } \sum_{y \in \mathcal{Y} } p(x, y) \log \frac{1}{p(y \mid x) } \<br>        &amp;= \mathbb{E} \left[  \log \frac{1}{p(y \mid x) } \right]<br>   \end{aligned}<br>   $$</p>
<ul>
<li><strong>Remark.</strong> <em>Conditioned on $X = x$, $Y$ is a random variable and therefore we can define its Entropy as $\mathbf{H}(Y \mid X = x)$. The conditional entropy $\mathbf{H}(Y \mid X)$ is the average of the $\mathbf{H}(Y \mid X = x)$ over the distribution of $X$. Both $\mathbf{H}(Y \mid X)$ and $\mathbf{H}(Y \mid X = x)$ represent a value. This is different from the conditional expectation: $\mathbb{E}[Y \mid X]$ is a random variable and $\mathbb{E}[Y \mid X = x]$ is a value.</em> </li>
</ul>
<p><strong><em>Chain Rule.</em></strong> For random variable $X$ and $Y$, it holds that<br>   $$<br>   \begin{aligned}<br>       \mathbf{H}(X, Y)<br>        &amp;= \sum_{x \in \mathcal{X} } \sum_{y \in \mathcal{Y} } p(x, y) \log \frac{1}{p(x, y) } \<br>        &amp;= \sum_{x \in \mathcal{X} } \sum_{y \in \mathcal{Y} } p(x, y) \log \frac{1}{p(y \mid x) p(x) } \<br>        &amp;= \sum_{x \in \mathcal{X} } \sum_{y \in \mathcal{Y} } p(x, y) \log \frac{1}{p(y \mid x) } + \sum_{x \in \mathcal{X} } \sum_{y \in \mathcal{Y} } p(x, y) \log \frac{1}{ p(x) } \<br>        &amp;= \mathbf{H}(Y \mid X) + \mathbf{H}(X)<br>   \end{aligned}<br>   $$</p>
<p><em>Corollary of</em> <strong><em>Chain Rule.</em></strong><br>   $$<br>   \mathbf{H}(X) + \mathbf{H}(Y \mid X) =<br>   \mathbf{H}(Y) + \mathbf{H}(X \mid Y)<br>   $$</p>
<p>   Or<br>   $$<br>   \mathbf{H}(X) - \mathbf{H}(X \mid Y)=<br>   \mathbf{H}(Y) - \mathbf{H}(Y \mid X)<br>   $$</p>
<h3 id="Binomial-Distribution"><a href="#Binomial-Distribution" class="headerlink" title="Binomial Distribution"></a>Binomial Distribution</h3><p>We study the relationship of binomial distribution $B(n, p)$ and entropy. As a rule of thumb, for reasonably large $n$ (say, $n \ge 100$) and moderate size of $p$ (e.g., $0.1 \le p \le 0.9$), the probability is concentrated on the interval $[np - \sqrt n, np + \sqrt n]$. </p>
<p>$N = 100, p = 0.5$.<br><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/Entropy/BinomialDist_N=100_P=0.5.png"></p>
<p>$N = 100, p = 0.3$.<br><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/Entropy/BinomialDist_N=100_P=0.3.png"></p>
<p>$N = 100, p = 0.1$.<br><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/Entropy/BinomialDist_N=100_P=0.1.png"></p>
<p>$N = 1000, p = 0.1$. Note that<br>$$<br>\Pr[ 100 - \sqrt{1000} \le X \le 100 + \sqrt{1000} ] \approx 0.9993<br>$$<br><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/Entropy/BinomialDist_N=1000_P=0.1.png"></p>
<p>*<strong>Lemma</strong>.* For $n\in \mathbf{Z}^+$, $k \in [n]$, it holds that<br>$$<br>\binom{n}{k} \ge \frac{1}{n + 1} 2^{n \mathbf{H}(\frac{k}{n} ) }<br>$$</p>
<p>*<strong>Proof</strong>.* Define $q = \frac{k}{n}$. Then<br>$$<br>\begin{aligned}<br>    (q + (1 - q))^n &amp;= \sum_{i = 0}^n \binom{n}{i} q^i (1 - q)^{n - i}<br>\end{aligned}<br>$$</p>
<p>The summation consists of $(n + 1)$ terms. We claim that<br>$$<br>\binom{n}{k} q^k (1 - q)^{n - k}<br>$$</p>
<p>is the largest one. For $i \in [n]$,<br>$$<br>\frac{ \binom{n}{i + 1} q^{i + 1} (1 - q)^{n - i - 1} }{ \binom{n}{i } q^{i} (1 - q)^{n - i } } = \frac{n - i }{i + 1} \frac{ q}{1 - q}<br>$$</p>
<p>The ratio is at least $1$ when $\frac{n - i}{i + 1} \ge \frac{1 -  q}{ q }$. We see that when $i = nq - 1 = k - 1$, it holds that<br>$$<br>\frac{n - i}{i + 1} = \frac{n - nq + 1}{ n q} \ge \frac{1 -  q}{ q }<br>$$<br>and when $i = k$,<br>$$<br>\frac{n - i}{i + 1} = \frac{n - nq}{ n q + 1} &lt; \frac{1 -  q}{ q }<br>$$</p>
<p>Therefore,<br>$$<br>\begin{aligned}<br>    \binom{n}{k} q^k (1 - q)^{n - k}<br>        &amp;= \binom{n}{k} 2^{k \log_2 q} 2^{ (n - k )\log_2 (1 - q)} \<br>        &amp;= \binom{n}{k} 2^{ n [ q \log_2 q +  (1 - q )\log_2 (1 - q) ]} \<br>        &amp;\ge \frac{1}{n + 1}<br>\end{aligned}<br>$$</p>
<p>$\blacksquare$</p>
<h4 id="Extracting-Random-Bits"><a href="#Extracting-Random-Bits" class="headerlink" title="Extracting Random Bits"></a>Extracting Random Bits</h4><p>Consider a uniform random variable $X$ at $[0, m - 1]$. By definition we know that<br>$$<br>\mathbf{H}[X] = \sum_{i = 0}^{m - 1} \frac{1}{m} \log_2 \frac{1}{\frac{1}{m} } = \log_2 m<br>$$</p>
<p>Given $X$ as an input, the following algorithm outputs a binary string $s$, such that each bit of $s$ can be interpreted as the outcome of independently Bernoulli random variables with probability $0.5$. </p>
<p>On the high level, we divide $m$ into intervals of powers of 2. When $X$ falls into an interval, we return a binary number that is within the range of that interval. Specifically, we rewrite<br>$$<br>m = 2^{d_k} + 2^{d_{k - 1} } + … + 2^{d_1}<br>$$</p>
<p>where $\lfloor \mathbf{H}[X] \rfloor = \lfloor \log_2 m \rfloor = d_k &gt; d_{k - 1} &gt; … &gt; d_1 \ge 0$ are the indexes of non-zero bits in the binary representation of $m$. The extraction is as follows:</p>
<blockquote>
<p><strong><em>Algorithm 1.</em></strong>  </p>
<ol>
<li>for $i \leftarrow k$ <em>down-to</em> $1$ <em>do</em>:  </li>
<li>$\quad$ <em>if</em> $X &lt; 2^{d_i}$ <em>then</em>:  </li>
<li>$\quad$ $\quad$ <em>return a $d_i$-bit binary representation of</em> $X$;  </li>
<li>$\quad$ <em>else:</em>  </li>
<li>$\quad$ $\quad$ $X \leftarrow X - 2^{d_i}$;  </li>
</ol>
</blockquote>
<p><strong>Example ($m = 13$).</strong><br><em>It is interesting to note that when $X = 12$, our proposed extraction method return no random bit, as $0 &lt; 2^0$. In this case our proposed method has wasted some randomness.</em></p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/Entropy/ExtractingRandomBits.png"></p>
<p><em>Question to ponder: Come up with some method that uses $n$ i.i.d. $X$’s to extract binary string with expected length close to $n \mathbf{H}[X]$.</em> </p>
<p>Let $s$ be the binary string returned by Algorithm 1. </p>
<p><strong><em>Theorem 1</em></strong>.<br>$$<br>\lfloor \log_2 m \rfloor - 1 \le \mathbf{E}[|s|] \le \log_2 m<br>$$</p>
<p><em>Proof.</em> It is easy to see that<br>$$<br>  \mathbf{E}[|s| ] = \sum_{i = 1}^k d_i \frac{2^{d_i} }{m }<br>$$<br>which depends on $m$. To show the upper bound,<br>$$<br>\begin{array}{lll}<br>    \sum_{i = 1}^k d_i \frac{2^{d_i} }{m } - \log_2 m<br>    = \sum_{i = 1}^k \frac{2^{d_i} }{m } \log_2 \frac{2^{d_i} }{m } \le 0<br>\end{array}<br>$$<br>The inequality follows from $\log_2 \frac{2^{d_i} }{m } \le 0$ for $1 \le i \le k$. </p>
<p>To show the lower bound, define the function<br>$$<br>f(m) = \sum_{i = 1}^k d_i \frac{2^{d_i} }{m }<br>$$</p>
<p>We prove by induction on $m$ that $f(m) \ge \lfloor \log_2 m \rfloor - 1 = d_k - 1$. The cases holds trivially when $m = 1$. Now suppose it holds for all integer less than $m$. We prove that it holds for $m$.   </p>
<p>Case 1. $m = 2^{d_k}$. Then $f(m) = d_k = \log_2 m$.   </p>
<p>Case 2. $m &gt; 2^{d_k}$. Now<br>$$<br>\begin{aligned}<br>    f(m) &amp;= \sum_{i = 1}^k d_i \frac{2^{d_i} }{m } \<br>    &amp;= d_k \frac{2^{d_k} }{m} + \left( \sum_{i = 1}^{k - 1} d_i \frac{2^{d_i} }{m - 2^{d_k}  }  \right) \frac{m - 2^{d_k} }{m} \<br>\end{aligned}<br>$$</p>
<p>But $\sum_{i = 1}^{k - 1} 2^{d_i} = m - 2^{d_k}$. It follows by induction<br>$$<br>\sum_{i = 1}^{k - 1} d_i \frac{2^{d_i} }{m - 2^{d_k}  } = f(m - 2^{d_k}) \ge d_{k - 1} - 1<br>$$</p>
<p>Finally,<br>$$<br>\begin{aligned}<br>    f(m)<br>    &amp;\ge d_k \frac{2^{d_k} }{m} + \left( d_{k - 1} -1 \right) \frac{m - 2^{d_k} }{m} \<br>    &amp;= d_k +  \left( d_{k - 1}- d_k -1 \right)  \frac{m - 2^{d_k} }{m} \<br>    &amp;= d_k -  \left( d_k + 1 - d_{k - 1}  \right) \left( 1 - \frac{ 2^{d_k} }{m} \right)\<br>    &amp;\ge  d_k -  \left( d_k + 1 - d_{k - 1}  \right) \left( 1 - \frac{ 2^{d_k} }{2^{d_k} + 2^{d_{k - 1} } } \right)\<br>    &amp;=  d_k -  \left( d_k + 1 - d_{k - 1}  \right) \left( \frac{ 2^{d_{k - 1} } }{2^{d_k} + 2^{d_{k - 1} } } \right)\<br>    &amp;=  d_k -  \left( \frac{ d_k  - d_{k - 1} + 1  }{2^{d_k - d_{k - 1} } + 1 } \right)\<br>    &amp;\ge  d_k -  \left( \frac{ d_k  - d_{k - 1} + 1  }{2^{d_k - d_{k - 1} } } \right)\<br>    &amp;\ge d_k - 1<br>\end{aligned}<br>$$</p>
<p>The last inequality holds since $d_{k - 1} \le d_k - 1$ and the function $f(x) = \frac{x + 1}{2^x}$ decreases when $x \ge 1$. </p>
<p>$\blacksquare$</p>
<h5 id="Binary-Strings"><a href="#Binary-Strings" class="headerlink" title="Binary Strings"></a>Binary Strings</h5><p>To illustrate the idea of entropy, we study another example of random bit extraction. </p>
<p><strong><em>Problem.</em></strong> <em>Let $t$ be an $n$-bit binary string each bit of which is interpreted as the outcome of independent bias coin flip that comes up head probability $p \le 0.5$. Given $t$ as input, we want to output a binary string $s$ (not necessary of length $n$) of independent unbiased random bits.</em></p>
<p><strong><em>Theorem.</em></strong><br>There is an extraction algorithm, such that,   </p>
<ol>
<li>$\forall \delta \in (0, 1)$, $\exists N &gt; 0$, $s.t.$, $\forall n \ge N$, $\mathbf{E}[|s|] \ge (1 - \delta) n\mathbf{H}(p)$.    </li>
<li>$\forall n &gt; 0$, $\mathbf{E}[|s|] \le n\mathbf{H}(p)$.</li>
</ol>
<p>The theorem states that the expected length of $s$ approximates $n\mathbf{H}(p)$. Equivalently,<br>$$<br>\lim_{n \rightarrow \infty} \frac{\mathbf{E}[|s|]}{n} = \mathbf{H}(p)<br>$$</p>
<p><strong><em>Proof.</em></strong><br>Define the random variable $Z$ to be the number of ones in $t$. For any integer $k \ge 0$, there are $\binom{n}{k}$ strings with $k$ ones. We can map these strings to ${0, 1, …, \binom{n}{k} - 1 }$. Conditioned on $Z = k$, the mapping of $t$ is uniform on ${0, 1, …, \binom{n}{k} - 1 }$. We can use Algorithm 1 to return  a binary string $s$. Now its expected length is<br>$$<br>\mathbf{E}[|s|] = \sum_{k = 1}^n \mathbf{E}\left[ |s| \mid Z = k \right] \Pr[Z = k]<br>$$</p>
<p>Further, by Hoeffding’s inequality, it holds that for $0 &lt; \epsilon &lt; p$,<br>$$<br>\Pr[ |Z - np | \ge n\epsilon] \le \exp\left(- 2 n \epsilon^2 \right)<br>$$</p>
<p>By setting the failure probability $\exp(-2 n \epsilon^2) = \delta / 2$, we get $\epsilon = \sqrt{\frac{\ln \frac{2}{\delta} }{2n} }$. </p>
<p>Let $LB = \lceil np - n\epsilon \rceil$ and $UB = \lfloor np + n\epsilon \rfloor$. Observing that $Z$ is an integer, we have<br>$$<br>\begin{array}{rl}<br>    \Pr[LB \le Z \le UB] &amp;= \Pr[np - n\epsilon \le Z \le np + n\epsilon] \<br>    &amp;\ge 1 - \delta/2<br>\end{array}<br>$$</p>
<p>As $p \le 0.5$, it holds that<br>$$<br>n = \lceil n/2 - n\epsilon \rceil + \lfloor n/2 + n\epsilon \rfloor \ge \lceil np - n\epsilon \rceil + \lfloor np + n\epsilon \rfloor<br>$$</p>
<p>Therefore,<br>$$<br>LB \le UB \le n - LB \<br>$$</p>
<p>Since $\binom{n}{k}$ increase for $k &lt; n / 2$ and decrease $k &gt; n / 2$, it holds that<br>$$<br>\binom{n}{LB} \le \binom{n}{UB}<br>$$</p>
<p>For $LB \le k \le UB$, we have<br>$$<br>\binom{n}{LB} \le \binom{n}{k}<br>$$</p>
<p>Define $q = \frac{ LB }{n}$,<br>$$<br>\binom{n}{LB}  \ge \frac{1}{n + 1} 2^{n \mathbf{H}( \frac{ LB }{n} ) } \ge \frac{1}{n + 1} 2^{n\mathbf{H}(p - \epsilon)}<br>$$</p>
<p>By <strong><em>Theorem 1</em></strong>, we have<br>$$<br>\begin{aligned}<br>    \mathbf{E}[|s|] &amp;= \sum_{k = 1}^n \mathbf{E}\left[ |s| \mid Z = k \right] \Pr[Z = k] \<br>    &amp;\ge \sum_{k = LB}^{UB} \mathbf{E}\left[ |s| \mid Z = k \right] \Pr[Z = k] \<br>    &amp;\ge \sum_{k = LB }^{UB } \left( \left\lfloor \log_2 \binom{n}{k} \right\rfloor - 1 \right) \binom{n}{k} p^k (1 - p)^{n - k}  \<br>    &amp;\ge \sum_{k = LB }^{UB } \left( \left\lfloor \log_2  \binom{n}{ LB  } \right\rfloor - 1 \right) \binom{n}{k} p^k (1 - p)^{n - k}  \<br>    &amp;=  \left( \left\lfloor \log_2  \binom{n}{ LB  } \right\rfloor - 1 \right) \Pr[LB \le Z \le UB] \<br>    &amp;\ge \left( n \mathbf{H}(p - \epsilon)  - \log_2 (n + 1) \right) (1- \delta / 2) \<br>    &amp;=  \left( \frac{\mathbf{H}(p - \epsilon)}{\mathbf{H}(p) }  - \frac{\log_2 (n + 1) }{ n\mathbf{H}(p) }\right) (1- \delta / 2 ) \cdot n \cdot \mathbf{H}(p) \<br>    &amp;=  \left( \frac{\mathbf{H} \left(p - \sqrt{\frac{\ln \frac{2}{\delta} }{2n} } \right) }{\mathbf{H}(p) }  - \frac{\log_2 (n + 1) }{ n\mathbf{H}(p) }\right) (1- \delta / 2 ) \cdot n \cdot \mathbf{H}(p) \<br>\end{aligned}<br>$$</p>
<p>$\exists N &gt; 0$, s.t.,  $\forall n &gt; N$, $\left( \frac{\mathbf{H} \left(p - \sqrt{\frac{\ln \frac{2}{\delta} }{2n} } \right) }{\mathbf{H}(p) }  - \frac{\log_2 (n + 1) }{ n\mathbf{H}(p) }\right) \ge (1 - \delta / 2)$, which finishes the proof of lower bound.</p>
<p>As for the upper bound, observe that<br>$$<br>\binom{n}{k} p^k ( 1- p)^{n - k} \le 1<br>$$</p>
<p>Therefore, $\binom{n}{k} \le p^{-k} ( 1- p)^{-(n - k) }$. Thus, we have<br>$$<br>\begin{aligned}<br>       \mathbf{E}[|s|] &amp;= \sum_{k = 1}^n \mathbf{E}\left[ |s| \mid Z = k \right] \Pr[Z = k] \<br>       &amp;\le \sum_{k = 1}^n \left( \log_2 \binom{n}{k} \right) \binom{n}{k} p^k (1 - p)^{n - k} \<br>       &amp;\le \sum_{k = 1}^n \binom{n}{k} p^k (1 - p)^{n - k} \log_2 \frac{1}{ p^k (1 - p)^{n - k} }<br>\end{aligned}<br>$$</p>
<p>The last term is exactly the entropy of the string. By independence of the bits, we know that it is equal to $n \mathbf{H}(p)$. </p>
<p>Remark: we may also prove it algebraically.<br>$$<br>\begin{aligned}<br>       \mathbf{E}[|s|]<br>       &amp;\le \sum_{k = 0}^n \binom{n}{k} p^k (1 - p)^{n - k} \log_2 \frac{1}{ p^k (1 - p)^{n - k} } \<br>       &amp;= \sum_{k = 1}^n \binom{n}{k} p^k (1 - p)^{n - k} \log_2 \frac{1}{ p^k } + \sum_{k = 0}^n \binom{n}{k} p^k (1 - p)^{n - k} \log_2 \frac{1}{ (1 - p)^{n - k} } \<br>       &amp;= \left( p \log_2 \frac{1}{p} \right) \sum_{k = 1}^n  \binom{n}{k} k p^{k - 1} (1 - p)^{n - k}  \<br>       &amp;\quad +  \left( ( 1- p) \log_2 \frac{1}{ 1 - p } \right) \sum_{k = 0}^{n - 1} \binom{n}{k} (n - k) p^k (1 - p)^{n - k - 1} \<br>       &amp;= \left( p \log_2 \frac{1}{p} \right) [(x + (1 - p))^n]_{x = p}’  +  \left( (1 - p) \log_2 \frac{1}{ 1 - p } \right) [(p + x)^n]_{x = 1-p}’ \<br>       &amp;= n \mathbf{H}(p)<br>\end{aligned}<br>$$</p>
<p>$\blacksquare$</p>
<h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference."></a>Reference.</h4><p>[1] S. Har-Peled, “Chapter 26 Entropy, Randomness, and Information,” p. 6.<br>[2] M. Mitzenmacher and E. Upfal, Probability and Computing: Randomized Algorithms and Probabilistic Analysis. Cambridge: Cambridge University Press, 2005.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/05/30/Integer-Shortest-Path/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/30/Integer-Shortest-Path/" class="post-title-link" itemprop="url">Integer Shortest Path</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-30 11:15:49" itemprop="dateCreated datePublished" datetime="2020-05-30T11:15:49+10:00">2020-05-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-06-18 13:01:58" itemprop="dateModified" datetime="2020-06-18T13:01:58+10:00">2020-06-18</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Single source shortest path is one of most popular the topics taught in a introductory algorithm course. Given a graph $G = \left&lt; V, E \right&gt;$ with $n$ vertices and $m$ edges, the famous Dijkstra’s algorithm has runtime $O(m \log n)$ by using a binary heap. When more advanced heap such such Fibonacci heap is deployed, the runtime can be improved to $O(m + n \log n)$. Most introductory courses are satisfied with the above solutions without going further. </p>
<p>Here we explore the topic by considering a special case where all edge weights are non-negative integers within the set ${0, 1, 2, …, C}$. We develop new heaps incrementally and we will finally see that Dijkstra algorithm can do substantially better than $O(m + n \log n)$. </p>
<h4 id="Time-O-m-nC-Space-O-nC"><a href="#Time-O-m-nC-Space-O-nC" class="headerlink" title="Time: $O(m + nC)$, Space: $O(nC)$."></a>Time: $O(m + nC)$, Space: $O(nC)$.</h4><p>As a warm up, we demonstrate an algorithm with runtime $O(m + nC)$ and space overhead $O(nC)$. Here we exclude the space $O(m + n)$ required for storing the graph to simplify the discussion and comparison between the algorithms. </p>
<p>The idea is very simple. We know that the possible distance from any vertex to the source vertex (denoted as $s$) is no less than $nC$. It suffices to keep an array $A_1$ with length $nC$, such that $A_1[i]$ maintains the set of vertices with temporary distance $i$. In this context, we call $A_1[i]$ a bucket and the array $A_1$ itself the buckets.  </p>
<p>Initially all $A_1[i]$’s are empty except that $A_1[0]$ contains the source vertex. The algorithm iterates over $A_1$ to find an unmarked vertex with the minimum distance, marked it, update its neighbors’ distances and move them to the corresponding buckets. </p>
<p>Each vertex is inserted into $A_1$ once. There are at most $m$ updates of vertices’ distances. As the minimum distance of the unmarked vertices is monotonically increasing, we scan the array $A_1$ only once. Summing over the cost we get the $O(m + nC)$ time complexity bound. </p>
<h4 id="Time-O-m-nC-Space-O-C"><a href="#Time-O-m-nC-Space-O-C" class="headerlink" title="Time: $O(m + nC)$, Space: $O(C)$."></a>Time: $O(m + nC)$, Space: $O(C)$.</h4><p>The space usage of the above algorithm can be improve to $O(C)$. Relabel the vertices as $s = v_0, v_1, v_2, …, v_n$ according to the order they are marked. </p>
<p>Suppose that Dijkstra’s algorithm uses an array $d$ to record the vertices’ distances to $s$. Initially, $d(s) = 0$ and $d(v) = \infty$ for $\forall v \neq s$. Now, consider the moment that $k$ ($0 \le k &lt; n$) vertices have been marked. For $i &gt; k$, the value of $d(v_i)$ is either </p>
<ol>
<li><p>$d(v_i) = \infty$, if $v_i$ is not adjacent to any vertex $v_j$ for $j \le k$. In this case $v_i$ is not in the array $A_1$.     </p>
</li>
<li><p>$d(v_i) = d(v_j) + w_{i,j}$ for some $j \le k$, where $w_{i,j}$ is the edge weight between $v_i$ and $v_j$.   </p>
</li>
</ol>
<p>By the property of Dijkstra’s algorithm, at this moment it also holds that<br>$$<br>0 = d(s) = d_(v_0) \le d(v_1) \le d(v_2) … \le d(v_k)<br>$$</p>
<p>Therefore, for $i &gt; k$, either $v_i$ is not in $A_1$ or<br>$$<br>d(v_i) \le d(v_j) + w_{i,j} \le d(v_k) + C<br>$$</p>
<p>All un-marked vertices that are in $A_1$ must be in the range of<br>$$<br>A_1[d(v_k) … d(v_k) + C]<br>$$</p>
<p>In general, let $\mu$ be the distance of the least marked vertex. It suffices to maintain a window of $A_1[\mu…\mu+C]$. We can implement this by initializing $A_1$ with size $C+1$ and use it in a wrap-around manner. </p>
<h4 id="Time-O-m-n-sqrt-C-Space-O-C"><a href="#Time-O-m-n-sqrt-C-Space-O-C" class="headerlink" title="Time: $O(m + n \sqrt C)$, Space: $O(C)$."></a>Time: $O(m + n \sqrt C)$, Space: $O(C)$.</h4><p>In previous section, we successfully reduce the size of $A_1$ to $1 + C$. But the runtime remains $O(m + nC)$. To motivate the algorithm discussed in this section, we first provide an alternative view of this complexity:</p>
<ol>
<li><p>We update the vertices’ distance and move the vertices between buckets, which has cost  $O(m)$;   </p>
</li>
<li><p> At each iteration of Dijkstra’s algorithm, in the worst case, we need to scan the entire array of $A_1$ to find an unmarked vertex with minimum distance, which takes $O(C)$ times. This is repeated $n$ times.  </p>
</li>
</ol>
<p>Where could we have wasted our time? Do we really have spend $O(C)$ time to find the unmarked vertex with minimum distance? </p>
<p>We can improve this to $O(\sqrt C)$ by using two-level buckets. We break the buckets in $A_1$ into $\sqrt { C + 1}$ blocks, each of size $\sqrt { C + 1}$ (assume here $\sqrt { C + 1}$ is an integer for simplicity). For each block, we use one flag bit to indicate whether this block is empty. This results in $\sqrt { C + 1}$ flags bits, which are stored in bit array $A_2$. From now on, </p>
<p> <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/IntegerShortestPath/1.png"></p>
<p>Now, to find an unmarked vertex with minimum distance, we scan $A_2$ to find the first non-zero bit then the corresponding bucket in $A_1$,  which takes $O(\sqrt C)$ time. Totaling the runtime, we obtain a bound of $O(m + n \sqrt C)$. </p>
<p><strong><em>Question to ponder: calculate the size of $\sqrt C$ for some values of $C$ which you consider reasonable in real applications.</em></strong></p>
<h4 id="Time-O-m-log-frac-m-n-C-Space-O-C"><a href="#Time-O-m-log-frac-m-n-C-Space-O-C" class="headerlink" title="Time: $O( m \log_{ \frac{m}{n} } C)$, Space: $O(C)$."></a>Time: $O( m \log_{ \frac{m}{n} } C)$, Space: $O(C)$.</h4><p>It is natural to extend the idea to $3$-level buckets. Suppose the block size if $\Delta$. Then the third level contains a single bit block of size $\Delta$, the second level contains $\Delta$ bit blocks (with total size $\Delta^3$), and the first level contains the buckets $A_1$ of size $\Delta^3 = C + 1$. It follows that $\Delta = (C + 1)^\frac{1}{3}$ and the time complexity is $O(m + n C^\frac{1}{3} )$. </p>
<p>We may use four level buckets, in which $\Delta = (C + 1)^\frac{1}{4}$ and the time complexity is $O(m + n C^\frac{1}{4})$. </p>
<p><strong><em>Question to ponder: calculate the size of $C^\frac{1}{3}$ and $C^\frac{1}{4}$ for some values of $C$ which you consider reasonable in real applications.</em></strong></p>
<p>Does the analysis carry for $k$-level buckets for general value of $k$? No. We can no longer consider the $k$ as a constant and have to take into consider the overhead of insertion, decrease-key and deletion explicitly. </p>
<p>For a $k$-level bucket structure with bucket size $\Delta = (1 + C)^\frac{1}{k} \ge 2$, </p>
<ol>
<li><p>insertion takes $O(k)$ time,  </p>
</li>
<li><p>decrease-key takes $O(k)$ time,  </p>
</li>
</ol>
<p>as we need to maintain the indicators bits in $2…k$ levels. Finally, </p>
<ol start="3">
<li>delete-min takes $O(k \Delta)$ time,  </li>
</ol>
<p>as we need to scan $k$ buckets, each of size $\Delta$, to find the min element and delete it. </p>
<p> <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/IntegerShortestPath/2.png"></p>
<p>The time complexity now becomes<br>$$<br>O(mk + n k \Delta) = O( mk + nkC^\frac{1}{k})<br>$$</p>
<p>Balancing the two terms, we get $\frac{1}{k} =  \frac{ \log \frac{m}{n} }{ \log C}$, i.e., $k = \log_{\frac{m}{n} } C$. To summarize, the time is<br>$$<br>O(m \log_{\frac{m}{n} } C)<br>$$</p>
<p>and the space overhead is<br>$$<br>O\left( \sum_{i = 0}^{k - 1} C / \Delta^i \right) = O(C)<br>$$</p>
<p><strong><em>Question to ponder: calculate the size of $\log_{\frac{m}{n} } C$ for some values of $C$ which you consider reasonable in real applications.</em></strong></p>
<h4 id="Time-O-m-n-frac-log-C-log-log-C-Space-O-frac-log-C-log-log-C-2"><a href="#Time-O-m-n-frac-log-C-log-log-C-Space-O-frac-log-C-log-log-C-2" class="headerlink" title="Time: $O(m + n \frac{\log C}{\log \log C})$, Space: $O( (\frac{\log C}{\log \log C} )^2  )$."></a>Time: $O(m + n \frac{\log C}{\log \log C})$, Space: $O( (\frac{\log C}{\log \log C} )^2  )$.</h4><p>The core idea underlying the k-level bucket structure discussed in the previous section is that every integer $w$ in $[0, C]$ can be written as a base-$\Delta$ number with length at most $k$:<br>$$<br>w = \sum_{i = 0}^{k - 1} w_i \cdot \Delta^i<br>$$</p>
<p>where $w_i \in [0, \Delta)$. For convenience, we write it as<br>$$<br>w = (w_{k - 1}, w_{k - 2}, …, w_0)_\Delta<br>$$</p>
<p>Now the meaning of the $k$-level buckets is clear. The $k^{th}$ level partitions the $w$’s according to the value of $w_{k - 1}$. The $(k - 1)^{th}$ level further partitions the $w$’s according to the value of $w_{k - 2}$, and so on. The path from the top level to bottom level is uniquely determined by the sequence $(w_{k - 1}, w_{k - 2}, …, w_0)_\Delta$. Indeed, this is a special case of <strong><em>trie</em></strong>, which has alphabet size $\Delta$ and contains only sequence of length $k$. </p>
<p>But we may still waste some work. Remember that our goal for designing the data structure is to find the min element. Therefore, it suffices to distinguish the min element from the rest. We should not waste our effort in determining the relative order between the non-min elements. </p>
<p>In the following example, the min elements $v_1, v_2$ fall into the subtree of the first bucket on the $k^{th}$ level while $v_{n - 1}, v_n$ fall into the last one. As $v_{n - 1}, v_n$ are not min elements, it is unnecessary to maintain a subtree to separate them. Worse still, if later decrease-key is applied to either $v_{n -1}$ or $v_n$, and if the new key has to be moved to a new bucket in the $k^{th}$ level, the effort we have spent in constructing the sub-tree is completely useless. </p>
<p>Instead, we can create an auxiliary set to the last bucket on level $k$, to pus $v_{n - 1}, v_n$ into the set directly. Similar idea apply to $v_3$ in the example. </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/IntegerShortestPath/3.png"></p>
<p>The new structure we get is as follows:</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/IntegerShortestPath/4.png"></p>
<p>In general, we may not even has a $k$-level trie. In the example below, we can already determine the min-element $v_1$ at some level $i &gt; 1$. Why should we bother to expand the buckets further? Note that this idea is similar to that of trie compression used in <strong><em>Patricia trie</em></strong>. </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/IntegerShortestPath/5.png"></p>
<p>We can be even more lazy. We expand a bucket only when it is necessary. See the example below as an example. In this example, $C = 15$ and $\Delta = 4$.  </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/IntegerShortestPath/Example1-2.png"></p>
<p>Now, to delete-min, we need to determine the order of $v_1, v_2$. </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/IntegerShortestPath/Example3.png"></p>
<p>Inserting a new element follows the current structure, until it finds a bucket to fall in. </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/IntegerShortestPath/Example4.png"></p>
<p>Delete-min begin the search from the lowest level non-empty bucket block.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/IntegerShortestPath/Example5.png"></p>
<p>After delete-min, we may need to delete the empty bucket blocks recursively.  For each bucket block, we maintain counter for the number of non-empty buckets. This allows us to delete empty bucket blocks in $O(k)$ time.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/IntegerShortestPath/Example6.png"></p>
<p>We decrease the key of $v_4$ to 9. Note that we do not need to compare $v_4$ and $v_5$ for the moment. Bucket block counter is maintained when $v_4$ is moved to another bucket. </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/IntegerShortestPath/Example7.png"></p>
<p>Delete-min is invoked again. We need to expand the bucket containing $v_5$ and $v_4$ to distinguish them.  </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/IntegerShortestPath/Example8.png"></p>
<p>We continue to insert a new element $v_6 = 12$. </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/IntegerShortestPath/Example9.png"></p>
<p>We decrease the key of $v_6$ to $10$. It is pushed down by one level.   </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/IntegerShortestPath/Example10.png"></p>
<p>We are now prepared to analyze the amortized cost of these operations:</p>
<ol>
<li><p>Insert: we pay an $O(k)$ amortized cost of insertion. Any subsequent pushed down operation on this element is charged to its insertion. Note that an element can be push-down by at most $k$ levels. </p>
</li>
<li><p>Decrease-key: we pay an $O(1)$ amortized cost of decrease-key operation. The push-down operation is charged to its insertion.  </p>
</li>
<li><p>Delete-min: to find the min-element, we scan the bucket block in the lowest level to find the first non-empty bucket. This has time $\Delta$. If the bucket found contains multiple elements, we perform an expansion and push the elements down, the cost of which is charged to insertion of these elements. Finally, we may need to delete empty bucket blocks recursively, which has cost $O(k)$.  </p>
</li>
</ol>
<p>Therefore, the Dijkstra’s algorithm with this structure has runtime $O(m + n(k + \Delta))$, which is minimized when<br>$$<br>k = \Delta = (C + 1)^\frac{1}{k}<br>$$</p>
<p>Solving the equation gives $k = O(\frac{\log C}{\log \log C} )$. </p>
<h4 id="Time-O-m-n-sqrt-log-C-Space-O-sqrt-log-C-cdot-2-sqrt-log-C"><a href="#Time-O-m-n-sqrt-log-C-Space-O-sqrt-log-C-cdot-2-sqrt-log-C" class="headerlink" title="Time: $O( m + n \sqrt{\log C} )$, Space: $O(\sqrt{\log C} \cdot 2^{\sqrt{\log C} })$."></a>Time: $O( m + n \sqrt{\log C} )$, Space: $O(\sqrt{\log C} \cdot 2^{\sqrt{\log C} })$.</h4><p>Beginning from the naïve approach, we have improved a lot on both time and space overhead. Amazingly, this is not the end of the story. To motivate what is possibly the inefficient part of $O(m + n \frac{\log C}{\log \log C})$ approach, look at the following example. </p>
<p>Suppose that $C$ is a large number. Initially the structure is empty. We insert an element $v_1$ followed by $v_2$ and they fall into the same bucket in the $k^{th}$ level. Next, we perform a delete-min operation. To distinguish, we expand the buckets all the way down to $1^{st}$ level. </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/IntegerShortestPath/Drawback.png"></p>
<p>But since there are two elements, why don’t we compare them directly and return the minimum one? In such case we avoid the unnecessary expansions. </p>
<p>We can extend the idea further. If the number of elements in a bucket is too few, we refuse to expand it. Instead we make of copy of the elements and construct a comparison based priority queue (e.g., Fibonacci heap) on them. Further, note that we are only interested in the possible min-element. Therefore the heap is constructed for only one bucket that contains the min-element.    </p>
<p>We use a parameter $t$ (to be determined) to control this number. In particular, if the number is at most $t$, we construct a comparison based priority queue. We perform expansion only if the number exceeds $t$. </p>
<ol>
<li><p>Insert: insert an element as before. If the element falls into the bucket that is associated with a priority, then also insert this element into the heap.</p>
</li>
<li><p>Decrease-key: if the element is in the bucket that is associated with a priority queue, perform decrease-key in the queue. Otherwise, perform decrease-key as before. If the element falls into the bucket that is associated with a priority queue, then also insert this element into the heap.</p>
</li>
<li><p>Delete-min: </p>
</li>
</ol>
<blockquote>
<ol>
<li>Find the first non-empty bucket in the lowest level     </li>
<li><strong><em>IF</em></strong> the bucket has more than $t$ elements <strong><em>THEN</em></strong>    </li>
<li>$\qquad$ Expand the bucket    </li>
<li>$\qquad$ <strong><em>GO TO STEP 1</em></strong> </li>
<li><strong><em>ELSE</em></strong> </li>
<li>$\qquad$ <strong><em>IF</em></strong> $\nexists$ queue <strong><em>THEN</em></strong>    </li>
<li>$\qquad\qquad$ Construct a queue</li>
<li>$\qquad$ Perform delete-min in the queue </li>
</ol>
</blockquote>
<p>Let $I(t), D(t), X(t)$ be the time needed to perform insert, decrease-key and delete-min operation in a comparison based priority queue respectively. Then it is obvious that the the structure we propose, the amortized time we need for insert and decrease-key is</p>
<ol>
<li>Insert: $O(k + I(t))$. </li>
<li>Decrease-key: $O(D(t) + I(t))$. </li>
</ol>
<p>To analyze the time needed for delete-min is more complicated. It relies on the implementation of  the following:</p>
<blockquote>
<p>Find the first non-empty bucket in the lowest level.     </p>
</blockquote>
<p>We record the previous deleted min element $\mu$ (initially set to 0).  Denote the $\Delta$-base representation of $\mu$ as<br>$$<br>\mu = (\mu_{k - 1}, \mu_{k - 2}, …, \mu_0)<em>\Delta<br>$$<br>Observe that the non-empty bucket block in the lowest level must contain $\mu$. Denote this level as $i$. To find the first non-empty bucket, we start scan from $\mu</em>{i - 1}^{th}$ bucket in the $i^{th}$ level. Therefore, each bucket block is only scanned once. Further, the buck block in the $i^{th}$ level is created from the $(i + 1)^{th}$ level because it contains more than $t$ elements. We can charge the scanned cost to these $t$ elements, each with $\frac{\Delta}{t}$. As there are $k$ level, a element could be charge at most $k$ times. It follows that the amortized cost of delete-min is given by</p>
<ol start="3">
<li>Delete-min: $O(X(t) + \frac{k \Delta}{t})$</li>
</ol>
<p>For Fibonacci heap, $I(t) = D(t) = 1$ and $X(t) = \log t$. Therefore, we have runtime<br>$$<br>O \left( m + n \left[k + \log t + \frac{k \Delta}{t} \right] \right)<br>$$</p>
<p>To minimize it, we need to set $k = \log t = \frac{k \Delta}{t}$. It holds that $t = 2^k$ and $t = \Delta = C^\frac{1}{k}$, which implies that $2^{k} = 2^{ \frac{\log C}{k} }$ and $k = \sqrt {\log C}$.  The time is<br>$$<br>O(m + n \sqrt{\log C})<br>$$</p>
<p>and the space overhead is $O(k \Delta) = O(\sqrt{\log C} \cdot 2^{\sqrt{\log C} })$. </p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1]. David R. Karger, MIT Advanced Algorithm, 2013.<br>[2]. B. V. Cherkassky, A. V. Goldberg, and C. Silverstein, “Buckets, Heaps, Lists, and Monotone Priority Queues,” SIAM J. Comput., vol. 28, no. 4, pp. 1326–1346, Jan. 1999</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/05/26/Splay-Tree/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/26/Splay-Tree/" class="post-title-link" itemprop="url">Splay Tree</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-26 16:19:41" itemprop="dateCreated datePublished" datetime="2020-05-26T16:19:41+10:00">2020-05-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-06-05 16:12:56" itemprop="dateModified" datetime="2020-06-05T16:12:56+10:00">2020-06-05</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Splay Tree [1] is a self-binary search tree that achieves $O(\log n)$ amortized time complexity for each operation. Unlike other balanced binary search trees, it does not require to maintain additional information to keep balance. Further, it has good property that more recently accessed nodes are more easily retrieved and achieves certain optimality even for an unknown sequence of operations.</p>
<h2 id="Basic-Operations"><a href="#Basic-Operations" class="headerlink" title="Basic Operations"></a>Basic Operations</h2><p>The philosophy of splay tree is very simple: just bring the last accessed node $x$ to the root of the tree, via a sequence of <em>rotations</em>. This brings the most recently visited nodes close to the root. </p>
<p>[Remark: For insertion, the last accessed node is the node inserted.  For a successful search operation, the last accessed node is the node found. For an unsuccessful search/deletion, it is the predecessor or successor of the search  node / deleted node. ]</p>
<p>The rotations that bring a node $x$ to the root is not unique. For example, the simplest one rotates $x$  with its parent until it becomes the root. However, we can easily find counter examples for this naïve approach. The rotations need to be carefully designed and are called <em>splays</em>.  At each step the node being splayed is brought up at most 2 levels. It can be divided into three categories. Call $x$ the node being splayed, $y$ its parent and $z$ its grandparent (if they exist).</p>
<ol>
<li>Root case: $x$ is the root. Do nothing. </li>
<li>The <em>Zig</em> case: $y$ is the root. We just perform $rotate(x, y)$.   <ul>
<li>See the following figure.<br><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/SplayTree/Zig.png"></li>
</ul>
</li>
<li>Otherwise, $x$ has a grandparent $z$. It is further divided into two categories: <ol>
<li><em>Zig-Zig</em> case: both $x$ and $y$ are left children or right children. We first perform $rotate(y, z)$ then $rotate(x, y)$.<br><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/SplayTree/ZigZig.png"></li>
<li><em>Zig-Zag</em> case: $x$ and $y$ are different children of their parents, i.e., $x$ is the left child and $y$ is the right child, or vice versa. We first perform $rotate(x, y)$ then $rotate(y, z)$.<br><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/SplayTree/ZigZag.png"> </li>
</ol>
</li>
</ol>
<p>The splay is performed repeatedly on $x$ until it reaches the root. It is also possible to perform equivalent operations in an top-down approach [1]. </p>
<h2 id="Time-Analysis"><a href="#Time-Analysis" class="headerlink" title="Time Analysis"></a>Time Analysis</h2><p>There is no explicit control over the height of the tree. It is possible that the accessed node has depth $\Omega(\log n)$.  The intuition is that, however, the imbalanced situation is not easy to create and must accumulate from previous operations. The number such operations can not be too to create the imbalance. We can charge the cost of accessing the node with long depth to these operations. Intuitively, each previous operation is required to reserve some additional “energy” for the amount of imbalanced it creates, which is used later to fix the imbalance. When a long path is encountered, there should be enough “energy” to cover the search on the path and the splay of the access node. </p>
<p>It is left to give a quantitative scheme for keeping the “energy” and “using” the “energy”. We need a few more definitions for a node $x$.</p>
<ol>
<li>$T(x):$ the subtree rooted at $x$. </li>
<li>$w(x):$ the weight associated with node $x$. This weight is only used for analysis and is not kept explicitly by splay tree. </li>
<li>$s(x)=\sum_{y \in T(x)} w_y:$ the sum of weights of nodes in $T(x)$, which is referred to as the size of $x$. </li>
<li>$r(x) \doteq \log r(x)$, the rank of $x$. </li>
</ol>
<p>Let $T$ be the splay tree. The potential function is defined as<br>$$<br>\Phi = \sum_{x \in T} r(x)<br>$$<br>which records the amount of “energy” in $T$. </p>
<p>The amortized cost of an operation is defined as<br>$$<br>\text{amortized cost} = \text{actual cost} + \Delta \Phi<br>$$<br>where $\Delta \Phi$ is the change of the potential function.</p>
<p>Now, let $r(x)$ be the rank of $x$ before we performed a single splay operation on $x$ and $r’(x)$ the one after. The <em>Access Lemma</em> states the $\Phi$ changes as follows:</p>
<blockquote>
<p><strong><em>Access Lemma</em></strong> For a single splay operation, the potential change is bounded by<br>$$ 3(r’(x) - r(x)) - 2 $$<br>for <em>zig-zig</em> and <em>zig-zag</em> case and<br>$$ r’(x) - r(x) $$<br>for the <em>zig</em> case.</p>
</blockquote>
<p>Before we prove this key lemma, we use it for the following theorem.</p>
<p><strong><em>Theorem.</em></strong> The amortized cost of the splaying a node $x$ to the root is $O(1 + \log \frac{s(root) }{s(x) })$. </p>
<p><em>Proof.</em>  To splay a node $x$ to the root, suppose that we have performed $k$ splays. Further, let $r_i(x)$ be the rank of $x$ after we performed the $i^{th}$ splay on $x$. We have $r_0(x) = \log s(x)$ and $r_k(x) = \log s(root)$. Observe that the actual cost of splay operation is $2$ for <em>zig-zig</em> and <em>zig-zag</em>  case and 1 for the <em>zig</em> case. Hence, the amortized cost is<br>$$<br>\begin{aligned}<br>\text{amortized cost}<br>&amp;\le \sum_{i = 1}^k 3(r_i(x) - r_{i - 1}(x)) +1 \<br>&amp;= 3(r_k(x) - r_0(x)) + 1<br>\end{aligned}<br>$$<br>The added 1 results from the final possible <em>zig</em> operation. </p>
<p>$\blacksquare$</p>
<p>If we set $w(x) = 1$ for all nodes, then $r_k(x) = \log n$ and $r_1(x) \ge \log 1 = 0$. Therefore, the amortized cost of splaying $x$ is bounded by $O(\log n)$. </p>
<h3 id="Proof-of-The-Access-Lemma"><a href="#Proof-of-The-Access-Lemma" class="headerlink" title="Proof of The Access Lemma."></a>Proof of The Access Lemma.</h3><h4 id="Zig-Zig"><a href="#Zig-Zig" class="headerlink" title="Zig-Zig"></a><strong><em>Zig-Zig</em></strong></h4><ul>
<li><p>Example.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/SplayTree/ZigZig.png"></p>
</li>
</ul>
<p>First, note that<br>$$<br>\begin{aligned}<br>        &amp;   \frac{1}{2} r’(z) + \frac{1}{2} r(x)    \<br>    =   &amp;   \frac{1}{2} \log s’(z) + \frac{1}{2} \log s(x)   \<br>    \le &amp;   \log \left[ \frac{s’(z)}{2}  + \frac{ s(x) }{2} \right] \<br>    &lt;   &amp;   \log \left[ \frac{s(z)}{2}  \right] \<br>\end{aligned}<br>$$</p>
<p>The first inequality follows from that the function $\log (\cdot )$ is concave and the second one follows from $s’(z) + s(x) = s(z) - 1 &lt; s(z)$.</p>
<p>Therefore,<br>$$<br>r’(z) + r(x) \le 2 \left[ r(z) - 1 \right]<br>$$</p>
<p>Now consider the potential change of the zig-zig operation:<br>$$<br>\begin{array}{rll}<br>        &amp;   r’(x) + r’(y) + r’(z) - r(x) - r(y) - r(z) \<br>    =   &amp;   r’(y) + r’(z) - r(x) - r(y) \<br>    \le &amp;   r’(x) + r’(z) - r(x) - r(x) \<br>    =   &amp;   [r’(x) - r(x)]  +[r’(z) + r(x)] - 2 r(x) \<br>    \le &amp;   [r’(x) - r(x)] +2[r(z) - 1] - 2 r(x) \<br>    =   &amp;   3[r’(x) - r(x)] - 2<br>\end{array}<br>$$</p>
<p>The first equality follows from $r’(x) = r(z)$, as $s’(x) = s(z)$. The first inequality holds since $r(x) \le r(y)$.</p>
<h4 id="Zig-Zag"><a href="#Zig-Zag" class="headerlink" title="Zig-Zag"></a><strong><em>Zig-Zag</em></strong></h4><ul>
<li><p>Example.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/SplayTree/ZigZag.png"></p>
</li>
</ul>
<p>First, note that<br>$$<br>\begin{aligned}<br>        &amp;   \frac{1}{2} r’(y) + \frac{1}{2} r’(z)    \<br>    =   &amp;   \frac{1}{2} \log s’(y) + \frac{1}{2} \log s’(z)   \<br>    \le &amp;   \log \left[ \frac{s’(y)}{2}  + \frac{ s’(z) }{2} \right] \<br>    &lt;   &amp;   \log \left[ \frac{s’(x)}{2}  \right] \<br>\end{aligned}<br>$$</p>
<p>The first inequality follows from that the function $\log (\cdot )$ is concave and the second one follows from $s’(y) + s’(z) = s’(x) - 1 &lt; s’(x)$.</p>
<p>Therefore,<br>$$<br>r’(y) + r’(z) \le 2 \left[ r’(x) - 1 \right]<br>$$</p>
<p>Now consider the potential change of the zig-zag operation:<br>$$<br>\begin{array}{rll}<br>        &amp;   r’(x) + r’(y) + r’(z) - r(x) - r(y) - r(z) \<br>    =   &amp;   r’(y) + r’(z) - r(x) - r(y) \<br>    \le &amp;   r’(y) + r’(z) - r(x) - r(x) \<br>    \le &amp;   2 \left[ r’(x) - 1 \right] - 2 r(x) \<br>    =   &amp;   2[r’(x) - r(x)] - 2<br>\end{array}<br>$$</p>
<p>The first equality follows from $r’(x) = r(z)$, as $s’(x) = s(z)$. The first inequality holds since $r(x) \le r(y)$.</p>
<h4 id="Zig"><a href="#Zig" class="headerlink" title="Zig"></a><strong><em>Zig</em></strong></h4><ul>
<li><p>Example.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/SplayTree/Zig.png"></p>
</li>
</ul>
<p>Now consider the potential change of the zig-zag operation:<br>$$<br>\begin{array}{rll}<br>        &amp;   r’(x) + r’(y)  - r(x) - r(y)  \<br>    =   &amp;   r’(y)  - r(x)  \<br>    \le &amp;   r’(x)  - r(x)<br>\end{array}<br>$$</p>
<p>$\blacksquare$</p>
<p>We now show the implementation of basic BST operations and their amortized cost. Throughout the analysis we assume that $w(x) = 1$. </p>
<h3 id="Cost-of-Insertion"><a href="#Cost-of-Insertion" class="headerlink" title="Cost of Insertion"></a>Cost of Insertion</h3><p>Inserting a node $x$ is the same as that in a BST.  Then we splay node $x$ to the root.   We charge the cost of going down the tree by the cost of splaying $x$, which has amortized cost $O(\log n)$. It is left to analyze the change of $\Phi$. Let $root = x_1, x_2, …, x_k, x_{k + 1} = x$ be the root to $x$ path right after inserting $x$. The insertion of $x$ increases  $s(x_1), s(x_2), …, s(x_{k })$ by 1, therefore,<br>$$<br>\begin{array}{llr}<br>\Delta \Phi &amp;= \sum_{i = 1}^k \log \frac{s(x_i) + 1 }{s(x_i)} \<br>            &amp;= \log \prod_{i = 1}^k \frac{s(x_i) + 1 }{s(x_i)} \<br>            &amp;\le \log \frac{s(x_1) + 1}{ s(x_k ) }<br>\end{array}<br>$$<br>The last inequality follows from that $s(x_i) \ge s(x_{i + 1}) + 1$ for $i \in [k]$. Therefore, $\Delta \Phi = O(\log n)$ and the overall amortized cost of insertion is $O(\log n)$. </p>
<p>Remark: $key(x_{k})$ is either the predecessor or successor of $key(x)$.   </p>
<h3 id="Cost-of-Search"><a href="#Cost-of-Search" class="headerlink" title="Cost of Search"></a>Cost of Search</h3><p>Whether the search is successful or not, we splay the last accessed node to the root and charge the cost of going down the tree to the splay-operations. Therefore, the amortized cost is $O(\log n)$. </p>
<p>Remark: in case of unsuccessful search, we find either the predecessor or successor of the search key. </p>
<h3 id="Cost-of-Deletion"><a href="#Cost-of-Deletion" class="headerlink" title="Cost of Deletion"></a>Cost of Deletion</h3><p>As in a BST, deletion is a little bit tricky. Let $x$ be the node to delete and $y$ be its parent (if exists). There are 3 cases</p>
<ul>
<li><p>If $x$ is a leaf node, then we just delete it and splay $y$ to the root. </p>
</li>
<li><p>If $x$ has only one child, we replace $x$ with its child as the child of $y$. Then we delete $x$ and splay $y$ to the root. </p>
</li>
</ul>
<p>The final case uses the first two cases as a sub-routine. We first discuss the amortized cost of the first two cases. The cost of going down to $x$ can be charged to the cost of splaying $y$ to the root, which has amortized cost $O(\log n)$. Deleting the node decreases the potential function, which will only lower the overall amortized cost. Therefore, the amortized cost of deletion is bounded by $O(\log n)$. </p>
<ul>
<li>If $x$ has two children, we find the predecessor node $pred(x)$ of $x$, which is the node with largest key in $x$’s left sub-tree. Note that $pred(x)$ has at most one child. Then we delete the node $pred(x)$. This reduces to case 1 or case 2. Finally we replace the $key(x)$ with $key(pred(x))$. </li>
</ul>
<p>In the following sections we analyze the properties of the splay tree on a sequence $S$ of $m$ operations. </p>
<h2 id="Static-Optimality"><a href="#Static-Optimality" class="headerlink" title="Static Optimality"></a>Static Optimality</h2><p>Suppose that $S$ consists of only successful search operations. Let $p_i &gt; 0<br>$ be the frequency that the $i^{th}$ element is accessed.  Define a static binary search tree to be the one whose structure is fixed. In particular, it can not perform rotations. </p>
<p><strong><em>Theorem.</em></strong> (Static Optimality) The total cost of  $S$ performed on the splay tree is at most a constant times the minimum possible cost of $S$ performed a static binary search tree, plus $O(m )$. </p>
<p><em>Proof.</em>  Let $T^*$ be the static binary search tree that minimizes the cost of $S$. For the $i^{th}$ element, let $l_i$ be the depth of $i$ in $T^*$, i.e. the number of nodes on the path from $i$ to the root, so $l(root) = 1$. The total cost in $T^*$ is given by $\sum_{i = 1}^n p_i \cdot m \cdot l_i$. We are going to prove that the cost for splay tree is<br>$$<br>O(m + \sum_{i = 1}^n p_i \cdot m \cdot l_i)<br>$$<br>Suppose that $T^*$ has maximum depth $d_{max}(T^*)$. We claim that for any $k &lt; d_{max}(T^*)$, $T^*$ must contain exactly $2^k$ nodes with depth $k$. Otherwise, we can cut some leaf node from its parent and pad it into the $i^{th}$ level. This will only decrease the access cost,  contradicting $T^*$ being the optimal static binary tree. Then, $d_{max}(T^*) \le \lfloor \log_2 n \rfloor + 1$ and<br>$$<br>\sum_{i = 1}^n 3^{-l_i} \le \frac{1}{2} \sum_{k = 1}^{ \lfloor \log_2 n \rfloor + 1 } (\frac{2}{3})^k \le 1<br>$$<br>To investigate the time for splay tree, we choose a different weight than earlier and just set $w_i = 3^{-l_i}$. Now the amortized cost of accessing $i^{th}$ element is given by<br>$$<br>O(1 + \log_2 \frac{s(root)}{s(i)}) = O(1 + \log_2 \frac{1}{3^{-l_i}}) = O(1 + l_i)<br>$$<br>Let $c_k$ be the actual cost of the $k^{th}$ operation in $S$ and $a_k$ be the amortized cost. Further, let $\Phi_k$ be the potential of the splay tree after the $k^{th}$ operation. Then<br>$$<br>\sum_{k = 1}^m a_k = \sum_{k = 1}^m (c_k + \Phi_k - \Phi_0) = \sum_{k = 1}^m c_k + \Phi_m - \Phi_0<br>$$<br>Hence, the actual cost on this sequence is bounded by<br>$$<br>\begin{aligned}<br>\sum_{k = 1}^m c_k &amp;= \Phi_0 - \Phi_m + \sum_{k = 1}^m a_k \<br>&amp;=    \Phi_0 - \Phi_m + \sum_{i = 1}^m p_i \cdot m \cdot \log 3^{l_i} \<br>&amp;=  \Phi_0 - \Phi_m + \sum_{i = 1}^m p_i \cdot m \cdot (l_i \log 3 + 1)  \<br>&amp;= m + \Phi_0 - \Phi_m + \sum_{i = 1}^m p_i \cdot m \cdot l_i \cdot \log 3<br>\end{aligned}<br>$$<br>It is left to bound $\Phi_0 - \Phi_m$. Let $r^0(i)$ be the rank of $i^{th}$ before and $r^m(i)$ be the rank after the operations. It holds that $r^0(i) \le \log_2 1 = 0$ and $r^m(i) \ge \log_2 w(i)$. Now,<br>$$<br>\begin{aligned}<br>\Phi_0 - \Phi_m &amp;= \sum_{i = 1}^n \left( r^0(i) - r^m(i) \right) \<br>&amp;\le \sum_{i  = 1}^n \log 3^{l_i} \<br>&amp;=  \sum_{i =1}^n l_i \log 3 \<br>\end{aligned}<br>$$<br>Under the assumption that each item is accessed at  least once, we know $p_i \cdot m \ge 1$ and $\Phi_0 - \Phi_m \in O(\sum_{i = 1}^m p_i \cdot m \cdot l_i \cdot \log 3 )$. </p>
<p><strong><em>Remark</em></strong>. Of course, we could bound<br>$$<br>\sum_{i =1}^n l_i \log 3 \le (1 + 2 \cdot 2 + 3 \cdot 2^2 + 4 \cdot 2^3 + … + (\lfloor \log_2 n \rfloor + 1) \cdot 2^{ \lfloor \log_2 n \rfloor }) \log 3<br>$$<br>Let $\Sigma=1 + 2 \cdot 2 + 3 \cdot 2^2 + 4 \cdot 2^3 + … +  (\lfloor \log_2 n \rfloor + 1) \cdot 2^{ \lfloor \log_2 n \rfloor }$, then<br>$$<br>2 \cdot \Sigma - \Sigma = (\lfloor \log_2 n \rfloor + 1) \cdot 2^{ \lfloor \log_2 n \rfloor + 1} - \sum_{i = 0}^{\lfloor \log_2 n \rfloor - 1} 2^i \in O(n \log n)<br>$$</p>
<p>Note that $n \log n$ is a lower bound of the access cost of the optimal static binary search tree, under the assumption that each item is accessed at least once. </p>
<p><strong><em>Remark</em></strong>:</p>
<p>In general,<br>$$<br>\sum_{i = 0}^k x^i = \frac{x^{k + 1} - 1}{x - 1}<br>$$<br>Applying $x \cdot \frac{\partial}{\partial x}$ to both sides,<br>$$<br>\begin{aligned}<br>\sum_{i = 1}^k i x^{i}<br>&amp;= x \cdot \frac{(k + 1) x^k (x - 1) - (x^{k + 1} - 1)}{(x - 1)^2} \<br>&amp;= x \cdot \frac{(k + 1) (x^{k +1} - x^k) - (x^{k + 1} - 1)}{(x - 1)^2} \<br>&amp;= x \cdot \frac{ k x^{k +1} - (k + 1) x^k  + 1}{(x - 1)^2} \<br>&amp;= x \cdot \left( \frac{k x^k }{x - 1} - \frac{ x^k  - 1}{(x - 1)^2} \right)\<br>\end{aligned}<br>$$</p>
<h2 id="Working-Set-Property"><a href="#Working-Set-Property" class="headerlink" title="Working Set Property"></a>Working Set Property</h2><p>Suppose that $S = {x_1, x_2, …, x_m}$ and let $t(k)$ be the number of  different nodes accessed before $x_k$ since the last access of node $x_k$, or since the beginning of the sequence if $x_k$ is the first access. </p>
<p><strong><em>Theorem</em>.</strong>  The overall cost of $S$ on the splay tree is bounded by<br>$$<br>O(m + n \log n + \sum_{k = 1}^n \log t(k) )<br>$$<br><strong><em>Proof.</em></strong>  We maintain $w(x) = \frac{1}{(j + 1)^2}$, if the sequence accesses $j$ different nodes since the last accessed of node $x$, or $w(x) = \frac{1}{n^2}$ if it is never accessed before. By definition of $t(k)$, we have $w(x_k) = \frac{1}{(t(x_k) + 1)^2}$. Now<br>$$<br>W \doteq \sum_{x \in T}^n w(x) \in O(1)<br>$$<br>For a node $x_k$ , if it is accessed for the first time, the amortized cost is<br>$$<br>O(1 + \log \frac{W}{w(x_k)} ) = O(\log n) = O(\log t(k))<br>$$<br>Summing over all nodes $x$ in the splay tree $T$, we get $O(n \log n)$.</p>
<p>Otherwise, if an item $x_k$ is accessed before, the amortized cost of accessing $x_k$ is<br>$$<br>O\left( 1 + \log \frac{W}{w(x_k) } \right) = O \left( 1 + \log t(k) \right)<br>$$<br>After each access of a node $x_k$ and splaying it to the root, we modify the weights of the nodes as follows: for all node $x$ with $t(x) &lt; t(x_k)$ (the nodes accessed after the last access of $x_k$), we set<br>$$<br>w(x) = \frac{1}{(t(x) + 1)^2}<br>$$<br>This guarantees that $w(x_k) = {1} / {(1 + t(k))^2}$ for $k \in [m]$. </p>
<p>The weight of the root does not change but the weight of other nodes may decrease after the reassignment. Therefore, the overall potential decreases. The amortized cost of the this access only decreases and is still bounded by $O(1 + \log t(k))$.</p>
<p>Hence<br>$$<br>\sum_{k = 1}^m a_k \in O(n \log n + m + \sum_{k = 1}^m \log t(k) )<br>$$<br>Finally, it is easy to see that $\Phi_0 - \Phi_m \in O(n \log n)$. Therefore,<br>$$<br>\sum_{k = 1}^m c_k \in O(n \log n + m + \sum_{k = 1}^m \log t(k) )<br>$$<br>$\blacksquare$</p>
<h2 id="Static-Finger-Property"><a href="#Static-Finger-Property" class="headerlink" title="Static Finger Property"></a>Static Finger Property</h2><p>The static finger property states that splay tree achieves some kind of locality. Suppose we order the nodes in the tree in increasing order according to their keys and labels them as $1, 2, …, n$. For a node $x$, we use $\pi(x)$ to denote its order. </p>
<p><strong><em>Theorem.</em></strong> For any fixed $i \in [n]$, the total cost of $S$ on the splay tree is bounded by<br>$$<br>O(n \log n + m + \sum_{k = 1}^m \log (|\pi(x_k) - i| + 1) )<br>$$<br><strong><em>Proof.</em></strong> For $x \in T$, we set $w(x) = \frac{1}{(|pi(x) - i| + 1)^2}$. Then<br>$$<br>W \doteq \sum_{x \in T} \in O(1)<br>$$<br>and the amortized cost of accessing $x_k$ is<br>$$<br>O(1 + \log \frac{W}{w(x_k)}) = O(1 + \log (|\pi(x_k) - i| + 1))<br>$$<br>The theorem then follows from $\Phi_0 - \Phi_m = O(n \log n)$. </p>
<p>$\blacksquare$.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1]. Sleator, D.D. and Tarjan, R.E., 1983. A data structure for dynamic trees. Journal of computer and system sciences, 26(3), pp.362-391.</p>
<p>[2]. Jelani Nelson, Lecture 7, CS 224: Advanced Algorithms.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/05/23/Total-Law-of-Variance/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/23/Total-Law-of-Variance/" class="post-title-link" itemprop="url">Total Law of Variance</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-05-23 21:16:25 / Modified: 21:33:04" itemprop="dateCreated datePublished" datetime="2020-05-23T21:16:25+10:00">2020-05-23</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Let $X$ and $Y$ be random variables. Then the conditional expectation<br>$$<br>E[Y \mid X]<br>$$<br>is a random variable that depends on $X$.  Correspondingly we define its variance as<br>$$<br>Var[E[Y \mid X]] = E[\left( E[Y \mid X] \right)^2] - (E\left[ E[Y \mid X] \right] )^2<br>$$<br>The <strong><em>Law of Total Variance</em></strong> states that<br>$$<br>\begin{aligned}<br>Var[Y]<br>&amp;= E[Y^2] - (E[Y])^2    \<br>&amp;= E[E[Y^2 \mid X]] - E[\left( E[Y \mid X] \right)^2] + E[\left( E[Y \mid X] \right)^2] - (E\left[ E[Y \mid X] \right] )^2 \<br>&amp;= E[E[Y^2 \mid X] - \left( E[Y \mid X] \right)^2] + Var[ E[Y \mid X] ] \<br>&amp;= E[Var[Y \mid X] ] + + Var[ E[Y \mid X] ]<br>\end{aligned}<br>$$<br>$\blacksquare$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/05/05/Cycle-Core-Connection-Game/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/05/Cycle-Core-Connection-Game/" class="post-title-link" itemprop="url">Cycle-Core Connection Game</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-05 10:56:51" itemprop="dateCreated datePublished" datetime="2020-05-05T10:56:51+10:00">2020-05-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-30 14:33:36" itemprop="dateModified" datetime="2021-01-30T14:33:36+11:00">2021-01-30</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Eisenbrand et al [1] proposed an interesting technique called cycle connection game. In the setting, there is a set of $n$ core points connected by an undirected cycle. Each core point is associated with a client. There is a pair of opposite directed edges between each core point and its associated client. Each edge has a weight. We denote $G$ be the resulting graph. </p>
<p>An example is shown as follows:</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/CycleCoreConnectionGame.png"></p>
<p>Given an instance, we would like to sample a set of clients randomly (we call the sampled clients the “marked” ones). Then each client sends a unit capacity flow to its nearest marked client (could be itself). The cost of each flow is the sum of edges weights it travels. We would like to bound the expected cost of sending the flows.</p>
<p>The selection process requires a probability $p$ as input and consists of two steps: </p>
<ol>
<li>Pick a client uniformly at random. This step ensures that at least one client is selected. </li>
<li>For the rest clients, pick each of them independently with some probability $p$. </li>
</ol>
<p>To analyze the expected cost, we divide the edges into three categories:</p>
<ol>
<li>Directed edges from the clients to the core points, denoted as $\mathcal{E}_{in}$;</li>
<li>Directed edges from the core points to the clients, denoted as $\mathcal{E}_{out}$;</li>
<li>Edges on the cycle, denoted as $\mathcal{C}$.</li>
</ol>
<p>The following theorem holds: </p>
<blockquote>
<p><em>Theorem.</em> The expected cost is bounded by<br>  $$<br>        \sum_{e \in \mathcal{E}<em>{in} \cup \mathcal{E}</em>{out} } w_e + \frac{1}{2p} \sum_{e \in \mathcal{C} } w_e<br>    $$</p>
</blockquote>
<p><strong><em>Proof.</em></strong><br>For each edge $e$, define a random variable $X_e$ to be the flow value of $e$. For $e \in \mathcal{E}<em>{in}$, it holds that $X_e \in {0, 1}$. However, for $e \in \mathcal{E}_{out} \cup \mathcal{C}$, it is possible that $X_e &gt; 1$. By linearity of expectation,<br>$$<br>    \mathbb{E} \left[ \sum_{e \in \mathcal{E}</em>{in} \cup \mathcal{E}<em>{out} } w_e \cdot X_e + \sum</em>{e \in \mathcal{C} } w_e \cdot X_e \right] = \sum_{e \in \mathcal{E}<em>{in} \cup \mathcal{E}</em>{out} } w_e \cdot \mathbb{E} \left[  X_e \right]  + \sum_{e \in \mathcal{C} } w_e \cdot \mathbb{E} \left[  \cdot X_e \right].<br>$$</p>
<ol>
<li><p>For $e \in \mathcal{E}_{in}$, there is a unit flow on $e$ if only the associated client is not sampled. This happens with probability $(1 - \frac{1}{n})(1 - p)$, where $n$ is the number of clients. Therefore, $\mathbb{E} [X_e \cdot w_e] = (1 - \frac{1}{n})(1 - p) \cdot w_e$ and<br>$$</p>
<pre><code> \mathbb&#123;E&#125; \left[ \sum_&#123;e \in \mathcal&#123;E&#125;_&#123;in&#125; &#125; X_e \cdot w_e \right] = (1 - \frac&#123;1&#125;&#123;n&#125;)(1 - p) \cdot \sum_&#123; e \in \mathcal&#123;E&#125;_&#123;in&#125; &#125; w_e.
</code></pre>
<p>$$ </p>
</li>
<li><p>For $e \in \mathcal{E}<em>{out}$, the analysis is a little tricky. For each particular sample instance, it holds that $\sum</em>{e \in \mathcal{E}<em>{out}} X_e = \sum_{e \in \mathcal{E}</em>{in}} X_e$, by flow conservation. Therefore,<br>$$</p>
<pre><code> \mathbb&#123;E&#125; \left[  \sum_&#123;e \in \mathcal&#123;E&#125;_&#123;out&#125;&#125; X_e \right] = \mathbb&#123;E&#125; \left[ \sum_&#123;e \in \mathcal&#123;E&#125;_&#123;in&#125;&#125; X_e \right] = (1 - \frac&#123;1&#125;&#123;n&#125;)(1 - p) n.
</code></pre>
<p>$$<br>By symmetry, ${ X_e }<em>{ e \in \mathcal{E}</em>{out} }$ are identical distributed random variables. Therefore $\mathbb{E} [X_e] = (1 - \frac{1}{n})(1 - p)$. It concludes that<br>$$</p>
<pre><code> \mathbb&#123;E&#125; \left[ \sum_&#123;e \in \mathcal&#123;E&#125;_&#123;out&#125; &#125; X_e \cdot w_e \right] = (1 - \frac&#123;1&#125;&#123;n&#125;)(1 - p) \cdot \sum_&#123; e \in \mathcal&#123;E&#125;_&#123;out&#125; &#125; w_e.
</code></pre>
<p>$$</p>
</li>
<li><p>For $e \in \mathcal{C}$, the analysis of $\mathbb{E} [X_e]$ is the hardest part. We look at the suboptimal flow routing scheme such that each un-marked client sends a unit flow to a nearest marked client, with respect to unit cycle edge weight. Let $Y_e$ be the number of flows on edge $e$. Clearly,<br> $$</p>
<pre><code> \mathbb&#123;E&#125; \left[ \sum_&#123;e \in \mathcal&#123;C&#125; &#125; X_e \cdot w_e \right] \le \mathbb&#123;E&#125; \left[ \sum_&#123;e \in \mathcal&#123;C&#125; &#125; Y_e \cdot w_e \right]. 
</code></pre>
<p> $$</p>
<p> Further, for each client $j$, let the random variable $Y_j$ be the number of cycle edges travelled by its flow, then<br> $$</p>
<pre><code> \sum_&#123;e \in \mathcal&#123;C&#125; &#125; Y_e = \sum_j Y_j.
</code></pre>
<p> $$</p>
<p> For a fixed $j$ and some integer $0 \le k \le \lfloor (n - 2) / 2 \rfloor$, the event $Y_j &gt; k$ happens if and only if $j$ is not marked and none of the first $k$ client neighbors to the left and right of $j$ is marked, the probability of which is given by<br> $$</p>
<pre><code> \Pr[Y_j &gt; k] = \left( 1 - \frac&#123;2k + 1&#125;&#123;n&#125; \right) q^&#123;2k + 1&#125;. 
</code></pre>
<p> $$</p>
<p> where $q = (1 - p)$. Now the expectation of $Y_j$ is given by<br> $$<br> \begin{aligned}</p>
<pre><code> \mathbb&#123;E&#125; [Y_j] 
     &amp;= \sum_&#123;k = 0&#125;^&#123;\lfloor (n - 2) / 2 \rfloor &#125; \left( 1 - \frac&#123;2k + 1&#125;&#123;n&#125; \right) q^&#123;2k + 1&#125; \\
     &amp;\le e^&#123; - \frac&#123; 1 &#125;&#123;n&#125; &#125; q \sum_&#123;k = 0&#125;^&#123;\lfloor (n - 2) / 2 \rfloor &#125; e^&#123; -  k \frac&#123; 2 &#125;&#123;n&#125; &#125; q^&#123;k2&#125; \\ 
     &amp;\le e^&#123; - \frac&#123; 1 &#125;&#123;n&#125; &#125; q \sum_&#123;k = 0&#125;^&#123;\lfloor (n - 2) / 2 \rfloor &#125; (e^&#123; - \frac&#123; 2 &#125;&#123;n&#125; &#125; q^&#123;2&#125; )^k \\ 
     &amp;= e^&#123; - \frac&#123; 1 &#125;&#123;n&#125; &#125; q \frac&#123; (1 - (e^&#123; - \frac&#123; 2 &#125;&#123;n&#125; &#125; q^&#123;2&#125; )^&#123;\lfloor (n - 2) / 2 \rfloor &#125; ) &#125;&#123;1 -  (e^&#123; - \frac&#123; 2 &#125;&#123;n&#125; &#125; q^&#123;2&#125; ) &#125; \\
     &amp;\le \frac&#123; e^&#123; - \frac&#123; 1 &#125;&#123;n&#125; &#125; q &#125;&#123; 1 -  (e^&#123; - \frac&#123; 2 &#125;&#123;n&#125; &#125; q^&#123;2&#125; ) &#125; \\
     &amp;\le \frac&#123;1&#125;&#123; 2 (1 - e^&#123; - \frac&#123; 1 &#125;&#123;n&#125; &#125; q) &#125;.
</code></pre>
<p> \end{aligned}<br> $$<br> The final inequality holds as $2x - 2x^2 \le 1 - x^2$. Replacing $q$ with $1 - p$, we have<br> $$</p>
<pre><code> \mathbb&#123;E&#125; [Y_j] \le  \frac&#123;1&#125;&#123; 2 (1 - e^&#123; - \frac&#123; 1 &#125;&#123;n&#125; &#125; (1 - p)) &#125; \le  \frac&#123;1&#125;&#123; 2 (1 - e^&#123; - \frac&#123; 1 &#125;&#123;n&#125; &#125;  + e^&#123; - \frac&#123; 1 &#125;&#123;n&#125; &#125; p) &#125;  \le \frac&#123;1&#125;&#123;2p&#125;.
</code></pre>
<p> $$</p>
<p> Remark: a more coarse calculation which leads to the same result would be<br> $$</p>
<pre><code> \mathbb&#123;E&#125; [Y_j] \le \sum_&#123;k = 0&#125;^\infty (1 - p)^&#123;2k + 1&#125; \le \frac&#123;1 - p&#125;&#123;1 - (1 - p)^2 &#125; \le \frac&#123;1&#125;&#123;2p&#125;.
</code></pre>
<p> $$</p>
<p> By symmetry, the $Y_j$’s are identical distributed random variables. So are the variable $Y_e$’s for $e \in \mathcal{C}$. It follows<br> $$<br> \begin{aligned}</p>
<pre><code> \mathbb&#123;E&#125; [Y_e] 
     = \mathbb&#123;E&#125; [Y_j] 
     &amp;\le \frac&#123;1&#125;&#123;2p&#125;. 
</code></pre>
<p> \end{aligned}<br> $$<br> and<br> $$<br> \begin{aligned}</p>
<pre><code> \mathbb&#123;E&#125; \left[ \sum_&#123;e \in \mathcal&#123;C&#125;&#125; Y_e \cdot w_e \right]  
     &amp;\le \frac&#123;1&#125;&#123;2p&#125; \sum_&#123;e \in \mathcal&#123;C&#125;&#125; w_e.
</code></pre>
<p> \end{aligned}<br> $$</p>
</li>
</ol>
<p>$\blacksquare$</p>
<p><strong>Reference:</strong>  </p>
<ol>
<li><p>Eisenbrand, Friedrich, Fabrizio Grandoni, Thomas Rothvoß, and Guido Schäfer. “Approximating connected facility location problems via random facility sampling and core detouring.” In Proceeding of Nineteenth annual ACM-SIAM Symposium (SODA’08), no. CONF, pp. 1174-1183. 2008.</p>
</li>
<li><p>Eisenbrand, F., Grandoni, F., Rothvoß, T., Schäfer, G., 2010. Connected facility location via random facility sampling and core detouring. Journal of Computer and System Sciences 76, 709–726. </p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/04/21/Linear-Transformation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/21/Linear-Transformation/" class="post-title-link" itemprop="url">Linear Transformation</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-21 22:13:49" itemprop="dateCreated datePublished" datetime="2020-04-21T22:13:49+10:00">2020-04-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-03 22:14:46" itemprop="dateModified" datetime="2020-05-03T22:14:46+10:00">2020-05-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>In linear algebra, we study vectors in some space $\mathcal{R}^n$. Linear transformation is defined on $\mathcal{R}^n$. For $v, u \in \mathcal{R}^n$, and $c \in \mathcal{R}$, a linear transformation $T : \mathcal{R}^n \rightarrow \mathcal{R}^n$ satisfies</p>
<ol>
<li>$T(v + u) = T(v) + T(u)$</li>
<li>$T(cv) = c T(v)$</li>
</ol>
<p>However, the “linear thing” is not limited to vectors. As an illustration, note that a vector<br>$$<br>v = \begin{bmatrix}<br>    v_1 \ v_2 \ . \ . \ . \ v_n<br>\end{bmatrix}<br>$$</p>
<p>can be viewed as the image of some function $f : {1, 2, …, n } \rightarrow \mathcal{R}$, such that $f(i) = v_i$. It is natural to study the functions ${\mathbb{I} \rightarrow \mathcal{R} }$, where $\mathbb{I} \subset \mathcal{R}$ is some open interval. For any $x \in \mathbb{I}$, $f(x)$ gives the value of $x$. The only difference with vectors is that, it not possible to enumerate all value of $x \in \mathbb{I}$. Instead, we specify a rule of obtaining the value at $x$. </p>
<p>For any two functions $f_1, f_2 : \mathbb{I} \rightarrow \mathcal{R}$, we can add them together and obtain a new function $f_1 + f_2 : \mathbb{I} \rightarrow \mathcal{R}$. Addition is closed in the space ${\mathbb{I} \rightarrow \mathcal{R} }$. Then for $x \in \mathbb{I}$,<br>$$<br>(f_1 + f_2) (x) = f_1(x) + f_2(x)<br>$$</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/LinearTransformation/Addition.jpg"></p>
<p>which is similar to that adding up coordinates of two vector. We can also define multiplication: for $c \in \mathcal{R}^n$, $f : \mathbb{I} \rightarrow \mathcal{R}$, $cf$ is a function in ${\mathbb{I} \rightarrow \mathcal{R} }$ such that<br>$$<br>(cf)(x) = c f(x)<br>$$</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/LinearTransformation/Scale.jpg"></p>
<p>Multiplication is closed in the space ${\mathbb{I} \rightarrow \mathcal{R} }$. </p>
<p><em>Example.</em> The derivative operation $T: {f: \mathbb{I} \rightarrow \mathcal{R} \wedge \text{differentiable} } \rightarrow {\mathbb{I} \rightarrow \mathcal{R} }$ is linear transformation. It is easy to verify for differentiable functions $f_1, f_2 \in \mathbb{I} \rightarrow \mathcal{R}$, and $c \in \mathcal{R}$, we have </p>
<ol>
<li>$(f_1 + f_2)’ = f_1’ + f_2’$</li>
<li>$(c f_1)’ = c f_1’$</li>
</ol>
<p>What is more, we can extend some other concepts in linear algebra. In linear algebra, “eigenvector” is a vector whose direction does not change under a linear transformation.  For derivative operation, the function $e^x$ is un-changed after the transformation:<br>$$<br>(e^x)’ = e^x<br>$$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/04/14/Catalan-Number/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/14/Catalan-Number/" class="post-title-link" itemprop="url">Catalan Number</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-04-14 17:22:31 / Modified: 20:33:46" itemprop="dateCreated datePublished" datetime="2020-04-14T17:22:31+10:00">2020-04-14</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Let $S$ be the set of binary strings with length $2n$ and equal number of $0$ and $1$’s. That is, if $s \in S$, then $s$ contains $n$ zeros and $n$ ones. Define<br>$$<br>\sigma(s) = \text{ number of 0 in } s \<br>\lambda(s) = \text{ number of 1 in } s<br>$$ </p>
<p>Then<br>$$<br>S = { s : s \in (0, 1)^{2n} \wedge \sigma(s) = \lambda(s) }<br>$$</p>
<p>Denote $s[1:i]$ the initial segment of $s$ with length. Of interest is the subset $P \subset S$ that contains strings whose initial segments has more (or equal) number of $0$ than $1$:<br>$$<br>P \doteq { s : \sigma(s[1:i]) \ge \lambda(s[1:i]), \forall i \in [2n] } \subset S<br>$$</p>
<p>The cardinality of $P$ is given by<br>$$<br>|P| = \frac{1}{n + 1} \binom{2n}{n}<br>$$</p>
<p>which is known as Catalan number. </p>
<p>Let $S \setminus P$ be the set of strings that do not satisfy the requirement and $T = { s : s \in (0, 1)^{2n} \wedge \sigma(s) = n - 1 \wedge \lambda(s) = n + 1 }$</p>
<p>The proof relies on the following theorem.</p>
<p><strong><em>Theorem</em></strong>. There is a bijection $f$ between $S \setminus P$ and $T$. </p>
<p>Before we prove it, we see how it gives Catalan number:<br>$$<br>\begin{aligned}<br>    |P|<br>        &amp;= |S| - |S\setminus P| \<br>        &amp;= \binom{2n}{n} - |T|  \<br>        &amp;= \binom{2n}{n} - \binom{2n}{n - 1}  \<br>        &amp;= \binom{2n}{n} - \binom{2n}{n} \frac{n}{n + 1} \<br>        &amp;= \frac{1}{n + 1} \binom{2n}{n}<br>\end{aligned}<br>$$</p>
<p><em>Proof of Theorem.</em>   </p>
<p>$\longrightarrow$:</p>
<p>If $s \in S \setminus P$, then there exists some $i \in [1, n - 1]$, such that $\sigma(s[1:i]) &lt; \lambda(s[1:i])$. Then we can select the smallest such $i$. Note the $i$ must be an odd number. Hence we can write $i = 2j  + 1$, $\sigma(s[1:i]) = j$ and $\lambda(s[1:i]) = j + 1$.</p>
<p>Further, as $s \in S$, we have $\sigma(s) = \lambda(s) = n$. Therefore,<br>$$<br>\sigma(s[i + 1:n]) = n - j \<br>\lambda(s[i + 1:n]) = n - j - 1<br>$$</p>
<p>To construct an $s’ \in T$ from $s$, we can flipped every bit in $s[i + 1:n]$, i.e.,<br>$$<br>s’ = (s[1:i], \ \ \overline{s[i + 1:n] } )<br>$$</p>
<p>For sanity check, the number of zeros in $s’$ is $j + n -j - 1 = n - 1$ and the number of ones is $j + 1 + n - j = n + 1$.</p>
<p>It is easy to see that this is a injection.</p>
<p>$\longleftarrow$:</p>
<p>If $s’ \in T$, then there must exist some $i \in [1, n - 1]$, such that $\sigma(s’[1:i]) &lt; \lambda(s’[1:i])$. Then we can select the smallest such $i$. Note the $i$ must be an odd number. Hence we can write $i = 2j  + 1$, $\sigma(s’[1:i]) = j$ and $\lambda(s’[1:i]) = j + 1$.</p>
<p>Further, as $s’ \in T$, we have $\sigma(s’) = n - 1$ and $\lambda(s’) = n + 1$. Therefore,<br>$$<br>\sigma(s’[i + 1:n]) = n - 1 - j\<br>\lambda(s’[i + 1:n]) = n + 1  - j - 1 = n - j<br>$$</p>
<p>To construct an $s \in S \setminus P$ from $s’$, we can flipped every bit in $s’[i + 1:n]$, i.e.,<br>$$<br>s = (s’[1:i], \ \ \overline{s’[i + 1:n] } )<br>$$</p>
<p>For sanity check, the number of zeros in $s$ is $j + n - j = n$ and the number of ones is $j + 1 + n - 1 - j = n$.</p>
<p>It is easy to see that this is a injection.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/04/11/k-Core-Decomposition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/11/k-Core-Decomposition/" class="post-title-link" itemprop="url">k-Core Decomposition</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-04-11 16:07:17 / Modified: 16:46:51" itemprop="dateCreated datePublished" datetime="2020-04-11T16:07:17+10:00">2020-04-11</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Given a graph $G = \left&lt; V, E \right&gt;$, and a subset $S \subset V$, the sub-graph $G(S)$ induced by $S$ is defined as<br>$$<br>G(S) = \left&lt; S, E_S \right&gt;<br>$$</p>
<p>where $E_S = { e : e = (u, v) \in E \wedge (u, v) \in S \times S}$. </p>
<p>$G(S)$ is called a $k$-core if it is the maximal sub-graph wuch that every vertex in $S$ has degree at least $k$ inside this sub-graph. Given the definition of $k$-core, the core number of a vertex $v \in V$ is the maximum $k$ such tha t $\exists S \subset V$, $G(S)$ is a $k$-core and $v \in S$. </p>
<p>The key observation is that, given a $k$-core $G(S)$, if we remove every vertex $v \in V$ (as long as edges incident to $v$) such that $d(v) &lt; k$, then $G(S)$ remains a $k$-core. Since </p>
<ol>
<li>If $d(v) &lt; k$, then $v \notin S$. </li>
<li>Removing edges incident to $v$ will not affect edges inside $G(S)$. Then, the vertices’ degree inside $G(S)$ remains unchanged. </li>
</ol>
<p>This gives an algorithm for computing the core number of each vertex. </p>
<blockquote>
<ol>
<li>for $v \in V$: </li>
<li>$\quad$ $check[v] \leftarrow$ false</li>
<li>while not $check[v] =$ true $\forall v \in V$:</li>
<li>$\quad$    Get an $v$ with smallest $d(v)$ and $check[v] =$ false</li>
<li>$\quad$    $check[v] \leftarrow$ true</li>
<li>$\quad$    $core[v] \leftarrow d(v)$</li>
<li>$\quad$    for $u \in N(v)$ such that $d(u) &gt; k$: </li>
<li>$\qquad$       Delete $(v, u)$</li>
<li>$\qquad$       $d(u) \leftarrow d(u) - 1$</li>
</ol>
</blockquote>
<p>We can use an array $D$ such that $D[i]$ is a linked list and contains all vertices with degree $i$. Therefore, line 4 can be executed in $O(1)$ time. </p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] Batagelj, V. and Zaversnik, M., 2003. An O (m) algorithm for cores decomposition of networks. arXiv preprint cs/0310049.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/04/02/QuakeHeap/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/02/QuakeHeap/" class="post-title-link" itemprop="url">Quake Heap</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-02 19:23:49" itemprop="dateCreated datePublished" datetime="2020-04-02T19:23:49+11:00">2020-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-05 10:57:54" itemprop="dateModified" datetime="2020-05-05T10:57:54+10:00">2020-05-05</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Quake Heap [1] is a min heap (or max heap) that supports the following operations: </p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Amortized Time</th>
</tr>
</thead>
<tbody><tr>
<td>insert(x)</td>
<td>$O(1)$</td>
</tr>
<tr>
<td>decrease-key(x,k)</td>
<td>$O(1)$</td>
</tr>
<tr>
<td>delete-min()</td>
<td>$O(\log n)$</td>
</tr>
</tbody></table>
<p>with $O(n)$ space. For comparison based min heap, either $insert(x)$ or delete-min() takes $O(\log n)$ amortized time. Otherwise, we would have an $o(n \log n)$ comparison based sorting algorithm. </p>
<p>In this blog we walk through its construction step by step and illustrate the philosophy behind. Some of the ideas also appear in other designs of min heaps. </p>
<h3 id="Insertion"><a href="#Insertion" class="headerlink" title="Insertion"></a>Insertion</h3><p>For insertion we are going to be lazy. Consider inserting the elements 1, 2, 3, 4, 5 into the heap. For each insertion, we just create a singleton node while maintaining a pointer (the “min-pointer”) to the minimum node. The picture below shows the heap we obtain after five insertions. Each insertion has time complexity $O(1)$. </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/Insertion.jpg"></p>
<h3 id="Deletion-and-Binomial-Heap"><a href="#Deletion-and-Binomial-Heap" class="headerlink" title="Deletion and Binomial Heap"></a>Deletion and Binomial Heap</h3><p>It would be easier to consider the case delete-min() without decrease-key(x) first. Now we try to delete the minimum element from heap. The first step, of course, is to remove the element $1$, after which we get the following heap. </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DeleteMin1-1.jpg"></p>
<p>Here comes the problem. The “min-pointer” is removed along with the deletion. To maintain it, it seems that we need to loop over the entire list to update the min, which takes $O(n)$ time. If we do nothing else than merely scanning all elements, we need another $O(n)$-scanning for the next deletion. We hope that the comparison performed for the current delete-min operation can reduce the ones we need to perform in the future. </p>
<p>The idea is to merge the elements into trees. <!-- Initially, we view each element as a tree with a single node. Recursively, if the root of tree $A$ is compared with and is less than the root of tree $B$, we make $A$ as a subtree of $B$.  --> Intuitively, the trees “remember” the comparison performed before and save us from comparing the same pairs again.</p>
<p>Various tree structure can be used to record the comparison and this may result in the design of different data structure. The one picked by Quake heap is the tournament tree.  It only compares and merges (linking) two trees of the same height. A new node is created as the root of the two trees. The new node’s value equals to the smaller one of the roots of the two trees. </p>
<p>For example, in the following example, both the node 4 and 5 are viewed as trees with height one. We can compare and link the two trees. A new node with value 4 (the smaller value between 4 and 5) is created as the new root of the merged tree. </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DeleteMin1-2.jpg"></p>
<p>We can continue to link node 3 and 2.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DeleteMin1-3.jpg"></p>
<p>The linking is performed recursively. Noting the the current two trees have the same height, we link them. We need to also update the “min-pointer” during the linking. </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DeleteMin1-4.jpg"></p>
<p>The construction takes $O(n)$ time. But we can charge the cost of these link operations into the creation of the trees’ roots before. We have performed 3 link operations for the four nodes each being the root of a singleton tree. On average, we pay $O(1)$ per operation. To make the amortized argument more vivid, we can think that conceptually we an additional coin for each singleton tree creation. Therefore, before linking, we have four coins as follows:</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DeleteMin1-1-Coin.jpg"></p>
<p>Merging node 5 and 4 has actual cost $O(1)$ and creates a new tree root. We use the coin of node 5 to pay the actual cost. Element 4 is the new root and it still has a coin. By using the coin idea, we charge (or averaging) the cost of this link operation to the cost of the creation of node 5. </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DeleteMin1-2-Coin.jpg"></p>
<p>Merging node 3 and 2 uses one coin. We use the coin reserved by node 3. After this, the elements 4 and 2 (the elements that are roots of some trees) still have a coin.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DeleteMin1-3-Coin.jpg"></p>
<p>Merging the two trees left uses one coin. We use the coin reserved by node 4. After this, the element 2 is still a root and still has a coin.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DeleteMin1-4-Coin.jpg"></p>
<p>In general, we may need to pay more than $O(1)$ for delete-min(). Consider we would like to perform the operation for the following. </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DeleteMin1-5-Coin.jpg"></p>
<p>We need to remove all nodes on a root-to-leaf path. In this example it is the path that contains element 2.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DeleteMin1-6-Coin.jpg"></p>
<p>After the removal, some children of the nodes in this root-to-leaf path are now exposed as tree roots. In this example, node 4 and 3 are tree roots. We need to reserve two coins node 4 and 3. The coins are reserved for potential linking performed in the future. </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DeleteMin1-7-Coin.jpg"></p>
<p>Finally we need to compare and link any two trees of the same height, in a recursive manner. This part is paid by the coins reserved for the tree roots. </p>
<p>To analyze the amortized running time of delete-min(), we define the height of the tree as $H$. We need to remove $H$ nodes from the root-to-leaf path, expose $\max {H - 1, 0 }$ node as tree roots and reserve coins for them, followed by recursively linking two trees with the same height. The final step is “free” and covered by the coins reserved. Therefore the amortized cost is $H + \max {H - 1, 0} = \max { 2H - 1, H } \le 2H$. </p>
<p><em>Key Observation:</em>  </p>
<blockquote>
<p><strong><em>To bound the time of delete-min() to $O(\log n)$, it is critical to control the size of $H$.</em></strong> </p>
</blockquote>
<p>To analyze how large $H$ could be, we study how it grow. Initially, a tree with $H  = 1$ contains only 1 key. When we link two trees with $H = 1$, the new tree has height $H = 2$ and $2$ keys (although it has $3$ nodes). In general, a tree with height $H = h$ contains $2^{h - 1}$ keys and this can be easily proved by induction. </p>
<blockquote>
<p>If there is no decrease-key operation, the tree with height $h$ has $2^{h - 1}$ keys and $2^h - 1$ nodes. As there are at most $n$ keys, the maximum possible height, denoted as $H$, is bounded by $\log n$. </p>
</blockquote>
<p>The heap we have constructed so far has a special name called “Binomial Heap”. </p>
<h3 id="Decrease-Key"><a href="#Decrease-Key" class="headerlink" title="Decrease-Key"></a>Decrease-Key</h3><p>If there is only insert() and decrease-key() operation, min heap is easy to implemented. We can use a linked list / dynamic array, while maintaining the min pointer / min index. </p>
<p>If we need to incorporate delete-min() operation, the decrease-key(x) itself is still easy, while the former requires significant modification. For decrease-key(x), we adopt a lazy strategy. If after decreasing, $x$’s value is still smaller than its parent (or $x$ is the root of the tree and has no parent), then everything is fine. For example, if we decrease $4$ to $3.5$ (the node 4 has parent 2), then we do not need to modify the tree after the operation.</p>
<img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DecreaseKey-1.jpg" alt="drawing" width="330" />


<p>On the other hand, if we decrease 4 to 1, then its value is smaller than its parent 2. </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DecreaseKey-2.jpg"></p>
<p>We need to detach the highest node containing value 4 from its parent node (in the meanwhile we maintain the “min-pointer”).</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DecreaseKey-3.jpg"></p>
<p>The only concern with this operation is the height of a heap. In the previous, the tree on the right hand side has height $3$ but contains only two keys. For a tree with $n$ keys, it could happens that it height is $\omega(\log n)$. Indeed, it could be as large as $O(n)$. This will invalidate the strategy we propose in the last section, which requires the height to be $O(\log n)$, to achieve the $O(\log n)$ amortized complexity for delete-min(). </p>
<p>There are various ways to fix this, the idea of which will give rise to Pairing heap [<em>Pairing heap achieve $O(\log n)$ amortized bound for deletion but requires $O(\log n)$ amortized time for both insertion and decrease-key(x). Its design philosophy is closely related to Splay tree.</em>], Fibonacci heap, etc. Here we discuss about the solution of Quake heap. </p>
<p>First, Quake heap records the number of nodes at each height explicitly, denoted as $n_1, n_2, …, n_H$, where $H$ is the maximum possible height. Further, it specifies a parameter $\alpha \in (0, 5, 1)$ and maintains the invariant that $n_{i + 1} \le \alpha \cdot n_i$ for each $i \ge 1$. This guarantees that $H = O(\log n)$. </p>
<p>In the following discussion, we take $\alpha = 0.75$. </p>
<p>Let’s discuss how the maintain the invariant $n_{i + 1} \le \alpha n_i$ for all $i \ge 1$ for insert(x), decrease-key(x) and delete-min() operation. </p>
<ol>
<li><p>For the operation insert(x), it create a singleton node at the bottom layer and increases $n_1$ by 1. If the invariant holds before insertion, it holds afterward. </p>
<p> <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/RecordingHeight.jpg"></p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/RecordingHeightAndInsertion.jpg"></p>
</li>
<li><p>For decrease, it will not change the number of nodes at each height. The following example shows the case where the children whose key is decreased is detached from its parent.<br><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DecreaseKey-2.jpg"></p>
<p> <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DecreaseKey-3.jpg"></p>
</li>
<li><p>Delete-min is the most difficult part. To maintain the invariant, now delete-min() consists of four part: </p>
<ul>
<li>Delete the min key (and all nodes that contain the min key). As before, this step may expose some children of the deleted nodes as new tree roots. </li>
<li>Recursively link all trees of the same height. After linking, scan all trees to maintain the min pointer. </li>
<li>Quake: if there is a level $i$ such that $n_{i + 1} &gt; \alpha n_i$, remove all nodes with level greater than $i$. </li>
</ul>
</li>
</ol>
<p>It is left to analyze the running time step by step. We use a potential function for analysis. By previous section, the potential should contain the number of trees. Further, by the last step of delete-min operation, it is suggested to includes the number of nodes in the potential function, to cover the cost of node removal. Inspired by this, our first design is given by<br>$$<br>\Phi = # \text{nodes} + 2 \cdot # \text{trees}<br>$$</p>
<p>We analyze the time for each step of delete-min()</p>
<ol>
<li><p>Before delete-min(), the invariant holds and therefore the maximum height $H = O(\log n)$. Deleting the min-key and its associated nodes take actual time $O(\log n)$. As for $\Phi$, the number of nodes decreases (indeed, this decrease will cover the removal of the nodes containing the min key) and the number of trees increases by at most $O(\log n)$.  Therefore, the amortized cost for the first step is $O(\log n)$. </p>
</li>
<li><p>Linking two trees of the same height has actual cost $1$. It creates a new node and decreases the number of trees by 1. Therefore, $\Delta \Phi = -1$. Hence the amortized cost is 0. This also explains why we need an coefficient 2 associated with #trees in the potential function. It is left to analyze the cost of scanning all tree. After linking, all trees are of different height. It suffices to show that the maximum  height is $O(\log n)$ to bound the scanning cost to $O(\log n)$. Before linking $H = O(\log n)$. As there are only $n$ keys, there are at most $n$ trees with height $H$ before and during the linking procedure. Linking $n$ trees of the same height results in a new tree with height $\log n$. Therefore, after linking, $H$ increases by at most $\log n$ and $H = O(\log n)$ still holds. Therefore, the amortized cost for the second step is $O(\log n)$. </p>
</li>
<li><p>Suppose in this step we delete $k$ nodes. The actual cost is $k$. However, the number of nodes decreases by $k$. It seems that the amortized cost is 0 for this step. But it isn’t. We have increased the number of tree. Denote $d_{i + 1}$ the number of nodes at level $i + 1$ with two children before removal and $s_{i + 1}$ the number of nodes with only one children. We have $n_{i + 1} = d_{i + 1} + s_{i + 1}$. On the other hand, we know $n_i \ge 2 d_{i + 1} + s_{i + 1}$. By the fact that $n_{i + 1} &gt; \alpha n_i$, we know that<br> $$<br> \begin{aligned}<br> s_{i + 1} </p>
<pre><code> &amp;= 2(d_&#123;i + 1&#125; + s_&#123;i + 1&#125;) - (2 d_&#123;i + 1&#125; + s_&#123;i + 1&#125;)\\
 &amp;\ge 2 n_&#123;i + 1&#125; - n_i \\
 &amp;\ge (2 \alpha - 1) n_i 
</code></pre>
<p> \end{aligned}<br> $$</p>
<p> as we create at most $n_i$ new trees, we can charge the creation of new trees into $s_{i + 1}$ and modify the potential as<br> $$<br> \Phi = # \text{nodes} + 2 \cdot # \text{trees} + \frac{2}{2\alpha - 1} # \text{nodes with one child}<br> $$</p>
<p> Now step 3 has amortized cost 0. For other steps, this modification will increase the cost of decrease-key(x) by at most $O(1)$. </p>
<p> <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DeleteMin2-1.jpg"><br> <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DeleteMin2-2.jpg"><br> <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DeleteMin2-3.jpg"><br> <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DeleteMin2-4.jpg"><br> <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DeleteMin2-5.jpg"><br> <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DeleteMin2-6.jpg"><br> <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/QuakeHeap/DeleteMin2-7.jpg"></p>
<p>Caveat: we can’t swap the order of step 2 and step 3, since linking tree may create violation to the invariant and we need step 3 to fix this. </p>
</li>
</ol>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] Chan, Timothy M. “Quake heaps: a simple alternative to Fibonacci heaps.” In Space-Efficient Data Structures, Streams, and Algorithms, pp. 27-32. Springer, Berlin, Heidelberg, 2013.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/04/01/Ball%20and%20Bins/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/01/Ball%20and%20Bins/" class="post-title-link" itemprop="url">Ball and Bins</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-01 10:24:00" itemprop="dateCreated datePublished" datetime="2020-04-01T10:24:00+11:00">2020-04-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-01 12:40:24" itemprop="dateModified" datetime="2021-01-01T12:40:24+11:00">2021-01-01</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Suppose we would like to throw $n$ balls into $n$ bins uniformly at random. We claim that the bin with maximum load has $\Theta( \frac{\ln n}{\ln \ln n})$ ball with high probability. </p>
<h3 id="Upper-Bound"><a href="#Upper-Bound" class="headerlink" title="Upper Bound"></a>Upper Bound</h3><p>The probability that a particular bin gets $k$ balls is given by </p>
<p>$$<br>\binom{n}{k}\frac{1}{n^k} \left( 1 - \frac{1}{n} \right)^{n - k} \le \binom{n}{k}\frac{1}{n^k} \le \frac{1}{k!} \le \frac{  e^k }{ k^k}<br>$$</p>
<p>where the last inequality comes from  $\frac{k^k}{k!} \le e^{ k }$ (by Tailor expansion of $e^x$ at the origin with $x = k - 1$ or $x = k$).</p>
<p>If we would like to use union bound over $n$ bins to show that no bin has more than $k$ ball with probability at least $1 - \frac{1}{n}$, we need to find some $k$ that satisfies<br>$$<br>\left( \frac{e}{ k} \right)^k = \frac{1}{n^2}.<br>$$</p>
<p>Taking $\log$ of both side,<br>$$<br>k \ln k - k = 2 \ln n \implies k \ln k = \Theta( \ln n) \implies \ln k = \Theta( \ln \ln n).<br>$$</p>
<p>Substituting $k \ln k = \Theta( \ln n)$ with $\ln k = \Theta( \ln \ln n)$, we get<br>$$<br>    k  = \Theta\left( \frac{\ln n}{\ln \ln n} \right).<br>$$</p>
<!-- We can trivially take $k = e \frac{ 2 }{ e - 1} \frac{ \ln n }{ \ln \ln n  } \le 3.2 \frac{ \ln n }{ \ln \ln n  }$. To verify this 

1. For $x \ge 0$, we have $x - e \ln x \ge 0$. Hence $\frac{1}{ e } \ge \frac{\ln x }{x}$. Replacing $x$ with $\ln \ln n$ (Assuming that $n \ge e$ ), we get $\frac{1}{ e} \ge \frac{\ln \ln \ln n }{ \ln \ln n}$

2. Therefore, 
   $$
        \begin{aligned}
            e\left( \frac{k}{ e} \right)^k
                &\ge \left( \frac{\ln n  }{ \ln \ln n} \right)^k \\ 
                &= \exp \left( k (\ln \ln n - \ln \ln \ln n ) \right) \\
                &= \exp \left( \frac{ 2 }{ e - 1} e  \ln n  - \frac{ 2 }{ e - 1} e \frac{\ln n \cdot \ln \ln \ln n }{ \ln \ln n}  \right) \\
                &\ge \exp \left( \frac{ 2 }{ e - 1}[e \ln n  -  \ln n ] \right) \\
                &= n^2
        \end{aligned}
    $$ -->

<!-- As when $k = O( { \ln n \over \ln \ln n})$, we have $k^k = O(n)$. It suffices to take $k = O( \alpha e { \ln n \over \ln \ln n})$. To check this more careful, note that 


$$
1 + k \ln k - k \ln \alpha e \ge 2 \ln n
$$ 

If we set $k = l \frac{\ln n}{ \ln \ln n}$ for some $l$, then  

$$
k \ln k = k [\ln l + \ln \ln n - \ln \ln \ln n] = k \ln l + l \ln n - k \ln \ln \ln n 
$$

When $l = \frac{2}{e - 1} \alpha e$, we need to show that 

$$
 (\frac{2}{e - 1}  \alpha e - 2) \ln n -  \frac{2}{e - 1}  \alpha e \frac{\ln n \cdot \ln \ln \ln n }{ \ln \ln n} \ge 0
$$

For let $y = \ln \ln n$, $\frac{\ln y}{ y} \le \frac{1}{e}$ always holds for $y > 1$ (assuming that $n > e^e$), as 
$$
(y - e \ln y)' = 1 - e / y = 0 \rightarrow y = e
$$

and $\frac{\ln y}{y}$ increases as $y < e$ and decreases as $y > e$. 

Now, 
$$
\begin{aligned}
    &(\frac{2}{e - 1}  \alpha e - 2) \ln n -   \frac{2}{e - 1} \alpha e \frac{\ln n \cdot \ln \ln \ln n }{ \ln \ln n} \\
    \ge&  ( \frac{2}{e - 1}  \alpha e - 2) \ln n -  \frac{2}{e - 1}  \alpha  \ln n \\
    =& ( \frac{2}{e - 1}  \alpha (e - 1) - 2) \ln n  \\
    =& 2(  \alpha - 1) \ln n  \\
    \ge& 0
\end{aligned}
$$

with the assumption that $\alpha \ge 1$.  -->

<h3 id="Lower-Bound"><a href="#Lower-Bound" class="headerlink" title="Lower Bound"></a>Lower Bound</h3><p>The lower bound is a little bit harder to prove. First note for $x &gt; 1$, the function<br>$$<br>y = (x - 1) \ln (1 - \frac{1}{x})<br>$$</p>
<p>is decreasing. As<br>$$<br>\begin{array}{rrl}<br>    &amp;y’  &amp;= \ln (1 - \frac{1}{x} ) + (x - 1) \frac{ 1 }{\frac{x - 1}{x} } \frac{1}{ x^2 } \<br>        &amp;&amp;= \ln (1 - \frac{1}{x} ) + \frac{1}{ x } \<br>\end{array}<br>$$<br>and for $x &gt; 1$,<br>$$<br>\begin{array}{rrl}<br>    &amp;y’’ &amp;= \frac{ 1 }{\frac{x - 1}{x} } \frac{1}{ x^2 } - \frac{1}{x^2} \<br>        &amp;&amp;= (\frac{x}{x - 1} - 1) \frac{1}{x^2} \<br>        &amp;&amp;\ge 0<br>\end{array}<br>$$</p>
<p>Further, note that $x \rightarrow \infty$, $y’ \rightarrow 0$. It concludes that $y’ \le 0$.</p>
<p>Therefore, the probability that a bin gets $k$ balls is given by (for $k \ge 1$)</p>
<p>$$<br>\begin{aligned}<br>    \binom{n}{k}\frac{1}{n^k} \left( 1 - \frac{1}{n} \right)^{n - k}<br>        &amp;\ge (\frac{n}{k} )^k \frac{1}{n^k} \left( 1 - \frac{1}{n} \right)^{n - 1} \<br>        &amp;\ge \frac{1}{k^k} \frac{1}{e}<br>\end{aligned}<br>$$</p>
<p>If we set $k = \frac{1}{3} \frac{ \ln n }{ \ln \ln n  }$, then<br>$$<br>k^k \le ( \ln n)^k = n^{1/3}<br>$$</p>
<p>Hence,<br>$$<br>\frac{1}{k^k} \frac{1}{e} \ge e^{ - 1} n^{-1 / 3}<br>$$ </p>
<p>This probability is rather smaller. At this point it seems that a single bin is unlikely to success. But by linearity of expectation, the expected number of bins with $k$ balls is given by $e^{ - 1} n^{ 2/ 3}$. In particular, define the indicator variables $X_i$ such that $X_i = 1$ if the $i$-th bin receives $k$ balls and let $X = \sum X_i$ be the number of bins with $k$ balls. Then </p>
<ol>
<li>$E[X_i] = \Pr[X_i = 1] \ge e^{-1} n^{ - 1 / 3}$.</li>
<li>$E[X] = \sum E[X_i] \ge e^{ - 1} n^{ 2/ 3}$. </li>
</ol>
<p>As in expectation there are $e^{-1} n^{2/ 3}$ such bins, it seems that we are likely to find one. To formalize the intuition, we need to make sure that $X$ does not deviate from its expectation much. To see why this might cause a problem, consider the random variable $Y$ such that<br>$$<br>\begin{aligned}<br>    \Pr[Y = e^{-1} n^{ 5 / 3} ]  &amp;= \frac{1}{n} \<br>    \Pr[Y = 0 ]  &amp;= 1 - \frac{1}{n} \<br>\end{aligned}<br>$$</p>
<p>It has expectation $E[Y] = e^{ - 1} n^{ 2 / 3}$. But it is very likely that $Y = 0$. </p>
<p>We investigate the variance of $X$:<br>$$<br>\begin{aligned}<br>Var[X]<br>    &amp;= \sum_i Var[X_i] + \sum_{i \neq j} Cor(X_i, X_j) \<br>    &amp;\le    \sum_i Var[X_i] \<br>    &amp;\le    \sum_i E[X_i^2] \<br>    &amp;=      \sum_i E[X_i] \<br>    &amp;\le    n<br>\end{aligned}<br>$$</p>
<p>The first inequality follows from </p>
<blockquote>
<p>Fact 1: For $i \neq j$, $Cor(X_i, X_j) &lt; 0$</p>
</blockquote>
<p>Intuitively, that bin $i$ obtains ball makes it more difficult for bin $j$ to obtain ball.</p>
<p><strong><em>Question to ponder: prove it rigorously.</em></strong> </p>
<p>Finally, by Chebyshev Inequality, we have<br>$$<br>\Pr[ |X - E[X]| \ge E[X] ] \le \frac{ Var[X] }{ E[X]^2} \le \frac{n}{ e^{-2} n^{4  / 3}} = \frac{e^2}{n^ {1 / 3} }<br>$$</p>
<!-- > Proof of Fact 1. 

Observe that $Cor(X_i, X_j) = E[X_iX_j] - E[X_i] E[X_j]$. Denote $C_i$ and $C_j$ the number of balls bin $i$ and bin $j$ get respectively. As $X_i$ and $X_j$ are indicator variables, $X_i X_j$ is an indicator variable that equals to $1$ only when $X_i = 1$ and $X_j = 1$. 

$$
\begin{aligned}    
    E[X_i X_j] &= \sum_{C_i = c_i \ge k, C_j = c_j \ge k,  c_i + c_j \le n } \Pr[C_i = c_i \wedge C_j = c_j] \\
    &= \sum_{c_i \ge k, c_j \ge k, c_i + c_j \le n} \binom{n}{c_i + c_j} \binom{c_i + c_j}{ c_i}  (\frac{1}{n} )^{ c_i } (\frac{1}{n})^{ c_j } (1 - \frac{2}{n} )^{ n - c_i - c_j} 
\end{aligned}
$$

On the other hand, for fix $c_i, c_j$, we have 
$$
\Pr[C_i = c_i ] = \binom{n}{c_i} (\frac{1}{n})^{ c_i }  (1 - \frac{1}{n} )^{ n - c_i} \\
\Pr[C_j = c_j ] = \binom{n}{c_j} (\frac{1}{n})^{ c_j }  (1 - \frac{1}{n} )^{ n - c_j}
$$

We claim that $\Pr[C_i = c_i \wedge C_j = c_j] \le \Pr[C_i = c_i ] \Pr[C_j = c_j ]$, as 

1. $\binom{n}{c_i + c_j} \binom{c_i + c_j}{ c_i}   \le \binom{n}{c_i} \binom{n}{c_j}$
2. Denote $z = n - c_i - c_j$, then 
    $$
    \begin{aligned}
        &(1 - \frac{2}{n} )^z \le (1 - \frac{1}{n} )^{ z + n} \\
        \Longleftrightarrow 
        &(\frac{n - 2}{n - 1})^z \le (\frac{ n - 1}{ n })^n \\
        \Longleftrightarrow 
        &(1 - \frac{1}{n - 1})^z \le (1 - \frac{  1}{ n })^n
    \end{aligned}
    $$ -->

<h4 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h4><p>In the appendix we discuss a rough approximation of $k^k$ for some $k \in \mathcal{Z}_+$. We claim that<br>$$<br>e \cdot \frac{k^k}{e^k} \le k! \le e \sqrt k \cdot \frac{k^k}{e^k}<br>$$</p>
<h5 id="Remark-1"><a href="#Remark-1" class="headerlink" title="Remark 1:"></a>Remark 1:</h5><p>As ($\ln$ here is based on $e$)<br>$$<br>\int_{x = 1}^k \ln x \ dx = x \ln x |<em>{x = 1}^k - \int</em>{x = 1}^k x \ d \ln x = k \ln k - (k - 1)<br>$$</p>
<p>We get</p>
<p>$$<br>\ln k! = \sum_{i = 1}^k \ln i \ge \int_{x = 1}^k \ln x \ dx  = k \ln k - (k - 1)<br>$$</p>
<p>Similarly, </p>
<p>$$<br>\begin{aligned}<br>\ln k!<br>&amp;= \sum_{i = 1}^k \ln i \<br>&amp;= \frac{1}{2} \sum_{i = 1}^{k - 1} [\ln i + \ln (i + 1) ] + \frac{1}{2} \ln k \<br>&amp; \le  \int_{x = 1}^k \ln x \ dx + \frac{1}{2} \ln k \<br>&amp;= (k + \frac{1}{2}) \ln k - (k - 1)<br>\end{aligned}<br>$$</p>
<!-- ##### Remark 2: 
An easier way to prove the lower bound is 

$$
\frac{k^k}{k!} = \frac{k^{k - 1} }{ (k - 1)!} \le \sum_{i = 1}^\infty \frac{(k - 1)^i}{i !} = e^{k - 1} 
$$

We have $e \frac{k^k}{ e^k } \le k!$.  -->

<h5 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h5><ol>
<li>Sanjeev Arora, Cos 521: Advanced Algorithm Design, Lecture 1: Course Intro and Hashing</li>
<li>Sariel Har-Peled, Chapter 4, The Occupancy and Coupon Collector problems.</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/03/31/Sampling-With-Or-Without-Replacement/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/31/Sampling-With-Or-Without-Replacement/" class="post-title-link" itemprop="url">Sampling With Or Without Replacement</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-03-31 22:58:36 / Modified: 23:59:13" itemprop="dateCreated datePublished" datetime="2020-03-31T22:58:36+11:00">2020-03-31</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Suppose that there are $a$ blue balls and $b$ red balls in a box and we would like to sample $k$ balls from them. We can sample the balls with replacement such that after picking each ball we put it back into the box, or we can do it without replacement. </p>
<p>For convenience of discussion, denote $n = a + b$, $p = \frac{a}{n}$ and $q = \frac{b}{n}$. Define $X_i$ ($i \in [k]$) the indicator random variable of whether the $i$-th selected ball is blue. Let<br>$$<br>X = \sum X_i<br>$$</p>
<p>Then we claim that<br>$$<br>E[X] = \sum_{i \in [k]} E[X_i] = kp<br>$$</p>
<p>The first equality holds by linearity of expectation. The second equality states that in expectation, $p$ fraction of the selected balls are blue. </p>
<p>The claim is trivial when we sample with replacement, as $\Pr[X_i = 1] = p$. To prove that the probability applies for the case of sampling without replacement requires a little more effort, as shown by the following </p>
<ol>
<li>There are in total $\begin{pmatrix} n \ k\end{pmatrix}$ possible combinations of choosing $k$ balls out of $n$.</li>
<li>Among them there are $\begin{pmatrix} a \ 1 \end{pmatrix} \cdot \begin{pmatrix} n  - 1 \ k - 1 \end{pmatrix}$ combinations such that the $i$-th ball is blue.</li>
<li>Therefore, $\Pr[X_i = 1] = \frac{ \begin{pmatrix} a \ 1 \end{pmatrix} \cdot \begin{pmatrix} n  - 1 \ k - 1 \end{pmatrix} }{ \begin{pmatrix} n \ k\end{pmatrix} } = \frac{a}{n} = p$.</li>
</ol>
<p>However, the two sampling scheme have different variance. </p>
<h5 id="Variance-of-Sampling-With-Replacement"><a href="#Variance-of-Sampling-With-Replacement" class="headerlink" title="Variance of Sampling With Replacement"></a>Variance of Sampling With Replacement</h5><p>By independence of $X_i$<br>$$<br>Var[X] \doteq \sigma^2 = \sum_{i \in [k]} Var[X_i] = k p q<br>$$</p>
<h5 id="Variance-of-Sampling-Without-Replacement"><a href="#Variance-of-Sampling-Without-Replacement" class="headerlink" title="Variance of Sampling Without Replacement"></a>Variance of Sampling Without Replacement</h5><p>In this case, the $X_i$’s are not independent.<br>$$<br>\begin{aligned}<br>       Var[X]<br>        &amp;= E \left[ X^2 \right] - \left( E[X] \right)^2 \<br>        &amp;= \sum_{i \in [k]} E[X_i^2] + \sum_{i, j \in [k]} E[X_i X_j] - (kp)^2 \<br>        &amp;=  kp + k(k - 1) \frac{ \begin{pmatrix} a \ 2 \end{pmatrix} \cdot \begin{pmatrix} n  - 2 \ k - 2 \end{pmatrix} }{ \begin{pmatrix} n \ k\end{pmatrix} } - (kp)^2 \<br>        &amp;=  kp + k(k - 1) \frac{ a(a-1) }{ n(n - 1) } - (kp)^2 \<br>        &amp;=  kp + kp \frac{ (k - 1) (a-1) }{ (n - 1) } - (kp)^2 \<br>        &amp;=  kp ( 1 + \frac{ (k - 1) (a-1) }{ (n - 1) } - k \frac{a}{ n } ) \<br>        &amp;=  kp \frac{n^2 - n + ka n - kn - an + n - kan + ka }{ n (n - 1) } \<br>        &amp;=  kp \frac{n^2  - kn - an  + ka }{ n(n - 1) } \<br>        &amp;=  kp \frac{(n - a) (n - k)}{ n (n - 1)} \<br>        &amp;=  kpq \frac{n - k}{n - 1} \<br>        &amp;= \sigma^2 \frac{n - k}{n - 1}<br>\end{aligned}<br>$$</p>
<p>We have shown that sampling without replacement has smaller variance than sampling with replacement. Moreover, if $n \succ k$, then $\frac{n - k}{n - 1} \approx 1$ and the two sampling scheme have almost the same variance. We can bound the concentration behavior of $X$ by Chebyshev’s inequality: for any $c &gt; 0$,<br>$$<br>\Pr[ |X - E[X] | \ge c \cdot \sigma] \le \frac{Var[X] }{c^2 \sigma^2} = \frac{1}{c^2}<br>$$ </p>
<p>The $3$-sigma rule says only $X$ deviates more than $3\sigma$ from its expectation with probability at most $11.11%$<br>$$<br>\Pr[ |X - E[X] | \ge 3 \cdot \sigma] \le \frac{Var[X] }{c^2 \sigma^2} = \frac{1}{9} \approx 0.1111<br>$$</p>
<p>It is also interesting to observe that the variance most related to the sample size $k$ and probabilities $p$ and $q$ , but not $n$!</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/03/30/LSH/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/30/LSH/" class="post-title-link" itemprop="url">LSH</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-03-30 16:14:46" itemprop="dateCreated datePublished" datetime="2020-03-30T16:14:46+11:00">2020-03-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-03 22:17:23" itemprop="dateModified" datetime="2020-05-03T22:17:23+10:00">2020-05-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong><em>Given a set $S \subset U$ of $n$ points, a metric $d$ defined on $U$, and a query point $v$, the nearest neighbor search (NNS) problem finds $v$’s nearest point in $S$:</em></strong><br>$$<br>u = \arg\min_{s \in S} d(v, s)<br>$$<br>Potential applications include web search and clustering.</p>
<p>If $U$ is a Euclidean space $\mathcal{R}^d$ for some $d$, the hardness of NNS depends largely on the value of $d$. Suppose $d = 1$, then we can pre-process the points by building a balanced binary search tree on $S$. Finding the nearest point to $v \notin S$ reduces to searching for its predecessor and successor, which takes $O(\log n)$ time. For $d = 2$, we can construct a Voronoi diagram.</p>
<p>For higher dimensions $d$ it is not easy to extend the index structures. A naïve search loops over all points and takes $O(nd)$ time. It is natural to ask whether we can do better. If we are willing to sacrifice accuracy for efficiency, this is possible. Instead of finding the exact nearest neighbor, we relax our goal to finding an approximate nearest neighbor whose distance is within $1 + \epsilon$ of the minimum one. </p>
<p>One possible solution is  Johnson–Lindenstrauss decomposition. We can generate a matrix $A \in R^{ O( \frac{ \log n }{ \epsilon^2 } )\times d}$ and multiply it with every element in $S$. The mapping $u \rightarrow Au$ preserves pair-wise distance up to a relative error of $\epsilon$. The pre-processing takes $O( \frac{n d \log n}{\epsilon^2} )$ time.  To answer an query, we map $v$ to $Av$, which takes $O(\frac{ d\log n }{ \epsilon^2 } )$ time. Then we perform a loop over all elements of ${ Au : u \in S}$, which takes $O(\frac{ n \log n }{ \epsilon^2 } )$ time. Therefore, the total time complexity is $O(\frac{ (n + d) \log n }{ \epsilon^2 } )$. </p>
<h3 id="Hashing"><a href="#Hashing" class="headerlink" title="Hashing"></a>Hashing</h3><p>[1] solves the problem by hashing. We call the pair of points that are close to each other the <em>similar pair</em> and the pair that are far from each other the <em>dissimilar pair</em>. Intuitively, we want similar pairs to be hashed to the same bucket and that dissimilar pairs to be hashed to different buckets. </p>
<p>Instead of finding the $(1 + \epsilon)$ approximate nearest neighbor directly, [1] further reduces it to the $(c, r)$-approximate neighbor search (ANNS$(c, r)$) problem, which is defined as follows:</p>
<p><strong><em>Given a query point $v$, if $\exists s \in S$, then return a point $u$, such that</em></strong><br>$$<br>d(v, u) \le c \cdot r<br>$$</p>
<p>The reduction from $1 + \epsilon$ to ANNS($c, r$) is not easy. Here we show one that returns the $(1 + \epsilon)^2$ approximate nearest neighbor. Let $d_{\max} = \max_{s, s’} d(s, s’)$ and $d_{\min} = \min_{s, s’} d(s, s’)$. We build a set of structures that answers ANNS($1 + \epsilon$, r) queries for the values of $r$:<br>$$<br>d_{\min}, \ d_{\min} (1 + \epsilon ), \ d_{min} (1 + \epsilon)^2,\ …,\ d_{\max}<br>$$</p>
<p>Then given the query point $v$, we do a binary search to find the smallest $r$ that returns a point. This imposes an additional cost of $\ln {\ln \frac{d_{\max} }{d_{\min} } \over \ln (1 + \epsilon) }$.</p>
<p>||<br>|:-:|<br>| $\text{NNS} \longrightarrow (1+\epsilon) \text{NNS} \longrightarrow \text{ANNS}(c, r) \longrightarrow (r, cr, p_1, p_2)\text{-LSH} \longrightarrow \text{Boosting Probability}$                   |<br>| The Problem Reduction Chain   |<br>||</p>
<h3 id="r-cr-p-1-p-2-Locality-Sensitive-Hashing-Family"><a href="#r-cr-p-1-p-2-Locality-Sensitive-Hashing-Family" class="headerlink" title="$(r, cr, p_1, p_2)$-Locality Sensitive Hashing Family"></a>$(r, cr, p_1, p_2)$-Locality Sensitive Hashing Family</h3><p>Now we show how to solve the ANNS$(c, r)$ problem with hashing. Designing a perfecting hashing that solves the problem directly is not easy. It is desirable to have some hashing which successes with some probability and then boost its probability systematically. To achieve this, we introduce the idea of $(r, cr, p_1, p_2)$-locality sensitive hashing family.</p>
<p><strong><em>Given a set of point $V$, a metric $d(\cdot , \cdot)$ defined on $V$, a collection of hash function $\mathcal{H} = { h: V \rightarrow Z}$ is called $(r, cr, p_1, p_2)$ locality sensitive  if for any $v, u \in V$ and an $h$ sampled uniformly from $\mathcal{H}$, it holds that</em></strong></p>
<ol>
<li>If $d(v, u) &lt; r$, then $\Pr_{h \in \mathcal{H} } [h(v) = h(u)] \ge p_1$.</li>
<li>If $d(v, u) \ge cr$, then $\Pr_{h \in \mathcal{H} } [h(v) = h(u)] \le p_2$</li>
</ol>
<p>where $p_2 &lt; p_1 \le 1$. Intuitively, pairs near to each other should be more likely to collide. Hence $p_1 = p_2^{\rho}$ for some $\rho = \log p_1 / \log p_2 &lt; 1$.</p>
<p>Ideally, we have $p_1 \approx 1$ and $p_2 \approx 0$. For other cases we can magnify the gap between $p_1$ and $p_2$ and boost $p_1$ to approximate $1$ and $p_2$ to approximate $0$. The hardness of the boosting highly depends on the value of $c$.</p>
<h4 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h4><p>Suppose that $U = {0, 1}^d$, $d(u, v) = u \oplus v = |u - v|<em>1$ and $\mathcal{H} = { h_i (u) = u_i }</em>{i \in [d]}$, where $h_i$ selects the $i$th bit of $u$. Picking an $h$ uniformly from $\mathcal{H}$ and applying $h$ to $u$ is equivalent to selecting a bit uniformly from $u$. Therefore,</p>
<ol>
<li>If $d(v, u) &lt; r$ ($u$ and $v$ has less then $r$ common bits), then $\Pr_{h \in \mathcal{H} } [h(v) = h(u)] \ge \frac{d - r}{d} = 1 - \frac{r}{d} =  p_1$.</li>
<li>If $d(v, u) \ge cr$, then $\Pr_{h \in \mathcal{H} } [h(v) = h(u)] \le \frac{d - cr}{d} = 1 - \frac{cr}{d} =  p_2$</li>
</ol>
<p>Now $p_1 \approx \exp(- r / d)$ and $p_2 \approx \exp(- cr / d)$. Hence $\rho \approx \frac{1}{c}$. Indeed it can be proven rigorously that<br>$$<br>\rho = \frac{\ln (1 - \frac{r}{d}) }{ \ln (1 - \frac{cr}{d}) } \le \frac{1}{c}<br>$$</p>
<p>as $( 1 - \frac{r}{d})^c \ge 1 - \frac{cr}{d}$. There are many ways to prove this. Since we are dealing with probability, we give a probabilistic interpretation of this inequality. Suppose that are $c$ independent events each happening with probability $\frac{r}{d}$. Then the probability that at least one of them happens is given by<br>$$<br>1 - \Pr[\textbf{none of them happens } ] = 1 - (1 - \frac{r}{d})^c<br>$$</p>
<p>On the other hand, by union bound, this is upper bounded by $\frac{cr}{d}$.</p>
<h3 id="Boosting-the-Probabilities"><a href="#Boosting-the-Probabilities" class="headerlink" title="Boosting the Probabilities"></a>Boosting the Probabilities</h3><p>We would like the boost the probability such that $p_1 \approx 1$ and $p_2 \approx 0$. We follow a two-step approach. First we sample $k$ (to be determined) hash functions independently from $\mathcal{H}$ can concatenate them as a single hash function $g$:<br>$$<br>g(v) = [h_1(v),  h_2(v), … ,h_k(v)]<br>$$</p>
<p>Here $g$ hash a point $v$ to a $k$ dimensional vector. After this,  $g(v) = g(u)$ happens only if $h_i(v) = h_i(u)$ for all $i \in [k]$. By independence of $h_i$’s, </p>
<ol>
<li><p>If $d(v, u) \ge cr$, the collision probability of $u$ with $v$ drops to $p_2^k$:<br> $$<br> \Pr [ g(v) = g(u) ] \le p_2^k<br> $$</p>
</li>
<li><p>On the other hand, if $d(v, u) &lt; r$, the collision probability also drops to $p_1^k = (p_2^k)^\rho$<br> $$<br> \Pr [ g(v) = g(u) ] \ge  p_1^k = p_2^{\rho k} = (p_2^{k})^\rho<br> $$<br> which is relatively small and not desirable.</p>
</li>
</ol>
<p>We need a second level of boosting to increase the collision probability of similar pairs. Instead of using only one function $g$, we use a collection of independent copies:<br>$$<br>g_1, g_2, …, g_l<br>$$</p>
<p>where $l$ is the number to be determined. Now, </p>
<ul>
<li>If $d(v, u) &lt; r$, the probability that at least one of the $g_i(u)$ equals to $g_i(v)$ is given by<br>  $$<br>  \begin{aligned}<pre><code>  \Pr \left[ \exists i \in [l], \ s.t., \ g_i(u) = g_i(v) \right] 
      &amp;= 1 - (1 - p_1^k)^l  \\
      &amp;= 1 - (1 - (p_2^k)^\rho)^l \\
      &amp;\ge 1 - \exp( - (p_2^k)^\rho l )
</code></pre>
  \end{aligned}<br>  $$</li>
</ul>
<p>We can take   </p>
<ol>
<li><p>$p_2^k = \frac{1}{n}$, i.e., $k = \frac{\log n }{ \log 1 / p_2 }$.</p>
</li>
<li><p>$\exp( - (p_2^k)^\rho l ) = \frac{1}{n}$, i.e., $l = \frac{1}{(p_2^k)^\rho } \ln n = n^\rho \ln n$.</p>
</li>
</ol>
<p>For a fixed query point $q$ and for any fixed $i \in [l]$,  by linearity of expectation,  the expected number of dissimilar collision is given by</p>
<p>$$<br>\begin{aligned}<br>    E \left[ |{ u \in S: d(q, u) \ge cr \wedge g_i(q) = g_i(u)  }| \right]<br>        &amp;= \sum_{ u \in S : \  d(q, u) \ge cr } \Pr[g_i(v)= g_i(u)] \<br>        &amp;\le n \cdot \frac{1}{n} = 1<br>\end{aligned}<br>$$</p>
<p>Therefore, there are $l$ of dissimilar collisions over all $i \in [l]$. This implies an expected overhead of $l$ examinations of dissimilar points. However, by Markov inequality, the number of such points is less than $2l$ with probability at least $1 / 2$. The time for examination of dissimilar point is  $O(ld) = O(d n^\rho \ln n)$.</p>
<h3 id="Time-and-Space"><a href="#Time-and-Space" class="headerlink" title="Time and Space"></a>Time and Space</h3><p>Now, given a query point $q$, computing $g_i(q)$ for a fixed $i$ takes $O(k)$ time. Computing $l$ of them takes $O(kl)$ time. In expectation, there are $l$ dissimilar collision points with $q$. Checking one collision point takes $O(d)$ time. Therefore, the expected query time is given by (note that we stop upon finding the first ANN of $q$):</p>
<p>$$<br>\begin{aligned}<br>    O(kl + dl)<br>    &amp;= O(\frac{\ln n}{\ln \frac{1}{p_2}} n^\rho \ln n + d n^\rho \ln n) \<br>    &amp;= O(n^{ \rho} \ln^2 n / \ln \frac{1}{p_2} + d n^\rho \ln n) \<br>    &amp;= \tilde{O}( n^\rho )<br>\end{aligned}<br>$$</p>
<p>As for the space usage, for each point $u$ in $S$, we need to compute $g_i(u)$ and store this value (we need to store this, because $g_i(u)$ is self could be a large number and when putting ${ g_i(u) : u \in S}$ into a hash table, we need to treat $g_i(u)$ as the key and store it for later collision comparison. But is it possible that when there is a collision, we re-compute this value again to avoid storing it ?). We need to repeat this for $l$ hash functions. Therefore, the space usage is given by<br>$$<br>O(nkl) = O(n^{1 + \rho} \ln^2 n / \ln \frac{1}{p_2})<br>$$</p>
<h3 id="Another-Boosting-Scheme"><a href="#Another-Boosting-Scheme" class="headerlink" title="Another Boosting Scheme"></a>Another Boosting Scheme</h3><p>In last section, we have a scheme that checks $O(n^\rho \ln n)$ dissimilar points in expectation. In this section we achieve it with high probability. </p>
<ol>
<li>First, to reduce the collision probability of dis-similar pairs, we concatenate $k$ functions from $\mathcal{H}$. This gives a<br>$$<pre><code> (r, cr, p_1^k, p_2^k)
</code></pre>
$$<br>locative sensitive hash function. We determine the value of $k$ later. <!-- We pick $k = \frac{\ln n}{\ln \frac{1}{p_2} }$, such that $p_2^k = 1 / n$. In expectation, at most $1$ dis-similar collision occurs.  --></li>
<li>Second, to boost the collision probability of similar pairs, we use $l$ concatenated hash functions independently. The probability at least one collision occurs is given by<br>$$<pre><code> 1 - (1 - p_1^k)^l \ge 1 - e^&#123;-p_1^k \cdot l&#125; 
</code></pre>
$$<br>We require this to happen with constant probability $1 - \frac{1}{e}$, hence we need to set $l = \frac{1}{p_1^k} = (\frac{1}{p_2^k})^\rho$.<!-- where $l = n^\rho$. The final equality holds since $p_1^k \cdot l = p_2^{k \cdot \rho} \cdot l = n^{-\rho} \cdot l = 1$ --></li>
<li>Now consider a query point $q$. We compute $g_1(q), g_2(q), …, g_l(q)$ and check the points $u$’s such that $g_i(u) = g_i(q)$ for some $i \in [l]$. Note that we check at most the first $4 n p_2^k l + 1$ points we found. Why $4 n p_2^k l + 1$? In expectation, there are $n p_2^k l$ dissimilar collisions. By Markov inequality, the probability of dissimilar collisions is no more than $4l$ is at most $1 / 4$. By union bound,<br> $$<br> \begin{aligned}<pre><code> &amp;\Pr[\exists \text&#123; more than &#125; 4l \text&#123; bad collision &#125; \vee \nexists \text&#123; good collision &#125;] \\
 &amp;\le \frac&#123;1&#125;&#123;e&#125; + \frac&#123;1&#125;&#123;4&#125; \\
 &amp;\le \frac&#123;1&#125;&#123;2.5&#125; + \frac&#123;1&#125;&#123;4&#125; \\
 &amp;= \frac&#123;5&#125;&#123;16&#125;
</code></pre>
 \end{aligned}<br> $$</li>
</ol>
<p>Therefore, the boosting strategy successes with constant probability. Now consider the running time of such boosting strategy. When a query point $q$ comes, we need to compute $g_1(q), g_2(q), …, g_l(q)$, which takes time $kl$. Further, the strategy checks at most $4 n p_2^k l + 1$ points and checking each point takes $O(d)$ time. The overall time used is<br>$$<br>O(kl + (4 n p_2^k l + 1)d)<br>$$</p>
<p>To minimize the running time, we need to choose proper value of $k$, such that<br>$$<br>k = 4np_2^k d \rightarrow \ln k + k \ln \frac{1}{p_2} = \ln (4nd)<br>$$</p>
<p>It suffice to take $k = \frac{\ln 4nd}{ \ln \frac{1}{p_2} }$. It follows that<br>$$<br>p_2^k = \frac{1}{4nd} \<br>l = \left( \frac{1}{p_2^k} \right)^\rho = (4nd)^\rho<br>$$</p>
<p>and the running time is given by<br>$$<br>O\left( (4nd)^\rho \frac{\ln (4nd)}{\ln \frac{1}{p_2} } \right)<br>$$</p>
<p>As $n \succ d$, this is equivalent to<br>$$<br>O\left( (4nd)^\rho \frac{\ln n}{\ln \frac{1}{p_2} } \right)<br>$$</p>
<p>We can repeat the above steps by $\ln n / \ln \frac{16}{5}$ times, to boost the success probability to $1 - \frac{1}{n}$. The overall running time is given by<br>$$<br>O\left( (4nd)^\rho \frac{\ln^2 n}{\ln \frac{1}{p_2} } \right)<br>$$</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol>
<li>Indyk, P. and Motwani, R., 1998, May. Approximate nearest neighbors: towards removing the curse of dimensionality. In Proceedings of the thirtieth annual ACM symposium on Theory of computing (pp. 604-613).</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/03/23/Working-Set-BST/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/23/Working-Set-BST/" class="post-title-link" itemprop="url">Working Set BST</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-03-23 23:59:24" itemprop="dateCreated datePublished" datetime="2020-03-23T23:59:24+11:00">2020-03-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-03-29 22:14:08" itemprop="dateModified" datetime="2020-03-29T22:14:08+11:00">2020-03-29</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Various implementations of Balanced Binary Search Tree (BST) guaranteed membership queries in $O(\log n)$ time, where $n$ is the number of elements in some set $S$. The working set property is a stronger requirement than $O(\log n)$ time complexity. Suppose that an item $x \in S$ is accessed $t$ queries before, then we want to perform $\text{find} (x)$ in $O(\log t)$ time. </p>
<p> <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/WorkingSetBSForest.jpg"></p>
<p>The idea is to maintain a sequence of Balanced BST’s, denoted as $T_0, T_1, T_2, …$. Denote the size of $T_i$ for some $i \ge  0$ as $n_i$. Then the $i$-th tree maintains the latest $n_i$ accessed items. The sizes of $n_i$’s satisfy</p>
<p>$$<br>\begin{aligned}<br>    &amp;   n_0 = 1 \<br>    &amp;   n_1 = 2 \<br>    &amp;   n_2 = 4 \<br>    &amp;   n_3 = 16 \<br>    &amp;   …     \<br>    &amp;   n_i = 2^{2^{i - 1} }  \<br>    &amp;   n_{i + 1} = n_i^2 = 2^{2^i } \<br>    &amp;   … \<br>    &amp;   n_k = 2^{2^{k - 1} }<br>\end{aligned}<br>$$</p>
<p>The largest tree has an index that equals to the smallest $k$ with $2^{k - 1} \ge \log n$ (assuming that $n \ge 1$). It implies that $k = O (\log \log n)$. The complexities for searching an element on these trees are<br>$$<br>\begin{aligned}<br>    &amp;   c_0 = 1 + \log 1    \<br>    &amp;   c_1 = 1 + \log 2    \<br>    &amp;   c_2 = 1 + \log 4    \<br>    &amp;   c_3 = 1 + \log 16   \<br>    &amp;   …     \<br>    &amp;   c_k = 1 + \log 2^{2^{k - 1}}\<br>\end{aligned}<br>$$</p>
<p>When a query $\text{find} (x)$ is invoked, we first search it on $T_0$. If we find it successfully, we stop. Otherwise we search it on $T_1$ and so on. If $x$ is accessed $t$ queries before (and is not accessed in the latest $t - 1$ queries if $t \ge 1$), then it is contained in the tree $T_{i_x}$, where<br>$$<br>i_x \doteq \text{ the smallest non-negative integer, } s.t. \ 2^{i_x - 1} \ge t<br>$$</p>
<p>As a sanity check, note that when $t = 0$ ($x$ is the latest accessed item), we have $i_x = 0$ as $2^{-1} \ge 0$. By definition of definition of $i_x$, $x$ is not contained in any $T_i$ with $i &lt; i_x$. The time to search $x$ is<br>$$<br>\begin{aligned}<br>    &amp;(1 + \log 1) + (1 + \log 2) + (1 + \log 4) + (1 + \log 16) + … + (1 + \log 2^{2^{i_x - 1} }) \<br>    &amp;=i_x + 1  + \sum_{i = 0}^{i_x - 1} 2^{i} \<br>    &amp;=i_x + 1  + 2^{i_x} - 1 \<br>    &amp;=O(\log \log t) + O(\log t) \<br>    &amp;=O(\log t)<br>\end{aligned}<br>$$</p>
<p>Finally, we need to update the trees $T_0$, $T_1$, … $T_{i_x}$ to reflect the last access of $x$. In particular, we 1) insert $x$ into $T_0$, $T_1$, … $T_{i_x - 1}$; 2) for each $i &lt; i_x$, we delete the least recently accessed item; 3) update the access time of $x$ in $T_{i_x}$. </p>
<p>Step 1) takes $O(\log t)$ time. To implement steps 2) and 3) in $O(\log t)$ time, we create a min-heap $H_i$ for each tree $T_i$ that keeps the the access time of items in $T_i$. Both fetching least recently accessed item and updating access time can be performed in $O(\log n_i)$ time. Therefore, steps 2) and 3) take $O(\log t)$ time in total. </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/03/09/Hessian/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/09/Hessian/" class="post-title-link" itemprop="url">Hessian</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-03-09 13:18:20 / Modified: 14:09:55" itemprop="dateCreated datePublished" datetime="2020-03-09T13:18:20+11:00">2020-03-09</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><em>Theorem.</em> A twice continuous differentiable function $f:\mathbb{ R } ^n \mathbb{ R } ightarrow \mathbb{ R } $ is convex if and only if $\nabla^2 f(x) \succeq 0$ for $x \in \mathbb{ R } ^n$. </p>
<p><em>Proof.</em> We use that fact that $f$ is convex iff $f(y) \ge f(x) + \nabla f(x)^T (y - x)$ for all $y, x \in \mathbb{ R } ^n$. </p>
<ol>
<li><p><em>If:</em> For $x, y \in \mathbb{ R } ^n$, exists $z = \lambda x + (1 - \lambda) y$, where $\lambda \in [0, 1]$, such that (by Taylor series expansion and Lagrange reminder)<br>$$<br>\begin{aligned}<br> f(y) </p>
<pre><code> &amp;= f(x) + \nabla f(x)^T (y - x) + \frac&#123;1&#125;&#123;2&#125; (y - x)^T \nabla^2 f(z) (y - x) \\
 &amp;\ge f(x) + \nabla f(x)^T (y - x) 
</code></pre>
<p>\end{aligned}<br>$$</p>
</li>
<li><p><em>Only If:</em> Rearranging the Taylor series we get,<br> $$<br> \begin{aligned}</p>
<pre><code> f(y) - f(x) - \nabla f(x)^T (y - x) 
     &amp;= \frac&#123;1&#125;&#123;2&#125; (y - x)^T \nabla^2 f(z) (y - x) 
</code></pre>
<p> \end{aligned}<br> $$</p>
<p> Which implies that,<br> $$<br> \begin{aligned}</p>
<pre><code> (y - x)^T \nabla^2 f(z) (y - x) \ge 0
</code></pre>
<p> \end{aligned}<br> $$</p>
<p> Since $\nabla^2 f(x)$ is continuous, $\forall \epsilon &gt; 0, \exists \delta &gt; 0$, such that  $\forall z \in \mathbb{B}(x, \delta)$, it holds that<br> $$<br> | \nabla^2 f(z) - \nabla^2 f(x) |_F \le \epsilon^2 / n^4<br> $$</p>
<p> where $| A |_F \doteq Tr(A^TA)$ for $A \in \mathbb{ R } ^{n \times n}$. Note that $| A |<em>F \le \epsilon^2 / n^4$  implies that $A</em>{i,j} \ge -\epsilon / n^2$. </p>
<p> Without lose of generality, suppose that $s \doteq y - x$ is a unit vector. Then $x + \delta s \in \mathbb{B}(x, \delta)$, and $z \in [x, x + \delta s]\subset \mathbb{B}(x, \delta)$ (where $[x, x+ \delta s]$ is the line segment between $x$ and $x + \delta s$). It follows:<br> $$<br> \begin{aligned}</p>
<pre><code> \delta^2 s^T \left(\nabla^2 f(x) - \nabla^2 f(z) \right) s
     &amp;\ge \sum_&#123;i, j&#125; \frac&#123;\epsilon&#125;&#123;n^2&#125; \delta |s_i| \cdot \delta | _j| \\
     &amp;= \delta \frac&#123;\epsilon&#125;&#123;n^2&#125; (|s|)^2
</code></pre>
<p> \end{aligned}<br> $$</p>
<p> where $|s| = \sum_{i \in [n]} |s_i| \le \sqrt n | s |$. Therefore, </p>
<p> $$<br> \begin{aligned}</p>
<pre><code> s^T \left(\nabla^2 f(x) - \nabla^2 f(z)  \right) s
     &amp;\ge -\epsilon \| s \|^2
     = -\epsilon
</code></pre>
<p> \end{aligned}<br> $$</p>
<p> Finally,<br> $$<br> \begin{aligned}</p>
<pre><code> s^T \nabla^2 f(x) s
     &amp;= s^T \nabla^2 f(z) s + s^T \left(\nabla^2 f(x) - \nabla^2 f(z) \right) s \\
     &amp;\ge -\epsilon
</code></pre>
<p> \end{aligned}<br> $$</p>
<p> As $\epsilon$ can be arbitrary small, it hold that $s^T \nabla^T f(x) s \ge 0$. This holds for any $| s | = 1$, it concludes that $\nabla^2 f(x) \succeq 0$.</p>
</li>
</ol>
<p>$\square$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/03/08/Norm-with-PSD-Matrix/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/08/Norm-with-PSD-Matrix/" class="post-title-link" itemprop="url">Norm with PSD Matrix</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-03-08 11:42:32" itemprop="dateCreated datePublished" datetime="2020-03-08T11:42:32+11:00">2020-03-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-03-09 15:28:01" itemprop="dateModified" datetime="2020-03-09T15:28:01+11:00">2020-03-09</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Let $A \in \mathbb{ R } ^{n \times n}$ be positive semi-definite matrix. Then $f (x) \doteq \sqrt {x^T A x}: \mathbb{ R } ^{n \times n} \rightarrow \mathbb{ R }$ is a norm. </p>
<p><em>Proof.</em>  We only check that it satisfies triangle inequality, i.e.,  $\forall x, y \in \mathbb{R}^n$<br>$$<br>\begin{aligned}<br>    f(x + y)<br>        &amp;\le f(x) + f(y)<br>        \<br>    &amp;\longleftrightarrow<br>        \<br>    \sqrt{ (x + y)^T A (x + y)^T }<br>        &amp;\le \sqrt{ x^T A x} + \sqrt{y^T A y}<br>        \<br>    &amp;\longleftrightarrow<br>        \<br>    y^T A x<br>        &amp;\le \sqrt{ x^T A x}  \sqrt{y^T A y}<br>\end{aligned}<br>$$<br>Since $A$ is PSD, then $\exists B \in \mathbb{ R } ^{n \times n}$, s.t., $A = B^T B$. Define $\bar y = B y$ and $\bar x = B x$, we need to prove<br>$$<br>\bar y^T \bar x \le | \bar x| \cdot | \bar y |<br>$$<br>But this is just Cauchy-Schwarz inequality.  </p>
<p>$\square$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description">你生之前悠悠千載已逝，未來還會有千年沉寂的期待</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">125</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WOW</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

</body>
</html>
