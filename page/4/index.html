<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
<meta property="og:type" content="website">
<meta property="og:title" content="WOW">
<meta property="og:url" content="http://example.com/page/4/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/4/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>WOW</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">WOW</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/10/28/Minimax-Theorem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/10/28/Minimax-Theorem/" class="post-title-link" itemprop="url">Minimax Theorem</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2019-10-28 18:54:52 / Modified: 20:00:38" itemprop="dateCreated datePublished" datetime="2019-10-28T18:54:52+11:00">2019-10-28</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>A zero-sum game is a game in which a player’s payoff implies the loss of another player. It is specified by a matrix $A \in R^{n \times m}$. The row player can choose from rows ${1, 2, …, n}$ and the column player chooses from columns ${1, 2, …, m}$. The entry $a_{ij}$ of $A$ is the payoff when the row player chooses $i$ and the column player chooses $j$. In such case the column player loses $a_{ij}$. </p>
<p>If one player makes a choice first and the other play follows, then the second player can always respond according the first player choice, to maximize its payoff or minimize its loss. </p>
<p>To make the game more fair, we require the row player to act with strategy $x \in R^n$, i.e., a distribution on the the rows, and the column player to act with strategy $y \in R^m$. At each round, the row player and column player act independently. Then the expected payoff is<br>$$<br>x^TAy<br>$$</p>
<p>But what is some player knows the other’s strategy? In this scenario, the row player choose its strategy $x$ first and the column player responds by a strategy $y$, or vise versa. Note that at each round they still act independently according to their strategies. The question is, whether the order of choosing a strategy implies a difference in the expected payoff.</p>
<p>First we write down what the expected payoff is. If the row player commit to a strategy $x$ first, the column player will choose a distribution $y$ minimize it expected loss:<br>$$<br>\min_y x^T A y<br>$$<br>As $x$ is known, this is equivalent to choosing the column with minimum value:<br>$$<br>\min_{j \in [m]} x^T A e_j<br>$$</p>
<p>Understanding the expected behavior of the column player, the row player should choose a strategy $x$, such that in the worst case, its expected payoff is maximized:<br>$$<br>\max_{x} (\min_y x^T A y) = \max_{x} (\min_{j \in [m]} x^T A e_j)<br>$$</p>
<p>Similarly, if the column player play first, the expected payoff is<br>$$<br> \min_y (\max_{x} x^T A y) = \min_{y} (\max_{i \in [n]} e_i^T A y)<br>$$</p>
<p>The minimax-theorem states that<br>$$<br>\begin{aligned}<br>&amp;\max_{x} (\min_y x^T A y)<br>&amp;= \max_{x} (\min_{j \in [m]} x^T A e_j) \<br>= &amp;\min_y (\max_{x} x^T A y)<br>&amp;= \min_{y} (\max_{i \in [n]} e_i^T A y)<br>\end{aligned}<br>$$</p>
<p>The proof is not difficult, by formulating the two optimizing problems as linear programming, and observing that they are dual to each other. If the row player goes first,<br>$$<br>\begin{aligned}<br>&amp;\max v \<br>&amp;v  -  \sum_{i = 1}^n a_{ij} x_i \le 0  &amp; \forall j \in [m] \<br>&amp;\sum_{i = 1}^n x_i = 1 \<br>&amp;x_i \ge 0 &amp; \forall i \in [n]<br>\end{aligned}<br>$$</p>
<p>To upper bound $v$, we introduce a variable $u \in R$. By noticing $\sum_{j = 1}^m y_j = 1$ and $y_j \ge 0$, we have </p>
<p>$$<br>\begin{aligned}<br>u&amp;\ge \sum_{j = 1}^m y_j (v  -  \sum_{i = 1}^n a_{ij} x_i) + u(\sum_{i = 1}^n x_i) \<br>&amp;= v (\sum_{j = 1}^m y_j) + \sum_{i = 1}^n x_i( u - \sum_{j = 1}^m a_{ij} y_j) \<br>&amp;\ge v<br>\end{aligned}<br>$$</p>
<p>which gives the dual program:<br>$$<br>\begin{aligned}<br>&amp;\min u \<br>&amp;u  -  \sum_{j = 1}^m a_{ij} y_j \ge 0  &amp; \forall i \in [n] \<br>&amp;\sum_{i = 1}^m y_j = 1 \<br>&amp;y_j \ge 0 &amp; \forall j \in [m]<br>\end{aligned}<br>$$</p>
<p>Strong duality tells us that the optimal value of the two program equals. </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/10/08/Balanced-Binary-Search-Tree/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/10/08/Balanced-Binary-Search-Tree/" class="post-title-link" itemprop="url">Balanced Binary Search Tree</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-10-08 11:49:33" itemprop="dateCreated datePublished" datetime="2019-10-08T11:49:33+11:00">2019-10-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-10-11 12:17:57" itemprop="dateModified" datetime="2019-10-11T12:17:57+11:00">2019-10-11</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>It is the depth of the binary search that affects the performance of it. We say that a binary search tree with $n$ nodes is balanced if its depth is of order $O(\log n)$ (hence we can perform find, insert and delete operations in time $O(\log n)$). </p>
<p>If a tree is unbalanced, we can maintain the balance by rotation. Further, we need some criteria to guide the rotation. In what’s follows we discuss some of the popular design of the criteria.</p>
<h4 id="By-the-number-of-elements-of-the-subtree"><a href="#By-the-number-of-elements-of-the-subtree" class="headerlink" title="By the number of elements of the subtree."></a>By the number of elements of the subtree.</h4><p>Denote a note $v$ and its left and right child $v.left$ and $v.right$ respectively. Define the size of $v$ ($s(v)$) the number of elements contained in the subtree rooted at $v$. </p>
<p>A critical observation is that, if for each node $v$ of the tree, the size of each of it subtrees is at most a constant fraction $\big($ denoted as $\epsilon \in (\frac{1}{2}, 1)$;<br>Exercise: why can’t we pick $\epsilon \in [0, \frac{1}{2}] \big)$ of its size, i.e.,<br>$$<br>s(v.left) \le \epsilon s(v) \<br>s(v.right) \le \epsilon s(v)<br>$$<br>then the depth of the tree is in the order of $O(\log n)$. The reason is obvious: let $r = v_0, v_1, v_2, …, v_k$ be any root-to-leaf path of the tree, then<br>$$<br>s(v_1) \le \epsilon s(v_0) \<br>s(v_2) \le \epsilon s(v_1) \<br>…\<br>s(v_k) \le \epsilon s(v_{k - 1})<br>$$<br>it follows that $1 = s(v_k) \le \epsilon^k s(v_0) = \epsilon^k n$ and $k \le \log_\epsilon \frac{1}{n} = O(\log n)$.</p>
<p>Therefore, we can pick arbitrary $\epsilon \in (\frac{1}{2}, 1)$ and maintain this criteria explicitly and recursively. </p>
<p>WLOG, suppose a new element is inserted into the left subtree of a vertex $v$. Denote the new size function $s$ as $s’$ after insertion. If after insertion, $s’(v.left) \le \epsilon s’(v)$, we do nothing and check the balance of $v$’s parent (if there is any). Otherwise, we may try a right rotation on $v$:<br>$$<br>\begin{aligned}<br>&amp;\qquad \qquad v \<br>&amp;/           &amp;\setminus \<br>&amp;v.left      &amp;&amp;v.right \<br>/           &amp;\setminus \<br>v.left.left &amp; \quad v.left.right<br>\end{aligned}<br>$$<br>the subtree transform into:<br>$$<br>\begin{aligned}<br>&amp;\qquad \qquad v.left \<br>&amp;/         &amp;\setminus \<br>v.left.left     &amp;&amp; v\<br>           &amp;&amp;/  &amp;\setminus \<br> &amp;&amp; v.left.right &amp; \quad v.right<br>\end{aligned}<br>$$<br>Since before insertion, $s(v.left) \le \epsilon s(v)$, it holds that $s’(v.left.left) \le \epsilon s’(v.left) = \epsilon (s(v) + 1)$. Therefore, the left subtree no longer violate the balance constraint. However, the constraint could be violated by the right subtree. Since it is possible that<br>$$<br>s’(v.left.right) + s’(v.right) + 1 &gt; \epsilon s’(v.left) = \epsilon (s(v)  + 1)<br>$$<br>For example, suppose that $\epsilon = 0.8$ and $s(v.left.right) = 0.8 s(v.left) = 0.64 s(v)$ and $s(v.right) = 0.2 s(v) - 1$, then<br>$$<br>s(v.left.right) + s(v.right) + 1 = 0.84 s(v)<br>$$<br>The reason is that there is so much weight that $v.left.right$ has. Therefore, we don’t want to rotate it to the right subtree. An alternative is to perform a left rotate on the left subtree first<br>$$<br>\begin{aligned}<br>&amp;\qquad \qquad v \<br>&amp;/           &amp;\setminus \<br>&amp;v.left.right      &amp;&amp;v.right \<br>/           &amp;\setminus \<br>v.left &amp; \quad v.left.right.right \<br>/ \setminus &amp; \<br>v.left.left &amp; \quad v.left.right.left<br>\end{aligned}<br>$$<br>Followed by a right rotation on $v$:<br>$$<br>\begin{aligned}<br>&amp;\qquad \qquad v.left.right  \<br>&amp;/           &amp;\setminus \<br>&amp;v.left     &amp;&amp;v \<br>/ &amp;\setminus   &amp;&amp;/ \setminus\<br>v.left.left &amp;\quad v.left.right.left&amp; \quad v.left.right.right &amp;\quad v.right\<br>\end{aligned}<br>$$</p>
<p>To satisfy the balance requirement, we require that </p>
<ol>
<li>$s’’(v.left.right.left) = s’(v.left.right.left) \le \epsilon s’’(v.left) = \epsilon (s’(v.left) - s’(v.left.right.right) -1 )$.</li>
<li>$s’(v.left.left) \le s’(v.left)$</li>
<li>$s’(v.left.right.right) + s’(v.right) + 1 \le \epsilon<br>s’(v.left.right)$</li>
</ol>
<p>Condition 1 implies that $s’(v.left.right.right)$ can take up too much weight of $s’(v.left)$, which imposes an upper bound on $\epsilon$ by<br>$$<br> (1 - \epsilon) \epsilon s’(v.left) - 1 \le \epsilon (s’(v.left) - \epsilon^2s’(v.left) - 1)<br>$$</p>
<h4 id="By-the-height-of-the-subtree-AVL-Tree"><a href="#By-the-height-of-the-subtree-AVL-Tree" class="headerlink" title="By the height of the subtree (AVL Tree)"></a>By the height of the subtree (AVL Tree)</h4>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/09/18/Divided-by-Three/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/18/Divided-by-Three/" class="post-title-link" itemprop="url">Divided by Three</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-18 21:51:17" itemprop="dateCreated datePublished" datetime="2019-09-18T21:51:17+10:00">2019-09-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-09-22 11:44:19" itemprop="dateModified" datetime="2019-09-22T11:44:19+10:00">2019-09-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Given a number $x = (x_1x_2x_3…x_n)_{10}$ in decimal form, what is reminder divided by 3. </p>
<p>Note that for any positive integer $k$,<br>$$<br>10^k \equiv 1^k \equiv 1 \mod 3<br>$$</p>
<p>Therefore,<br>$$<br>x = x_1 10^{n - 1} + x_2 10^{n - 2} + … + x^n \equiv x_1 + x_2 + … + x_n \mod 3<br>$$</p>
<p>$\square$.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/09/03/Primality-Test/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/03/Primality-Test/" class="post-title-link" itemprop="url">Primality Test</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-03 17:15:48" itemprop="dateCreated datePublished" datetime="2019-09-03T17:15:48+10:00">2019-09-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-02 19:56:55" itemprop="dateModified" datetime="2019-12-02T19:56:55+11:00">2019-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Although there is no polynomial algorithm for computing the prime decomposition of an integer, testing primality can be done in polynomial time. The central idea of is to find a certificate that we can verify in polynomial time for the compositeness of an integer.</p>
<p>We begin with Fermat’s Test, which gives false positive but works for most cases. It relies on the Fermat’s Little Theorem and Lagrange Theorem.</p>
<h3 id="Fermat’s-Little-theorem"><a href="#Fermat’s-Little-theorem" class="headerlink" title="Fermat’s Little theorem."></a>Fermat’s Little theorem.</h3><p>If $n$ is a prime number, then for any $x \in [n - 1]$, we have<br>$$<br>x^{n - 1} \equiv 1 \mod n<br>$$</p>
<p>where throughout the article we use $[n - 1]$ to denote the integer set ${1, 2, …, n - 1}$.</p>
<p><strong>Proof:</strong> Consider the set of numbers $\langle x, 2x, 3x, …, (n - 1)x \rangle$. Note that all numbers are different in terms of $\mod n$. Otherwise $ix \equiv jx \mod n$ implies that $(i - j) x \equiv 0 \mod n$. But $i \neq j$ and $x \neq 0$ concludes that $n$ in not prime, a contradiction. $\blacksquare$</p>
<h4 id="Lagrange-Theorem"><a href="#Lagrange-Theorem" class="headerlink" title="Lagrange Theorem"></a>Lagrange Theorem</h4><p>If $Z$ is a finite group and $S$ is a subgroup of $Z$, then the size of $S$ divides that of $Z$, i.e., $|S| \equiv 0 \mod |Z|$. </p>
<p><strong>Proof</strong>: Order the elements in $Z$ as $z_1, z_2, … z_n$. Consider the sets defined by<br>$$<br>z_i S \doteq { z \in S, s.t., z = z_i \cdot s, where \quad  s \in S}<br>$$<br>We claim $|z_i S| = |S|$. This is true as for $x \in S, y \in S$ and $x \neq y$, we have $z_i x \neq z_i y$. </p>
<p>Now we have the collection of sets $z_1 S, z_2 S, …, z_n S$. We remove duplicates among them and keep only one copy of each set. Suppose $m$ sets are left and reorder them as $S_1, S_2, …, S_m$, then they constitute a partition of $Z$. </p>
<ol>
<li>Clearly $S_1 \cup S_2 \cup … \cup S_m = Z$. </li>
<li>Moreover, $S_i \cap S_j = \emptyset$. for $i \neq j$. Otherwise, let $x \in S_i \cap S_j$. By definition of $S_i$ and $S_j$, there exists $z’ \in Z$ and $z’’ \in Z$, such that $S_i = z’ S$ and $S_j = z’’ S$. Then $x = z’ x = z’’ y$ for some $x, y \in S$. It follows that $z’ = z’’ y x^{-1} \in z’’ S$ and $S_i = S_j$, contradiction the construction of $S_i$ and $S_j$. </li>
</ol>
<p>$\blacksquare$</p>
<p>Before proceeding to the algorithm, we introduce a lemma. </p>
<h4 id="Lemma"><a href="#Lemma" class="headerlink" title="Lemma"></a>Lemma</h4><p>Given two positive integers $n$ and $m$, if $gcd(n, m) = k$, then $\exists a, b \in Z$, s.t., $an + bm = k$. </p>
<p><strong>Proof.</strong>. Consider the set $E = { an + bm, a, b\in Z}$ and define $c = \min_{e \in E \wedge e &gt; 0} e$. Note that $c$ is well-defined – since both $n$ and $m$ are positive, there are positive integers in $E$. Further, it holds that $c \le n (a = 1, b = 0)$ and $c \le m (a = 0, b = 1)$. </p>
<p>We claim that $c \equiv 0 \mod n$ and $c \equiv 0 \mod m$. WLOG, we prove only the former case. Suppose it is not, let $y \equiv c \mod n$. There exists integers $x$ s.t., $cx + y = n$ . But now it follows that $y = n - xc \in E$, contradicting the definition of $c$. </p>
<p>Now $c$ is common divisor of $n$ and $m$. It is also the greatest one, since every divisor of $n$ and $m$ divides any element in $E$. </p>
<p>$\blacksquare$</p>
<h3 id="Algorithm-Fermat’s-Test"><a href="#Algorithm-Fermat’s-Test" class="headerlink" title="Algorithm :  Fermat’s Test."></a>Algorithm :  Fermat’s Test.</h3><p>The algorithm is relatively easy and shown as follows.</p>
<ol>
<li>Input: an integer $n$.</li>
<li>Output: whether $n$ is a prime number. </li>
<li>Take a number of $x \in [n - 1]$ uniformly at random. </li>
<li>Check whether $x^{n - 1} \equiv 1 \mod n$. If not, output “NO”. </li>
<li>Repeat steps $3, 4$ a specified number of times. </li>
<li>Output “YES”. </li>
</ol>
<p>Now we analyze the algorithm. Given $n$, denote $Z_n^* = { x \in [n - 1] \wedge  gcd(x, n) = 1 }$, i.e., the set of numbers in $[n - 1]$ that are coprime to $n$. Note that $Z_n^*$ is a group under multiplication: </p>
<ul>
<li>$1 \in Z_n^*$.</li>
<li>If $x \in Z_n^*$, then $\exists a, b \in Z$,  s.t., $ax + bn = 1$ by definition of $Z_n^*$. Hence $(a \mod n ) \in Z_n^*$ and $x^{-1} = (a \mod n )$. </li>
<li>If $x, y \in Z_n^*$, then $gcd(xy, n) = 1$, therefore $xy \in Z_n^*$.</li>
<li>Clearly multiplication is associative. </li>
</ul>
<p>On the other hand, consider the set of integers that satisfies Fermat’s Little Theorem: $S = { x \in [n - 1] \wedge x^{n - 1} \equiv 1 \mod n }$. Clearly $S$ is a subset of $Z_n^*$, since elements in $S$ are invertible module $n$. Besides, $S$ is itself a group:</p>
<ul>
<li>$1 \in S$.</li>
<li>If $x \in S$, then $x^{(n - 2)(n - 1)} \equiv x^{(n - 1)(n - 2)} \equiv 1 \mod n$. It holds that $x^{n - 2} \in S$ and $x^{-1} = x^{n - 2}$. (The other way to see this is that $1 \equiv x x^{-1} \equiv x^{n - 1} x^{- (n - 1)} \equiv x^{- (n - 1)}$, hence $x^{-1} \in S$.)</li>
<li>Clearly multiplication is associative. </li>
<li>If $x, y \in S$, then $(xy)^{n - 1} \equiv x^{n - 1} y^{n - 1} \equiv 1 \mod n$. </li>
</ul>
<p>Therefore, $S$ is a subgroup of $Z_n^*$. As $Z_n^*$ is finite, by <em>Lagrange’s Theorem</em>, </p>
<p>$$<br>|Z_n^*| \text{ is a multiple of } |S|<br>$$</p>
<p>If there is an element $x \in Z_n^*$ but $x \notin S$, then $|Z_n^*| \ge 2 |S|$ and step $3, 4$ successfully reports “NO” with probability at least a half. </p>
<p>However relative rare, systematic error exists. There are numbers such that all numbers coprime to them satisfy Fermat’s Little Theorem, i.e., $|Z_n^*| = |S|$. The smallest one, 561, was found by Carmichael in 1910 and such number are called Carmichael numbers. This motivates the invention of the Rabin/Miller test. The heart lies on finding a pseudo square root of $1$. </p>
<h5 id="Theorem"><a href="#Theorem" class="headerlink" title="Theorem"></a>Theorem</h5><p>If $n$ is prime and $x^2 \equiv 1 \mod n$,  then $x = \pm 1 \mod n$, where $-1 \mod n$  is defined as $n - 1$. </p>
<p>Proof: $x^2 \equiv 1 \mod n$ implies $(x - 1)(x  + 1) \equiv 0 \mod n$. As $n$ is a prime, $x - 1 \equiv 0 \mod n$ or  $x + 1 \equiv 0 \mod n$. $\blacksquare$</p>
<p>Observe that when $n &gt; 2$, $n - 1 \neq 1$. </p>
<h3 id="Algorithm-2-Rabin-Miller-Test"><a href="#Algorithm-2-Rabin-Miller-Test" class="headerlink" title="Algorithm 2: Rabin Miller Test"></a>Algorithm 2: Rabin Miller Test</h3><ol>
<li><p>Input: an integer $n$.</p>
</li>
<li><p>Output: whether $n$ is a prime number. </p>
</li>
<li><p>If $n \neq 2$ and $n$ is even, output “NO”. </p>
</li>
<li><p>If $n$ is the power of some integer, output “NO”. </p>
</li>
<li><p>Find the maximum integer $k$, such that $n - 1 = 2^k m$ for some odd number $m$. </p>
</li>
<li><p>Take a number of $x \in [n - 1]$ uniformly at random. </p>
</li>
<li><p>Check whether $x^{n - 1} \equiv 1 \mod n$. If not, output “NO”.  [Now Fermat’s Test Is Passed. Need Further Verification.]</p>
</li>
<li><p>Otherwise, compute the certificate<br>$$<br>C = (x^m, x^{2m}, x^{4m}, …, x^{2^{k - 1}m}, x^{2^km})<br>$$<br>We must have $x^{2^km} \equiv 1$ since it passes Fermat’s test. We check whether $\exists i$, such that $x^{2^i m} \neq \pm 1$ but $x^{2^{i + 1} m} = 1$. If so, we find a pseudo square root of unity and output “NO”. </p>
</li>
<li><p>Repeat steps $6 - 8$ a specified number of times. </p>
</li>
<li><p>Output “YES”. </p>
</li>
</ol>
<p>We claim that line 4 runs in polynomial time. If $n$ is the power of some integer, the smallest integer is $2$, which gives the power value $\log n$. Therefore we need only to check for each integer $i \in [\log n]$ whether it holds that $n^{1/i}$ is a integer, which can be computed in polynomial time. </p>
<p>Now we prove the main theorem. </p>
<p><strong>Theorem</strong>: If $n$ is composite, then the algorithm output “YES” with probability at least $1/2$.</p>
<p>Proof: we call $x \in [n - 1]$ a Rabin Miller witness, if $n$ is a composite and the algorithm outputs “YES” when choosing $x$. Otherwise we call $x$ a Rabin Miller non-witness. Such $x$’s satisfies<br>$$<br>    x^m \equiv 1 \text{ or } x^{2^i m} \equiv -1 \mod n \text{ for } 0 \le i &lt; k<br>$$</p>
<p>We are going to construct a proper subgroup $S \subset Z_n^*$, such that all Rabin Miller non-witness belong to $S$. Then by Lagrange Theorem, it holds that<br>$$<br>|{ \text{Rabin Miller non-witness} } | \le |S| \le \frac{1}{2} |Z_n^*| \le \frac{n}{2}<br>$$</p>
<p>The construction considers the collection of subsets:<br>$$<br>S_r = { x \in [n -  1] : x^r \equiv \pm 1 \mod n }<br>$$<br>for $r = m, 2m, 4m, …, 2^k m$. Define<br>$$<br>S = \max_r S_r, s.t., \exists x \in S_r: x^r \equiv -1 \mod n<br>$$<br>In other words, $S$ is defined to be the set $S_r$ that contains an element whose $r$-th power equals to $-1$ for the largest $r$. Such $S$ must exists since $-1 \in S_m$. $S$ has two important properties: </p>
<ol>
<li>All Rabin Miller non-witness belongs to $S$. </li>
<li>$S$ is subgroup of $Z_n^*$.</li>
<li>$\exists y \in Z_n^*$, s.t., $y \notin S$, i.e., $S \neq Z_n^*$</li>
</ol>
<p>Property (1) is obvious by the definition of Rabin Miller non-witness. To show (2), we need to verify $S$ is close under multiplication,  each element in $S$  belongs to $Z_n^*$ and is invertible in $S$: </p>
<ul>
<li>If $x \in S, y \in S$, then $(xy)^r \pm x^r y^r \equiv \pm 1 \mod n$. </li>
<li>If $x \in S$, then $x^r \equiv 1 \mod n$ or $x^{2r} \equiv 1 \mod n$. Clearly $x$ is invertible. Hence $x \in Z_n^*$. </li>
<li>If $x \in S$, then $1 \equiv (x x^{-1})^r \equiv x^r x^{-r} \equiv x^{-r} \mod n$. </li>
</ul>
<p>Finally, we prove Property (3). As $n$ is composite, we can write $n = ab$, where $a$ and $b$ are coprime. By definition of $S$, $\exists x \in S$, such that<br>$$<br>x^r \equiv -1 \mod n<br>$$<br>By Chinese Remainder Theorem, this is equivalent to<br>$$<br>x^r \equiv n-1 \mod a \wedge x^r \equiv n-1 \mod b<br>$$<br>i.e.,<br>$$<br>x^r \equiv -1 \mod a \wedge x^r \equiv -1 \mod b<br>$$</p>
<p>However, another use of Chinese Remainder Theorem asserts $\exists y \in [n]$, such that<br>$$<br>y \equiv x \mod a \wedge y \equiv 1 \mod b<br>$$</p>
<p>which implies that<br>$$<br>y^r \equiv x^r \equiv -1 \mod a \wedge y^r \equiv 1 \mod b<br>$$</p>
<p>Hence it is impossible that $y^r \equiv \pm 1 \mod n$. It is left to prove $y$ is invertible module $n$:</p>
<ul>
<li>$y \in Z_n^*$, as $\gcd(x, n) = \gcd(x, ab) = 1 \rightarrow \gcd(x,a ) = 1 \wedge \gcd(x, b) = 1 \rightarrow \gcd(y, a) = \gcd(x, a) = 1 \rightarrow \gcd(y, ab) = 1$. </li>
</ul>
<p>$\blacksquare$</p>
<h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h4><ol>
<li> <a target="_blank" rel="noopener" href="http://theory.stanford.edu/~valiant/teaching/CS265/primality.pdf">Primality Testing, CS265/CME309, Fall 2017. Gregory Valiant</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/09/03/Less-Communication/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/03/Less-Communication/" class="post-title-link" itemprop="url">Less Communication</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2019-09-03 14:19:55 / Modified: 15:35:25" itemprop="dateCreated datePublished" datetime="2019-09-03T14:19:55+10:00">2019-09-03</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>A set of $k$ servers are receiving requests and they are required to report to a coordinator the numbers of requests they process. An event is trigerrd by the coordinator if the culmulative requests received by the serves reaches a threshold $\tau$. The goal is to minimized the communicaiton between the coordinator and the servers. </p>
<p>A naive approach asks the servers to send a notificiation to the coordinator each time they process a request, resulting in $O(\tau)$ bits communication in total. </p>
<p>An alternative approach achieves $O(h \log \tau)$ words communication cost. Instead of response to the coordinator every a new request comes, the server reports only after some requests reaches. However, we don’t want the coordinator to miss the $\tau$ threshold, i.e., it must triger the event when exactly $\tau$ requests come in total. </p>
<p>Here is the scheme.  </p>
<ol>
<li>If $\tau \le 5 \cdot h$, the server report each time a request comes. </li>
<li>The coordinator sends the threshold $\lfloor \frac{\tau}{ 2h} \rfloor$ to each server. This requires $h$ words. </li>
<li>Each server sends a report to the coordinator every $\lfloor \frac{\tau}{ 2h} \rfloor$ requests comes. </li>
<li>When the coordinator learns that, the servers has processed $\lfloor \tau / 2 \rfloor$ requests (at most $2h$ words communication needed), it collects how many requests are proceed in each servers which are not reported to it (at most $2h$ words communication needed). The number of requests comes is at most<br>$$<pre><code> \lfloor \tau / 2 \rfloor + (h - 1) (\lfloor \tau / 2h \rfloor - 1) &lt; \tau /2 + \tau / 2 = \tau
</code></pre>
$$</li>
<li>The number of requests remains to reach the $\tau$ threshold is at most $\tau’ \doteq \lceil \tau / 2 \rceil$. We set $\tau’$ as the new threshold and go to step 1. </li>
<li>The overall communication cost is given by<br>$$<pre><code> T(\tau) = T(\lceil \tau / 2 \rceil) + 5 \cdot h
</code></pre>
$$<br>for some constant $k$. </li>
<li>There are at most $2 \log \tau$ recursions. Each recursion requires $k$ words communication, resulting in a total communication cost $O(h \log \tau)$ words. </li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/08/15/Chinese-Reminder-Theorem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/15/Chinese-Reminder-Theorem/" class="post-title-link" itemprop="url">Chinese-Reminder-Theorem</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-15 11:37:18" itemprop="dateCreated datePublished" datetime="2019-08-15T11:37:18+10:00">2019-08-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-03 20:24:48" itemprop="dateModified" datetime="2019-12-03T20:24:48+11:00">2019-12-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Given integers $n_1, n_2,…,n_k$ that are relatively prime, and integers $a_1, a_2, …, a_k$, the Chinese-Reminder-Theorem states that there exists an integer $x$ such that<br>$$<br>\begin{aligned}<br>x \equiv a_1 \mod n_1 \<br>x \equiv a_2 \mod n_2 \<br>… \<br>x \equiv a_k \mod n_k<br>\end{aligned}<br>$$</p>
<p>Now denote $N_i = \frac{\prod_{j = 1}^k n_j}{n_i}$.</p>
<p>The proof is intuitive. For any $i \in [1, k]$, $N_i$ is coprime to $n_i$. Therefore, it has an inverse ($\mod n_i$). Let the inverse be $M_i$, i.e., $M_i N_i\equiv 1 \mod n_i$. It follows that $a_i M_i N_i \equiv a_i \mod n_i$. Further, as $N_i$ contains $n_j$ ($j \neq i$) as a factor, $a_i M_i N_i \equiv 0 \mod n_j$.</p>
<p>It is easy to see that<br>$$<br>\sum_{i = 1}^k a_i M_i N_i<br>$$<br>is a solution to the problem. </p>
<p>Moreover, we claim that any solution has the form<br>$$<br>\sum_{i = 1}^k a_i M_i N_i + l \cdot \prod_{i = 1}^k n_i<br>$$<br>for some integer $l$. Suppose that $x$ and $y$ are two solutions to the problem, then for any $i \in [1, k]$,<br>$$<br>x - y \equiv 0 \mod n_k<br>$$<br>Hence, $x - y = l \cdot \prod_{i = 1}^k n_i$ for some $l$. The immediate corollary is that there is a unique solution in $[0, \prod_{i = 1}^k n_i - 1]$ for the problem.  </p>
<p><em>Proof 2:</em> there is a probability more intuitive proof. First we investigate a simple example of pair $2$ and $3$ and their modules<br>$$<br>\begin{aligned}<br>&amp;        &amp; 0 &amp;&amp; 1 &amp;&amp; 2 &amp;&amp; 3 &amp;&amp; 4 &amp;&amp; \qquad 5 &amp;&amp; … \<br>&amp;\mod 2 &amp; 0 &amp;&amp; 1 &amp;&amp; 0 &amp;&amp; 1 &amp;&amp; 0 &amp;&amp; \qquad 1 &amp;&amp; … \<br>&amp;\mod 3 &amp; 0 &amp;&amp; 1 &amp;&amp; 2 &amp;&amp; 0 &amp;&amp; 1 &amp;&amp; \qquad 2 &amp;&amp; …<br>\end{aligned}<br>$$<br>Note that there is one-to-one correspondence between numbers in ${0, 1, 2, 3, 4, 5}$ and pairs in ${0, 1} \times {0, 1, 2}$. In general, given integers $n_1, n_2,…,n_k$ that are relatively prime, and two numbers $1 \le x \le y \le \prod_j n_j$, if<br>$$<br>\begin{aligned}<br>x \equiv y \mod n_1 \<br>x \equiv y \mod n_2 \<br>… \<br>x \equiv y \mod n_k<br>\end{aligned}<br>$$<br>then $x = y$. To see this, we have for any $1 \le j \le k$,<br>$$<br>n_j | (y - x )<br>$$<br>As the $n_j$’s are coprime, we have $\prod_j n_j | (y - x)$, hence $y - x = 0$ and $y = x$. Then we can define a one-to-one correspondence between $[\prod_j n_j]$ and the $k$ dimension vectors $[n_1] \times [n_2] \times … \times [n_k]$. </p>
<h2 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h2><p>The theorem has many interesting applications. Here are some:</p>
<p>Theorem 1: Let $\varphi(n)$ be the numbers in $[n]$ that are coprime with $n$. If $n = pq$ for primes $p$ and $q$, then $\varphi(n) = (p - 1)(q - 1)$. </p>
<p>Proof: By Chinese Reminder Theorem, there is a one-to-one correspondence between $[n]$ and $[p] \times [q]$. If $x \in [n]$ is not coprime with $n$, either $p \mid x$ or $q \mid x$. Therefore, $x$ corresponds to a pair $(p, a)$ or $(b, q)$ for some $a \in [q]$ or $b \in [p]$. The number of such pairs is given by $p + q - 1$. $\blacksquare$</p>
<p>Theorem 2: If $n = pq$ for positive integers $p, q$ and $p$ and $q$ are coprime, then $\varphi(n) = \varphi(p) \varphi(q)$. </p>
<p>Proof: By Chinese Reminder Theorem, there is a one-to-one correspondence between $[n]$ and $[p] \times [q]$. If $x \in [n]$ is coprime with $n$, it holds that $\gcd(x, p) = 1 \wedge \gcd(x, q) = 1$. Therefore, $x$ corresponds to a pair  for $(x \mod p, x \mod q)$ , such that $x \mod p$ is coprime with $p$ and $x \mod q$ is coprime with $q$.  The number of possible values of $x \mod p$ is $\varphi(p)$, and the number of possible values of $x \mod q$  is $\varphi(q)$ . Hence $\varphi(n) = \varphi(p) \varphi(q)$. $\blacksquare$</p>
<p>Theorem 3: Let $n = p_1^{k_1} p_2^{k_2} … p_m ^{k_m}$ be the unique prime factorization of $n$, then $\varphi(n) = n \prod_{i = 1}^m (1 - 1/p_i)$. </p>
<p>Proof:<br>$$<br>\varphi(n) = \prod_{i = 1}^m \varphi(p_i^{k _i})<br>$$<br>On the other hand, there are $p_i^{k _i - 1}$ numbers in $[p_i^{k _1}]$ there are not coprime with $p_i^{k_i}$, namely<br>$$<br>1\cdot p_i, 2 \cdot p_i, 3 \cdot p_i…, p_i^{k_i - 1} p_i<br>$$<br>Therefore, $\varphi(p_i^{k_i}) = p_i^{k_i} - p_i^{k_i - 1} = p_i^{k_i}( 1 - 1/p_i)$ and<br>$$<br>\varphi(n) = \prod_{i = 1}^m p_i^{k_i} (1 - 1/ p_i) =  n \prod_{i = 1}^m (1 - 1/ p_i)<br>$$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/06/01/Matrix-Norm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/06/01/Matrix-Norm/" class="post-title-link" itemprop="url">Matrix Norm</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-06-01 19:37:46" itemprop="dateCreated datePublished" datetime="2019-06-01T19:37:46+10:00">2019-06-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-12-23 21:15:20" itemprop="dateModified" datetime="2020-12-23T21:15:20+11:00">2020-12-23</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>A function $f: \mathbb{R}^{m \times n} \rightarrow \mathbb{R}$ is called a matrix norm if it satisfies that $\forall A, B \in \mathbb{R}^{m \times n}$ and $k \in \mathbb{R}$,  </p>
<ol>
<li>$f(A) = 0 \rightarrow A = 0$.  </li>
<li>$f(kA) = kf(A)$.  </li>
<li>$f(A + B) \le f(A) + f(B)$.  </li>
</ol>
<h2 id="Frobenius-Norm"><a href="#Frobenius-Norm" class="headerlink" title="Frobenius Norm"></a>Frobenius Norm</h2><p>The Frobenius Norm view a matrix as a vector and is defined as $|A|<em>F = \sqrt{\sum</em>{i, j} a_{i,j}^2 }$, where $a_{i,j}$ is the element in the $i$-th row and $j$-th column. Clearly this is a norm.  </p>
<h2 id="2-norm-or-spectral-norm"><a href="#2-norm-or-spectral-norm" class="headerlink" title="2-norm or spectral norm"></a>2-norm or spectral norm</h2><p>The 2-norm is defined as $|A|_2 = \sigma_1$, where $\sigma_1$ is the maximum singular value of $A$. We prove this is a norm by checking triangle inequality.</p>
<p><em>Proof:</em> First, note that<br>$$<br>|A|<em>2 = \max</em>{x \in \mathbb{R}^n \wedge ||x|| = 1 } ||Ax||<br>$$</p>
<p>This can  be verified by writing $A$ as its singular value decomposition<br>$$<br>A = \sigma_1 u_1 v_1^T + … + \sigma_r u_r v_r^T<br>$$<br>where $u_1, …, u_r \in \mathbb{R}^m$ are orthogonal, $v_1, v_2, …, v_r \in \mathbb{R}^n$ are orthogonal and $\sigma_1 \ge \sigma_2 \ge … \ge \sigma_r \ge 0$. </p>
<p>We augment $v_1, v_2, …, v_r$ to $v_1, .., v_n$ such that they constitutes an orthogonal base of $\mathbb{R}^n$. Then we can write $x \in \mathbb{R}^n$ as<br>$$<br>x = x_1 v_1 + x_2 v_2 + … + x_n v_n<br>$$<br>where $\sum_{i = 1}^n x_i^2 = 1$.</p>
<p>Therefore,<br>$$<br>||Ax|| = \sqrt{\sum_{i = 1}^r \sigma_i^2x_i^2 }<br>$$</p>
<p>Clearly $||Ax||$ is maximized when $x_1 = 1$ and $x_i = 0$ for $i \neq 1$:<br>$$<br>\max_{x} ||Ax|| =  \sigma_1<br>$$</p>
<p>Now, for any $x \in \mathbb{R}^n$ and $||x|| = 1$, by triangle inequality of vectors, it holds that<br>$$<br>||(A + B)x|| \le ||Ax|| + ||Bx|| \le |A|_2 + |B|_2<br>$$</p>
<p>Maximizing over the left hand side gives the desired triangle inequality.  </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/05/29/Kraft-Inequality/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/05/29/Kraft-Inequality/" class="post-title-link" itemprop="url">Kraft Inequality</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-05-29 20:07:02" itemprop="dateCreated datePublished" datetime="2019-05-29T20:07:02+10:00">2019-05-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-05-30 00:56:35" itemprop="dateModified" datetime="2019-05-30T00:56:35+10:00">2019-05-30</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Assume that we would like to encode a set of symbol $S = { s_1, s_2, …, s_n }$ into binary strings $T = { t_1, t_2, …, t_n : t_i \text{ is a 0, 1 sequence of finite length} }$, such that $\forall i \neq j$, $t_i$ is not a prefix of $t_j$. Denote the length of $t_i$ as $n_i$. Then the <em>Kraft Inequality</em> states that<br>$$<br>\sum_{i = 1}^n 2^{-n_i} \le 1<br>$$</p>
<p>For convenience, we write $t_i \ll t_j$ if $t_i$ is a prefix of $t_j$. Intuitively, we can view a particular sequence $t_i = t_i^1t_i^2 …t_i^{n_i}$ as the abbreviation of number $0.t_i^1t_i^2 …t_i^{n_i}$. The fact that for $j \neq i$, neither $t_i \ll t_j$ nor $t_j \ll t_i$ implies that $t_j$ does not lies in the interval $[0.t_i^1t_i^2 …t_i^{n_i}, 0.t_i^1t_i^2 …t_i^{n_i} + 2^{-n_i})$. As the intervals induced by $t_i$’s are mutually exclusive, we can easily conclude that<br>$$<br>\sum_{i = 1}^n 2^{-n_i} \le 1<br>$$</p>
<p>Indeed, the statement of Kraft Inequality can be made stronger such that the inequality holds as long as ${ t_1, t_2, …, t_n }$ are uniquely decodable. To verify this, note that for any sequence $\tau \in T^*$ with length $k$, there are at most only $2^k$ possible combinations. Therefore,<br>$$<br>(\sum_{i = 1}^n 2^{-n_i})^l = \sum_{k = 1}^{l \cdot n_{max}} C_k 2^{-k}<br>$$<br>where $n_{max} = \max{n_1, n_2, …, }$ and $C_k \le 2^k$. Hence<br>$$<br>(\sum_{i = 1}^n 2^{-n_i})^l \le l \cdot n_{max} \rightarrow \sum_{i = 1}^n 2^{-n_i} \le l^{1/l} \cdot n_{max}^{1/l}<br>$$</p>
<p>Taking $l$ to infty we get the desired result.  </p>
<p>An immediately implication is that Entropy is the lower bound of the encode length of a document. To see this, denote the probability of $s_i$ as $p_i$. Then<br>$$<br>\begin{aligned}<br>\sum_{i} p_i \log \frac{1}{p_i} - \sum_{i} p_i n_i<br>&amp;= \sum_{i} p_i \log \frac{1}{p_i} \cdot \frac{1}{2^{n_i} } \<br>&amp;\le \log \sum_{i} p_i  \frac{1}{p_i} \cdot \frac{1}{2^{n_i} } \<br>&amp;\le \log \sum_{i} \frac{1}{2^{n_i} } \<br>&amp;\le 0<br>\end{aligned}<br>$$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/05/18/The-Number-of-Distinct-Elements/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/05/18/The-Number-of-Distinct-Elements/" class="post-title-link" itemprop="url">The Number of Distinct Elements</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-05-18 16:09:20" itemprop="dateCreated datePublished" datetime="2019-05-18T16:09:20+10:00">2019-05-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-06-21 21:01:48" itemprop="dateModified" datetime="2020-06-21T21:01:48+10:00">2020-06-21</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>In many network applications, data comes as a stream $S = {x_1, x_2, …, x_n }$, where each $x_i$ ($1 \le i \le n$) belongs to the domain $D$. Suppose each element in $D$ appear at least once in $S$, we want to evaluate the size of $D$, i.e., the number of distinct elements in $S$ (denoted as $N = |D|$).  </p>
<p>Potential solutions include</p>
<ol>
<li>We can sort the elements in $S$ and count the number of distinct elements. This requires $O(n \log n)$ time (with quicksort) and $O(n)$ space.  </li>
<li>We can use hashing to count the distinct elements. This can be done in $O(n)$ time and $O(n)$ space with two level hashing.  </li>
</ol>
<p>In real world application, $n$ could be extremely large. Therefore, the demand for $O(n)$ space is expansive or even impossible. Can we do this with $O(1)$ space? If we allow some error, this is possible.  </p>
<h2 id="Solution-1"><a href="#Solution-1" class="headerlink" title="Solution 1"></a>Solution 1</h2><p>The tool we resort to is a set of hash functions $\mathcal{H} = { h | h: U \rightarrow [0, 1] }$ such that<br>$$<br>\begin{aligned}<br>&amp;\Pr_{h \in \mathcal{H} } [h(x) \in [a, b]] = \frac{1}{b - a}, &amp;\forall x \in U \wedge [a, b] \subset [0, 1]<br>\end{aligned}<br>$$</p>
<p>That is, given an element $x \in U$, if we choose an $h$ from $U$ randomly, then $h$ maps $x$ to a number between $[0, 1]$ uniformly at random. Further, we assume that $h$ maps different elements in $U$ to $[0, 1]$ independently (Remark: to what extend is this possible?).  </p>
<p>Further, denote $h(S) = { h(x_1), h(x_2), …, h(x_n)}$ the image of $S$ under a function $h$. We claim that, if $h$ is selected randomly from $\mathcal{H}$, then the minimum expected value of $h(S)$ is  $1 / (N + 1)$:<br>$$<br>\underset{h \in \mathcal{H} }{E} [\min h(S)] = \int_{z = 0}^1 z \Pr_{h \in \mathcal{H}} [\min h(S) = z] \ dz = \frac{1}{N + 1}<br>$$</p>
<p>To see this, observe that the probability that $\Pr_{h \in \mathcal{ H } }[\min h(S) \ge z] = (1 - z)^N​$, therefore $\Pr_{h \in \mathcal{ H } }[\min h(S) \le z] = 1 - (1 - z)^N​$ and the density function is given as<br>$$<br>p_{h \in \mathcal{H  } }[\min h(S) = z] = \frac{\partial \Pr_{h \in \mathcal{H}  }[\min h(S) \le z] }{ \partial z} = N (1 - z)^{N - 1}<br>$$</p>
<p>Taking the expectation over $z = 0$ to $1$ gives the desired result.  </p>
<p>Another way to prove this is to introduce an additional element $x_{n + 1}$ which is different from any other element in $D$ and let $S’ = S \cup { x_{n + 1} }$. What is the probability that $h(x_{n + 1})$ is the smallest in $h(S’)$, i.e., $\min h(S’) = h(x_{n + 1})$? Conditioning on the minimum value of ${ h(x_1), h(x_2), …, h(x_n) }$ ($\min h(S)$) being some $z$ ($z \in [0, 1]$), the probability becomes<br>$$<br>\begin{aligned}<br>&amp;\Pr[\min h(S’) = h(x_{n + 1}) \mid \min h(S) = z] \<br>= &amp;\Pr[h(x_{n + 1}) \in [0, z] \mid \min h(S) = z] \<br>= &amp;z<br>\end{aligned}<br>$$</p>
<p>Integrating over all possible values of $z$, we have<br>$$<br>\Pr[\min h(S’) = h(x_{n + 1})] = \int_{z = 0}^1 z \Pr[\min h(S) = z] \ dz<br>$$</p>
<p>This is exactly the expectation of $\min h(S)$. Moreover, by symmetry, $\Pr[\min h(S’) = h(x_{n + 1})] = \frac{1}{N + 1}$. Therefore, it follows that $E[\min h(S)] = \frac{1}{N + 1}$.</p>
<p>It is natural to ask how accurate our estimation is. On the one hand, by Markov inequality,<br>$$<br> \Pr_{h \in \mathcal{H} } [\min h(S) \ge 2 \frac{1}{N + 1}] \le \frac{E[\min h(S)]}{2 \frac{1}{N + 1} } = \frac{1}{2}<br>$$</p>
<p>By repeating the algorithm $k$ times, the failure probability drops to $\frac{1}{2^k}$. However, Markov inequality can not give a lower bound of $\min h(S)$. What comes to our rescue is Chebyshev’s inequality. First, note that<br>$$<br>\begin{aligned}<br>\underset{h \in \mathcal{H} }{E} [ (\min h(S))^2 ]<br>&amp;= \int_{z = 0}^1 N z^2(1 - z)^{N - 1} dz \<br>&amp;= \int_{z = 0}^1 N [(z - 1)^2  + 2(z - 1) + 1] (1 - z)^{N - 1}dz \<br>&amp;= -\frac{N}{N + 2}(1 - z)^{N + 2} \mid_{0}^1 + \frac{2N}{N + 1} (1 - z)^{N + 1} \mid_{0}^1 - \frac{N}{N} (1 - z)^{N} \mid_{0}^1  \<br>&amp;= \frac{N}{N + 2} - \frac{2N}{N + 1} + \frac{N}{N} \<br>&amp;= \frac{-(N - 1)(N + 2) + N^2 + N}{(N +2)(N + 1)} \<br>&amp;= \frac{2}{(N +2)(N + 1)}<br>\end{aligned}<br>$$</p>
<p>It follows that $\underset{h \in \mathcal{H} }{Var} [ (\min h(S))^2 ] = \frac{2}{(N + 1)(N +2)} - \frac{1}{(N + 1)^2} \le \frac{1}{(N + 1)^2}$. However, this alone is not enough to give an accurate estimate. </p>
<p><em>Question to ponder: try to apply Chebyshev’s inequality directly on this single estimate. Can we get a meaningful lower bound for $\min h(S)$?</em></p>
<p>Instead, we repeat the algorithm $k$ times, and take the average over the $\min h(S)$’s. Let $\overline X$ denote this average value. Then $\underset{h \in \mathcal{H} }{Var} [ \overline X ] \le \frac{1}{k (N + 1)^2}$. Given a parameter $0 &lt; l &lt; 1$ (to be determined later),<br>$$<br>\Pr[ |\overline{X} - \frac{1}{N + 1} | \ge \frac{l}{N + 1}] \le  (\frac{1}{k(N + 1)^2}) / (\frac{l^2}{(N + 1)^2}) = \frac{1}{k l^2}<br>$$</p>
<p>That is, $\overline{X} \in \frac{1}{N + 1}[1 - l, 1 + l]$ with probability $\frac{1}{k l^2}$. That is $n \in \frac{1}{\overline{X} } [1 - l , 1 + l]$ with probability $\frac{1}{k l^2}$.</p>
<p><strong>Remark 1</strong>: there exists other analysis for the concentration behavior when we repeat the experiment for $k$ times. Note that for $N \ge 1$,  </p>
<p>$$<br>\begin{aligned}<br>\Pr_{h \in \mathcal{ H } }[\min h(S) \ge (1 + \epsilon) \frac{1}{N + 1}]<br>&amp;= (1 - \frac{1 + \epsilon}{N + 1})^N \le \exp \left( -\frac{1 + \epsilon}{N + 1}N \right) \le \exp \left( -\frac{1 + \epsilon}{2} \right) = \frac{1}{\sqrt e} e^{-\epsilon / 2}\<br>\Pr_{h \in \mathcal{ H } }[\min h(S) \le (1 - \epsilon) \frac{1}{N + 1}]<br>&amp;= 1 - (1 -  \frac{1 - \epsilon}{N + 1})^N \le 1 - \exp \left( - \frac{ 1 - \epsilon }{2(N + 1)}N \right) \le 1 - \exp \left( - \frac{ 1 - \epsilon }{2} \right) = 1 - \frac{1}{\sqrt e} e^{ \epsilon / 2}<br>\end{aligned}<br>$$</p>
<p>We claim that if we take the $\frac{k}{\sqrt e}​$-th smallest element, our estimate $\overline X​$ satisfies</p>
<p>$$<br>\left| \overline X - \frac{1}{N + 1} \right| \le \epsilon \frac{1}{N + 1}<br>$$</p>
<p>with high probability.</p>
<p>Denote $z_1, z_2, …, z_k$ a set of i.i.d Bernoulli variables with mean $\frac{1}{\sqrt e} e^{-\epsilon / 2}$. Then by Chernoff bound,<br>$$<br>\begin{aligned}<br>\Pr[ \sum z_i \ge \frac{k}{\sqrt e} ]<br>&amp;= \Pr[ \sum z_i \ge (1 + (e^{\epsilon / 2} - 1) ) \frac{k}{\sqrt e} e^ {-\epsilon / 2}] \<br>&amp;\le \exp \left( -(e^{\epsilon / 2} - 1)^2 \frac{k}{\sqrt e} e^ {-\epsilon / 2} / 3 \right) \<br>&amp;= \exp \left( -(e ^\epsilon - 2 e^{\epsilon / 2} + 1) e^ {-\epsilon / 2} \frac{k}{\sqrt e}  / 3 \right) \<br>&amp;= \exp \left( -( e^{\epsilon / 2} - 2 + e^ {-\epsilon / 2}) \frac{k}{\sqrt e}  / 3 \right) \<br>&amp;\le \exp \left( - \frac{ \epsilon^2 }{4} \frac{k}{\sqrt e}  / 3 \right) \<br>&amp; = \delta<br>\end{aligned}<br>$$</p>
<p>It suffices to set $k = \frac{12 \sqrt e}{\epsilon^2} \ln \frac{1}{\delta}$.</p>
<p>By symmetry, we can prove the inequality of the other hand.</p>
<p><strong>Remark 2:</strong> Suppose that we have a function $h$ that maps each of the $N$ elements to a non-negative real number according to exponential distribution $\exp(-1)$ independently (the same element is mapped to the same number), then the minimum of these real numbers serves also as an unbiased estimator of $\frac{1}{N}$. To verify this,<br>$$<br>\Pr[ \min h(S) \le z] = 1 - \exp(-zN)<br>$$</p>
<p>Therefore,<br>$$<br>p[\min h(S) = z] = \frac{\partial \Pr[ \min h(S) \le z]}{\partial z} = N \exp(-Nz)<br>$$<br>and<br>$$<br>E[\min h(S)] = \int_{0}^\infty Nz \exp(-Nz) dz = -\int_{0}^\infty z \ d\exp(-Nz) = -z \exp(-Nz) \mid_{0}^\infty + \int_0^\infty \exp(-Nz) dz = \frac{1}{N}<br>$$<br>Further,<br>$$<br>\Pr[\min h(S) \ge (1 + \epsilon)  \frac{1}{N}] = \exp( - 1 - \epsilon) = \frac{1}{e}e^{-\epsilon} \<br>\Pr[\min h(S) \le (1 - \epsilon)  \frac{1}{N}] = 1 - \exp( - 1 + \epsilon) = 1 - \frac{1}{e}e^{\epsilon}<br>$$<br>Similarly, we can show that if we repeat the experiment $k = O(\frac{\ln 1 / \delta }{\epsilon^2 } )$ times, with probability at least $1 - \delta$, the $\frac{1}{e}$ smallest elements is an $1 \pm \epsilon$ estimator of $\frac{1}{N}$. </p>
<h2 id="Solution-2"><a href="#Solution-2" class="headerlink" title="Solution 2"></a>Solution 2</h2><p>Suppose we only want to know whether $N \ge t​$ or $N \le t / 2​$ for a given integer $t​$, is this possible?  </p>
<p>The answer is yes and the solution is amazingly easy. We hash each element in $D$ uniformly at random into the range $[1, 2, 3, …, t]$. If $N \ge t$, the probability that no elements is assigned the value $t$ is given by<br>$$<br>(1 - 1 / t)^N \le (1 - 1 / t)^t \le 1/e<br>$$<br>The second inequality holds since $(1 - 1 / t) \le e^{1 / t}$.</p>
<p>On the other hand, when $N \le t / 2$, the probability that no element is assigned the value $t$ is greater than<br>$$<br>(1 - 1 / t)^N \ge (1 - 1 / t)^{t / 2} \ge 1 / e<br>$$<br>The second inequality holds since $(1 - 1 / t) \ge e^{- 2 / t} = 1 - \frac{2}{t} + \frac{1}{2!}(\frac{2}{t})^2 - \frac{1}{3!}(\frac{2}{t})^3 + …$ when $1 / t \le 1/ 2$.</p>
<p>We can boost the probability to some defined threshold $1 - \delta$ by repeating $k = \log 1 / \delta$ times and check whether the majority of the answers are “yes”. Note that the expected number of “yes” is more than $(1 - 1 / e)k$ and by chernoff bound the probability that less than $0.5 k$ “yes” are returned is given by $\delta$.  </p>
<p>Now, to estimate $N$, we can set up $\log n$ values of $t: 1, 2, 4, 8, …, n$ and test for each value of $t$ whether $N \ge t$ or $N \le t / 2$.  We can find an interval $[t_1, t_2]$, such that $N \in [t_1, t_2]$ and $N / 2 \le t_1 \le t_2 \le 2\cdot N$. The space complexity is $O(\log n \log 1 / \delta)$.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/05/17/Jaccard-Similarity/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/05/17/Jaccard-Similarity/" class="post-title-link" itemprop="url">Jaccard Similarity</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-05-17 21:41:06" itemprop="dateCreated datePublished" datetime="2019-05-17T21:41:06+10:00">2019-05-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-05-19 00:54:26" itemprop="dateModified" datetime="2019-05-19T00:54:26+10:00">2019-05-19</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>The Jaccard similarity measures the fraction of shared elements between set. In particular, given set $A$ and $B$, the Jaccard similarity between them is defined as<br>$$<br>J(A, B) = \frac{|A \cap B|}{|A \cup B|}<br>$$<br>The naive calculation of $J(A, B)$ has time complexity $O(|A \cup B|)$ by scanning all elements in the two sets once. Here we discuss how randomization might save time.  </p>
<h2 id="Lemma-One"><a href="#Lemma-One" class="headerlink" title="Lemma One"></a>Lemma One</h2><p>If we select an item $x$ uniformly at random from $|A \cup B|$, then $\Pr[x \in A \cap B] = \frac{|A \cap B|}{|A \cup B|}$.</p>
<p>Define the random variable<br>$$<br>X = \begin{cases}<br>1, \ if \ x \in \ A \cap B \<br>0, \ otherwise<br>\end{cases}<br>$$</p>
<p>Then we see that $X$ is an unbiased estimator of $J(A, B)$, i.e., $E[X] = J(A, B)$.  </p>
<p>Suppose that we have a sequence of i.i.d. copies of $X$, denoted $X_1, X_2, …, X_k$, then the average $\mu = \frac{1}{k} \sum_{i = 1}^k X_i$ is also an unbiased estimator of $J(A, B)$. Moreover, by law of large number, $\mu \rightarrow J(A, B)$ as $k \rightarrow \infty$. The problem is, how many $X_i$’s are enough.  </p>
<p>The answer depends on a few factors:  </p>
<ol>
<li>Whether the value of the required error is relative to $J(A, B)$ or independent to $J(A, B)$.</li>
<li>What is the tolerance of failure probability.</li>
</ol>
<p>In the following discussion we consider only the case of finding an estimator $\mu$ such that $J(A, B) \in [\mu \pm \epsilon]$ with probability at least $1 - \delta$, where both $\epsilon$ and $\delta$ are given parameters. Then the convergence behavior with respect to the number of samples $k$ can be captured by Hoeffding inequality:<br>$$<br>\Pr[ |\mu - J(A, B)| \ge \epsilon] \le 2\exp \left( -\frac{2\epsilon^2}{k} \right) = \delta<br>$$  </p>
<p>Solving the equation gives<br>$$<br>k = \frac{2}{\epsilon^2}\log \frac{2}{\delta}<br>$$</p>
<p>Or equivalent, when we interpret $\epsilon$ as the width of confidence interval,<br>$$<br>\epsilon = \sqrt \frac{\log \frac{2}{\delta} }{k}<br>$$<br>which has order $O(\sqrt \frac{1}{k})$.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/04/05/Multiplicative-Weight-Updates/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/04/05/Multiplicative-Weight-Updates/" class="post-title-link" itemprop="url">Multiplicative Weight Updates</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-04-05 18:05:10" itemprop="dateCreated datePublished" datetime="2019-04-05T18:05:10+11:00">2019-04-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-12-14 17:48:44" itemprop="dateModified" datetime="2020-12-14T17:48:44+11:00">2020-12-14</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Consider a problem that might arises from many application scenarios. We have a sequence of $T$ binary variables indexed by time $X_1, X_2, …, X_T$, where $X_t \in {0, 1}, \forall t \in [T]$. We try to predict the value of $X_t$, such that we win $1$ dollar if our guess is correct and $0$ dollar otherwise.</p>
<p>We don’t make decision on our own. Instead, we resort a group of $n$ experts. At each time $t$, each expert $i$ gives a prediction $p_i^t$ of $X_t$. Based on the experts’ prediction,  we make prediction our prediction $p_A^t$. The value of $X_t$ is then revealed and we make a mistake if our prediction is wrong. The goal to minimize the number of mistakes. </p>
<h3 id="How-Good-Can-We-Do"><a href="#How-Good-Can-We-Do" class="headerlink" title="How Good Can We Do"></a>How Good Can We Do</h3><p>The first question is how good can we do? Define </p>
<ol>
<li> $L_i^t:$ the indicator variable of whether the expert $i$ makes a mistake at round $t$. </li>
<li> $L_i = \sum_{t \in [T] } L_i^t:$ the total number of mistakes expert $i$ makes, when $T$ is fixed. </li>
<li> $L_A:$ the one made by our algorithm. </li>
</ol>
<p>Ideally, we would like achieve as few mistakes as<br>$$<br>    \sum_{t \in [T] } \min_{i \in [n]} L_i^t.<br>$$</p>
<p>However, this is impossible. To see this, suppose $X_t$ is a sequence of independent Bernoulli random variable with probability $0.5$ equal to<br>$1$. No matter what strategy we use, the expected number of mistakes is always $T / 2$. On the other hand, $\sum_{t \in [T] } \min_{i \in [n]} L_i^t$ could be $0$. </p>
<p>Despite the negative result, there is hope to achieve as few mistakes as the best expert (up to some constant), that is<br>$$<br>O \left( \min_{i \in [n]} \sum_{t \in [T] } L_i^t \right) = O \left( \min_{i \in [n] } L_i \right).<br>$$</p>
<h3 id="Follow-the-Majority"><a href="#Follow-the-Majority" class="headerlink" title="Follow the Majority"></a>Follow the Majority</h3><p>We start with an easy case where there exists an expert who always gives the correct guess. Under this assumption, we can achieve<br>$$<br>\min_{i \in [n] } L_i + \log n<br>$$</p>
<p>mistakes. We simply keep track of a set of experts who do not make any mistake so far. Each time we make a decision, we follow the majority of the set. </p>
<blockquote>
<p>Algorithm 1. <strong>Follow the Majority</strong>  </p>
<ol>
<li>Let $E_0 \leftarrow { 1, 2, …, n }$ be the set of all experts.    </li>
<li>For $t \leftarrow 1$ to $T$   </li>
<li>$\qquad$ Let $S$ be the subset of $E_{t - 1}$ that predicts 0 at time $t$.   </li>
<li>$\qquad$ Let $\bar S$ be the subset of $E_{t - 1}$ that predicts 1 at time $t$.   </li>
<li>$\qquad$ If $|S| &gt; |\bar S|$,  then predict 0 ($p_A^t \leftarrow 0$);   </li>
<li>$\qquad\qquad\qquad\quad$      else predict 1 ($p_A^t \leftarrow 1$).  </li>
<li>$\qquad$ Reveal $X_t$.  </li>
<li>$\qquad$ If $X_t = 0$, then $E_t \leftarrow S$;   </li>
<li>$\qquad\qquad\qquad$   else $E_t \leftarrow \bar S$.   </li>
</ol>
</blockquote>
<p><em>Theorem. If there is a perfect expert, the algorithm <em>Follow the Majority</em> makes at most $\log n$ mistakes.</em><br><em>Proof.</em>  Let $M$ be the number of mistakes the algorithm makes. Each time it makes a mistake, the size of $E_{t}$ shrink by half.  Hence,<br>$$<br>1 \le |E_T| \le |E_1| \frac{1}{2^M}  = \frac{n}{2^M}.<br>$$</p>
<p>The first inequality follows from the existence of perfect expert. It concludes that<br>$$<br>M \le \log n.<br>$$<br>$\square$</p>
<h3 id="Follow-the-Majority-With-Reset"><a href="#Follow-the-Majority-With-Reset" class="headerlink" title="Follow the Majority With Reset"></a>Follow the Majority With Reset</h3><p>We continue with the case without a perfect expert. By modifying the <em>Follow the Majority</em> a little, we can achieve<br>$$<br>\left( \min_{i \in [n] } L_i  + 1 \right) \cdot \log n<br>$$<br>mistakes. As before, we maintain a set of experts who do not make any mistake so far and we follow the majority of the set to make decisions. </p>
<blockquote>
<p>Algorithm 2. <strong>Follow the Majority With Reset</strong>  </p>
<ol>
<li>Let $E_0 \leftarrow { 1, 2, …, n }$ be the set of all experts.    </li>
<li>For $t \leftarrow 1$ to $T$   </li>
<li>$\qquad$ Let $S$ be the subset of $E_{t - 1}$ that predicts 0 at time $t$.   </li>
<li>$\qquad$ Let $\bar S$ be the subset of $E_{t - 1}$ that predicts 1 at time $t$.   </li>
<li>$\qquad$ If $|S| &gt; |\bar S|$,  then predict 0 ($p_A^t \leftarrow 0$);   </li>
<li>$\qquad\qquad\qquad\quad$      else predict 1 ($p_A^t \leftarrow 1$).  </li>
<li>$\qquad$ Reveal $X_t$.  </li>
<li>$\qquad$ If $X_t = 0$, then $E_t \leftarrow S$;   </li>
<li>$\qquad\qquad\qquad$   else $E_t \leftarrow \bar S$.   </li>
<li>$\qquad$ If $E_t = \emptyset$, then reset $E_t \leftarrow {1, 2, …, n}$. </li>
</ol>
</blockquote>
<p><em>Theorem. If there isn’t a perfect expert, the algorithm <em>Follow the Majority</em> makes at most $\left( \min_{i \in [n] } L_i + 1 \right) \cdot \log n$ mistakes.</em><br><em>Proof.</em>  Let $M$ be the number of mistakes the algorithm makes. As analysed before, between two consecutive resets of $E_t$, the algorithm makes at most $\log n$ mistakes while the best expert makes at least one mistake. Therefore,<br>$$<br>\frac{M}{ \log n } \le \min_{i \in [n] } L_i + 1\implies M \le \left( \min_{i \in [n]}  L_i  + 1\right) \cdot \log n<br>$$</p>
<p>$\square$</p>
<h3 id="Follow-the-Weighted-Majority"><a href="#Follow-the-Weighted-Majority" class="headerlink" title="Follow the Weighted Majority"></a>Follow the Weighted Majority</h3><p>One drawback of the previous approach is that, the algorithm forgets the relative performance of the experts each time it resets $E_t$. To fix this, we assign each expert $i$ a weight $w_i^t$ and we follow the weighted majority at time $t$. This reduces the number of mistakes to<br>$$<br>    2.41 \cdot ( \min_{i \in [n]} L_i + \log n).<br>$$</p>
<blockquote>
<p>Algorithm 3. <strong>Follow the Weighted Majority</strong>  </p>
<ol>
<li>Set $w_i \leftarrow 1, \forall i \in [n].$    </li>
<li>For $t \leftarrow 1$ to $T$   </li>
<li>$\qquad$ Let $S$ be the set of experts who predict 0.   </li>
<li>$\qquad$ Let $\bar S$ be the set of experts who predict 1.   </li>
<li>$\qquad$ If $\sum_{i \in S} w_i &gt; \sum_{i \in \bar S} w_i$,  then predict 0 ($p_A^t \leftarrow 0$);   </li>
<li>$\qquad\qquad\qquad\qquad\qquad\qquad$      else predict 1 ($p_A^t \leftarrow 1$).  </li>
<li>$\qquad$ Reveal $X_t$.  </li>
<li>$\qquad$ For each expert $i$ who predicts wrong</li>
<li>$\qquad\qquad$ $w_i \leftarrow w_i / 2$</li>
</ol>
</blockquote>
<p><strong><em>Analysis.</em></strong> Let $w_i^t$ be the weight of player $i$ at time $t$ and define $W^t = \sum_{i = 1}^n w_i^t$. Each time we make a mistake, the experts who make wrong the prediction have sum of weight $\ge \frac{1}{2} W^t$. Since their weights halve, we have<br>$$<br>W^{t + 1} \le W^t ( 1 - \frac{1}{2}\frac{1}{2}) = \frac{3}{4} W^t.<br>$$ </p>
<p>Let $M$ be the number of mistakes the algorithm makes. It follows that $\forall i \in [n]$,<br>$$<br> \left( \frac{1}{2} \right)^{L_i} = w_i^T \le W^T \le \left( \frac{3}{4} \right)^M W_0 = \left( \frac{3}{4} \right)^M n,<br>$$</p>
<p>which implies<br>$$<br>M \le  \frac{1}{ \log \frac{4}{3} } ( L_i + \log n) \le 2.41 \cdot (L_i + \log n).<br>$$</p>
<p><em>Remark:</em> it is not necessary to halve an expert’s weight when it makes a mistake. We can decrease it by any factor $(1 - \epsilon)$ for $\epsilon \in (0, 1)$. In such case, we get<br>$$<br>\begin{aligned}<br>    &amp;\qquad (1- \epsilon)^{L_i} \le \left( 1 - \frac{1 - (1 - \epsilon)}{2} \right)^M n \<br>    &amp;\implies L_i \cdot \ln (1 -\epsilon) \le M \ln \left( 1 - \frac{\epsilon}{ 2 } \right) + \ln n \<br>    &amp;\implies M \le \frac{ L_i \ln \frac{1}{1 - \epsilon} + \ln n}{ \ln \frac{ 2 }{ 2 - \epsilon } }.<br>\end{aligned}<br>$$</p>
<p>Let $x = \frac{1}{1 - \epsilon} &gt; 0$, then $1 - \epsilon = \frac{1}{x}$ and $\frac{2 - \epsilon }{ 2 } = \frac{x + 1}{2x}$. Define<br>$$<br>y = \frac{ L_i \ln x + \ln n}{ \ln 2x - \ln ( x + 1  ) }.<br>$$</p>
<p>Then<br>$$<br>\begin{aligned}<br>    y’ \ge 0<br>        &amp;\implies  \frac{L_i}{x} (\ln 2x - \ln ( x + 1  ) ) - \left( \frac{1}{x} - \frac{1}{x + 1} \right) (L_i \ln x + \ln n ) \ge 0 \<br>        &amp;\implies  L_i(x + 1) (\ln 2x - \ln ( x + 1  ) ) - (L_i \ln x + \ln n ) \ge 0 \<br>        &amp;\implies  (x + 1) (\ln 2x - \ln ( x + 1  ) ) - \ln x \ge \frac{\ln n}{L_i}<br>\end{aligned}<br>$$</p>
<p>It is not easy to compute a closed-form solution for $x$. But observe that the function $(x + 1) (\ln 2x - \ln ( x + 1  ) ) - \ln x$ equals to $0$ for $x = 1$ and is increasing for $x &gt; 1$. Hence, there exists some $x &gt; 1$, s.t., the value of the functions equal to $\frac{ \ln n }{ L_i }$. </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/MultiplicativeWeightUpdate/MultiplicativeWeightUpdate.png?raw=true"></p>
<p>$\square$</p>
<h3 id="Multiplicative-Weight-Updates"><a href="#Multiplicative-Weight-Updates" class="headerlink" title="Multiplicative Weight Updates"></a>Multiplicative Weight Updates</h3><p>We are in good shape so far. Let’s extend the problem to more general settings. In this cases, the experts interact with the environment in round-robin fashion. At each round $t$,  </p>
<ol>
<li>The expert $i$ performs action, termed $a_i^t$. </li>
<li>The environment returns the loss of performing $a_i^t$, denoted as $l_i^t \in [0, 1]$.</li>
</ol>
<p>Although there is no restriction of the experts’ actions and their losses, we can come up with some strategy the expected loss of which is almost as good as the best expert:<br>$$<br>    \min_{i \in [n] } L_i + 2 \sqrt{ T \ln n },<br>$$</p>
<p>where $L_i \doteq \sum_{t \in [T] } l_i^t$ is the loss of expert $i$. This implies that the average expected loss converges at a rate of $\sqrt \frac{1}{T}$ to the best one.  </p>
<blockquote>
<p>Algorithm 4. <strong>Multiplicative Weight Update</strong>  </p>
<ol>
<li>Set $w_i \leftarrow 1, \forall i \in [n].$    </li>
<li>For $t \leftarrow 1$ to $T$   </li>
<li>$\qquad$ Let $W = \sum_{i \in [n] } w_i$.   </li>
<li>$\qquad$ Follow action $a_i^t$ with probability $w_i / W$. </li>
<li>$\qquad$ For each expert $i$:</li>
<li>$\qquad\qquad$ $w_i \leftarrow w_i \cdot (1 - \epsilon l_i^t)$</li>
</ol>
</blockquote>
<p><strong><em>Analysis.</em></strong> Let $l_A^t$ be the loss of the algorithm at round $t$ and $L_A \doteq \sum_{t \in [T] } l_A^t$. Let $w_i^t$ be the weight of expert $i$ and $W^t$ be the sum of weights at round $t$. Then<br>$$<br>\mathbb{E} [ l_A^t ] = \sum_{i \in [n] } \frac{ \epsilon w_i^t l_i^t }{ W^t }.<br>$$</p>
<p>By the update rule of the $w_i$’s, we see<br>$$<br>W^{t + 1} = \sum_{i \in [n] } w_i^t (1 - \epsilon l_i^t) = W^t ( 1 - \epsilon \mathbb{E} [ l_A^t ] ) \le W^t \exp( - \epsilon \mathbb{E} [ l_A^t ] ).<br>$$</p>
<p>By induction, we can write<br>$$<br>W^T \le W^1 \exp( - \sum_{t \in [T] } \epsilon \mathbb{E} [ l_A^t ] ) = n \cdot \exp( - \epsilon \mathbb{E} [ L_A ] ).<br>$$</p>
<p>To upper bound $\mathbb{E} [ L_A ]$, we try to lower bound the value of $n \cdot \exp( - \epsilon \mathbb{E} [ L_A ] )$. We uses that $\forall i \in [n]$,<br>$$<br>    \prod_{t \in [T] } (1 - \epsilon l_i^t) = w_i^T \le W^T.<br>$$</p>
<p>Using the fact that $\ln(1 - \epsilon ) \ge \epsilon - \epsilon^2$ for $0 &lt; \epsilon &lt; 0.5$, we know that $\forall i \in [n]$, </p>
<p>$$<br>\exp \left( - \sum_{i \in [T] } \epsilon l_i^t  - \sum_{i \in [T] } (\epsilon l_i^t)^2 \right) \le n \cdot \exp ( - \epsilon \mathbb{E} [ l_A^t ] ).<br>$$</p>
<p>Taking the log, we get<br>$$<br>\mathbb{E} [ l_A^t ] \le \frac{1}{\epsilon } \ln n  + L_i + \epsilon \sum_{i \in [T] } (l_i^t)^2.<br>$$</p>
<p>There are various ways to upper bound $\sum_{i \in [T] } (l_i^t)^2$. Naively, this is at most $T$. Hence,<br>$$<br>\mathbb{E} [ l_A^t ] \le \frac{1}{\epsilon } \ln n  + L_i + \epsilon T.<br>$$</p>
<p>Setting $\epsilon = \sqrt{ \frac{ \ln n}{T} }$, we get<br>$$<br>\mathbb{E} [ l_A^t ] \le L_i + 2 \sqrt{ T \ln n}.<br>$$</p>
<p>$\blacksquare$</p>
<h4 id="Last-Updated-Date-Dec-14th-2020"><a href="#Last-Updated-Date-Dec-14th-2020" class="headerlink" title="Last Updated Date: Dec 14th, 2020."></a>Last Updated Date: <strong>Dec 14th, 2020</strong>.</h4><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] Aaron Roth, “The Polynomial Weights Algorithm”, NETS 412: Algorithmic Game Theory, </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/03/24/Monotone-Class/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/24/Monotone-Class/" class="post-title-link" itemprop="url">Monotone Class</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-24 16:06:49" itemprop="dateCreated datePublished" datetime="2019-03-24T16:06:49+11:00">2019-03-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-04-02 02:14:05" itemprop="dateModified" datetime="2019-04-02T02:14:05+11:00">2019-04-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Theorem"><a href="#Theorem" class="headerlink" title="Theorem"></a>Theorem</h1><p>If $M$ is a monotone class and $R \subset M$ is a ring, then $M$ contains the $\sigma$-ring $\sigma(R)$ generated by $R$ and use the following lemma.</p>
<p><strong>Proof:</strong>  </p>
<p>Consider the monotone class $M_0$ generated by $R$. By definition $M_0 \subset M$. The goal is show that $M_0$ is a ring that contains $R$.</p>
<h2 id="Lemma"><a href="#Lemma" class="headerlink" title="Lemma"></a>Lemma</h2><p>If $M_0$ is a ring, then it must be a $\sigma$-ring.  </p>
<p><em>Pf:</em> For each countable collection of sets $( E_n )$, $\cup_{n} E_n = \cup_{n} (\cup_{k = 1}^n E_k)$. Denote $F_n = \cup_{k = 1}^n E_n$, and $F = \cup_{n} E_n$. Clearly $F_n \uparrow F$, which implies that $F \subset M_0$.  </p>
<p>$\blacksquare$  </p>
<p>It immediately follows that $M_0 \supset \sigma(R)$.<br>Indeed, as $\sigma(R)$ itself is a monotone class and $M_0$ is the smallest monotone class that contains $R$, we have $\sigma(R) \supset M_0$. It concludes that $M_0 = \sigma(R)$.  </p>
<p>To show $M_0$ is a ring, we need to verify that $E, F \in M_0$, $E \cup F = M_0$ and $E \setminus F \in M_0$.  </p>
<p>Define $S_E = { F \in M_0 : E \cup F \in M_0, E \setminus F \in M_0 }$, the collection of sets that satisfies the conditions. Note that $S_E$ is a monotone class.  </p>
<ol>
<li><p>$(F_n) \subset S_E$, and $(F_n) \uparrow F$, then $E \cup F = E \cup [\cup_n F_n] = \cup_n [E \cup F_n]$. By definition of $S_E$, $E \cup F_n \in M_0$. As $F_n \uparrow$ and $M_0$ is monotone, $E \cup F \in M_0$. Hence $F \in M_0$.  </p>
</li>
<li><p>$(F_n) \subset S_E$, and $(F_n) \uparrow F$, then $E \setminus F = E \setminus [\cup_n F_n] = \cap_n [E \cap F_n] \in M_0$.  </p>
</li>
</ol>
<p>We claim that for each $E \in M_0$, it holds that $F \in S_E$ for any $F \in M_0$, i.e., $M_0 \subset S_E$. But this is equivalent to show $E \in S_F$.  Since $M_0$ is the smallest monotone class that contains $R$, it suffices to prove $R \subset S_F$. We need to utilize the following observation.  </p>
<p><em>Let $O \subset R$, then $S_O \supset R$, which implies that $S_O \supset M_0$, as $S_O$ is a monotone class.</em></p>
<p>Therefore, $\forall F \in M_0$, $R \subset S_F$.  </p>
<p>$\blacksquare$.  </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/03/21/Partial-Derivatives/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/21/Partial-Derivatives/" class="post-title-link" itemprop="url">Partial Derivatives</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-21 19:14:45" itemprop="dateCreated datePublished" datetime="2019-03-21T19:14:45+11:00">2019-03-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-01-08 14:53:45" itemprop="dateModified" datetime="2020-01-08T14:53:45+11:00">2020-01-08</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Theorem-The-Mix-Derivative"><a href="#Theorem-The-Mix-Derivative" class="headerlink" title="Theorem The Mix Derivative"></a>Theorem The Mix Derivative</h1><p><em>Theorem (Symmetry of Second Partial Derivative)</em>: If the function $f : R^2 \rightarrow R$ has continuous derivatives $f_{xy}$ and $f_{yx}$ at some point $(a, b)$, then<br>$$<br>f_{xy}(a, b) = f_{yx}(a, b)<br>$$</p>
<p><strong>Proof:</strong></p>
<p>W.L.O.G, for $h &gt; 0, k &gt; 0$, define<br>$$<br>\Delta = [f(a + h, b + k) - f(a + h, b)] - [f(a, b + h) - f(a, b)]<br>$$</p>
<p>Define $F(x) = f(x, b + k) - f(x, b)$, which is continuous and differentiable (since $f_x$ exists on $R$). By mean value theorem, $\exists a_1 \in [a, a + h]$ for which  </p>
<p>$$<br>\Delta = F(a + h) - F(a) = F’(a_1) h = [f_x(a_1, b + k) - f_x(a_1, b)] h<br>$$</p>
<p>Apply again mean value theorem, $\exists b_1 \in [b, b + k]$, s.t.,  </p>
<p>$$<br>\begin{aligned}<br>\Delta &amp;= f_{xy}(a_1, b_1) k h<br>\end{aligned}<br>$$</p>
<p>We can also define $G(y) = f(a + h, y) - f(a, y)$ and rewrite  </p>
<p>$$<br>\Delta = G(b + h) - G(b)<br>$$</p>
<p>Similarly, by applying mean value theorem twice, $\exists b_2 \in [b, b + k], a_2 \in [a, a + h]$, s.t,  </p>
<p>$$<br>\Delta = f_{yx}(a_2, b_2)hk<br>$$</p>
<p>Putting together  </p>
<p>$$<br>\Delta = f_{xy}(a_1, b_1) k h = f_{yx}(a_2, b_2)hk<br>$$</p>
<p>Because both $f_{xy}$ and $f_{yx}$ are continuous, as $h \rightarrow 0$ and $k \rightarrow 0$, $f_{xy}(a_1, b_1) \rightarrow f_{xy}(a, b)$ and $f_{yx}(a_2, b_2) \rightarrow f_{yx}(a, b)$, as desired.  </p>
<p>$\blacksquare$.  </p>
<h1 id="Theorem-The-Increment"><a href="#Theorem-The-Increment" class="headerlink" title="Theorem The Increment"></a>Theorem The Increment</h1><p>If function $f : R^2 \rightarrow R$ has continuous derivative $f_x$ and $f_y$ at some point $(a, b)$, then</p>
<p>$$<br>f(a + h, b + k) - f(a, b) = f_x(a, b) h + f_y(a, b)k + \epsilon_1 h + \epsilon_2 k<br>$$</p>
<p>where $\epsilon_1, \epsilon_2 \rightarrow 0$ as $h,k \rightarrow 0$.</p>
<p><strong>Proof:</strong>  </p>
<p>By mean value theorem, $\exists a_1$ between $a$ and $a + h$, $\exists b_1$ between $b$ and $b + k$, s.t.,  </p>
<p>$$<br>\begin{aligned}<br>f(a + h, b + k) - f(a, b)<br>&amp;= f(a + h, b + k) - f(a + h, b) + f(a + h, b) - f(a, b) \<br>&amp;= f_y(a + h, b_1)k + f_x(a_1, b)h<br>\end{aligned}<br>$$</p>
<p>Define $\epsilon_1 = f_x(a_1, b) - f_x(a, b)$ and $\epsilon_2 = f_y(a + h, b_1) - f_y(a, b)$, we infer that  </p>
<p>$$<br>f(a + h, b + k) - f(a, b) = f_x(a, b) h + f_y(a, b)k + \epsilon_1 h + \epsilon_2 k<br>$$</p>
<p>The claim $\epsilon_1, \epsilon_2 \rightarrow 0$ as $h,k \rightarrow 0$ results from the continuity of $f_x$ and $f_y$.  </p>
<p>$\blacksquare$.  </p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol>
<li>George B. Thomas, Jr., Maurice D. Weir, Joel Hass, <em>THOMAS’ CALCULUS</em></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/03/19/Lebesgue-s-Theorem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/19/Lebesgue-s-Theorem/" class="post-title-link" itemprop="url">Lebesgue's Theorem</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-19 22:55:49" itemprop="dateCreated datePublished" datetime="2019-03-19T22:55:49+11:00">2019-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-03-22 19:39:19" itemprop="dateModified" datetime="2019-03-22T19:39:19+11:00">2019-03-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Lebesgue showed that a striking result that a monotone function is differentiable almost everywhere on an interval. We begin the discussion from a key concept, Vitali Cover.  </p>
<h1 id="Definition-Vitali-Cover"><a href="#Definition-Vitali-Cover" class="headerlink" title="Definition Vitali Cover"></a>Definition Vitali Cover</h1><ol>
<li>$F:$ a collection of closed, bounded non-degenerate(of positive length) intervals.  </li>
<li>$E:$ a set.  </li>
<li>Then $F$ is a Vitali cover of $E$ if $\forall x \in E$, $\forall \epsilon &gt; 0$, $\exists$ interval $I \in F$, s.t., $x \in I$ and $\mu(I) &lt; \epsilon$.  </li>
</ol>
<h1 id="Theorem-Vitali-Covering-Lemma"><a href="#Theorem-Vitali-Covering-Lemma" class="headerlink" title="Theorem Vitali Covering Lemma"></a>Theorem Vitali Covering Lemma</h1><ol>
<li><p>$E$ a set of finite outer measure.  </p>
</li>
<li><p>$F$ a Vitali cover of $E$.  </p>
</li>
<li><p>$\forall \epsilon &gt; 0$, $\exists$ a finite disjoint collection of intervals ${ I_k } _{k = 1}^n$ of $F$ for which  </p>
<p>$$<br>\mu^*(E \setminus \cup_{k = 1}^n I_k) \le \epsilon<br>$$</p>
</li>
</ol>
<p><strong>Proof:</strong> Since $E$ is of finite outer measure, there is a open set $O$ of finite measure that contains $E$ for which $\mu(O) \le \mu^*(E) + \epsilon$. For each $x \in E$, we have $x \in O$. As $O$ is open, $\exists \epsilon &gt; 0$, s.t., $N_\epsilon(x) \subset O$. Because $F$ is a Vitali cover of $E$, there exists an interval $I$ that contains $x$ with length $\mu(I) &lt; \epsilon / 2$. This means $I \subset N_\epsilon(x) \subset O$. Therefore, we may assume that $F$ contains only intervals within $O$.  </p>
<p>Then we are going to select a disjoint countable (either finite or infinite) sub-collection of intervals from $F$. Suppose $n$ is a natural number and the collection ${ I_k } <em>{k = 1 }^n$ of $F$ has been chosen. If ${ I_k } _{k = 1}^n$ covers $E$, then we are done. Otherwise, we pick a new interval $I</em>{k + 1}$ from $F$ according to two criteria:</p>
<ol>
<li>$I_{k + 1}$ should be disjoint with the collection ${ I_k }<em>{k = 1}^n$, i.e., $I</em>{k + 1} \cap (\cup_{k = 1}^n I_k) = \emptyset$.  </li>
<li>The length of $I_{k + 1}$ should be as large as possible.  </li>
</ol>
<p>Such $I_{k + 1}$ always exists. Let $x \in E \setminus \cup_{k = 1}^n I_k$. As $\cup_{k = 1}^n I_k$ is closed, $O \setminus \cup_{k = 1}^n I_k$ is open.  Therefore, there is an interval in $F$ that is inside that open set and contains $x$. We can now define the nonempty collection of such intervals in $F$ as $F_n$:<br>$$<br>F_n \doteq { I \in F : I \cap (\cup_{k = 1}^n I_k ) = \emptyset }<br>$$</p>
<p>As all interval in $F_n$ are contained in $O$ with finite measure,<br>$$<br>\alpha_n \doteq \sup_{I \in F_n} \mu(I)<br>$$<br>exists and is a real number. Although we may not be able to find an interval $I$ that achieves the maximum length, i.e., $\mu(I) = \alpha_n$, it suffices to find one that is “a little bit” shorter. The criteria is not unique and for our proof we choose an $I_{k + 1}$ of measure $\mu(I_{k + 1}) &gt; \alpha_n / 2$.  </p>
<p>Now ${ I_k }<em>{k = 1}^\infty$ is a disjoint collection whose union is within $O$. By the countable additivity and monotonicity of measure,<br>$$<br>\mu(\cup</em>{k = 1}^\infty I_k) = \sum_{k = 1}^\infty \mu( I_k) \le \mu(O) \le \mu(E) + \epsilon<br>$$</p>
<p>We infer that $\mu(I_k) \rightarrow 0$. Moreover, ${ I_k }_{k = 1}^\infty$ has the following property: for each interval $I \in F$ that contains an element $x \in E$, either it belongs to or overlaps with ${ I_k }_{k = 1}^\infty$. Otherwise, $I$ is disjoint with ${ I_k }_{k = 1}^\infty$. But the selection process guarantees that $\mu(I) \le 2 \mu(I_k)$ for all $k$, which implies $\mu(I) = 0$, a contradiction (any $I \in F$ must have positive length).  </p>
<p>We claim that for any natural number $n$, it holds that<br>$$<br>E \setminus \cup_{k = 1}^n I_k \subset \cup_{k = n + 1}^\infty 5 * I_k<br>$$</p>
<p>As before, for $x \in E \setminus \cup_{k = 1}^n I_k$, $\exists \ I \in F_n$ for which $x \in I$. Then $I$ must belongs to or intersect with $\cup_{k = n + 1}^\infty I_k$. Let $m$ be the first natural number that $I_{m} \cap I \neq \emptyset$. By the selection process of $I_m$, $\mu(I_m) \ge \mu(I) / 2$. This means $I \subset 5 * I_m$.  </p>
<p>Let $\epsilon &gt; 0$, $\exists N &gt; 0$, s.t., $\sum_{k = N}^\infty \mu(I_k) &lt; \epsilon / 5$. This choice of $N$, together with the fact that $E \setminus \cup_{k = 1}^n I_k \subset  (\cup_{k = n + 1}^\infty 5 * I_k)$, establishes the desired result.</p>
<p>$\blacksquare$</p>
<h1 id="Lemma"><a href="#Lemma" class="headerlink" title="Lemma"></a>Lemma</h1><p>Let $f : [a, b] \rightarrow R$ be a non-decreasing function, then for each $\alpha &gt; 0$,<br>$$<br>\alpha \mu^* ({ x \in [a, b] : \bar D f(x) \ge \alpha }) \le f(b) - f(a)<br>$$</p>
<p>and  </p>
<p>$$<br>\mu^*({ x \in (a, b) : \bar D f(x) = \infty }) = 0<br>$$</p>
<p><strong>Proof:</strong><br>Define $E = { x \in [a, b] : \bar D f(x) \ge \alpha }$. For each $0 &lt; \lambda &lt; \alpha$, let $F_{\lambda} = { [c, d] \subset [a, b], f(d) - f(c) \ge \lambda (d - c) }$. Since $\bar D f \ge \alpha$ on $E$, $F$ is a Vitali cover of $E$.  By Vitali Covering Theorem, there is a finite disjoint sub-collection of intervals ${ [c_k, d_k] }<em>{k = 1}^n$ of $F$ for which<br>$$<br>\mu^*(E \setminus \cup</em>{k = 1}^n I_k) \le \epsilon<br>$$</p>
<p>Therefore,  </p>
<p>$$<br>\begin{aligned}<br>\mu^*(E)<br>&amp;\le \mu(\cup_{k = 1}^n I_k) + \mu^*(E \setminus \cup_{k = 1}^n I_k) \<br>&amp;\le \mu(\cup_{k = 1}^n I_k) + \epsilon \<br>&amp;= \sum_{k = 1}^n \mu(I_k) + \epsilon \<br>&amp;= \sum_{k = 1}^n (d_k - c_k) + \epsilon \<br>&amp;\le \sum_{k = 1}^n \frac{1}{\lambda} [f(d_k) - f(c_k)] + \epsilon \<br>&amp;\le \frac{1}{\lambda} [f(d) - f(c)] + \epsilon<br>\end{aligned}<br>$$</p>
<p>Taking the limit of $\lambda \rightarrow \alpha$, and $\epsilon \rightarrow 0$, we proves</p>
<p>$$<br>\alpha \mu^* (E) \le f(d) - f(c)<br>$$</p>
<p>$\blacksquare$.  </p>
<h1 id="Theorem-Lebesgue"><a href="#Theorem-Lebesgue" class="headerlink" title="Theorem Lebesgue"></a>Theorem Lebesgue</h1><p>If a function $f$ is monotone on a interval $(a, b)$, then it is differentiable almost everywhere.  </p>
<p><strong>Proof:</strong><br>Without lost of generality, assume $f$ is increasing. The set of non-differentiable points can be written as<br>$$<br>E = \cup_{\alpha, \beta \in Q} { x \in (a, b) : \bar D f(x) \ge \alpha &gt; \beta &gt; \underline D f(x) }<br>$$</p>
<p>where $Q$ is the set of rational numbers. It suffices to consider just $E_{\alpha, \beta} = { x \in (a, b) : \bar D f(x) \ge \alpha &gt; \beta &gt; \underline D f(x) }$. We prove that $E_{\alpha, \beta}$ has zero measure and therefore by countable additivity $E$ has measure zero.  </p>
<p>For fix $E_{\alpha, \beta}$, choose an open set $O$ for which $E_{\alpha, \beta} \subset O \subset (a, b)$ and $\mu^*(O \setminus E_{\alpha, \beta}) \le \epsilon$. Let $F_{\beta} = { [c, d] \subset O, f(d) - f(c) \le \beta (d - c) }$ be a Vitali cover of $E_{\alpha, \beta}$. By Vitali Covering Theorem, there is a finite disjoint sub-collection of intervals ${ [c_k, d_k] }<em>{k = 1}^n$ for which<br>$$<br>\mu^*(E</em>{\alpha, \beta} \setminus \cup_{k = 1}^n I_k) \le \epsilon<br>$$</p>
<p>Therefore,  </p>
<p>$$<br>\begin{aligned}<br>\mu^*(E_{\alpha, \beta})<br>&amp;\ge \mu(O) - \epsilon \<br>&amp;\ge \mu(\cup_{k = 1}^n I_k) - \epsilon \<br>&amp;= \sum_{k = 1}^n \mu(I_k) - \epsilon \<br>&amp;= \sum_{k = 1}^n (d_k - c_k) - \epsilon \<br>&amp;\ge \sum_{k = 1}^n \frac{1}{\beta} [f(d_k) - f(c_k)] - \epsilon \<br>\end{aligned}<br>$$</p>
<p>On the other hand, for each interval $[c_k, d_k]$, by the previous lemma,<br>$$<br>f(d_k) - f(c_k) \ge \alpha \mu({x \in [c_k, d_k] \cap E_{\alpha, \beta} })<br>$$</p>
<p>Together with sub-additivity of outer measure,  </p>
<p>$$<br>\begin{aligned}<br>\mu^*(E_{\alpha, \beta})<br>&amp;\le \mu^*(\cup_{k = 1}^n I_k \cap E_{\alpha, \beta}) + \mu^*(E_{\alpha, \beta} \setminus \cup_{k = 1}^n I_k) \<br>&amp;\le \mu(\cup_{k = 1}^n I_k \cap E_{\alpha, \beta}) + \epsilon \<br>&amp;\le \sum_{k = 1}^n \frac{1}{\alpha} [f(d_k) - f(c_k)] + \epsilon \<br>\end{aligned}<br>$$</p>
<p>Combined, we obtained<br>$$<br>\sum_{k = 1}^n \frac{1}{\beta} [f(d_k) - f(c_k)] - \epsilon  \le \mu^*(E_{\alpha, \beta}) \le \sum_{k = 1}^n \frac{1}{\alpha} [f(d_k) - f(c_k)] + \epsilon<br>$$</p>
<p>By arbitrariness of $\epsilon$, it holds that<br>$$<br>\beta \mu^*(E_{\alpha, \beta}) \ge \alpha \mu^*(E_{\alpha, \beta})<br>$$</p>
<p>It concludes that $\mu^*(E_{\alpha, \beta}) = 0$.  </p>
<p>$\blacksquare$.  </p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol>
<li>H.L.Royden, P.M. Fitzpatrick, <em>Real Analysis</em></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/03/18/Fundamental-Theorem-of-Calculus/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/18/Fundamental-Theorem-of-Calculus/" class="post-title-link" itemprop="url">Fundamental Theorem of Calculus</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-18 20:03:31" itemprop="dateCreated datePublished" datetime="2019-03-18T20:03:31+11:00">2019-03-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-03-22 19:45:50" itemprop="dateModified" datetime="2019-03-22T19:45:50+11:00">2019-03-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>The relation between integration and differentiation constitutes the key study of calculus.</p>
<h1 id="Fundamental-Theorem-of-Calculus"><a href="#Fundamental-Theorem-of-Calculus" class="headerlink" title="Fundamental Theorem of Calculus"></a>Fundamental Theorem of Calculus</h1><ol>
<li>If $f : [a, b] \rightarrow$ is bounded and Riemann integrable,  and $F(x) = \int_a^x f(t) \ dt$ for $x \in [a, b]$, then $F(x)$ is uniformly continuous and $F’(x)$ exists for all $x$ where $f(x)$ is continuous and $F’(x) = f(x)$.  </li>
<li>If $F: [a, b] \rightarrow R$ is differentiable and $f: [a, b] \rightarrow R$ is integrable. Suppose $F’(x) = f(x)$ for all $x \in [a, b]$, then</li>
</ol>
<p>$$<br>F(b) - F(a) = \int_a^b f(t) \ dt<br>$$</p>
<p><strong>Remark:</strong></p>
<ol>
<li><p>Claim one require the condition that $f$ is bounded. Can we omit the condition?  </p>
</li>
<li><p>The condition $f$ is integrable is necessary.  </p>
</li>
</ol>
<p><strong>Proof:</strong>  </p>
<ol>
<li><p>As $f$ is bounded, we assume that $\sup_{t \in [a, b]} |f(t)| \le M$. For any $x \in  [a, b]$ and $x + h \in [a, b]$,  </p>
<p> $$<br> \left| F(x + h) - F(x) \right| = \left| \int_x^{x + h} f(t) \ dt \right| \le M|h|<br> $$  </p>
<p> This show that $F(x)$ is uniformly continuous.</p>
<p> Now, assume that $f(x)$ is continuous at point $x$. $\forall \epsilon &gt; 0$, $\exists \delta &gt; 0$, s.t., $\forall t \in (x \pm \delta)$, $|f(t) - f(x)| \le \epsilon$. We see that  </p>
<p> $$<br> \begin{aligned}<br> \left| F(x + h) - F(x) - f(x) h  \right|<br> &amp;= \left| \int_x^{x + h} f(t) \ dt - \int_x^{x + h} f(x) \ dt \right| \<br> &amp;= \left| \int_x^{x + h} [f(t) - f(x)] \ dt \right| \<br> &amp;\le \int_x^{x + h} \left| f(t) - f(x) \right| \ dt \<br> &amp;\le \epsilon h<br> \end{aligned}<br> $$</p>
<p> As desired.  </p>
</li>
<li><p>For partition $P = { a = x_0 &lt; x_1 &lt; x_2 &lt; … &lt; x_n = b }$ of $[a, b]$,  apply the mean value theorem to $F$ on a sub-interval.<br> $$<br> F(x_k) - F(x_{k - 1}) = F’(t_k) (x_k - x_{k -1})  \quad t_k \in [x_{k - 1}, x_k] \quad \forall \ 1 \le k \le n,<br> $$<br> Let $U(f, P), L(f, )$ be the upper sum and lower sum of the partition respectively,<br> $$<br> \begin{aligned}<br> F(b) - F(a)<br> &amp;= \sum_{k = 1}^n F(x_k) - F(x_{k - 1}) \<br> &amp;= \sum_{k = 1}^n F’(t_k) (x_k - x_{k -1}) \<br> &amp;= \sum_{k = 1}^n f(t_k) (x_k - x_{k -1}) \<br> &amp;\in [L(f, P), U(f, P)]<br> \end{aligned}<br> $$<br> This is independent of the choice of $P$. Taking the limit of upper sum and lower sum, we conclude that $F(b) - F(a) \in [\sup_P L(f, P), \inf_P U(f, P)] = \left[ \int_a^b f(t) \ dt, \int_a^b f(t) \ dt \right]$. </p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/03/14/Radon-Nikodym-Theorem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/14/Radon-Nikodym-Theorem/" class="post-title-link" itemprop="url">Radon Nikodym Theorem</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-14 20:17:37" itemprop="dateCreated datePublished" datetime="2019-03-14T20:17:37+11:00">2019-03-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-03-22 00:07:56" itemprop="dateModified" datetime="2019-03-22T00:07:56+11:00">2019-03-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>We consider a measure space $(X, \Omega, \mu)$, where $X$ is a set of elements, $\Omega$ is a collection of measurable sets and $\mu : \Omega \rightarrow R$ a $\sigma$-finite measure defined on $\Omega$.  </p>
<h1 id="Theorem-The-Radon-Nikodym-Theorem"><a href="#Theorem-The-Radon-Nikodym-Theorem" class="headerlink" title="Theorem. The Radon-Nikodym Theorem"></a>Theorem. The Radon-Nikodym Theorem</h1><p>Let $\nu$ be a $\sigma$-finite signed measure with domain $\Omega$ and absolutely continuous with respect to $\mu$ ($\nu \ll \mu$). Then there exists a real-valued measurable function $f$ on $\Omega$ such that<br>$$<br>\nu(E) = \int_E f \ d \mu<br>$$<br>for every measurable set $E$ for which $|\nu|(E) &lt; \infty$. If $g$ is another function such that $\nu(E) = \int_E g \ d \mu$ for any measurable set $E$ for which $|\nu|(E) &lt; \infty$, then $f = g \ a.e.$ with respect to $\nu$.  </p>
<p><strong>Proof:</strong></p>
<p>Since both $\mu$ and $\nu$ are $\sigma$-finite, it suffices to consider the case in which $\mu(X) &lt; \infty$ and $|\nu| (X) &lt; \infty$. Further, we may assume that $\nu$ is a measure, otherwise we can consider the Hahn decomposition of $\nu$ separately.</p>
<p>Define the collection of functions  </p>
<p>$$<br>D = \left{ f \text{ is measurable and } \nu(E) \ge \int_E f \ d \mu \quad \forall E \in \Omega \right}<br>$$</p>
<p>Note that $D$ is non-empty, since at least $f \equiv 0$ satisfies the conditions and belongs to $D$. Consider the supremum of integrals of function in $D$  </p>
<p>$$<br>\left( \alpha \doteq \sup_{f \in D} \int f \ d \mu \right) \le \nu(X)<br>$$</p>
<p>Then $\exists { g_n } \subset D$, a sequence of functions whose integral approaches the supremum</p>
<p>$$<br>\lim_n \int g_n \ d \mu  = \alpha<br>$$<br>Define $f_n = \max_{1 \le i \le n} g_i$. It has the following properties:  </p>
<ol>
<li><p>$f_n \in D$. To verify this, for any measurable set $E$, consider $F_{n,i} = { x \in E : f_n(x) = g_i(x) }$. Rewrite $E_{n, i} = F_{n,i} \setminus \cup_{j = 1}^{n - 1} F_{n,j}$ as a collection of mutually exclusive sets. For $1 \le k \le n$,  </p>
<p> $$<br> \begin{aligned}<br> \int_E f_n \ d \mu<br> &amp;= \sum_{i = 1}^n \int_{E_{n,i}} f_n \ d \mu  \<br> &amp;= \sum_{i = 1}^n \int_{E_{n,i}} g_i \ d \mu  \<br> &amp;\le \sum_{i = 1}^n \nu(E_{n,i}) \<br> &amp;= \nu( \cup_{i = 1}^n E_{n,i} ) \<br> &amp;= \nu(E)<br> \end{aligned}<br> $$</p>
</li>
<li><p>${ f_n }$ is monotone increasing and<br> $$<br> \alpha = \lim_k \int g_k \ d \mu \le \lim_n \int f_n \ d \mu \le \alpha<br> $$<br> We must have $\lim_n \int f_n \ d \mu = \alpha$.  </p>
</li>
</ol>
<p>Let $f = \lim_n f_n$. According to Monotone Convergence Theorem, $f$ is integrable<br>$$<br>\alpha = \lim_n \int f_n \ d \mu= \int f \ d \mu<br>$$</p>
<p>It is left to show that $\lambda(E) = \int_E f$ for each measurable set $E$. Define function $\lambda : \Omega \rightarrow R$ as  </p>
<p>$$<br>\lambda(E) = \nu(E) - \int_E f \ d \mu<br>$$</p>
<p>We complete the proof by showing that $\lambda(E) \equiv 0$.  </p>
<p>It is easy to verify that $\lambda$ is a measure ($\lambda \ge 0$) as $\nu(E) \ge \int_E f d \mu$. Further, $\int_E f \ d \mu \ll \mu$ and $\nu \ll \mu$ imply that $\lambda \ll \mu$.  </p>
<p>Suppose $\lambda \ne 0$. By assumption $\mu(X) &lt; \infty$, then there exists $\epsilon &gt; 0$, such that $\lambda(X) - \epsilon \mu(X) &gt; 0$. Let ${ A, B}$ be the Hahn decomposition of $\lambda - \epsilon \mu$ such that $A$ is positive. Let $g = f + \epsilon \chi_{A}$. It satisfies</p>
<ol>
<li><p>$g \in D$, since $\forall E \in \Omega$,<br>$$<br>\lambda(E) - \int_E g \ d  \mu = \lambda(E) - \int_E f \ d \mu - \int_E \epsilon \chi_{A} \ d \mu \ge 0<br>$$</p>
</li>
<li><p>$\int g \ d \mu \ge \alpha$,<br> $$<br> \int g \ d \mu = \int f + \epsilon \chi_{A} \ d \mu = \int f \ d \mu + \int \epsilon \chi_A \ d \mu = \alpha + \epsilon \mu(A) \ge \alpha<br> $$</p>
</li>
</ol>
<p>If follows that $\mu(A) = 0$. Now $0 &lt; (\lambda - \epsilon \mu)(X) = (\lambda - \epsilon \mu)(A) + (\lambda - \epsilon \mu)(B) = 0 + (\lambda - \epsilon \mu)(B) \le 0$. Contradiction. We thus have proved that $\lambda = 0$.  </p>
<p>$\blacksquare$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/03/03/Integral/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/03/Integral/" class="post-title-link" itemprop="url">Integral</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-03 21:15:57" itemprop="dateCreated datePublished" datetime="2019-03-03T21:15:57+11:00">2019-03-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-03-14 18:47:35" itemprop="dateModified" datetime="2019-03-14T18:47:35+11:00">2019-03-14</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>We consider a measure space $(X, \Omega, \mu)$, where $X$ is a set of elements, $\Omega$ is a collection of measurable sets and $\mu : \Omega \rightarrow R$ a measure defined on $\mu$. Note that by definition $\Omega$ is a $\sigma$ algebra and $\mu$ satisfies  </p>
<ol>
<li>(Zero element) $\mu(\emptyset) = 0​$,  </li>
<li>(Non negativity) $\mu(E) \ge 0​$ for all $E \in \Omega$,  </li>
<li>(Complete additivity) $\mu(\cup_{i = 1}^\infty E_i) = \sum_{i = 1}^\infty \mu(E_i)$ for a collection of mutually exclusive sets ${E_i : i \in \mathbf{N} }$.  </li>
</ol>
<h1 id="Definition-Simple-Function"><a href="#Definition-Simple-Function" class="headerlink" title="Definition. Simple Function"></a><strong>Definition.</strong> Simple Function</h1><p><em>A characteristic function $[ \cdot ] \rightarrow {0, 1}​$ is a function that takes value 1 if its argument is true and zero otherwise. A characteristic function $\chi_E : X \rightarrow {0, 1}​$ for a set $E \subset X​$ is denoted as $\chi_E \doteq [x \in E]​$</em>.</p>
<p><em>A simple function $f : X \rightarrow R$ is summation of finite terms:</em><br>$$<br>f = \sum_{i = 1}^n a_i \chi_{E_i}<br>$$</p>
<p><em>where ${E_1, E_2,… E_n }$ are measurable sets and constitute a partition of $X$, i.e., $\cup_{i = 1}^n E_i = X$ and $E_i \cap E_j = \emptyset$ for $i \neq j$</em>.  </p>
<h1 id="Definition-Integrable-Simple-Function"><a href="#Definition-Integrable-Simple-Function" class="headerlink" title="Definition. Integrable Simple Function"></a><strong>Definition.</strong> Integrable Simple Function</h1><p><em>A simple function $f=\sum_{i=1}^n a_i \chi_{E_i }$ is said to be integrable if $\mu(E_i ) &lt; \infty$ for all the indices $i$ for which $a_i \neq 0$, i.e., $a_i \neq 0 \rightarrow \mu(E_i) &lt; \infty$.<br>The integral of $f$ is the real number $\sum_{i=1}^n a_i \mu(E_i)$, where we agree to take $a_i \mu(E_i ) = 0$ for all the indices $i$ for which $a_i=0, \mu(E_i )=  \infty$. We denote this sum by</em><br>$$<br>\int f= \sum_{i=1}^n a_i \mu(E_i )<br>$$</p>
<h1 id="Theorem"><a href="#Theorem" class="headerlink" title="Theorem"></a><strong>Theorem</strong></h1><p><em>The integration is well defined and independent of the representation of $f$.</em>  </p>
<p><strong>Proof:</strong> Let $f = \sum_{i = 1}^n a_i \chi_{E_i}$  and $g = \sum_{j = 1}^m b_j \chi_{F_j}$. Suppose that $f \equiv g$, the goal is to show that $\int f = \int g$. Define $S_{ij} = E_i \cap F_j$. If $S_{ij} \neq \emptyset$, we must have $a_i = b_j$. To see this, let $s \in S_{i,j}$. Since ${E_1, E_2,… E_n }$ is a partition of $X$,only one of the value ${ \chi_{E_i} (s) : i \in [1, n] }$ takes value 1 and  $f(s) = \sum_{i = 1}^n a_i \chi_{E_i}(x) = a_i  \chi_{E_i}(x) = a_i$. Similarly, $g(s) = b_j$. We have $a_i = b_j$ as $f \equiv g$.  </p>
<p>Now, let $c_{i,j} = a_i = b_j$ if $S_{i,j} \neq \emptyset$ and $c_{i,j}= 0$ otherwise. Using the fact that ${ F_1, …, F_m }$ also constitutes a partition of $X$, we have $E_i = \cup_{j = 1}^m E_i \cap F_j$ for $i \in [1, n]$. By finite additivity of measure,<br>$$<br>\begin{aligned}<br>\int f<br>&amp;= \sum_{i=1}^n a_i \mu (E_i ) \<br>&amp;= \sum_{i=1}^n a_i \mu (\cup_{j=1}^m E_i \cap F_j) \<br>&amp;= \sum_{i=1}^n a_i \sum_{j = 1}^m \mu (E_i \cap F_j) \<br>&amp;= \sum_{i=1}^n \sum_{j=1}^m c_{i,j} \mu( S_{i,j} )<br>\end{aligned}<br>$$</p>
<p>By symmetry, we can show $\int g = \sum_{i=1}^n \sum_{j=1}^m c_{i,j} \mu( S_{i,j} )$, which implies that $\int f = \int g$, as desired. </p>
<p>NOTE: in the proof we see that $\sum_{i=1}^n \sum_{j=1}^m c_{i,j} \mu( S_{i,j} ) = \int f &lt; \infty$. It follows that $\mu(S_{i, j}) = \infty \rightarrow c_{i,j} = 0$</p>
<p>$\blacksquare​$</p>
<h1 id="Theorem-Integration-on-a-measurable-set"><a href="#Theorem-Integration-on-a-measurable-set" class="headerlink" title="Theorem.  Integration on a measurable set"></a><strong>Theorem.</strong>  Integration on a measurable set</h1><p><em>If $E$ is any measurable set and $f$ is an integrable simple function, then $\chi_E f \doteq \chi_{E} \sum_{i = 1}^n a_i \chi_{E_i}$ is also an integrable simple function.</em></p>
<p><strong>Proof:</strong><br>$$<br>\chi_E f = \chi_{E} \sum_{i = 1}^n a_i \chi_{E_i} = \sum_{i = 1}^n a_i \chi_{E_i \cap E}<br>$$<br>By monotonicity of measure, if $a_i \neq 0$, then $\mu(E_i \cap E) \le \mu(E_i) &lt; \infty$. Therefore, $\chi_E f$ is integrable.  </p>
<p>$\blacksquare​$</p>
<h1 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a><strong>Definition</strong></h1><p>The integration of $\chi_E f$ is abbreviated as<br>$$<br>\int_E f = \int \chi_E f<br>$$</p>
<p>Now we show some basic properties of simple integration. These properties really inherit from the non-negativity and complete additivity of measure $\mu$  </p>
<h1 id="Basic-Properties-of-Simple-Integrable-Functions"><a href="#Basic-Properties-of-Simple-Integrable-Functions" class="headerlink" title="Basic Properties of Simple Integrable Functions"></a><strong>Basic Properties of Simple Integrable Functions</strong></h1><p>Let $f=\sum_{i=1}^n a_i \chi_{E_i }$ and $g=\sum_{j=1}^m b_j \chi_{F_j }$ be two integrable simple functions, and $\alpha, \beta \in R$ two real values.</p>
<ol>
<li><p><em>Integrable simple functions forms a vector space, i.e., $\int \alpha f + \beta g =a \int f + \beta \int g​$</em><br> <strong>Proof:</strong><br> Define $S_{ij} = E_i \cap F_j​$. Now ${ S_{i,j} }​$ is a partition of $X​$. Let $c_{i,j} = a_i = b_j​$ if $S_{i,j} \neq \emptyset​$ and $c_{i,j}= 0​$ otherwise. Moreover, we have $c_{i,j} \neq 0 \rightarrow \mu(S_{i,j} ) = 0​$.<br> $$<br> \begin{aligned}<br> \alpha f + \beta g<br> &amp;= \alpha \sum_{i = 1}^n a_i \chi_{E_i} + \beta \sum_{j = 1}^m b_j \chi_{F_j} \<br> &amp;= \sum_{i,j} (\alpha + \beta) c_{i,j} \chi_{S_{i,j} } \<br> \int \alpha f + \beta g<br> &amp;= \sum_{i,j} (\alpha + β) c_{i,j} \mu(S_{i,j}) \<br> &amp;= \alpha \sum_{i,j} c_{i,j} \mu(S_{i,j} ) + β \sum_{i,j} c_{i,j} \mu( S_{i,j} ) \<br> &amp;= \alpha \int f + \beta \int g \qquad \qquad \qquad \qquad \qquad \blacksquare<br> \end{aligned}<br> $$</p>
</li>
<li><p><em>If $f \ge 0 \ a.e.$,  then $\int f \ge 0$.</em><br> <strong>Proof:</strong><br> Let $f = \sum_{i = 1}^n a_i \chi_{E_i}$. We claim that $a_i \mu(E_i) \ge 0$ for all indices $i$.<br> a. If $\mu(E_i) = \infty$, then $a_i = 0$, since $f$ is measurable.<br> b. If $\mu(E_i) &gt; 0$, then $a_i \ge 0$. Otherwise, we have $f &lt; 0$ on a set $E_i$ with positive measure, contradicting $f \ge 0 \ a.e.$.<br> c. If $\mu(E_i) = 0$, the claim is trivially true.<br> Therefore, $\int f = \sum_i a_i \mu(E_i ) \ge0$.<br> $\blacksquare$</p>
</li>
<li><p><em>If $f \ge g \ a.e$, then $\int f \ge \int g$.</em><br> <strong>Proof:</strong><br> a. $\int f-\int g=\sum_{i = 1}^n a_i \mu(E_i ) -\sum_{j = 1}^m b_j \mu(F_j ) = \sum_{i =1}^n \sum_{j =1 }^m (a_i - b_j ) \mu(E_i  \cap  F_j)$.<br> b. $a_i-b_j &lt; 0 \rightarrow \mu(E_i  \cap  F_j ) = 0$.  </p>
<p> NOTE: Another way to prove this is by defining $h \doteq f - g$ which if non-negative almost everywhere and use conclusion of (1).<br> $\blacksquare$</p>
</li>
<li><p><em>$|f|$ is an integrable simple function, and $|\int f|\le \int |f|$.</em><br> <strong>Proof:</strong><br> $|f|=\sum_i |a_i | \chi_{E_i }$. Therefore, $|a_i| ≠ 0  \rightarrow  \mu(E_i )=0$. $|f|$ is simple and integrable.<br> $$<br> \int|f| =\sum_i |a_i |\mu(E_i ) \ge|\sum_i a_i \mu(E_i ) |=\left| \int f \right| \qquad \blacksquare<br> $$</p>
</li>
<li><p><em>$\int|f+g | \le \int |f| + \int |g|$.</em><br> <strong>Proof:</strong><br> $\int|f+g| \le \int(|f|+|g|) =\int|f| +\int|g|. \qquad \blacksquare$</p>
</li>
<li><p><em>If $m \le f \le \Omega \ a.e.$ on a measurable set $E$ with $\mu(E) &lt; \infty$, then $m \mu(E) \le \int_E f \le \Omega \mu(E)$.</em><br> <strong>Proof:</strong><br> The condition $\mu(E) &lt; \infty$ ensures that $m \mu(E) &lt; \infty$.<br> a. $\int_E f=\sum_i a_i \mu(E_i  \cap  E)$<br> b. $a_i &lt; m  \rightarrow  \mu(E_i  \cap E) = 0  ⇒  \sum_i (a_i-m) \mu(E_i  \cap E) \ge0$, as desired.<br> The other side of the inequality can be proved by symmetry.  </p>
<p> NOTE: another way is to utilize that $\mu \chi_E$ is simple, integrable $\mu \chi_E \le f$ almost everywhere.<br> $\blacksquare$</p>
</li>
<li><p>If $f \ge 0,\ a.e.$, and if $E$ and $F$ are measurable sets with $E⊂F$, then      $\int_E f \le \int_F f$.<br> <strong>Proof:</strong><br> $\int_E f = \sum_i a_i \mu(E_i  \cap  E) \le \sum_i a_i \mu(E_i  \cap  F) =\int_F f$.<br> Then inequality holds since it is always true that $a_i \mu(E_i \cap E) \le a_i \mu(E_i  \cap  E)$<br> a. If $\mu(E_i \cap E) \le \mu(E_i \cap F) = \infty$, then $a_i = 0$.<br> b. If $0 &lt; \mu(E_i \cap E) \le \mu(E_i  \cap  E) &lt; \infty$, then $a_i \ge 0$.<br> c. If $0 = \mu(E_i \cap E) = \mu(E_i  \cap  E)$, then it is trivially true.  </p>
<p> NOTE: another way is to utilize that $\chi_E f \le \chi_F f$ almost everywhere.<br> $\blacksquare​$</p>
</li>
<li><p><em>If $F$ is a disjoint union $\cup_{m=1}^\infty F_n$ of measurable sets, then<br> $\int_F f=\sum_{m=1}^\infty \int_{F_m} f$.</em><br> <strong>Proof:</strong><br> This is a consequence of complete additivity of measure.<br> $$<br> \begin{aligned}<br> \int_F f<br> &amp;= \sum_{i=1}^n a_i \mu(E_i \cap F) \<br> &amp;=\sum_{i=1}^n  a_i \mu(E_i \cap  (\cup_{m=1}^\infty F_m ))  \<br> &amp;=\sum_{i=1}^n  a_i \mu(\cup_{m=1}^\infty E_i  \cap  F_m )  \<br> &amp;=\sum_{i=1}^n  a_i \sum_{m=1}^\infty \mu(E_i  \cap  F_m) &amp; \text{ by complete additivity of measure }\<br> &amp;=\sum_{i=1}^n  a_i   \lim_{k \rightarrow \infty} ⁡\sum_{m=1}^k \mu(E_i \cap F_m) \<br> &amp;= \lim_{k \rightarrow \infty} ⁡\sum_{i=1}^n   a_i \sum_{m=1}^k  \mu(E_i \cap F_m) &amp; \text{ exchange order of limit and finite summation} \<br> &amp;= \lim_{k \rightarrow \infty} ⁡ \sum_{m=1}^k  \sum_{i=1}^n   a_i \mu(E_i \cap F_m)  \<br> &amp;= \lim_{k \rightarrow \infty} ⁡\sum_{i=1}^k \int_{F_m} f \qquad \blacksquare<br> \end{aligned}<br> $$</p>
</li>
<li><p><em>If $F_1 \subset F_2 \subset F_3 \subset …​$ is a sequence of increasing  measurable sets and let $F = \cup_{n} F_n​$, then $\lim_n \int_{F_n} f = \int_F f​$.</em><br> <strong>Proof:</strong><br> Let $F_n’ = F_n - F_{n - 1}​$. The result follows immediately from the previous property.<br> $\blacksquare​$</p>
</li>
<li><p><em>If $F_1 \supset F_2 \supset F_3 \supset …$ is a sequence of decreasing  measurable sets and let $F = \cap_{n} F_n$, then $\lim_n \int_{F_n} f = \int_F f$.</em><br><strong>Proof:</strong><br>Let $f = \sum_{i = 1}^N a_i \chi_{E_i}$. It follow that for $a_i \neq 0$, we have $\mu(E_i \cap F_1) &lt; \infty$, hence $\lim_n \mu(E_i \cap F_n) = \mu(E_i \cap \lim_n F_n) = \mu (E_i \cap F)$, which implies that $\lim_n \int_{F_n} f = \int_F f$.<br><strong>Remark:</strong><br>We don’t even require that $\mu(F_1) &lt; \infty$.<br>$\blacksquare$  </p>
</li>
<li><p><em>Let $f = \sum_{i = 1}^n a_i \chi_{E_i}$ and define the support $N(f)$ of simple integrable function $f$ to be the set of elements with non-zero values $N(f) = { x \in X : f(x) \neq 0 } = \cup_{i, a_i \neq 0} E_i$, then $\mu( N(f) ) \le \infty$.</em><br><strong>Proof:</strong><br>Since $f$ is integrable, $a_i \neq 0$ implies $\mu(E_i) &lt; \infty$. Now<br>$$<br>\mu( N(F) ) = \sum_{1 \le i \le n, a_i \neq 0} \mu(E_i) &lt; \infty \qquad \qquad \blacksquare<br>$$</p>
</li>
</ol>
<p>With simple integrable functions as building blocks, we are ready to define integration for functions in general.  </p>
<p>Fist we introduce a notation of convergence we need in the following discussion.</p>
<h1 id="Definition-Cauchy-In-Mean"><a href="#Definition-Cauchy-In-Mean" class="headerlink" title="Definition. Cauchy In Mean"></a><strong>Definition.</strong> Cauchy In Mean</h1><p><em>A sequence ${ f_n }​$ of simple functions is called Cauchy in mean if</em><br>$$<br>\lim_{n, m} \int |f_n - f_m| = 0<br>$$</p>
<p>Cauchy in mean does not implies Cauchy almost everywhere. Consider the sequence of functions  </p>
<ol>
<li>$\chi_{[0, 1/2]}, \chi_{[1 / 2, 1]}$,  </li>
<li>$\chi_{ [0, 1 / 4 ] }, \chi_{ [1 / 4, 1 / 2] }, \chi_{ [ 1 / 2, 3 /  4 ] }, \chi_{ [3 / 4, 1] }$,  </li>
<li>…</li>
<li>$… \chi_{ [ i / 2^n, (i + 1) / 2^n ] } …,(i \in {0, 1, 2, …, 2^{n}  - 1 } )$</li>
</ol>
<p>They are Cauchy in mean but don’s Cauchy almost everywhere. But it is Cauchy in measure.  </p>
<h1 id="Theorem-1"><a href="#Theorem-1" class="headerlink" title="Theorem"></a><strong>Theorem</strong></h1><p><em>If a sequence ${ f_n }​$ of simple functions is Cauchy in mean, it is Cauchy in measure.</em>  </p>
<p><strong>Proof:</strong><br>Let $h_{n, m} = |f_n - f_m| ​$. As $f_n​$ and $f_m​$ are simple and integrable, $h_{n, m}​$ is  simple and integrable. Moreover, it is non-negative. We write it as $h_{n,m} = \sum_{j =1}^k b_j \chi_{F_j}​$, where $b_j \ge 0​$. For arbitrary positive number $\delta &gt; 0​$, $b_j \ge  \delta &gt; 0​$ implies that $\mu(F_j) &lt; \infty​$. Now<br>$$<br>\delta \cdot \mu( { x \in X: h_{n,m}(x) \ge \delta} ) = \sum_{1 \le j \le k, b_j \ge \delta} \delta \cdot \mu(F_j) \le  \sum_{1 \le j \le k, b_j \ge \delta} b_j \mu(F_j)  \le \int h_{n,m} = \int |f_n - f_m|<br>$$<br>Hence, $\mu( { x \in X: h_{n,m}(x) \ge \delta} ) \le \frac{ \int |f_n - f_m| }{ \delta }$. For any fix $\delta$, this can be arbitrary small as $n, m \rightarrow \infty$.<br>$\blacksquare$.  </p>
<p>NOTE: the converse is not true.  </p>
<h1 id="Example"><a href="#Example" class="headerlink" title="Example"></a><strong>Example</strong></h1><p>Consider this sequence of functions:<br>$$<br>{ n \cdot \chi_{[0, 1 / n] } : n \in \mathbf{N}         }<br>$$</p>
<p>It converges in measure to $f \equiv 0$. But $\int n \cdot \chi_{[0, 1 / n] } = 1$ for all $n$. $\lim_n \int n \cdot \chi_{[0, 1 / n] } \neq \int f$.  </p>
<p>The implication here is that we need additional condition more than converge in mean to define the integral for a general function $f​$. We need to connect the sequence ${ f_n }​$ with $f​$, the function we want to define integral. Can we say something like ${ f_n }​$ converges to $f​$ in mean, i.e., $\lim_n \int  |f_n - f| = 0​$. But we have not define integral of non-simple function yet. Here is how we establish the connection.  </p>
<h1 id="Definition-Integrable-Functions"><a href="#Definition-Integrable-Functions" class="headerlink" title="Definition. Integrable Functions"></a><strong>Definition.</strong> Integrable Functions</h1><p><em>An extended real-valued, measurable function $f$, on a measure space $(X, \Omega,  \mu)$ is said to be integrable if there exists a sequence ${ f_n }$ of integrable simple functions having the following properties:</em>  </p>
<ol>
<li>${ f_n }​$ <em>is a Cauchy sequence in the mean.</em>  </li>
<li>$\lim_{n} f_n (x) = f(x) \quad a.e.​$.</li>
</ol>
<p><em>The integral of $f​$ is defined to the number $\lim_{n} \int f_n​$, and is denoted by</em> $\int f​$. Thus,<br>$$<br>\int f = \lim_{n} \int f_n<br>$$</p>
<p>There are two issues we need to answer for the definition to be well-defined. The first one is that the limit of $\int f_n​$ indeed exists. Second, we need to show that for any sequence satisfying condition (1) and (2), their integral converges to the same limit.</p>
<h1 id="Theorem-Existence-of-Limit"><a href="#Theorem-Existence-of-Limit" class="headerlink" title="Theorem.   Existence of Limit"></a><strong>Theorem.</strong>   Existence of Limit</h1><p><em>$\int f_n$ converges as $n \rightarrow \infty$.</em>  </p>
<p><strong>Proof:</strong><br>$$<br>\left| \int f_n - \int f_m \right| \le \int | f_n - f_m |  \rightarrow 0 \qquad as \quad n, m \rightarrow \infty<br>$$<br>Therefore, ${ \int f_n : n \in \mathbf{N} }$ (note that each element in this set is a real number) is a Cauchy sequence and its limit exists. $\blacksquare$</p>
<h1 id="Theorem-Uniqueness-of-Limit"><a href="#Theorem-Uniqueness-of-Limit" class="headerlink" title="Theorem. Uniqueness of Limit"></a><strong>Theorem.</strong> Uniqueness of Limit</h1><p><em>Let ${ f_n }$ and ${ g_n }$ be two Cauchy sequences in the mean of integrable simple functions, such that</em><br>$$<br>\lim_n f_n = \lim_n g_n = f \qquad a.e.<br>$$<br>Then<br>$$<br>\lim_n \int f_n = \lim_n \int g_n<br>$$</p>
<p><strong>Proof:</strong><br>Define $h_n \doteq f_n - g_n$ for $n \in \mathbf{N}$. As $f_n$ and $g_n$ are simple and integrable, $h_n$ is simple and integrable. We claim that  </p>
<ol>
<li>${ h_n }$ is Cauchy in mean.</li>
<li>$\lim_n h_n = 0 \quad a.e.$.  </li>
</ol>
<p>The first claim is due to triangle inequality and tha fact that both ${ f_n }$ and ${ g_n }$ are Cauchy in mean,<br>$$<br>\int |h_n - h_m| = \int | f_n - g_n - (f_m - g_m)| \le \int |f_n - f_m| + |g_n - g_m| = \int |f_n - f_m| + \int |g_n - g_m|<br>$$</p>
<p>The second claim results from the $\lim_n f_n = f​$ and $\lim_n g_n = f​$ $a.e.​$.  </p>
<p>We are going to prove $\lim_n \int h_n = 0​$, which then implies<br>$$<br>\lim_n \int (f_n - g_n) =\lim_n \left( \int f_n - \int g_n \right) = \lim_n \int f_n - \lim_n \int g_n = 0​<br>$$<br>, which is as desired.  </p>
<p>It is left to show that $\forall \epsilon &gt; 0$, $\exists N &gt; 0$, s.t., $\forall n &gt; N, | \int h_n | &lt; O(\epsilon)$. Here $O(\epsilon)$ denote $\epsilon$ times some constant number.  </p>
<p>The trick here is to restrict the discussion of $\int h$ on a $\sigma$-finite measurable set. Define the support $N(f_n)​$ of $f_n​$ to be the set with non-zero values: $N(f_n) = { x \in X : f_n(x) \neq 0}​$. As $f_n​$ is a simple integrable function, $\mu(N(f_n)) &lt; \infty​$. Let $E_n = \cup_{k = 1}^n N(f_k) \cup N(g_k)​$ and $E = \cup_n E_n​$. We have $\mu(E_n) &lt; \infty​$, $E_n \uparrow E​$ and $E​$ is $\sigma​$-finite. Further, for any $n​$, we have<br>$$<br>\int h_n = \int_{E} h_n​<br>$$</p>
<p>First, as ${ h_n }$ is Cauchy in mean, for $\epsilon &gt; 0$, $\exists N_1 &gt; 0$, s.t, for $n, k &gt; N_1$, we have $\int |h_n -  h_k| \le \epsilon$ . We choose an integer $k &gt; N_1$. As $h_k$ is a simple integrable function,  and as $E_m \uparrow E$,  it holds that<br>$$<br>\lim_m \int_{E_m} h_k = \int_E h_k = \int h_k<br>$$</p>
<p>For fix $k$, we choose an integer $m$, s..t, $\left| \int h_k - \int_{E_m} h_k \right| \le \epsilon$.  </p>
<p>For a fix $k &gt; N_1$, we claim that for any $n &gt; N_1​$, we have $| \int h_n - \int_{E_m} h_n | &lt; \epsilon​$,<br>$$<br>\begin{aligned}<br>\left| \int h_n  - \int_{E_m} h_n \right|<br>&amp;= \left| \int h_n - \int  h_k  + \int h_k  - \int_{E_m} h_k +  \int_{E_m} h_k - \int_{E_m} h_n\right|  \<br>&amp;\le \left| \int h_n - \int  h_k \right| + \left| \int h_k  - \int_{E_m} h_k \right| + \left| \int_{E_m} h_k - \int_{E_m} h_n \right| \<br>&amp;\le \epsilon + \epsilon + \int_{E_m} |h_k - h_n| \<br>&amp;\le 3\epsilon<br>\end{aligned}<br>$$</p>
<p>We have successfully restrict our discussion on a set with finite measure. The key here is that $\int_{E_m} h_n$ converges uniformly to $\int h_n$, as $m$ increases, independent of the choice of $n$, as long as ${ h_n }$ is Cauchy in mean.  </p>
<p>Indeed, what we have shown here is that $\lim_n \lim_m \int_{E_m} h_n = \lim_m \lim_n \int_{E_m} h_n$</p>
<p>Second, we claim $\int_{E_m} h_n​$ could be arbitrary small if we choose large enough $n &gt; N_1​$. So far we have not used the condition $\lim_n h_n = 0 \ a.e.​$ It is time to turn to it. Define<br>$$<br>S_n = { x  \in E_m :  |h_n(x)| &gt; \epsilon / \mu(E_m) }<br>$$</p>
<p>Clearly $\cup_{i = n}^\infty S_n \downarrow$ with $n$ and $\mu(\lim_n \cap_{i = n}^\infty S_n) = 0$. As $h_k$ is a simple function, it is bounded by some integer $K \ a.e. $.  As $\mu(E_m) &lt; \infty$, $\exists N_2 &gt; N_1$, s.t., for $n &gt; N_2$, we have $\mu(S_n) \le \mu(\cup_{i = n}^\infty S_n ) \le \epsilon / K$. Now,</p>
<p>$$<br>\begin{aligned}<br>\left| \int_{E_m} h_n \right|<br>&amp;\le \left| \int_{S_n} h_n \right| + \left| \int_{E_m \setminus S_n} h_n \right| \<br>&amp;\le \left| \int_{S_n} h_n \right| + \frac{\epsilon}{ \mu(E_m) }  \mu(E_m) \<br>&amp;\le \left| \int_{S_n} h_n \right| + \epsilon<br>\end{aligned}<br>$$</p>
<p>Finally, we argue that $\left| \int_{S_n} h_n \right|​$ is small enough.<br>$$<br>\left| \int_{S_n} h_n \right| \le \left| \int_{S_n} h_n - h_k  + h_k \right| \le \int |h_n - h_k| + \int_{S_n} |h_k| \le \epsilon + K \cdot \mu(S_n) \le 2 \epsilon<br>$$</p>
<p>Indeed, the technique demonstrated here shows that ${ \int_E h_n }$ is uniformly absolutely continuous with respect to $\mu(E)$.</p>
<p>$\blacksquare$</p>
<h2 id="Corollary-1"><a href="#Corollary-1" class="headerlink" title="Corollary 1"></a><strong>Corollary 1</strong></h2><p><em>Let ${ h_n }$ be a sequence of simple integrable function that are Cauchy in mean and $E_1 \subset E_2 \subset E_3 …$ a sequence of increasing measurable sets that converge to $E = \cup_{i = 1}^\infty E_i$. Then $\int_{E_m} h_n \rightarrow \int_{E} h_n$ uniformly, i.e., $\forall \epsilon &gt; 0, \exists M &gt; 0$, s.t., for $m &gt; M$, we have</em><br>$$<br>\left| \int_{E_m} h_n - \int_E h_n \right| \le \epsilon<br>$$</p>
<h2 id="Corollary-2"><a href="#Corollary-2" class="headerlink" title="Corollary 2"></a><strong>Corollary 2</strong></h2><p><em>Let ${ h_n }$ be a sequence of simple integrable function that are Cauchy in mean. $\forall \epsilon &gt; 0, \exists \delta &gt; 0$, s.t, for any measurable set $E$ with $\mu(E) &lt; \delta$, we have $|\int_E h_n| &lt; \epsilon$ independent of $n$</em></p>
<h1 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition"></a><strong>Definition</strong></h1><p>Let $f$ be an integrable function and $E$ be a measurable set. Then $\chi_E f$ is integrable and its integral is denoted as<br>$$<br>\int \chi_E f = \int_E f<br>$$</p>
<p><strong>Remark:</strong><br>If $f$ is integrable, then there is a sequence simple, integrable function ${f_n }$ that are Cauchy in mean and converges to $f$ almost every. It is easy to see that ${ \chi_E f_n }$ is simple, integrable, Cauchy in mean and converges to $\chi_E f$ almost everywhere, therefore $\chi_E f$ is integrable. An immediately consequence is the following lemma</p>
<h1 id="Lemma-1"><a href="#Lemma-1" class="headerlink" title="Lemma 1"></a><strong>Lemma 1</strong></h1><p>$\int_E f_n$ converges to $\int_E f$ uniformly irrespective of $E$.<br><strong>Proof:</strong><br>It suffices to show the sequence ${ \int_E f_n : n \in \mathbf{N} }$ is a uniformly Cauchy irrespectively of $E$,<br>$$<br>\left| \int_E f_n - \int_E f_m \right| \le \int_E |f_n - f_m| \le \int |f_n - f_m| \rightarrow 0<br>$$<br>Therefore, for $\forall E \subset \Omega$, $\exists N &gt; 0$, for all $n，m &gt; N$, we have<br>$$<br>\left| \int_E f_n - \int_E f_m \right| \le \epsilon<br>$$<br>Taking limit with respect to $m$, we get $\lim_m \int_E f_m - \epsilon \le \int_E f_n \le \lim_m \int_E f_m + \epsilon$, i.e.,<br>$$<br>\left| \int_E f_n - \int_E f \right| \le \epsilon<br>$$<br> as desired.  </p>
<p>Combining Corollary 2 and Lemma 1, we have the following theorem.  </p>
<h1 id="Theorem-Integration-as-Finite-Signed-Measure"><a href="#Theorem-Integration-as-Finite-Signed-Measure" class="headerlink" title="Theorem. Integration as Finite Signed Measure"></a><strong>Theorem.</strong> Integration as Finite Signed Measure</h1><p>If $f$ is integrable, then<br>$$<br>\lambda(E) = \int_E f<br>$$<br>is absolute continuous.<br><strong>Proof:</strong><br>Let ${ f_n }$ as defined before. For $\forall \epsilon &gt; 0$, $\exists N_1 &gt; 0$, for all $n &gt; N_1$, we have $| \int_E f - \int_E f_n | \le \epsilon$. On the other hand, For $\forall \epsilon &gt; 0$, $\exists \delta &gt; 0$, for all $E$ with $\mu(E) &lt; \delta$, we have $|\int_E f_n| &lt; \epsilon$.  In combination,<br>$$<br>\left| \int_E f \right| \le \left| \int_E f - f_n \right| + \int_E |f_n| \le 2\epsilon<br>$$</p>
<p>$\blacksquare$</p>
<p>Next we discussion the convergence behavior of a sequence of integrable functions.</p>
<h1 id="Lemma"><a href="#Lemma" class="headerlink" title="Lemma"></a>Lemma</h1><p>If ${ f_k }$ is a sequence of simple, integrable function that are</p>
<ol>
<li>Cauchy in the mean,  </li>
<li>Converge to $f$ almost everywhere.  </li>
</ol>
<p>Then<br>$$<br>\lim_k \int |f_k - f| = 0<br>$$</p>
<p><strong>Proof:</strong><br>Note that $|f_k - f |$ may not be a simple function. To investigate the value of its integral, we need to characterize it according to the definition of integral for general functions. Here is how we do it. For a fix $k$, the sequence ${ |f_k - f_n| : n \in \mathbf{N} }$ is simple, integrable, and converges to $|f_k - f |$ almost everywhere. Moreover,  as ${ f_k }$ itself is Cauchy in mean,  for $\forall \epsilon &gt; 0$, $\exists N &gt; 0$,  s.t., $\forall k, n, m &gt; N$,<br>$$<br>\int \left| |f_k - f_n| - |f_k - f_m| \right| \le \int |f_k - f_n - (f_k - f_m)| = \int |f_m - f_n| \le \epsilon<br>$$</p>
<p>As a consequence ${|f_k - f_n| : n \in \mathbf{N} }$ is Cauchy in the man. $|f_k - f|$ is integrable and $\int |f_k - f| = \lim_n \int |f_k - f_n|$. But for $k, n, m &gt; N$,<br>$$<br>\int |f_k - f| = \lim_m \int |f_k - f_m| \le \int |f_k - f_n| + \epsilon \le 2\epsilon<br>$$</p>
<p>As $\epsilon$ could be arbitrary small, we have $\lim_k \int |f_k - f| = 0$.</p>
<p>$\blacksquare$.  </p>
<h1 id="Theorem-2"><a href="#Theorem-2" class="headerlink" title="Theorem"></a><strong>Theorem</strong></h1><p><em>If ${g_k}$ is a sequence of integrable functions satisfying the conditions</em>  </p>
<ol>
<li>${g_k}$ is a Cauchy sequence in the mean.  </li>
<li>${g_k}$ converges in measure to $f$.  </li>
</ol>
<p>then $f$ is integrable and $\int f = \lim⁡_k \int g_k$.</p>
<p><strong>Proof:</strong><br>For each $g_k$, there is a sequence ${ g_{km} : m ∈ \mathbf{N} }$ simple integrable functions,  </p>
<ol>
<li><p>${ g_{km} }$ is a Cauchy sequence in the mean.  </p>
</li>
<li><p>${ g_{km} }$ converges in measure to $g_k$.  </p>
</li>
<li><p>$\int g_k = \lim_m ⁡\int g_{km}$  </p>
</li>
</ol>
<p>For fix $k​$, we choose such an integer $m​$, such that $\int |g_k - \int g_{k m} |\le 1 / k​$ and $\mu({ x:|g_k (x) - g_{km} (x) | \ge 1 / k } ) \le 1 / k​$. For convenience, denote $g_{k m}​$ as $f_k​$. Now we claim the sequence ${ f_{k}  }​$ of simple integrable functions  satisfies</p>
<ol>
<li>is a Cauchy sequence in the mean.  </li>
<li>converges to $f​$ in measure.  </li>
</ol>
<p>The first one result from the fact ${ g_k }$ is Cauchy sequence in the mean and triangle inequality<br>$$<br>\begin{aligned}<br>\int | f_{m} - f_{n} |<br>&amp;\le \int | f_{m} - g_m | +| g_m - g_n |+| g_n - f_n | \<br>&amp;\le \int | f_{m} - g_m | + \int | g_m - g_n | + \int | g_n - f_n | \<br>&amp;\le \frac{1}{m} + \int | g_m - g_n | + \frac{1}{n} \<br>&amp;\rightarrow 0 \quad \text{as } n, m \rightarrow \infty<br>\end{aligned}<br>$$</p>
<p>The second claim also results from triangle inequality. For any $\delta &gt; 0$, $\exists 1 / k \le \delta​$, s.t.,<br>$$<br>\begin{aligned}<br>\mu({ x \in X: |f_k - f | \ge \delta } )<br>&amp;\le \mu({ x \in X: |f_k - g_k | \ge \delta } ) + \mu({ x \in X: |g_k - f | \ge \delta } ) \<br>&amp;\le 1/k + \mu({ x \in X: |g_k - f | \ge \delta } ) \<br>&amp;\rightarrow 0 \quad \text{as } k \rightarrow \infty<br>\end{aligned}<br>$$</p>
<p>$\blacksquare$</p>
<h1 id="Theorem-Lebesgue’s-Bounded-Convergence-Theorem"><a href="#Theorem-Lebesgue’s-Bounded-Convergence-Theorem" class="headerlink" title="Theorem. Lebesgue’s Bounded Convergence Theorem"></a>Theorem. Lebesgue’s Bounded Convergence Theorem</h1><p>Let ${ f_n }$ be a sequence of integrable functions that converges either in measure or a.e. to a measurable function $f$. If $|f_n(x)| \le g(x) \ a.e.$ for all $n$, where $g$ is an integrable function, then $f$ is integrable.  </p>
<p>Note: compared to definition of $f$ being integrable,  </p>
<ol>
<li>We no longer require ${ f_n }​$ to be simple functions.  </li>
<li>We no longer require ${ f_n }$ to be Cauchy in mean.  </li>
</ol>
<p><strong>Proof:</strong></p>
<p>It suffices to show ${ f_n }$ is a Cauchy sequence in mean.  </p>
<ol>
<li><p>Each ${ f_n }$ can be approximated by a sequence of simple functions. Therefore, we can find a $\sigma$-finite measurable set $F_n$ such that $\int_{F_n} f_n = \int_F$. Similarly, we can find a $\sigma$ finite measurable set $G$ such that $\int_G g = \int g$.  </p>
</li>
<li><p>The measurable set $E = (\cup_n F_n) \cup G$ is $\sigma$ finite. There exists a sequence of increasing, finite measurable set $E_1 \subset E_2 \subset E_3 …$ which satisfies $E_n \uparrow E$.  </p>
</li>
<li><p>As $\int_E g &lt; \infty​$, and $\lim_m \int_{E_m} g = \int_E g​$, $\forall \epsilon &gt; 0, \exists m &gt; 0​$, s.t., $|\int_{E \setminus E_m} g | \le \epsilon​$.  </p>
</li>
<li><p>The integral of $|f_n - f_m|​$ outside $E_m​$ is small: $\int_{E \setminus E_m} |f_n - f_m| \le \int_{E \setminus E_m} |f_n| + |f_m| \le 2 \int_{E \setminus E_m} g \le 2 \epsilon​$.</p>
</li>
<li><p>Consider the integral inside the finite set $E_m$. Define $S_k \doteq { x \in E_m : |f_i(x) - f_j(x)| \ge \epsilon / \mu(E_m) \text{ for all } i, j \ge k}$.  As ${ f_n }$ converges to $f$ in measure or a.e., and $\mu(E_m) &lt; \infty$, $\mu(S_k) \rightarrow \mu(E_m)$. We can choose an $k$, s.t., $\mu(E_m \setminus S_k) \le \delta$, where $\delta$ is chosen with $\int_{E_m \setminus S_k} g &lt; \epsilon$. Such $\delta$ exists because $g$ is integrable, therefore $\int_{E_m \setminus S_k} g$ absolute continuous with respect to $\mu(E_m \ S_k)$. Now, for $n, m \ge k$,  </p>
</li>
<li><p>$\int_{E_m} | f_n - f_m | = \int_{S_k} |f_n - f_m| + \int_{E_m \setminus S_k} |f_n - f_m| \le \frac{\epsilon}{\mu(E_m) }\mu(E_m) + 2 \int_{E_m \setminus S_k} g \le 3 \epsilon​$</p>
</li>
<li><p>$\int_E |f_n - f_m| = \int_{E \setminus E_m} |f_n - f_m| + \int_{E_m} | f_n - f_m| \le 2 \epsilon + 3 \epsilon = 5 \epsilon​$.  </p>
</li>
</ol>
<p>$\blacksquare$</p>
<h1 id="Theorem-Lebesgue’s-Monotone-Convergence-Theorem"><a href="#Theorem-Lebesgue’s-Monotone-Convergence-Theorem" class="headerlink" title="Theorem. Lebesgue’s Monotone Convergence Theorem"></a>Theorem. Lebesgue’s Monotone Convergence Theorem</h1><p>Let ${ f_n }$ be a monotone increasing sequence of non-negative integrable functions that converges almost everywhere to $f$. Then  </p>
<p>$$<br>\lim_n \int f_n = \int f<br>$$</p>
<p>Note: compared to the definition of integral of $f$</p>
<ol>
<li>We no longer require ${ f_n }$ to be simple functions.  </li>
<li>$\int f_n$ might diverge to $\infty$. In this case, $f$ is not integrable as $\int f = \infty$. But the equation still holds.  </li>
</ol>
<p><strong>Proof:</strong><br>First consider the case $\int f_n$ is unbounded. Then $\int f = \int_n f_n = \infty$ by definition.  </p>
<p>Otherwise, suppose $\lim_n \int f_n$ is bounded. Then $\int f_n$ is an increasing sequence that converges to a real number. It follows that for $n &gt; m$, then $f_n &gt; f_m$. Consequently<br>$$<br>\int |f_n - f_m| = \int f_n - f_m = \int f_n - \int f_m  \rightarrow 0 \qquad \text{ as } n, m \rightarrow \infty<br>$$</p>
<p>Thus, ${ f_n }$ is a Cauchy sequence in the mean. Hence, $f$ is integrable and $\lim_n \int f_n = \int f$.</p>
<h1 id="Theorem-Fatou-‘s-Lemma"><a href="#Theorem-Fatou-‘s-Lemma" class="headerlink" title="Theorem. Fatou ‘s Lemma"></a>Theorem. Fatou ‘s Lemma</h1><p>Let ${ f_n }$ be a sequence of non-negative and integrable functions. Then<br>$$<br>\int \liminf_n f_n \le \liminf_n \int f_n<br>$$</p>
<p><strong>Proof:</strong><br>Let $h_n = \inf_{k \ge n} f_k$. Then $h_n$ is a sequence of monotone increasing measurable functions that converges to $\liminf_n h_n$. By monotone convergence theorem,<br>$$<br>\int \lim_n h_n = \lim_n \int h_n<br>$$<br>On the other hand, $h_n = \inf_{k \ge n} f_k \le f_m$ for all $m \ge n$. It follows that<br>$$<br>\begin{aligned}<br>\int h_n        &amp;\le \inf_{m \ge n} \int f_m \<br>\lim_n \int h_n &amp;\le \lim_n \inf_{m \ge n} \int f_m = \liminf_n \int f_n<br>\end{aligned}<br>$$<br>Combining the two equations we obtain the Fatou ‘s lemma.  </p>
<h1 id="Basic-Properties-of-Integrable-Functions"><a href="#Basic-Properties-of-Integrable-Functions" class="headerlink" title="Basic Properties of  Integrable Functions"></a><strong>Basic Properties of  Integrable Functions</strong></h1><p>Let $f$ and $g$ be two integrable functions, and $\alpha, \beta \in R$ two real values.</p>
<ol>
<li><p><em>Integrable functions forms a vector space, i.e., $\int \alpha f + \beta g = \alpha \int f + \beta \int g$</em><br><strong>Proof:</strong><br>Let ${ f_n }$ and ${ g_n }$ be two sequence of simple, integrable functions that define the integral of $f$ and $g$ respectively.<br>Then ${ \alpha f_n + \beta g_n }$ is a sequence of simple, integrable functions that are Cauchy in the mean and converges to $\alpha f + \beta g$ almost everywhere (assuming that $\lim_n f_n = f \ a.e.$ and $\lim_n g_n = g \ a.e.$).<br>$$<br>\int \alpha f + \beta g = \lim_n \int \alpha f_n + \beta g_n = \alpha \lim_n \int f_n + \beta \lim_n \int g_n = \alpha \int f + \beta \int g<br>$$<br> $\blacksquare$  </p>
</li>
<li><p><em>If $f \ge 0 \ a.e.​$,  then $\int f \ge 0​$.</em><br> <strong>Proof:</strong><br> Let ${ f_n }​$ be a sequence of simple, integrable function that are Cauchy in mean and $\lim_n f_n = f \ a.e.​$. Then $\lim_n \int f_n = \int f​$.<br> As $f \ge 0 \ a.e.​$, ${ |f_n| }​$ converges to $f​$ almost everywhere.<br> Moreover, ${ |f_n| }​$ is simple, integrable and Cauchy in the mean.<br> Therefore, we also have<br> $$<br> \int f = \lim_n \int |f_n| \ge 0<br> $$<br> $\blacksquare$  </p>
</li>
<li><p><em>If $f \ge g \ a.e$, then $\int f \ge \int g$.</em><br> <strong>Proof:</strong>  </p>
<p> Define $h = f - g$, then $h \ge 0 \ a.e.$. By property 2 and 1, we obtain<br> $$<br> \int h = \int f - g = \int f - \int g \ge 0<br> $$</p>
<p> NOTE: it is also possible to prove this from scratch.  Let ${ f_n }$ and ${ g_n }$ be two sequence of simple, integrable functions that define the integral of $f$ and $g$ respectively. Define $h_n = f_n - g_n$ be a sequence of simple, integrable functions that are Cauchy in the mean. Moreover, we have $\lim h_n \ge 0 \ a.e.$. We need to show that $\int h = \lim_n \int h_n \ge 0$.  </p>
<p> As before, we would like to restrict our discussion on a $\sigma$-finite measurable set. Define $F_m = \cup_{i = 1}^m N(f_i) \cup \cup_{i = 1}^m N(g_i)$ and $F = \cup_{m = 1}^\infty F_m$. Clearly $F_m \uparrow F$ and $\int h = \int_{F} h$.  </p>
<p> On the other hand,<br> $$<br> \begin{aligned}<br> \int h<br> &amp; \ge \int h_n - \left| \int h_n - \int h \right| \<br> &amp;=  \int_{F_m} h_n - \int_{F_m} h_n + \int_{F_m} h_k - \int_{F_m} h_k + \int h_k - \int h_k + \int h_n - |\int h_n - \int h|  \<br> &amp;\ge \int_{F_m} h_n - \left| \int_{F_m} h_n - \int_{F_m} h_k \right| - \left| \int_{F_m} h_k - \int h_k \right| - \left| \int h_k - \int h_n \right|  - \left| \int h_n - \int h \right| \<br> &amp;\ge \int_{F_m} h_n - \int \left| h_n - h_k \right| - \left| \int_{F_m} h_k - \int h_k \right| - \int \left|  h_k - h_n \right|  - \int \left|  h_k - h_n \right| \<br> \end{aligned}<br> $$<br> Since ${h_n}$ is Cauchy in mean, we can take sufficient large $N$, s.t., for $n, k \ge N$, $\int |h_k - h_n| \le \epsilon$. Now we choose an $k \ge N$ and fix its value. Further, as $F_m \uparrow F$, we can choose an $m$, s.t., $|\int_{F_m} h_k - \int h_k| \le \epsilon$. It follow<br> $$<br> \int h \ge \int_{F_m} h_n - 3 \epsilon<br> $$<br> It suffice to show $\int_{F_m} h_n$ is sufficient large on a measurable set $F_m$ with finite measure for large enough $n$. Define $S_n \doteq { x \in F_m : h_i (x) \ge - \epsilon / \mu(F_m) \text{ for all } i \ge n }$. As $\lim_n h \ge 0 \ a.e.$,  $S_n \uparrow$ and $\exists n$ s.t., $\mu(F_m \setminus S_n) \le \delta$, where $\delta$ is chosen s.t., $\int_{F_m \setminus S_n} |h_k| \le \epsilon$. Such $\delta$ exists since $h_k$ is simple and integrable. For such an $n$,<br> $$<br> \begin{aligned}<br> \int h<br> &amp; \ge \int_{S_n} h_n + \int_{F_m \setminus S_n} h_n - 3 \epsilon \<br> &amp;\ge \frac{-\epsilon}{\mu(F_m)}\mu(F_m) + \int_{F_m \setminus S_n} h_k - \int_{F_m \setminus S_n} h_k + \int_{F_m \setminus S_n} h_n - 3 \epsilon \<br> &amp;\ge -4 \epsilon - \left| \int_{F_m \setminus S_n} h_k \right| - \int |h_k - h_n| \<br> &amp;\ge -6 \epsilon<br> \end{aligned}<br> $$<br> As $\epsilon$ could be arbitrary value, it must be true that $\int h \ge 0$.  </p>
<p> $\blacksquare$</p>
</li>
<li><p><em>$|f|$ is an integrable function, and $|\int f| \le \int |f|$.</em><br> <strong>Proof:</strong><br> Let ${ f_n }$ be a sequence of simple, integrable function that are Cauchy in mean and $\lim_n f_n = f \ a.e.$ Then Let ${ |f_n| }$ be a sequence of simple, integrable function that are Cauchy in mean and $\lim_n |f_n| = |f| \ a.e.​$<br> $$<br> \int|f| = \lim_n \int |f_n| \ge \pm \lim_n \int f_n = \pm \int f \qquad \blacksquare<br> $$</p>
</li>
<li><p><em>$\int|f+g | \le \int |f| + \int |g|$.</em><br> <strong>Proof:</strong><br> $\int|f+g| \le \int(|f|+|g|) =\int|f| +\int|g|. \qquad \blacksquare$</p>
</li>
<li><p><em>If $m \le f \le M \ a.e.$ on a measurable set $E$ with $\mu(E) &lt; \infty$, then $m \mu(E) \le \int_E f \le M \mu(E)$.</em><br> <strong>Proof:</strong><br> The condition $\mu(E) &lt; \infty$ ensures that $m \mu(E) &lt; \infty$.<br> Then utilize that $\mu \chi_E$ is simple, integrable $\mu \chi_E \le f$ almost everywhere.<br> $\blacksquare$</p>
</li>
<li><p>If $f \ge 0,\ a.e.$, and if $E$ and $F$ are measurable sets with $E⊂F$, then $\int_E f \le \int_F f$.<br> <strong>Proof:</strong><br> Utilize that $\chi_E f \le \chi_F f$ almost everywhere.<br> $\blacksquare$</p>
</li>
<li><p><em>If $F$ is a disjoint union $\cup_{m=1}^\infty F_n$ of measurable sets, then<br> $\int_F f=\sum_{m=1}^\infty \int_{F_m} f$.</em><br> <strong>Proof:</strong><br> Let ${ f_n }$ be a sequence of simple, integrable function that are Cauchy in mean and $\lim_n f_n = f \ a.e.$. What we are going to prove is<br> $$<br> \lim_n \lim_k \int_{\cup_{m = 1}^k F_m} f_n = \lim_k \lim_n \int_{\cup_{m = 1}^k F_m} f_n = \lim_k \sum_{m = 1}^k \int_{F_m} f<br> $$<br> The exchange order of limit is justified as ${f_n}​$ is a sequence that is Cauchy in mean:<br> $$<br> \begin{aligned}<br> \left| \int_F f \right|<br> &amp;= \left| \int_F f_n \right| + \left| \int_F f_n - \int f \right| \<br> &amp;\le \left| \int_{\cup_{m=1}^k F_m} f_n \right| + \left| \int_{\cup_{m=1}^k F_m} f_n -  \int_F f_n \right| + \left| \int_F f_n - \int f \right| \<br> &amp;\le \left| \int_{\cup_{m=1}^k F_m} f \right| + \left| \int_{\cup_{m=1}^k F_m} f - \int_{\cup_{m=1}^k F_m} f_n \right| + \left| \int_{\cup_{m=1}^k F_m} f_n -  \int_F f_n \right| + \left| \int_F f_n - \int f \right| \<br> &amp;\le \left| \sum_{m=1}^k \int_{F_m} f \right| + \epsilon + \left| \int_{\cup_{m=1}^k F_m} f_n -  \int_F f_n \right| + \epsilon<br> \end{aligned}<br> $$<br> for large enough $n$. The conclusion follows as $m \rightarrow \infty$.  </p>
<p> $\blacksquare$.  </p>
</li>
<li><p><em>If $F_1 \subset F_2 \subset F_3 \subset …$ is a sequence of increasing  measurable sets and let $F = \cup_{n} F_n$, then $\lim_n \int_{F_n} f = \int_F f$.</em><br> <strong>Proof:</strong><br> Let $F_n’ = F_n - F_{n - 1}$. The result follows immediately from the previous property.<br> $\blacksquare$</p>
</li>
<li><p><em>If $F_1 \supset F_2 \supset F_3 \supset …$ is a sequence of decreasing  measurable sets and let $F = \cap_{n} F_n$, then $\lim_n \int_{F_n} f = \int_F f$.</em><br><strong>Proof:</strong><br>Let $F_n = F_{n} - F_{n + 1}$ for $n \ge 1$ and $F = \cap_n F_n$. Then $F_1 = (\cup_{n} F_n’) \cup F$<br>$$<br>\sum_{n = 1}^\infty \int_{F_n’} f + \int_F f = \int_{F_1} f<br>$$<br>The fact that $f$ is integrable implies $\int_{F_1} f &lt; \infty$. Hence<br>$$<br>\int_F f = \int_{F_1} f - \sum_{n = 1}^\infty \int_{F_n’} f = \lim_k \left(\int_{F_1} f - \sum_{n = 1}^k \int_{F_n’} f \right) = \lim_k \int_{F_{k + 1} } f<br>$$<br>$\blacksquare$</p>
</li>
<li><p>Let $f$ be an integrable function. Then for $\forall \epsilon &gt; 0$, the set $E = { x \in X : f(x) &gt; \epsilon }$ has finite measure and $\mu(E) \le \frac{\int_E f}{\epsilon}$.<br><strong>Proof:</strong><br>Clearly $E$ is measurable. Further, consider the set $F = { x \in X : f(x) \neq 0 }$, which is $\sigma$ finite. We can rewrite it as an increasing sequence of finite measurable set $F_1 \subset F_2 \subset F_3 …$, s.t., $F_n \uparrow F$. As $\mu(E \cap F_n) \le \infty$, $ \epsilon \chi_{E \cap F_n}$ is integrable. By monotonicity of integration,<br>$$<br>\epsilon \mu(E \cap F_n) = \int \epsilon \chi_{E \cap F_n} \le \int f \chi_{E \cap F_n} \le \int_E f &lt; \infty<br>$$<br>Now we see that $\mu(E \cap F_n) \le \frac{\int f}{\epsilon }$. Taking the limit of $n \rightarrow \infty$, we obtain the desired result.<br>$\blacksquare$</p>
</li>
</ol>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol>
<li>AVNER FRIEDMAN, <em>Foundations of Modern Analysis</em></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/03/02/Exchange-Order/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/02/Exchange-Order/" class="post-title-link" itemprop="url">Exchange Order</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2019-03-02 15:06:27 / Modified: 21:52:42" itemprop="dateCreated datePublished" datetime="2019-03-02T15:06:27+11:00">2019-03-02</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Consider a matrix $A = (a_{i,j})$ with countable rows and columns. Suppose for any $m \in \mathbf{N}$,<br>$$<br>\sum_{i = 1}^\infty a_{i,m} = \lim_n \sum_{i = 1}^n a_{i, m} =  x_m<br>$$<br>exists. Moreover, $\forall \epsilon &gt; 0$, $\exists N \in \mathbf{N}$, s.t., for $n &gt; N$, we have $|\sum_{i = 1}^n \sum_{j = 1}^m a_{i,j} -  \sum_{j = 1}^m x_m | \le \epsilon$ for whatever choice of $m \in \mathbf{N}$.<br>We also know that for any $n \in \mathbf{N}$,<br>$$<br>\sum_{j = 1}^\infty a_{n, j} = \lim_{m} \sum_{j = 1}^m a_{n, j} = y_n<br>$$<br>exists. Suppose that<br>$$<br>s = \lim_{n} \sum_{i = 1}^n y_i<br>$$<br>then<br>$$<br>\lim_m \sum_{j = 1}^m x_m \ \text{exists and } \  s = \lim_m \sum_{j = 1}^m x_m<br>$$</p>
<p><em>Proof:</em><br>$$<br>\begin{aligned}<br>|s - \sum_{j = 1}^m x_m|<br>&amp;\le |s - \sum_{i = 1}^n y_i| + |\sum_{i = 1}^n y_i - \sum_{i = 1}^n \sum_{j = 1}^m a_{i,j}| + |\sum_{i = 1}^n \sum_{j = 1}^m a_{i,j} - \sum_{j = 1}^m x_m| \<br>&amp;= |s - \sum_{i = 1}^n y_i| + | \sum_{i = 1}^n (y_i - \sum_{j = 1}^m a_{i,j} ) | + |\sum_{i = 1}^n \sum_{j = 1}^m a_{i,j} - \sum_{j = 1}^m x_m|<br>\end{aligned}<br>$$</p>
<ol>
<li>As $\sum_{i = 1}^n y_i \rightarrow s$, $\exists N_1 \in \mathbf{N}$, s.t., $n &gt; N_1 \rightarrow |s - \sum_{i = 1}^n y_i| \le \epsilon / 3$, </li>
<li>For any choice of $m$, $\exists N_3 \in \mathbf{N}$, s.t., $n &gt; N_3 \rightarrow |\sum_{i = 1}^n \sum_{j = 1}^m a_{i,j} - \sum_{j = 1}^m x_m| \le \epsilon / 3$, </li>
<li>Now, taking $n &gt; \max { N_1, N_3 }$, we have<br>$$<br>|s - \sum_{j = 1}^m x_m| \le \epsilon / 3 + |\sum_{i = 1}^n y_i - \sum_{i = 1}^n \sum_{j = 1}^m a_{i,j}| + \epsilon / 3<br>$$<br>If we fix $n$, $\exists N_2 \in \mathbf{N}$, s.t., $m &gt; N_2 \rightarrow |\sum_{i = 1}^n y_i - \sum_{i = 1}^n \sum_{j = 1}^m a_{i,j}| &lt; \epsilon$. Therefore, we have $|s - \sum_{j = 1}^m x_m| \le \epsilon$, as desired. </li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/03/01/Measurable-Functions/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/01/Measurable-Functions/" class="post-title-link" itemprop="url">Function Convergence</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-01 18:18:08" itemprop="dateCreated datePublished" datetime="2019-03-01T18:18:08+11:00">2019-03-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-03-03 01:51:47" itemprop="dateModified" datetime="2019-03-03T01:51:47+11:00">2019-03-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>In this article we discuss several important convergence properties of a sequence ${f_n }$ of functions with defined on the measure space $(X, a, \mu)$. </p>
<h5 id="Definition-Pointwise-Convergence"><a href="#Definition-Pointwise-Convergence" class="headerlink" title="Definition (Pointwise Convergence)"></a>Definition (Pointwise Convergence)</h5><p><em>${ f_n }​$ converges to $f​$ almost every (a.e.) if ${ f_n }$ converges to $f$ except on a set of measure zero, i.e, $\exists E \subset X​$, s.t., $\mu(X - E) = 0​$ and $\forall x \in E, \lim_n f_n(x) = f(x)​$.</em> </p>
<h5 id="Definition-Uniform-Convergence"><a href="#Definition-Uniform-Convergence" class="headerlink" title="Definition (Uniform Convergence)"></a>Definition (Uniform Convergence)</h5><p>${ f_n }​$ converges to $f​$ almost uniformly if $\forall \epsilon &gt; 0​$. $\exists F \subset X​$, s.t, $\mu(X - F) \le \epsilon​$ and ${ f_n }​$ converges uniformly to $f​$ on $F​$. </p>
<p>The following two theorems discuss the relation between pointwise and almost uniform convergence.</p>
<h5 id="Theorem-1-Almost-Uniform-rightarrow-Pointwise"><a href="#Theorem-1-Almost-Uniform-rightarrow-Pointwise" class="headerlink" title="Theorem 1.[Almost Uniform $\rightarrow$ Pointwise]"></a>Theorem 1.[Almost Uniform $\rightarrow$ Pointwise]</h5><p><em>If ${ f_n }$ converges to $f$ almost uniformly, then ${ f_n }$ converge to $f$ almost everywhere</em>. </p>
<p><em>Proof:</em> By definition, $\forall 1 / n &gt; 0, \exists F_n \subset X, s.t., \mu(X - F_n) \le 1/n$ and ${ f_n }$ converges uniformly to $f$ on $F_n$. But this immediately implies that ${ f_n }$ converges pointwise on $F_n$ and therefore it converges pointwise on $\cup_{n = 1}^\infty F_n$. </p>
<p>We claim that $\mu(X - \cup_{n = 1}^\infty F_n)$ has measure zero and hence ${ f_n }$ converges to $f$ almost everywhere. Since $\mu(X - \cup_{n = 1}^\infty F_n) = \mu( \cap_{n = 1}^\infty (X - F_n)) \le \mu(X - F_n) = 1/n$ for any $n \in \mathbf{N}$, $\mu(X - \cup_{n = 1}^\infty F_n) = 0$, as desired.   </p>
<p>$\blacksquare$</p>
<h5 id="Theorem-2-Pointwise-rightarrow-Almost-Uniform-Egorov"><a href="#Theorem-2-Pointwise-rightarrow-Almost-Uniform-Egorov" class="headerlink" title="Theorem 2. [Pointwise $\rightarrow$ Almost Uniform][Egorov]"></a>Theorem 2. [Pointwise $\rightarrow$ Almost Uniform][Egorov]</h5><p><em>Let ${f_n}$ be a sequence of measurable functions that converges pointwise to $f$ almost everywhere and suppose $\mu(X) \le \infty$, then ${ f_n }$ converges to $f$ almost uniformly.</em></p>
<p><em>Proof:</em><br>Without lost of generality, we assume that ${ f_n }$ converge to $f$ everywhere on $X$. </p>
<p>Given $\epsilon &gt; 0$, we need to find a set $F$ such that ${ f_n } \rightarrow f$ uniformly on $F$ and $m(X - F) \le \epsilon$. </p>
<p>For each pair of $k, m \in \mathbf{N}$, consider the set $F_{k, m} = \cap_{n = m}^\infty { x : |f_n(x) - f(x)| \le  1 / k }$. Now fix $k$ and note that $F_{k, m} \subset F_{k, m+1}$.    </p>
<p>Next, $\forall x \in E$, $\lim_n f_n(x) = f(x)$. For fix $x$ and $k$,  $\exists m &gt; 0$, s.t., for all $n &gt; m, |f_n(x) - f(x)| \le 1/k$. Hence $x \in F_{k, m}$. </p>
<p>We conclude that $F_{k, m}$ is a sequence of monotone increasing sets and $\lim_{m} F_{k,m} = X$. Thus we have $\lim_{m} F_{k,m}) = \mu(X) &lt; \infty$. For arbitrary $\epsilon &gt; 0$, we can find an integer $N_k$, s.t., $\mu(X - F_{k, N_k}) \le \epsilon / 2^k$.  Now for convenience we abbreviate $F_{k, N_k}$ as $F_k$.</p>
<p>Observe that ${ f_n }$ converges uniformly on $F = \cap_{k = 1}^\infty F_k$, as for any $\lambda &gt; 0, \exists k \in \mathbf{N}, s.t., 1 / k &lt; \lambda$, and $x \in F$ implies $x \in F_k$. Therefore if $n &gt; N_K$, $|f_n(x) - f(x)| \le 1/k \le \lambda​$. </p>
<p>It remains to prove $\mu(X - F)$ is small enough. This is because of<br>$$<br>\begin{aligned}<br>\mu(E - F)<br>&amp;= \mu(E - \cap_{k = 1}^\infty F_k) \<br>&amp;= \mu(\cup_{k = 1}^\infty (E - F_k)) \<br>&amp;\le \sum_{k = 1}^\infty \mu(E - F_k) \<br>&amp;\le \sum_{k = 1}^\infty \epsilon / 2^k \<br>&amp;= \epsilon<br>\end{aligned}<br>$$</p>
<p>$\blacksquare$</p>
<p>There are another two frequently used definitions for convergence. </p>
<h5 id="Definition-Converges-in-measure"><a href="#Definition-Converges-in-measure" class="headerlink" title="Definition (Converges in measure)"></a>Definition (Converges in measure)</h5><p>${ f_n }$ converges to $f$ in measure if $\forall \epsilon &gt; 0$, $\forall \delta &gt; 0$, $\exists N \in \mathbf{N}$, s.t, for $n &gt; N$, $\mu( { x : |f_n (x) - f(x)| \ge \epsilon } ) &lt; \delta, i.e,$,<br>$$<br>\lim_{n} \mu( { x : |f_n(x) - f(x)| \ge \epsilon }) = 0<br>$$</p>
<h5 id="Definition-Cauchy-in-measure"><a href="#Definition-Cauchy-in-measure" class="headerlink" title="Definition (Cauchy in measure)"></a>Definition (Cauchy in measure)</h5><p>${ f_n }$ is Cauchy in measure if $\forall \epsilon &gt; 0$, $\forall \delta &gt; 0$, $\exists N \in \mathbf{N}$, s.t, for $n, m  &gt; N$, $\mu( { x : |f_n (x) - f_m(x)| \ge \epsilon } ) &lt; \delta, i.e,$,<br>$$<br>\lim_{n, m} \mu( { x : |f_n(x) - f_m(x)| \ge \epsilon }) = 0<br>$$</p>
<p>It is easy to see that if ${ f_n }$ converge in measure, then it is Cauchy in measure. Later we will show that the converse is also true. </p>
<p>Remark: Converging in measure does not imply converge almost every where. To see this, consider a countable sequence of functions defined on $[0, 1]$. </p>
<ol>
<li>$f_{1, 1} = \mathbf{1}<em>{[0, 1/2]}​$, $f</em>{1, 2} = \mathbf{1}_{[1/2, 1]}​$</li>
<li>$f_{2, 1} = \mathbf{1}<em>{[0, 1/4]}$, $f</em>{2, 2} = \mathbf{1}<em>{[1/4, 1/2]}$, $f</em>{2, 3} = \mathbf{1}<em>{[1/2, 3/4]}$, $f</em>{2, 4} = \mathbf{1}_{[3/4, 1]}$</li>
<li>….</li>
<li>$f_{n, 1} = \mathbf{1}<em>{ [0, 1/2^n] }$, …, $f</em>{n, i} = \mathbf{1}<em>{ [(i - 1) / 2^{n}, i /2^n] }$, …, $f</em>{n, n} = \mathbf{1}_{ [1 - 1/2^{n}, 1] }$</li>
<li>…</li>
</ol>
<p>We can list the functions as ${ f_{1, 1}, f_{1, 2}, f_{2, 1}, …}$ and relabel them concisely as ${g_1, g_2, g_3, … }$. Apparently, ${ g_n }$ converges to $g(x) \equiv  0$ in measure. But for any $x \in [0, 1]$, there are infinite number of functions from the sequence ${ g_n }$  such that $g_n(x) = 1$ and so ${ g_n } \nrightarrow g, a.e$.</p>
<p>However, we have the following theorem. </p>
<h5 id="Theorem-3"><a href="#Theorem-3" class="headerlink" title="Theorem 3"></a>Theorem 3</h5><p>If ${ f_n }$ is Cauchy is Cauchy in measure, then it has a sub-sequence that converges to a measurable function $f$ almost uniformly. </p>
<p>Key Observation: if we look at the previous example, $f_{n, i}$ only deviates from $g(x) \equiv 0$ by a small interval $[( i - 1) / 2^n, i / 2^n]$ with length $1 / 2^n$. However, there are $2^n$ functions with such deviation and the intervals of deviation do not overlap. This motivates filtering out a sub-sequence. </p>
<p><em>Proof:</em> Since ${ f_n }$ is Cauchy, $\forall k &gt; 0$, we can find an integer $n_k &gt; 0, s.t., \forall n, m \ge n_k, \mu( { x: |f_n(x) - f_m(x)| \ge 1 / 2^k } ) \le 1/ 2^k$. We choose such a increasing sequence $(n_k)$ satisfying<br>$$<br>n_1 &lt; n_2 &lt; n_3 &lt; … n_k &lt; …<br>$$<br>and the corresponding sub-sequence ${ f_{n_k} }$ of ${ f_n }$. </p>
<p>Let<br>$$<br>\begin{aligned}<br>F_k &amp;= {x : |f_n(x) - f_m(x)| \le 1 / 2^k, \forall n, m \ge n_k } \<br>E_n &amp;= \cap_{k = n}^\infty F_k<br>\end{aligned}<br>$$. </p>
<p>Then ${ f_{n_k} }$ is uniformly Cauchy in $E_n$ and therefore converge uniformly. It follows that there is a measurable function defined on </p>
<p>$$<br>F = \cup_{n = 1}^\infty E_n<br>$$</p>
<p>such that ${ f_{n_k} }$ converges uniformly on each $E_n$. We can extend the domain of $f$ to $X$ by defining $f(x) = 0$ for $x \in X - F$. Note that $f$ is measurable on $X$.  </p>
<p>Finally,<br>$$<br>\mu(X - E_n) = \mu(X - \cap_{k = n}^\infty F_k) \le \sum_{k = n}^\infty \mu(x - F_k) \le 1 / 2^{n - 1}<br>$$.<br>It follows that $\mu(F) = \mu(X)$ and $( f_{n_k} )$ converge almost uniformly on $F$. </p>
<p>$\blacksquare$</p>
<h5 id="Corollary"><a href="#Corollary" class="headerlink" title="Corollary"></a>Corollary</h5><p>If ${ f_n }$ is Cauchy is Cauchy in measure, then it converges to a measurable function $f$ in measure. </p>
<h5 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h5><ol>
<li>Avner Friedman, <em>Foundation of Modern Analysis</em>.</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/02/28/Compact-Set/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/02/28/Compact-Set/" class="post-title-link" itemprop="url">Compact Set</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2019-02-28 19:46:25 / Modified: 23:39:22" itemprop="dateCreated datePublished" datetime="2019-02-28T19:46:25+11:00">2019-02-28</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="Definition-Compact-Set"><a href="#Definition-Compact-Set" class="headerlink" title="Definition. Compact Set"></a>Definition. Compact Set</h4><p>A set $S \subset R$ is compact if every sequence in $S$ has a convergent sub-sequence whose limit is in $S$. </p>
<h5 id="Theorem-S-is-compact-if-and-only-if-it-is-closed-and-bounded"><a href="#Theorem-S-is-compact-if-and-only-if-it-is-closed-and-bounded" class="headerlink" title="Theorem. $S$ is compact if and only if it is closed and bounded."></a>Theorem. $S$ is compact if and only if it is closed and bounded.</h5><p><em>Proof:</em>  </p>
<ol>
<li>$”\Rightarrow”$: Suppose $S$ is not bounded. Then there is a sequence $(a_n)$ is $S$, such that $|a_n| \ge n$,  $\forall n \in N$. Now every sub-sequence in $(a_n)$ diverges. Therefore $S$ must be bounded. Next we show that $S$ contains all its limit points. Let $a$ be a limit point of $S$. Then there is a sequence $(a_n) \rightarrow a$. $(a_n)$ is a sub-sequence of itself and so $a \in S$. We have proved that $S$ is closed. </li>
<li>$”\Leftarrow”$: Assume $S$ is closed and bounded. Consider a sequence $(a_n)$ in $S$. By Weierstrass Theorem, there is a convergent sub-sequence $( a_{n_k} )$. But since $S$ is closed, $\lim_k a_{n_k} \in S$. </li>
</ol>
<h5 id="Theorem-S-is-compact-if-and-only-if-every-open-cover-of-S-has-a-finite-sub-cover"><a href="#Theorem-S-is-compact-if-and-only-if-every-open-cover-of-S-has-a-finite-sub-cover" class="headerlink" title="Theorem. $S$ is compact if and only if every open cover of $S$ has a finite sub-cover."></a>Theorem. $S$ is compact if and only if every open cover of $S$ has a finite sub-cover.</h5><p><em>Proof:</em>  </p>
<ol>
<li><p>$”\Rightarrow”$: If $S$ is compact, it is bounded. We can find a closed interval $I_0$ that contains $S$. Suppose $S$ can not be covered by a finite sub-cover. We bisect $I_0$ into two closed intervals of equal length. At least one of them can not be covered with finite sets. Denote this interval $I_1$. We continue the process, resulting in a series of intervals $I_1 \supset I_2 \supset I_3 \supset …$. Define $J_n = I_n \cap S \quad \forall n \in N$. The construction of $I_n$ ensures $J_n \neq \emptyset  \quad \forall n \in N$ and the length of $I_n$ approaches $0$ as $n \rightarrow \infty$. We claim that $\cap_n J_n \neq \emptyset$. Indeed, there is an element $a_n \in J_n$ for $n \in N$. It not difficult to see $(a_n)$ is a Cauchy sequence since $\forall m &gt; n \ge N$, $a_n, a_m \in I_N$ and $|a_n - a_m| \le |I_N|$. Let $a = \lim_n a_n$. We conclude that $a \in J_n$ for $n \in N$. This is because $a_{n + 1}, a_{n + 2}…, \in J_n$ for all $n \in N$. It follows that $a \in \cap_n J_n$. Now $a$ must be covered by some open set $O_a$. On the other hand, the construction of $I_n$ ensures that there is an integer $N_a$ such that $I_{N_a}$ is small enough such that $I_{N_a} \subset O_a$. Contradicting the assumption that $I_{N_a}$ cannot be covered with finite sets.</p>
</li>
<li><p>$”\Leftarrow”$: Consider the collection of open balls ${ B(O, 1),\ B(O, 2),\ B(O, 3), …}$ centered at $0$ with radii $1, 2, 3, …$. It covers $S$ and has a finite sub-cover. It follows that $S$ is bounded by the ball with largest radius in the finite sub-cover. To show $S$ is closed, it suffices to prove it complement $S^c$ is open. Let $a \in S^c$. Take the collection of closed balls ${ \bar B(a, 1),\ \bar B(a, 1/2),\ \bar B(a, 1/3), …}$ centered at $a$ with radii $1, 1/2, 1/3, …, 1/n, …$. Their complements ${ \bar B(a, 1)^c,\ \bar B(a, 1/2)^c,\ \bar B(a, 1/3)^c, …}$ constitute an open cover of $S$. By assumption we can find a finite subset of them that covers $S$. Let $\bar B(a, \epsilon)^c$ be the one with the smallest radius in the finite subset collection. We learn that $B(a, \epsilon) \subset S^c$ and therefore $S^c$ is open.</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description">你生之前悠悠千載已逝，未來還會有千年沉寂的期待</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">125</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WOW</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
