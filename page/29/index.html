<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="WOW">
<meta property="og:url" content="http://example.com/page/29/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/29/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>WOW</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">WOW</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">你生之前悠悠千載已逝<br>未來還會有千年沉寂的期待</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/11/02/Laplace-Distribution-and-Mechanism/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/11/02/Laplace-Distribution-and-Mechanism/" class="post-title-link" itemprop="url">Laplace Distribution and Mechanism</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-02 18:22:41" itemprop="dateCreated datePublished" datetime="2020-11-02T18:22:41-05:00">2020-11-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-01-15 07:32:55" itemprop="dateModified" datetime="2022-01-15T07:32:55-05:00">2022-01-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>The density function of a Laplace distribution (denoted as
Laplace(<span class="math inline">\(\mu, b\)</span>) ) with location and
scale parameters <span class="math inline">\(\mu\)</span> and <span
class="math inline">\(b\)</span> is given by <span
class="math display">\[
p(x) = \frac{1}{2 b} \exp \left( -\frac{ | x - \mu |  }{ b } \right)
\]</span></p>
<p>The density function of the distribution is symmetric with respect to
<span class="math inline">\(\mu\)</span>, where it achieves peak value
<span class="math inline">\(\frac{1}{2b}\)</span>. We plot below a few
Laplace distributions with different parameters of <span
class="math inline">\(\mu\)</span> and <span
class="math inline">\(b\)</span>.</p>
<p><img
src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/Laplace-Distribution.png?raw=true" /></p>
<h1 id="properties"><strong>Properties</strong></h1>
<p>We list and prove a few properties of the distribution. Let <span
class="math inline">\(X\)</span> be a random variable that follows
Laplace(<span class="math inline">\(\mu, b\)</span>).</p>
<ol type="1">
<li><p><span class="math inline">\(\mathbb{E}[X] = \mu\)</span>.</p>
<p><strong>Proof.</strong> <span class="math display">\[ \small
\begin{aligned}
     \frac{1}{2} \int_{ - \infty }^\infty \frac{1}{2b} x \cdot \exp
\left( -\frac{ | x - \mu | }{b} \right) \ dx
     &amp;= \int_{ - \infty }^\infty \frac{1}{2b} ( x - \mu ) \cdot \exp
\left( -\frac{ | x - \mu |}{b} \right) \ dx \\
     &amp;+ \int_{ - \infty }^\infty \frac{1}{2b} \mu \cdot \exp \left(
-\frac{ | x - \mu |}{b} \right) \ dx
     \\
     &amp;= \int_{\mu }^\infty \frac{\mu}{b} \exp \left( -\frac{x -
\mu}{b} \right) \ dx \\
     &amp;= \int_{0 }^\infty \frac{ \mu }{b} \exp \left( -\frac{x}{b}
\right) \ dx \\
     &amp;= \mu.
\end{aligned}
\]</span></p></li>
<li><p><span class="math inline">\(\forall t \ge 0, \Pr[| X - \mu | \ge
b \cdot t] \le \exp(-t)\)</span>.<br />
<strong>Proof.</strong> <span class="math display">\[ \small
     \begin{aligned}
         \Pr[ | X - \mu | \ge t]
             &amp;= \int_{\mu + b \cdot t }^\infty \frac{1}{b} \exp
\left( -\frac{x - \mu}{b} \right) \ dx \\
             &amp;= \int_{ b \cdot t }^\infty \exp( -x ) \ dx \\
             &amp;=  \exp(-t).
     \end{aligned}
\]</span> <span class="math inline">\(\square\)</span></p></li>
<li><p><span class="math inline">\(\mathbb{Var}[X] = 2b^2\)</span>.</p>
<p><strong>Proof.</strong> First, for an integer <span
class="math inline">\(n \ge 0\)</span>, we define <span
class="math display">\[
\Gamma(n) = \int_{0 }^\infty x^n \exp( -x ) \ dx
\]</span></p>
<p>Therefore, <span class="math inline">\(\Gamma(0) = 1\)</span>.
Suppose <span class="math inline">\(n \ge 1\)</span>, we have <span
class="math display">\[
\begin{aligned}
     \Gamma(n)
         &amp;= -\int_{0 }^\infty x^n \ d \exp( -x ) \\
         &amp;= - x^n \exp(-x) \mid_0^\infty + \int_{0 }^\infty \exp( -x
) \ d x^n \\
         &amp;= n\int_{0 }^\infty x^{n - 1} \exp( -x ) \ dx \\
         &amp;= n \Gamma(n - 1)
\end{aligned}
\]</span></p>
<p>By induction, we conclude <span class="math inline">\(\Gamma(n) =
n!\)</span>. Now, consider</p>
<p><span class="math display">\[
\begin{aligned}
     \frac{1}{2} \int_{\mu }^\infty \frac{1}{b} (x - \mu)^2 \exp \left(
-\frac{x - \mu}{b} \right) \ dx
     &amp;= \frac{1}{2} \int_{0 }^\infty \frac{1}{b} x^2 \exp \left(
-\frac{x}{b} \right) \ dx \\
     &amp;= \frac{b^2}{2} \int_{0 }^\infty x^2 \exp( -x ) \ dx \\
     &amp;= \frac{b^2}{2} \Gamma(2) \\
     &amp;= b^2
\end{aligned}
\]</span> The proof follows from symmetry of Laplace(<span
class="math inline">\(\mu, b\)</span>) at <span
class="math inline">\(\mu\)</span>.</p></li>
<li><p>Let <span class="math inline">\(X&#39; \sim Laplace(\mu,
b)\)</span> and define another random variable <span
class="math inline">\(Y = X&#39; + b\)</span>, then the density function
of <span class="math inline">\(Y\)</span> shares the same shape with
that of <span class="math inline">\(X&#39;\)</span>, with its center
shifted to the right by distance <span class="math inline">\(b\)</span>.
To distinguish their density function, denote <span
class="math inline">\(p_{X&#39;} (\cdot)\)</span> the one for random
variable <span class="math inline">\(X&#39;\)</span> and <span
class="math inline">\(p_Y(\cdot)\)</span> the one for <span
class="math inline">\(Y\)</span>. For any <span class="math inline">\(t
\in \mathbb{R}\)</span>,</p>
<p><span class="math display">\[
\frac{ p_{X&#39;} (t) }{ p_Y(t) } = \exp( - \frac{ |t - \mu | - | t - (
\mu + b ) | }{ b  }) \in [ \exp(-1), \exp(1) \ ]
\]</span></p></li>
<li><p>If <span class="math inline">\(X, X&#39; \sim Laplace(\mu,
\frac{b}{\epsilon} )\)</span> be a pair of independent random variables,
and <span class="math inline">\(Y = X&#39; + b\)</span>, then</p>
<p><span class="math display">\[
\frac{ p_X(t) }{ p_Y(t) } = \exp \left( - \epsilon \frac{ |t - \mu | - |
t - ( \mu + b ) | }{ b  } \right) \in [ \exp( -\epsilon ), \exp(
\epsilon ) \ ]
\]</span></p></li>
<li><p>Continued. Let <span class="math inline">\(S\)</span> be any
interval in <span class="math inline">\(\mathbb{R}\)</span>.</p>
<p><span class="math display">\[
\frac{ \Pr[X \in S] }{ \Pr[Y \in S] } = \frac{ \int_{t \in S} p_X(t) \
dt }{ \int_{t \in S} p_Y(t) \ dt } \in [ \exp( -\epsilon ), \exp(
\epsilon ) \ ]
\]</span></p></li>
<li><p>Continued. Denote <span class="math inline">\(P_X\)</span> and
<span class="math inline">\(P_Y\)</span> the probability functions of
<span class="math inline">\(X\)</span> and <span
class="math inline">\(Y\)</span> respectively. Let <span
class="math inline">\(S\)</span> be any Borel set in <span
class="math inline">\(\mathbb{R}\)</span>.</p>
<p><span class="math display">\[
\frac{ \Pr[X \in S] }{ \Pr[Y \in S] } = \frac{ \int_S 1 \ d P_X }{
\int_S 1 \ d P_Y } \in [ \exp( -\epsilon ), \exp( \epsilon ) \ ]
\]</span></p></li>
<li><p>Let <span class="math inline">\(X = (X_1, X_2, ..., X_n), X&#39;
= (X_1&#39;, X_2&#39;, ..., X_n&#39;)\)</span> be independent random
vectors with dimension <span class="math inline">\(n\)</span>, where
<span class="math inline">\(X_i, X_i&#39; \sim Laplace(0, \Delta /
\epsilon )\)</span> (for <span class="math inline">\(1 \le i \le
n\)</span>) are independent random variables. Let <span
class="math inline">\(Y \doteq X&#39; + \mu = (Y_1, Y_2, ...,
Y_n)\)</span> be another random vector, such that <span
class="math inline">\(Y_i = X_i&#39; + \mu_i\)</span> for <span
class="math inline">\(1 \le i \le n\)</span> and <span
class="math inline">\(|\mu| = \sum_{i \in [n] } \mu_i \le
\Delta\)</span>. For any <span class="math inline">\(t \in
\mathbb{R}^n\)</span>,</p>
<p><span class="math display">\[
\begin{aligned}
    \frac{ p_X(t) }{ p_Y(t) } &amp;= \frac{ \exp \Big( - \big(  \epsilon
/ \Delta \big) \cdot \sum_{i \in [n] } |t_i| \Big) }{ \exp \Big( -
\big(  \epsilon / \Delta \big) \cdot \sum_{i \in [n] } |t_i - \mu_i|
\Big) } \\
    &amp;= \exp \left( - \epsilon \frac{ |t | - | t - \mu| }{ \Delta  }
\right) \\
    &amp;\in \Big[ \exp \Big( - \epsilon \frac{ |\mu| }{ \Delta  } \Big)
, \exp \Big( \epsilon \frac{ |\mu| }{ \Delta  } \Big) \Big] \\
    &amp;\subset [ \exp( -\epsilon ), \exp( \epsilon ) \ ]
\end{aligned}
\]</span></p></li>
<li><p>Continued. Let <span class="math inline">\(S \subset
\mathbb{R}^n\)</span> be any Borel set. Then</p>
<p><span class="math display">\[
    \frac{ \Pr[X \in S] }{ \Pr[Y \in S] } \in [ \exp( -\epsilon ), \exp(
\epsilon ) \ ]
\]</span></p></li>
</ol>
<h1 id="laplacian-mechanism">Laplacian Mechanism</h1>
<p>Let <span class="math inline">\((\mathcal{X}, d)\)</span> be a metric
space and <span class="math inline">\(f: \mathcal{X} \rightarrow
\mathbb{R}^n\)</span> a function defined on <span
class="math inline">\(\mathcal{X}\)</span>.</p>
<blockquote>
<p><strong>Definition.</strong> <span class="math inline">\(x, x&#39;
\in \mathcal{X}\)</span> are called neighboring points if <span
class="math inline">\(d(x, x&#39;) = 1\)</span>.</p>
</blockquote>
<blockquote>
<p><strong>Definition.</strong> The sensitivity <span
class="math inline">\(\Delta\)</span> of <span
class="math inline">\(f\)</span> is defined as <span
class="math display">\[
\Delta \doteq \max_{x, x&#39; \in \mathcal{X}, d(x, x&#39;) = 1} \Vert
f(x) - f(x&#39;) \Vert_1
\]</span> where <span class="math inline">\(\Vert \cdot \Vert_1\)</span>
is the <span class="math inline">\(\ell_1\)</span> distance. In other
words, <span class="math inline">\(\Delta\)</span> is the maximum <span
class="math inline">\(\ell_1\)</span> distance between the images of two
neighboring points.</p>
</blockquote>
<p>We now construct a new randomized function, called <em>Laplacian
mechanism</em> from <span class="math inline">\(f\)</span>, as
follows.</p>
<blockquote>
<p><strong><em>Definition.</em></strong> The Laplacian mechanism of
<span class="math inline">\(f\)</span> is defined as <span
class="math display">\[
g(x) = f(x) + Y
\]</span> where <span class="math inline">\(Y = (Y_1, Y_2, ...,
Y_n)\)</span> is a random vector with independent random variables <span
class="math inline">\(Y_i \sim Laplace(\Delta / \epsilon)\)</span>.</p>
</blockquote>
<p><span class="math inline">\(\square\)</span></p>
<blockquote>
<p><strong>Theorem.</strong> <em><span class="math inline">\(g\)</span>
is <span class="math inline">\((\epsilon, 0)\)</span>-differentially
private.</em></p>
</blockquote>
<p><em>Proof.</em> Let <span class="math inline">\(S \subset
\mathbb{R}^n\)</span> be an arbitrary Borel set. We need to prove for
any pair of neighboring <span class="math inline">\(x, x&#39; \in
\mathcal{X}\)</span>, <span class="math display">\[
    \frac{ \Pr[ g(x) \in S]}{ \Pr[ g(x&#39;) \in S] } \le \exp(\epsilon)
\]</span></p>
<p>Denote <span class="math inline">\(p_x\)</span> and <span
class="math inline">\(p_{x&#39;}\)</span> the density functions for
<span class="math inline">\(g(x)\)</span> and <span
class="math inline">\(g(x&#39;)\)</span> respectively. It reduces to
prove the following property of the density function <span
class="math display">\[
    \frac{ p_x(t) }{ p_{x&#39;} (t)  } \le \exp(\epsilon), \qquad
\forall t \in \mathbb{R}^n
\]</span></p>
<p>But <span class="math display">\[
\begin{aligned}
    \frac{ p_x(t) }{ p_{x&#39;} (t)  }
        &amp;= \frac{ \exp( - {\epsilon \Vert t - f(x) \Vert_1 } /
{\Delta} ) }{ \exp( - {\epsilon \Vert t - f(x&#39;) \Vert_1 } /{\Delta}
)  } \\
        &amp;= \exp\Big( - \frac{\epsilon }{\Delta} \big( \Vert t -
f(x)\Vert_1  - \Vert t - f(x&#39;) \Vert_1  \big)  \Big) \\
        &amp;\le \exp \Big( \frac{\epsilon }{\Delta}  \Vert f(x) -
f(x&#39;) \Vert   \Big) \\
        &amp;= \exp( \epsilon )
\end{aligned}
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/11/01/Randomized-Response/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/11/01/Randomized-Response/" class="post-title-link" itemprop="url">Randomized Response</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-01 18:41:39" itemprop="dateCreated datePublished" datetime="2020-11-01T18:41:39-05:00">2020-11-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-11-09 01:26:31" itemprop="dateModified" datetime="2020-11-09T01:26:31-05:00">2020-11-09</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>In the setting of randomized response, there is a coordinator and a
set of <span class="math inline">\(n\)</span> players each having a
secrete bit <span class="math inline">\(x_i \in \{0, 1\}\)</span>.
Instead of sending <span class="math inline">\(x_i\)</span> to the
coordinator directly, the player sends a randomly perturbed version
<span class="math inline">\(X_i\)</span>, such that <span
class="math display">\[
X_i =
\begin{cases}
    x_i, \qquad \text{with probability } 0.5 + \epsilon \\
    \bar{ x}_i, \qquad \text{with probability } 0.5 - \epsilon \\
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(\epsilon \in [0, 0.5]\)</span> and
<span class="math inline">\(\bar{x}_i = 1 - x_i\)</span>. If <span
class="math inline">\(\epsilon = 0\)</span>, then the response from play
<span class="math inline">\(i\)</span> is totally random. On the other
hand, if <span class="math inline">\(\epsilon = 0.5\)</span>, there
isn't noise in <span class="math inline">\(X_i\)</span>.</p>
<p>The coordinator would like to estimate the ratio of <span
class="math inline">\(1\)</span>'s among the <span
class="math inline">\(x_i\)</span>'s. Let <span class="math display">\[
\bar{X} = \frac{1}{n} \sum_{i \in [n] } X_i.
\]</span></p>
<p>Denote <span class="math inline">\(\mu = \frac{1}{n} \sum_{i \in [n]
} x_i\)</span> the true ratio. Now <span class="math display">\[
\begin{aligned}
    \mathbb{E} [ \bar{X} ] &amp;= \frac{1}{n} \sum_{i \in [n] }
\mathbb{E}[ X_i ] \\
                            &amp;= \frac{1}{n} \sum_{i \in [n] } [ (0.5
+ \epsilon) x_i + (0.5 - \epsilon )\bar{x}_i ] \\
                            &amp;= \frac{1}{n} \sum_{i \in [n] } [ 2
\epsilon x_i  + (0.5 - \epsilon) (x_i + \bar{x}_i) ] \\
                            &amp;= \frac{1}{n} \sum_{i \in [n] } [ 2
\epsilon x_i  + (0.5 - \epsilon)  ] \\
                            &amp;= \frac{1 - 2\epsilon }{2n}  +
2\epsilon \mu
\end{aligned}
\]</span></p>
<p>and <span class="math display">\[
\begin{aligned}
    \mathbb{Var} [ \bar{X} ] = \frac{1}{n} \sum_{i \in [n] }
\mathbb{Var}[ X_i ]
                            \le \frac{1}{4n}
\end{aligned}
\]</span></p>
<p>Hence, <span class="math display">\[
\mu = \mathbb{E}[ \frac{1}{2\epsilon} (\bar X + \frac{2\epsilon -
1}{2n}) ]
\]</span></p>
<p>and <span class="math inline">\(\hat \mu \doteq \frac{1}{2\epsilon}
(\bar X + \frac{2\epsilon - 1}{2n})\)</span> is an unbiased estimator of
<span class="math inline">\(\mu\)</span>. As <span
class="math display">\[
\mathbb{Var}[ \hat \mu ] = \frac{1}{4 \epsilon^2 } \mathbb{Var}[\bar{X}
] \le \frac{1}{16 n \epsilon^2}
\]</span></p>
<p>By Chebyshev's inequality, <span class="math display">\[
\Pr[ |\hat \mu - \mu | \ge \sqrt{2} \cdot \frac{1 }{4\epsilon \sqrt{n} }
] \le \frac{ \mathbb{Var}[ \hat \mu ] }{ ( \sqrt{2} \cdot \frac{1 }{4
\epsilon \sqrt{n} } )^2 } = \frac{1}{2}
\]</span></p>
<p>Or we can apply Hoeffding inequality to show that, with probability
at least <span class="math inline">\(1 - \delta\)</span>, <span
class="math display">\[
|\bar{X} - \mathbb{E} [ \bar{X} ] | \le \sqrt{ \frac{\log
\frac{2}{\delta} }{2n} }
\]</span></p>
<p>i.e., <span class="math display">\[
|\hat \mu - \mu | = \frac{1}{2 \epsilon} |\bar{X} - \mathbb{E} [ \bar{X}
] | \le \frac{1}{ 2 \epsilon } \sqrt{ \frac{\log \frac{2}{\delta} }{2n}
}
\]</span></p>
<p>which is much tighter than Chebyshev inequality.</p>
<p>Finally, observe that to get a meaningful estimate <span
class="math inline">\(\hat \mu\)</span>, we require that <span
class="math inline">\(\frac{ 1 }{\epsilon \sqrt{n} } \le 1\)</span>,
i.e., <span class="math inline">\(n \in
\Omega(\frac{1}{\epsilon^2})\)</span> or <span
class="math inline">\(\epsilon \in \Omega( \frac{1}{ \sqrt{n} }
)\)</span>.</p>
<p><span class="math inline">\(\square\)</span></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/10/27/Twin-Drive-or-Not/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/10/27/Twin-Drive-or-Not/" class="post-title-link" itemprop="url">Twin Drive or Not?</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-10-27 01:15:03" itemprop="dateCreated datePublished" datetime="2020-10-27T01:15:03-04:00">2020-10-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-11-05 19:08:17" itemprop="dateModified" datetime="2020-11-05T19:08:17-05:00">2020-11-05</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>In this article, we introduce differential privacy. We start with a
story of information leakage.</p>
<h3 id="twin-drive-or-not">Twin Drive or Not</h3>
<p>Celestial Being is a private military organization with superior
technology. It has four advanced machines. The most powerful one is the
Gundam 00.</p>
<p>The Gundam 00 is about to engage the enemy.</p>
<div style="text-align:center">
<p><img src="https://lh5.googleusercontent.com/-9AOc-O5bdRk/S_mZxjf1DWI/AAAAAAAACvs/uXI0SvAMqWc/s640/5.jpg" width="500" height="250" /></p>
</div>
<p>Due to maintenance, Gundam 00 is not always equipped with two engines
(known as <strong><em>twin drive system</em></strong>). With probability
<strong><em>0.5</em></strong>, it uses one drive. We use <span
class="math inline">\(T = (1, 1)\)</span> to denote the status of
equipping with the twin drive system, and <span class="math inline">\(S
= (1, 0)\)</span> (or <span class="math inline">\((0, 1)\)</span>) for
status of single drive. Let <span class="math inline">\(X\)</span> be a
random variable that indicates drive status. Therefore, <span
class="math display">\[
\Pr[ X = T ] = 0.5, \\
\Pr[ X = S ] = 0.5.  
\]</span></p>
<div style="text-align:center">
<p><img src="https://knolly.files.wordpress.com/2009/03/00gundamdrive1.jpg" width="500" height="250" /></p>
</div>
<p>Raiser sword is one of Gundam 00 most powerful weapon. The energy
level of the Raiser sword, denote as <span
class="math inline">\(Y\)</span>, is a random variable in <span
class="math inline">\([0, 100]\)</span>, whose distribution, denoted as
<span class="math inline">\(\Pr[\cdot \mid X]\)</span>, depends on the
drive status. Thus, <span class="math inline">\(\Pr[Y = y \mid X =
T]\)</span> (or <span class="math inline">\(\Pr[Y = y \mid X =
S]\)</span>) is the probability that <span
class="math inline">\(Y\)</span> equals to <span
class="math inline">\(y\)</span> conditioned on <span
class="math inline">\(X = T\)</span> (<span class="math inline">\(X =
S\)</span>). Specifically, <span class="math display">\[
\Pr[\cdot \mid T] \sim B(100, 0.81) \\
\Pr[\cdot \mid S] \sim B(100, 0.09)
\]</span></p>
<p>where <span class="math inline">\(B(n, p)\)</span> denotes a binomial
distribution. The expected energy level is <span
class="math inline">\(81\)</span> with <em>twin drive system</em>,
compared to only <span class="math inline">\(9\)</span> with single
drive. This is called "<strong><em>squaring</em></strong>" phenomenon of
<em>twin drive</em>.</p>
<div style="text-align:center">
<p><img src="https://vignette.wikia.nocookie.net/gundam/images/8/84/Raiser_sword.png/revision/latest?cb=20101124151429" width="500" height="250" /></p>
</div>
<p>Now suppose that you're the enemy pilot of a mobile suit with just
average performance. Before you start dog fighting with Gundam 00, you
will be attacked by the 00's long-range raiser sword (you have not seen
00 yet). Luckily, you survive the raiser sword attack. Now you need to
make a decision. If 00 is equipped with twin drive, there is zero chance
that you can win the dog fight. The best choice is to leave the battle.
Otherwise, you can outperform 00 and you would like to engage it.</p>
<div style="text-align:center">
<p><img src="https://blogimg.goo.ne.jp/user_image/79/da/c198b8cf829b5f7f7dd507d40bb39ba5.jpg" width="500" height="250" /></p>
</div>
<p>Since you have just been attacked by the raiser sword, you have an
observation of its energy level <span class="math inline">\(y\)</span>.
By Bayes' theorem, <span class="math display">\[
\begin{aligned}
\Pr[ X = T \mid Y = y] = \frac{ \Pr[Y = y \mid X = T] \cdot \Pr[X = T]
}{ \Pr[Y = y \mid X = T] \cdot \Pr[X = T] + \Pr[Y = y \mid X = S] \cdot
\Pr[X = S] }
\\
\\
\Pr[ X = S \mid Y = y] = \frac{ \Pr[Y = y \mid X = S] \cdot \Pr[X = S]
}{ \Pr[Y = y \mid X = T] \cdot \Pr[X = T] + \Pr[Y = y \mid X = S] \cdot
\Pr[X = S] }
\end{aligned}
\]</span></p>
<p>Substituting with <span class="math inline">\(\Pr[X = S] = \Pr[X = T]
= 0.5\)</span>, we get <span class="math display">\[
\begin{aligned}
\Pr[ X = T \mid Y = y] = \frac{ \Pr[Y = y \mid X = T]  }{ \Pr[Y = y \mid
X = T]  + \Pr[Y = y \mid X = S] }
\\
\\
\Pr[ X = S \mid Y = y] = \frac{ \Pr[Y = y \mid X = S]  }{ \Pr[Y = y \mid
X = T]  + \Pr[Y = y \mid X = S] }
\end{aligned}
\]</span></p>
<p>The distributions <span class="math inline">\(B(100, 0.09)\)</span>
and <span class="math inline">\(B(100, 0.81)\)</span> are plotted
together below.</p>
<p><img
src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/B-100-0.09-vs-B-100-0.81.png?raw=true" /></p>
<p>Immediately, you can draw some conclusions based on single value of
<span class="math inline">\(y\)</span>, such as</p>
<ol type="1">
<li>If <span class="math inline">\(y = 10\)</span>, it is likely 00 has
only one drive.<br />
</li>
<li>If <span class="math inline">\(y = 75\)</span>, it is likely 00 has
twin drive.</li>
</ol>
<p>Or you can conclude based on the range of <span
class="math inline">\(y\)</span>, such as</p>
<ol type="1">
<li>If <span class="math inline">\(y \in [0, 20]\)</span>, it is likely
00 has single drive.</li>
<li>If <span class="math inline">\(y \in [70, 90]\)</span>, it is likely
00 has twin drive.</li>
</ol>
<p>Before the observation of <span class="math inline">\(y\)</span>, as
<span class="math inline">\(\Pr[X = S] = \Pr[X = T] = 0.5\)</span>, you
have only random guess over the engine status of 00. After the
observation, you might be much more confident about your guess, even
though the energy level of the raiser sword is a random variable.</p>
<p>Why does this happen? Because the two distributions are
well-separated. They are far from each other. Further, the prior
probabilities <span class="math inline">\(\Pr[X = S]\)</span> and <span
class="math inline">\(\Pr[X = T]\)</span> play important roles. If you
know <span class="math inline">\(\Pr[X = S] = 10^{-10}\)</span>, even if
you observe an energy level of <span class="math inline">\(y =
10\)</span>, you had better not engage Gundam 00. You know it could be
just a trap!</p>
<h3 id="formal-definition">Formal Definition</h3>
<p>Database managers face similar scenarios in privacy protection. We
know define the setting for differential privacy. We view a dataset
<span class="math inline">\(D\)</span> as a table of <span
class="math inline">\(n\)</span> rows, each of which comes from a domain
<span class="math inline">\(\mathcal{X}\)</span>. Hence <span
class="math inline">\(D \in \mathcal{X}^n\)</span>. Instead of releasing
the dataset directly, the manager runs a randomized algorithm <span
class="math inline">\(A: \mathcal{X}^n \rightarrow \mathcal{Y}\)</span>
on <span class="math inline">\(D\)</span>, and outputs <span
class="math inline">\(Y = A(D) \in \mathcal{Y}\)</span>. Here <span
class="math inline">\(\mathcal{Y}\)</span> is called the co-domain of
<span class="math inline">\(A\)</span> and does not necessarily equal to
<span class="math inline">\(\mathcal{X}^n\)</span>. Note that the output
distribution of <span class="math inline">\(A\)</span> may depend on the
input <span class="math inline">\(D\)</span>. Further, for simplicity of
discussion, we believe a uniform prior distribution over datasets in
<span class="math inline">\(\mathcal{X}^n\)</span>.</p>
<p>In the Gundam 00's story, <span class="math inline">\(\mathcal{X} =
\{0, 1\}^2\)</span>, and <span class="math inline">\(\mathcal{Y} = [0,
100]\)</span>.</p>
<p>Suppose there is another dataset <span
class="math inline">\(D&#39;\)</span> that differs only one row from
<span class="math inline">\(D\)</span>. The algorithm <span
class="math inline">\(A\)</span> is said to be differentially private if
a malicious user is unlikely to distinguish the input to <span
class="math inline">\(A\)</span> between <span
class="math inline">\(D\)</span> and <span
class="math inline">\(D&#39;\)</span>, by merely observing <span
class="math inline">\(A\)</span>'s output. Simply put, the conditional
distributions of <span class="math inline">\(\Pr[\cdot \mid X =
D]\)</span> and <span class="math inline">\(\Pr[\cdot \mid X =
D&#39;]\)</span> should be similar, where <span
class="math inline">\(X\)</span> is a variable that denotes the input
dataset.</p>
<p>We observe in the previous section that, if the distributions are
well separated, then we can infer the underlying input with high
confidence when the output value takes specific values or lies in
certain ranges.</p>
<p>There are many ways to characterize the closeness of two
distributions. We introduce the one proposed in [1].</p>
<blockquote>
<p>Algorithm <span class="math inline">\(A\)</span> is called <span
class="math inline">\((\epsilon, \delta)\)</span> differentially
private, if for any pair of neighboring datasets <span
class="math inline">\(D\)</span> and <span
class="math inline">\(D&#39;\)</span> (the ones that differ in only one
row), and for any (measurable) subset <span
class="math inline">\(\mathcal{R} \subset \mathcal{Y}\)</span>, it holds
that <span class="math display">\[
\Pr[Y \in \mathcal{R} \mid X = D ] \le \exp(\epsilon) \cdot \Pr[Y \in
\mathcal{R} \mid X = D&#39; ]+ \delta
\]</span></p>
</blockquote>
<p>In other words, we can't find a subset <span
class="math inline">\(\mathcal{R}\)</span>, with which we can
distinguish <span class="math inline">\(D\)</span> and <span
class="math inline">\(D&#39;\)</span> with high confidence. In the
previous example, such <span class="math inline">\(\mathcal{R}\)</span>
exists. E.g., <span class="math inline">\(R = [70, 90]\)</span>. If
<span class="math inline">\(Y\)</span> lies in <span
class="math inline">\(\mathcal{R}\)</span>, we can infer that Gundam 00
is likely to have twin drive.</p>
<h3 id="hypothesis-testing">Hypothesis Testing</h3>
<p>There is alternative view of <span class="math inline">\((\epsilon,
0)\)</span> differential privacy as hypothesis testing. Suppose that we
know the underlying dataset is either <span
class="math inline">\(D\)</span> or <span
class="math inline">\(D&#39;\)</span> with equal probability. After
observing the output of <span class="math inline">\(A\)</span>, we need
to decide which hypothesis of the following holds: <span
class="math display">\[
H_0: \text{ the dataset if } D \\
H_1: \text{ the dataset if } D&#39;
\]</span></p>
<p>Assume that we adopt a fixed strategy:</p>
<ol type="1">
<li>First we choose a fixed subset <span
class="math inline">\(\mathcal{R} \subset \mathcal{Y}\)</span>,</li>
<li>If <span class="math inline">\(Y \in \mathcal{R}\)</span>, we choose
to accept <span class="math inline">\(H_0\)</span>,</li>
<li>Otherwise, we accept <span class="math inline">\(H_1\)</span>.</li>
</ol>
<p>There are two kinds of errors we can make. The type I error is the
one when the true hypothesis is <span class="math inline">\(H_0\)</span>
and we accept <span class="math inline">\(H_1\)</span>. Conversely, type
II error is the one when the true hypothesis is <span
class="math inline">\(H_1\)</span> and we accept <span
class="math inline">\(H_0\)</span>. Let <span
class="math inline">\(p\)</span> and <span
class="math inline">\(q\)</span> be the probabilities we make type I and
II errors respectively. The following theorem holds</p>
<blockquote>
<p>Algorithm A is <span class="math inline">\((\epsilon, 0)\)</span>
differentially private then</p>
<ol type="1">
<li><span class="math inline">\(\frac{1}{1 + \exp(\epsilon) } \le q \le
\frac{1}{1 + \exp(-\epsilon) }\)</span><br />
</li>
<li><span class="math inline">\(\frac{1}{1 + \exp(\epsilon) } \le p \le
\frac{1}{1 + \exp(-\epsilon) }\)</span></li>
</ol>
</blockquote>
<p><em>Proof.</em> By definition, <span class="math display">\[
\begin{aligned}
    q   &amp;= \Pr[ X = D \mid  Y \in \bar{\mathcal{R}} ] \\
        &amp;= \frac{ \Pr[  Y \in \bar{\mathcal{R}} \mid X = D ] \Pr[X =
D ] }{ \Pr[  Y \in \bar{\mathcal{R}} \mid X = D ] \Pr[X = D ] + \Pr[  Y
\in \bar{\mathcal{R}} \mid X = D&#39; ] \Pr[X = D&#39; ] } \\
        &amp;= \frac{ \Pr[  Y \in \bar{\mathcal{R}} \mid X = D ]  }{
\Pr[  Y \in \bar{\mathcal{R}} \mid X = D ]  + \Pr[  Y \in
\bar{\mathcal{R}} \mid X = D&#39; ]  }
\end{aligned}
\]</span></p>
<p>As <span class="math inline">\(A\)</span> is <span
class="math inline">\((\epsilon, 0)\)</span> differentially private, it
holds that <span class="math display">\[
\Pr[  Y \in \bar{\mathcal{R}} \mid X = D&#39; ] \le \exp(\epsilon) \cdot
\Pr[  Y \in \bar{\mathcal{R}} \mid X = D ]
\]</span> and <span class="math display">\[
\Pr[  Y \in \bar{\mathcal{R}} \mid X = D ] \le \exp(\epsilon) \cdot
\Pr[  Y \in \bar{\mathcal{R}} \mid X = D&#39; ]
\]</span></p>
<p>therefore, <span class="math display">\[
\frac{1}{1 + \exp(\epsilon) } \le q \le \frac{1}{1 + \exp(-\epsilon) }
\]</span></p>
<p>By symmetry, we also have <span class="math display">\[
\frac{1}{1 + \exp(\epsilon) } \le p \le \frac{1}{1 + \exp(-\epsilon) }
\]</span></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<h3 id="reference">Reference</h3>
<p>[1] C. Dwork and A. Roth, “The Algorithmic Foundations of
Differential Privacy,” Foundations and Trends in Theoretical Computer
Science, vol. 9, no. 3–4, pp. 211–407, 2013<br />
[2] L. Wasserman and S. Zhou, “A statistical framework for differential
privacy,” arXiv:0811.2501 [math, stat], Oct. 2009, Accessed: Oct. 27,
2020.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/28/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/28/">28</a><span class="page-number current">29</span><a class="page-number" href="/page/30/">30</a><span class="space">&hellip;</span><a class="page-number" href="/page/66/">66</a><a class="extend next" rel="next" href="/page/30/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">196</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WOW</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
