<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="WOW">
<meta property="og:url" content="http://example.com/page/10/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/10/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>WOW</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">WOW</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">你生之前悠悠千載已逝<br>未來還會有千年沉寂的期待</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/11/16/Total-Variation-Distance-and-Product-Measure/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/11/16/Total-Variation-Distance-and-Product-Measure/" class="post-title-link" itemprop="url">Total Variation Distance and Product Measure</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-11-16 01:02:49 / Modified: 01:38:05" itemprop="dateCreated datePublished" datetime="2021-11-16T01:02:49+01:00">2021-11-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Let <span class="math inline">\(\mu_i, \nu_i\)</span> be probability
measures on the finite space <span class="math inline">\((\Omega_i,
2^{\Omega_i} )\)</span>, <span class="math inline">\(i \in [n]\)</span>.
Define <span class="math inline">\(\mu = \prod_{i \in [n]}
\mu_i\)</span> and <span class="math inline">\(\nu = \prod_{i \in [n]}
\nu_i\)</span> be the product measure on the product space <span
class="math inline">\((\Omega, 2^{\Omega})\)</span>. Then <span
class="math display">\[
    \Vert \mu - \nu \Vert_{TV} \le \sum_{i \in [n] } \Vert \mu_i - \nu_i
\Vert_{TV},
\]</span> where <span class="math inline">\(\Vert \cdot
\Vert_{TV}\)</span> is the total variation distance.</p>
<p><strong>Proof.</strong> Consider an <span class="math inline">\(x =
(x_1, \ldots, x_n) \in \Omega\)</span>.</p>
<p>For each <span class="math inline">\(i \in 0, \ldots, n\)</span>, let
<span class="math display">\[
    s(i) \doteq \mu_1 (x_1) \cdots \mu_i(x_i) \cdot \nu_{i + 1} (x_{i +
1} ) \cdots \nu_n (x_n).
\]</span> So <span class="math inline">\(s(0) = \nu(x)\)</span> and
<span class="math inline">\(s(n) = \mu(x)\)</span>. It follows that
<span class="math display">\[
    \begin{aligned}
        \nu(x) - \mu(x)
            &amp;= \sum_{i \in [n]} \left( s(i - 1) - s(i) \right) \\
            &amp;= \sum_{i \in [n]} \left( \big( \nu_i(x_i) - \mu_i(x_i)
\big) \cdot \mu_1 (x_1) \cdots \mu_{i - 1} (x_{i - 1}) \cdot \nu_{i + 1}
(x_{i + 1} ) \cdots \nu_n (x_n)\right).
    \end{aligned}
\]</span> Hence, <span class="math display">\[
    \begin{aligned}
        2 \cdot \Vert \mu - \nu \Vert_{TV}
            &amp;= \sum_{x \in \Omega} \vert \nu(x) - \mu(x) \vert \\
            &amp;= \sum_{x \in \Omega} \left\vert \sum_{i \in [n]} \big(
\nu_i(x_i) - \mu_i(x_i) \big) \cdot \mu_1 (x_1) \cdots \mu_{i - 1} (x_{i
- 1}) \cdot \nu_{i + 1} (x_{i + 1} ) \cdots \nu_n (x_n)\right\vert \\
            &amp;\le \sum_{x \in \Omega} \sum_{i \in [n]} \left\vert
\nu_i(x_i) - \mu_i(x_i) \right\vert \cdot \mu_1 (x_1) \cdots \mu_{i - 1}
(x_{i - 1}) \cdot \nu_{i + 1} (x_{i + 1} ) \cdots \nu_n (x_n) \\
            &amp;= \sum_{i \in [n]} \sum_{x_i \in \Omega_i} \left\vert
\nu_i(x_i) - \mu_i(x_i) \right\vert \\
            &amp;= \sum_{i \in [n]} 2 \cdot \Vert \mu_i - \nu_i
\Vert_{TV}.
    \end{aligned}
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/11/01/Coupling-Lemma/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/11/01/Coupling-Lemma/" class="post-title-link" itemprop="url">Coupling Lemma</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-11-01 23:07:54" itemprop="dateCreated datePublished" datetime="2021-11-01T23:07:54+01:00">2021-11-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-07-08 15:43:58" itemprop="dateModified" datetime="2024-07-08T15:43:58+02:00">2024-07-08</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Let $\mu$ and $\nu$ be two probability measures over a finite set $\Omega$.</p>
<blockquote>
<p><strong>Definition.</strong> A probability measure $\omega$ over $\Omega \times \Omega$ is a coupling of $(\mu, \nu)$ if its marginals are $\mu$ and $\nu$; that is</p>
<ol>
<li><p>$\forall x \in \Omega$, $\sum_{y \in \Omega} \omega(x, y) = \mu(x)$,</p>
</li>
<li><p>$\forall y \in \Omega$, $\sum_{x \in \Omega} \omega(x, y) = \nu(x)$.</p>
</li>
</ol>
</blockquote>
<h1 id="Coupling-Lemma"><a href="#Coupling-Lemma" class="headerlink" title="Coupling Lemma"></a>Coupling Lemma</h1><blockquote>
<p><strong>Lemma</strong> </p>
<ol>
<li>For any coupling $\omega$ of $(\mu, \nu)$, if the random variable $(X, Y)$ is distributed according to $\omega$, then <script type="math/tex; mode=display">
 \Pr[ X \neq Y ] \ge \Vert \mu - \nu \Vert_{TV}.</script></li>
<li>There exists a coupling $\omega^*$ (which is called the maximal coupling) for $(\mu, \nu)$ for which<script type="math/tex; mode=display">
 \Pr[ X \neq Y ] = \Vert \mu - \nu \Vert_{TV}.</script></li>
</ol>
</blockquote>
<h1 id="First-Proof"><a href="#First-Proof" class="headerlink" title="First Proof"></a>First Proof</h1><p><strong>Claim 1.</strong><br>First, observe that for every measurable set $S \subseteq \Omega$, it holds that </p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \mu(S) - \nu(S) 
            = \Pr [ X \in S ] - \Pr [ Y \in S ]
            \le \Pr[ X \in S, Y \notin S ] 
            \le \Pr[ X \neq Y ].
    \end{aligned}</script><p>It follows that </p>
<script type="math/tex; mode=display">
    \Vert \mu - \nu \Vert_{TV} = \max_{ \text{ measurable } S \subseteq \Omega} \big( \mu(S) - \nu(S) \big) \le \Pr[ X \neq Y ].</script><p><strong>Claim 2.</strong><br>Next, we show how to construct $\omega^*$.<br>For each $z \in \Omega$, define </p>
<script type="math/tex; mode=display">
    \omega^*(z, z) = \min \{ \mu(z), \nu(z) \}.</script><p>Clearly it holds that </p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \Pr[ X \neq Y ] 
            = 1 - \sum_{ z \in \Omega } \min \{ \mu(z), \nu(z) \}
            = \Vert \mu - \nu \Vert_{TV}.
    \end{aligned}</script><p>It is left to assign the probability mass $\Vert \mu - \nu \Vert_{TV}$ to $(x, y) \in \Omega \times \Omega$, for $x \neq y$. </p>
<p><strong>Case 1 $\big( \Vert \mu - \nu \Vert_{TV} = 0 \big)$.</strong><br>Then we can set $\omega^*(x, y) = 0$ for all $x \neq y$.<br>Further, it holds that $\mu(z) = \nu(z)$ for all $z \in \Omega$.<br>Therefore, </p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \sum_{ y \in \Omega } w^* (x, y) = w^*(x, x) = \min \{ \mu(x), \nu(x) \} = \mu( x ), \\
        \sum_{ x \in \Omega } w^* (x, y) = w^*(y, y) = \min \{ \mu(y), \nu(y) \} = \nu( y )\,. 
    \end{aligned}</script><p><strong>Case 2 $\big( \Vert \mu - \nu \Vert_{TV} \neq 0 \big)$.</strong><br>Denote $S_+ \doteq { z \in \Omega: \mu(z) \ge \nu(z) }$.<br>Define two probability mass functions </p>
<script type="math/tex; mode=display">
    \lambda_1 (z) \doteq \frac{ \mu(z) - \nu(z) }{ \Vert \mu - \nu \Vert_{TV} } \cdot \mathbf{1}[z \in S_+],\qquad
    \lambda_2 (z) \doteq \frac{ \nu(z) - \mu(z) }{ \Vert \mu - \nu \Vert_{TV} } \cdot \mathbf{1}[z \notin S_+].</script><p>Then $\lambda<em>1 ( \Omega ) = \lambda_1 (S</em>+) = \lambda<em>2 (\Omega) = \lambda_2 ( \bar S</em>+ ) = 1$.</p>
<p>Now, for $x, y \in \Omega, x \neq y$, define</p>
<script type="math/tex; mode=display">
    \omega^*(x, y) = \Vert \mu - \nu \Vert_{TV} \cdot \lambda_1 (x) \cdot \lambda_2 (y) .</script><p>Also note that for all $z \in \Omega$, $\Vert \mu - \nu \Vert_{TV} \cdot \lambda_1 (z) \cdot \lambda_2 (z) = 0$.<br>Therefore, </p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \sum_{ y \in \Omega } w^* (x, y) 
            &= w^*(x, x) + \sum_{ y \in \Omega : \, y \neq x } w^* (x, y) \\
            &= \min \{ \mu(x), \nu(x) \} + \sum_{ y \in \Omega } \Vert \mu - \nu \Vert_{TV} \cdot \lambda_1 (x) \cdot \lambda_2 (y) \\
            &= \min \{ \mu(x), \nu(x) \} + \Vert \mu - \nu \Vert_{TV} \cdot \lambda_1 (x) \cdot \lambda_2 (\Omega) \\
            &= \min \{ \mu(x), \nu(x) \} + \big( \mu(x) - \nu(x) \big) \cdot \mathbf{1}[x \in S_+] \\
            &= \mu(x). 
    \end{aligned}</script><p>Similarly, we can verify that for each $y \in \Omega$, </p>
<script type="math/tex; mode=display">
    \sum_{y \in \Omega} \omega^*(x, y) = \nu(y).</script><p>$\square$ </p>
<h1 id="Second-Proof"><a href="#Second-Proof" class="headerlink" title="Second Proof"></a>Second Proof</h1><p><strong>Claim 1.</strong> We see that </p>
<script type="math/tex; mode=display">
    \Pr[X = Y] = \sum_{z \in \Omega} \Pr[X = z, Y = z] \le \sum_{z \in \Omega} \min \{ \mu(z), \nu(z) \}.</script><p>Hence, </p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \Pr[X \neq Y] 
            &= 1 - \Pr[X = Y] \ge 1 - \sum_{z \in \Omega} \min \{ \mu(z), \nu(z) \} \\
            &= \sum_{z \in \Omega} \Big( \mu(z) - \min \{ \mu(z), \nu(z) \} \Big)
            = \Vert \mu - \nu \Vert_{TV}. 
    \end{aligned}</script><p><strong>Claim 2.</strong><br>The case is trivial if $\Vert \mu - \nu \Vert<em>{TV}$.<br>Suppose that $\eta =  \Vert \mu - \nu \Vert</em>{TV} &gt; 0$. </p>
<p>Define </p>
<script type="math/tex; mode=display">
    \lambda(z) \doteq \min \{ \mu(z), \nu(z) \}, \qquad  \forall z \in \Omega.</script><p>Further, define the distributions $\pi_0$ and $\pi_1$ by </p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \pi_0 (x, y) 
            &\doteq \frac{1}{1 - \eta} \cdot \lambda(x) \cdot \mathbb{I}{[x = y]}, 
            & \forall x, y \in \Omega, \\
        \pi_1 (x, y) 
            &\doteq \frac{\mu(x) - \lambda(x)}{\eta} \cdot \frac{\nu(y) - \lambda(y)}{ \eta }
            & \forall x, y \in \Omega. 
    \end{aligned}</script><p>Then $\pi = (1 - \eta) \pi_0 + \eta \pi_1$ is a distribution, whose marginals are </p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \sum_{y \in \Omega} \pi(x, y) 
            &= \lambda(x) + \big( \mu(x) - \lambda(x) \big) = \mu(x), \\
        \sum_{x \in \Omega} \pi(x, y) 
            &= \lambda(y) + \big( \nu(y) - \lambda(y) \big) = \nu(y), 
    \end{aligned}</script><p>where we use the fact that </p>
<script type="math/tex; mode=display">
    \Vert \mu - \nu \Vert_{TV} = \sum_{x \in \Omega} \big(\mu(x) - \lambda(x) \big) = \sum_{y \in \Omega} \big( \nu(y) - \lambda(y) \big).</script><p>Finally, consider the marginals of $\pi_0$ and $\pi_1$: </p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \pi_0 (x, \cdot) 
            &\doteq \sum_{y \in \Omega} \frac{1}{1 - \eta} \cdot \lambda(x) \cdot \mathbb{I}{[x = y]}
            = \frac{1}{1 - \eta} \cdot \lambda(x)
            & \forall x \in \Omega, \\
        \pi_0 (\cdot, y) 
            &\doteq \sum_{x \in \Omega} \frac{1}{1 - \eta} \cdot \lambda(x) \cdot \mathbb{I}{[x = y]}
            = \frac{1}{1 - \eta} \cdot \lambda(y)
            & \forall y \in \Omega, \\
        \pi_1 (x, \cdot) 
            &\doteq \sum_{y \in \Omega} \frac{\mu(x) - \lambda(x)}{\eta} \cdot \frac{\nu(y) - \lambda(y)}{ \eta }
            = \frac{\mu(x) - \lambda(x)}{\eta}
            & \forall x \in \Omega, \\
        \pi_1 (\cdot, y) 
            &\doteq \sum_{x \in \Omega} \frac{\mu(x) - \lambda(x)}{\eta} \cdot \frac{\nu(y) - \lambda(y)}{ \eta }
            = \frac{\nu(y) - \lambda(y)}{ \eta }
            & \forall y \in \Omega, 
    \end{aligned}</script><p>Then $\pi_1 (x, \cdot)$ and $\pi_1 (\cdot, y)$ have disjoint support, and $\eta$ is the minimum parameter such that the following condition hold: </p>
<script type="math/tex; mode=display">
    \mu = (1 - \eta) \cdot \pi_0 (x, \cdot)  + \eta \cdot \pi_1 (x, \cdot), \\
    \nu = (1 - \eta) \cdot \pi_0 (\cdot, y)  + \eta \cdot \pi_1 (\cdot, y).</script><p>$\square$ </p>
<p><strong>Reference</strong></p>
<p>[1] <em>Constantinos Daskalakis, <a target="_blank" rel="noopener" href="https://people.csail.mit.edu/costis/6896sp11/lec3s.pdf">6.896 Probability and Computation, Lecture 3</a>, 2011.</em>  </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/09/06/Sum-of-Independent-Laplacian-Random-Variables/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/09/06/Sum-of-Independent-Laplacian-Random-Variables/" class="post-title-link" itemprop="url">Sum of Independent Laplacian Random Variables</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-09-06 14:33:15" itemprop="dateCreated datePublished" datetime="2021-09-06T14:33:15+02:00">2021-09-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-09-07 15:30:47" itemprop="dateModified" datetime="2021-09-07T15:30:47+02:00">2021-09-07</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Let <span class="math inline">\(X_i \sim Laplace(0, b_i)\)</span>,
<span class="math inline">\(i \in [n]\)</span> be independent random
variables that follow Laplacian distributions, i.e., for each <span
class="math inline">\(i \in [n]\)</span>, the probability density
function of <span class="math inline">\(X_i\)</span> is <span
class="math display">\[
    p(X_i = x) = \frac{1}{ 2 b_i } \exp \left( - \frac{ |x| }{ b_i
}\right),\, \forall x \in \mathbb{R}.
\]</span></p>
<h1 id="moment-generating-function">Moment Generating Function</h1>
<blockquote>
<p><strong>Fact.</strong> For each <span class="math inline">\(i \in
[n]\)</span>, the moment generating function of <span
class="math inline">\(X_i\)</span> is <span class="math display">\[
\mathbb{E} [ \exp ( t X_i) ] = \frac{1}{1 - b_i^2 \cdot t^2 },\,
\text{where } |t| &lt; 1 / b_i.
\]</span></p>
</blockquote>
<p><strong>Proof.</strong> Let <span class="math inline">\(|t| &lt; 1 /
b_i\)</span>. Via the definition of moment generating function, we get
<span class="math display">\[
    \begin{aligned}
        \mathbb{E}[ \exp (t X_i) ]
            &amp;= \int \exp ( t x) \cdot \frac{1}{ 2 b_i } \exp \left(
- \frac{ |x| }{ b_i } \right) \\
            &amp;=
            \frac{1}{ 2 b_i } \left( \int_{ -\infty }^0 \exp \left( tx +
\frac{ x }{ b_i }\right)
            +
            \int_0^{ \infty } \exp \left( tx - \frac{ x }{ b_i }\right)
\right) \\
            &amp;=
            \frac{1}{ 2 b_i } \left( \frac{1}{t + 1 / b_i }\exp \left(
tx + \frac{ x }{ b_i } \right) \mid_{-\infty}^0
            +
            \frac{1}{t - 1 / b_i } \exp \left( tx - \frac{ x }{ b_i }
\right) \mid_0^\infty \right) \\
            &amp;=
            \frac{1}{ 2 b_i } \left( \frac{1}{t + 1 / b_i }
            -
            \frac{1}{t - 1 / b_i }  \right) \\
            &amp;=
            \frac{1}{ 2 b_i } \left( \frac{ - 2 / b_i }{t^2 - 1 / b_i^2
} \right) \\
            &amp;= \frac{1}{ 1 - b_i^2 \cdot t^2  }.
    \end{aligned}
\]</span> <span class="math inline">\(\square\)</span></p>
<h1 id="concentration-inequalities">Concentration Inequalities</h1>
<p>Define <span class="math inline">\(X = \sum_{i \in [n] }
X_i\)</span>. There are various ways to obtains concentration
inequalities for <span class="math inline">\(X\)</span>.</p>
<h2 id="one">One</h2>
<blockquote>
<p><strong>Theorem.</strong> If <span class="math inline">\(0 \le
\lambda \le \big( 2 \sqrt{2} \cdot \sum_{i \in [n] } b_i^2 \big) \cdot
\min_{i \in [n] } 1 / b_i\)</span>, then <span class="math display">\[
\Pr[ X \ge \lambda ] \le \exp \left( - \frac{\lambda^2}{8 \cdot \sum_{i
\in [n] } b_i^2 } \right).
\]</span> If <span class="math inline">\(\big( 2 \sqrt{2} \cdot \sum_{i
\in [n] } b_i^2 \big) \cdot \min_{i \in [n] } 1 / b_i \le
\lambda\)</span>, then <span class="math display">\[
\Pr[ X \ge \lambda ] \le \exp \left( - \frac{\lambda}{2} \cdot \left(
\min_{i \in [n] } \frac{ 1 }{ b_i \cdot \sqrt{2} } \right) \right).
\]</span></p>
</blockquote>
<p>The proof applies similar techniques to the ones in the proofs of
Chernoff Bounds.</p>
<p><em>The inequalities state that when <span
class="math inline">\(\lambda\)</span> is small, we have Gaussian like
bounds. When <span class="math inline">\(\lambda\)</span> is large, we
have a exponential tail bound, which is much fatter than the Gaussian
one.</em></p>
<p>The second one seems counter intuitive at the first glance. Consider
the special case where the <span class="math inline">\(b_i\)</span> are
identical, and <span class="math inline">\(b_i = b\)</span> for all
<span class="math inline">\(i \in [n]\)</span>. Then the RHS of the
inequality becomes <span class="math inline">\(\exp( - \lambda / (2
\sqrt{2} \cdot b) )\)</span>. It seems that the tail bound does not
depend on <span class="math inline">\(n\)</span>! However it does. To
apply the second tail bound, we need that <span class="math display">\[
    \lambda \ge \big( 2 \sqrt{2} \cdot \sum_{i \in [n] } b^2 \big) \cdot
\min_{i \in [n] } 1 / b = 2 \sqrt{2} \cdot n \cdot b.
\]</span></p>
<p>Before proving the theorem, we need the following lemma.</p>
<blockquote>
<p><strong>Lemma.</strong> For each <span class="math inline">\(i \in
[n]\)</span>, when <span class="math inline">\(0 \le t \le 1 / (b_i
\cdot \sqrt{2})\)</span>, it holds that <span class="math display">\[
\frac{1}{ 1 - b_i^2 \cdot t^2  } \le \exp( 2 \cdot b_i^2 \cdot t^2 ).
\]</span></p>
</blockquote>
<p><img
src="https://raw.githubusercontent.com/wuhao-wu-jiang/BlogImgs/master/Sum-of-Independent-Laplacian-Random-Variables/pic.png" /></p>
<p><em>Proof.</em> For <span class="math inline">\(x \in [0, 1 /
2]\)</span>, <span class="math display">\[
    1 + x \le e^x \le \frac{1}{1 - x} \le 1 + 2 x \le \exp(2  x).
\]</span></p>
<p>The tangent line of the function <span class="math inline">\(y = 1 /
(1 - x)\)</span> at <span class="math inline">\(x = 0\)</span> is given
by <span class="math inline">\(y = 1 + x\)</span>. As <span
class="math inline">\(y = 1 / (1 - x)\)</span> is a convex function, it
is above the line <span class="math inline">\(y = 1 + x\)</span> for
<span class="math inline">\(x \le 1\)</span>. If we increase the slope
of <span class="math inline">\(y = 1 + x\)</span> a little bit, then the
new line should lie above <span class="math inline">\(y = 1 / (1 -
x)\)</span>, if <span class="math inline">\(x\)</span> is not "too far"
away from <span class="math inline">\(0\)</span>. As <span
class="math inline">\(x \rightarrow 1\)</span>, the function <span
class="math inline">\(y = 1 / (1 - x)\)</span> approaches infty, we
can't hope to upper bound it by a linear nor even exponential
function.</p>
<p><span class="math inline">\(\square\)</span></p>
<p><strong>Proof of the Theorem.</strong></p>
<p>Let <span class="math inline">\(0 \le t \le \min_{i \in [n] } 1 /
(b_i \cdot \sqrt{2} )\)</span>, <span class="math display">\[
    \begin{aligned}
        \Pr[ X \ge \lambda ]
            &amp;= \Pr[ \exp( t X) \ge \exp( t \lambda ) ] \\
            &amp;\le \exp( - t \lambda) \cdot \mathbb{E}[ \exp(t X) ] \\
            &amp;= \exp( - t \lambda) \cdot \prod_{i \in [n] }
\mathbb{E}[ \exp(t X_i) ] \\
            &amp;\le \exp \left( - t \lambda + \sum_{i \in [n] } 2 \cdot
b_i^2 \cdot t^2 \right)
    \end{aligned}
\]</span> The function <span class="math inline">\(f(t) \doteq \left(
\sum_{i \in [n] } 2 \cdot b_i^2 \right) \cdot t^2 - \lambda t\)</span>
decreases when <span class="math display">\[
    t \le \frac{\lambda}{4 \cdot \sum_{i \in [n] } b_i^2  },
\]</span> and increases afterwards. If <span
class="math inline">\(\min_{i \in [n] } 1 / (b_i \cdot \sqrt{2} ) \ge
\lambda / \big( 4 \cdot \sum_{i \in [n] } b_i^2 \big)\)</span>, then
<span class="math display">\[
    \begin{aligned}
        \min_{ 0 \le t \le \min_{i \in [n] } 1 / (b_i \cdot \sqrt{2} ) }
f(t)
        &amp;= \left( \sum_{i \in [n] } 2 \cdot b_i^2 \right) \cdot
\left( \frac{\lambda}{4 \cdot \sum_{i \in [n] } b_i^2  } \right)^2 -
\lambda \cdot \frac{\lambda}{4 \cdot \sum_{i \in [n] } b_i^2  } \\
        &amp;= - \frac{\lambda^2}{8 \cdot \sum_{i \in [n] } b_i^2  }.
    \end{aligned}
\]</span> Otherwise, <span class="math inline">\(\min_{i \in [n] } 1 /
(b_i \cdot \sqrt{2} ) \le \lambda / \big( 4 \cdot \sum_{i \in [n] }
b_i^2 \big)\)</span>, then <span class="math display">\[
    \begin{aligned}  
        \min_{ 0 \le t \le \min_{i \in [n] } 1 / (b_i \cdot \sqrt{2} ) }
f(t)
        &amp;= \left( \sum_{i \in [n] } 2 \cdot b_i^2 \right) \cdot
\left( \min_{i \in [n] } \frac{ 1 }{ b_i \cdot \sqrt{2} } \right)^2 -
\lambda \cdot \left( \min_{i \in [n] } \frac{ 1 }{ b_i \cdot \sqrt{2} }
\right) \\
        &amp;= \left( \left( \sum_{i \in [n] } 2 \cdot b_i^2 \right)
\cdot \left( \min_{i \in [n] } \frac{ 1 }{ b_i \cdot \sqrt{2} } \right)
- \lambda \right) \cdot \left( \min_{i \in [n] } \frac{ 1 }{ b_i \cdot
\sqrt{2} } \right) \\
        &amp;\le \left( \frac{\lambda}{2} - \lambda \right) \cdot \left(
\min_{i \in [n] } \frac{ 1 }{ b_i \cdot \sqrt{2} } \right) \\
        &amp;= - \frac{\lambda}{2} \cdot \left( \min_{i \in [n] } \frac{
1 }{ b_i \cdot \sqrt{2} } \right).
    \end{aligned}
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h2 id="two">Two</h2>
<p>There is a trick to combine the two cases into to one. We can choose
arbitrary <span class="math inline">\(\nu \in \mathbb{R}\)</span>, such
that <span class="math display">\[
    \nu \ge \sqrt{\sum_{i \in [n] } b_i^2 },\, \quad\, \nu \ge \sqrt{
\frac{\lambda }{ 2 } \cdot \max_{i \in [n] } (b_i \cdot \sqrt{2}) }.
\]</span> Then, for <span class="math inline">\(0 \le t \le \min_{i \in
[n] } 1 / (b_i \cdot \sqrt{2} )\)</span>, <span class="math display">\[
    \begin{aligned}
        \Pr[ X \ge \lambda ]
            &amp;\le \exp \left( - t \lambda + \sum_{i \in [n] } 2 \cdot
b_i^2 \cdot t^2 \right) \\
            &amp;\le \exp \left( - t \lambda + 2 \cdot \nu^2 \cdot t^2
\right)
    \end{aligned}
\]</span> We can always set <span class="math display">\[
    t = \frac{\lambda}{4 \cdot \nu^2  } \le \min_{i \in [n] } \frac{1}{
b_i \cdot \sqrt{2} },
\]</span></p>
<p>and obtain <span class="math display">\[
    \Pr[ X \ge \lambda ] \le \exp \left( - \frac{\lambda^2}{ 8 \nu^2 }
\right).
\]</span></p>
<p>To make the bound as tight as possible, we would like <span
class="math inline">\(\nu\)</span> to be as small as possible.
Therefore, the best choice would be <span class="math display">\[
    \nu = \max \left\{ \sqrt{ \sum_{i \in [n] } b_i^2 }, \sqrt{
\frac{\lambda }{ 2 } \cdot \max_{i \in [n] } (b_i \cdot \sqrt{2})
}  \right\}.
\]</span></p>
<p>The bound is indeed equivalent to the one in the previous
section.</p>
<h2 id="can-we-do-better">Can We Do Better</h2>
<p>Can we improve the bound, if we have better approximation of <span
class="math inline">\(y = 1 / (1 - x)\)</span>? Observe that <span
class="math display">\[
    \begin{aligned}
        \exp( - t \lambda) \cdot \prod_{i \in [n] } \mathbb{E}[ \exp(t
X_i) ]
        &amp;= \exp( - t \lambda) \cdot \prod_{i \in [n] } \frac{1}{1 -
b_i^2 \cdot t^2 }
    \end{aligned}
\]</span> Previously, we apply the approximation <span
class="math inline">\(1 / (1 - x) \le \exp(2 x)\)</span> to upper bound
the RHS.</p>
<p>On the other hand, as <span class="math inline">\(1 / (1 - x) \ge
e^x\)</span> for <span class="math inline">\(x \in [0, 1]\)</span>, any
upper bound for the RHS is lower bounded by <span
class="math display">\[
    \begin{aligned}
        \exp \left( - t \lambda + \sum_{i \in [n] } b_i^2 \cdot t^2
\right)
    \end{aligned}
\]</span></p>
<p>Even if we give maximum freedom to <span
class="math inline">\(t\)</span> by allowing it to take any value in
<span class="math inline">\([0, \min_{i \in [n] } 1/ b_i ]\)</span>, the
above term is minimized to <span class="math display">\[
    \begin{cases}
        \exp \left( - \lambda^2 / \big( 4 \cdot \sum_{i \in [n] }
b_i^2  \big) \right), &amp; \lambda / \big( 2 \cdot \sum_{i \in [n] }
b_i^2  \big) \le \min_{i \in [n] } 1/ b_i \\
        \exp \left( - \lambda \cdot ( \min_{i \in [n] } 1 / b_i ) +
\sum_{i \in [n] } b_i^2 \cdot ( \min_{i \in [n] } 1 / b_i )^2 \right),
&amp; \lambda / \big( 2 \cdot \sum_{i \in [n] } b_i^2  \big) &gt;
\min_{i \in [n] } 1/ b_i
    \end{cases}
\]</span></p>
<p>This implies that, even if we find some better approximation for
<span class="math inline">\(y = 1 / (1 - x)\)</span> to derive a
concentration inequality, we can only improve it by a constant (in the
exponent), compared to the ones we prove in the previous section.</p>
<h1 id="reference">Reference</h1>
<p>[1]. <em>Chan, T.H.H., Shi, E. and Song, D., 2011. Private and
continual release of statistics. ACM Transactions on Information and
System Security (TISSEC), 14(3), pp.1-24.</em></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/9/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><span class="page-number current">10</span><a class="page-number" href="/page/11/">11</a><span class="space">&hellip;</span><a class="page-number" href="/page/65/">65</a><a class="extend next" rel="next" href="/page/11/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">195</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WOW</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
