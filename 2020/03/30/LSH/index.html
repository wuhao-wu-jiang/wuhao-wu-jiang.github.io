<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Given a set \(S \subset U\) of \(n\) points, a metric \(d\) defined on \(U\), and a query point \(v\), the nearest neighbor search (NNS) problem finds \(v\)&#39;s nearest point in \(S\): \[ u &#x3D; \arg\min_">
<meta property="og:type" content="article">
<meta property="og:title" content="LSH">
<meta property="og:url" content="http://example.com/2020/03/30/LSH/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:description" content="Given a set \(S \subset U\) of \(n\) points, a metric \(d\) defined on \(U\), and a query point \(v\), the nearest neighbor search (NNS) problem finds \(v\)&#39;s nearest point in \(S\): \[ u &#x3D; \arg\min_">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-03-30T05:14:46.000Z">
<meta property="article:modified_time" content="2020-05-03T12:17:23.000Z">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2020/03/30/LSH/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>LSH | WOW</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">WOW</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">你生之前悠悠千載已逝<br>未來還會有千年沉寂的期待</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/03/30/LSH/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          LSH
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-03-30 16:14:46" itemprop="dateCreated datePublished" datetime="2020-03-30T16:14:46+11:00">2020-03-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-03 22:17:23" itemprop="dateModified" datetime="2020-05-03T22:17:23+10:00">2020-05-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><strong><em>Given a set <span class="math inline">\(S \subset U\)</span> of <span class="math inline">\(n\)</span> points, a metric <span class="math inline">\(d\)</span> defined on <span class="math inline">\(U\)</span>, and a query point <span class="math inline">\(v\)</span>, the nearest neighbor search (NNS) problem finds <span class="math inline">\(v\)</span>'s nearest point in <span class="math inline">\(S\)</span>:</em></strong> <span class="math display">\[
u = \arg\min_{s \in S} d(v, s)
\]</span> Potential applications include web search and clustering.</p>
<p>If <span class="math inline">\(U\)</span> is a Euclidean space <span class="math inline">\(\mathcal{R}^d\)</span> for some <span class="math inline">\(d\)</span>, the hardness of NNS depends largely on the value of <span class="math inline">\(d\)</span>. Suppose <span class="math inline">\(d = 1\)</span>, then we can pre-process the points by building a balanced binary search tree on <span class="math inline">\(S\)</span>. Finding the nearest point to <span class="math inline">\(v \notin S\)</span> reduces to searching for its predecessor and successor, which takes <span class="math inline">\(O(\log n)\)</span> time. For <span class="math inline">\(d = 2\)</span>, we can construct a Voronoi diagram.</p>
<p>For higher dimensions <span class="math inline">\(d\)</span> it is not easy to extend the index structures. A naïve search loops over all points and takes <span class="math inline">\(O(nd)\)</span> time. It is natural to ask whether we can do better. If we are willing to sacrifice accuracy for efficiency, this is possible. Instead of finding the exact nearest neighbor, we relax our goal to finding an approximate nearest neighbor whose distance is within <span class="math inline">\(1 + \epsilon\)</span> of the minimum one.</p>
<p>One possible solution is Johnson–Lindenstrauss decomposition. We can generate a matrix <span class="math inline">\(A \in R^{ O( \frac{ \log n }{ \epsilon^2 } )\times d}\)</span> and multiply it with every element in <span class="math inline">\(S\)</span>. The mapping <span class="math inline">\(u \rightarrow Au\)</span> preserves pair-wise distance up to a relative error of <span class="math inline">\(\epsilon\)</span>. The pre-processing takes <span class="math inline">\(O( \frac{n d \log n}{\epsilon^2} )\)</span> time. To answer an query, we map <span class="math inline">\(v\)</span> to <span class="math inline">\(Av\)</span>, which takes <span class="math inline">\(O(\frac{ d\log n }{ \epsilon^2 } )\)</span> time. Then we perform a loop over all elements of <span class="math inline">\(\{ Au : u \in S\}\)</span>, which takes <span class="math inline">\(O(\frac{ n \log n }{ \epsilon^2 } )\)</span> time. Therefore, the total time complexity is <span class="math inline">\(O(\frac{ (n + d) \log n }{ \epsilon^2 } )\)</span>.</p>
<h3 id="hashing">Hashing</h3>
<p>[1] solves the problem by hashing. We call the pair of points that are close to each other the <em>similar pair</em> and the pair that are far from each other the <em>dissimilar pair</em>. Intuitively, we want similar pairs to be hashed to the same bucket and that dissimilar pairs to be hashed to different buckets.</p>
<p>Instead of finding the <span class="math inline">\((1 + \epsilon)\)</span> approximate nearest neighbor directly, [1] further reduces it to the <span class="math inline">\((c, r)\)</span>-approximate neighbor search (ANNS<span class="math inline">\((c, r)\)</span>) problem, which is defined as follows:</p>
<p><strong><em>Given a query point <span class="math inline">\(v\)</span>, if <span class="math inline">\(\exists s \in S\)</span>, then return a point <span class="math inline">\(u\)</span>, such that</em></strong> <span class="math display">\[
d(v, u) \le c \cdot r
\]</span></p>
<p>The reduction from <span class="math inline">\(1 + \epsilon\)</span> to ANNS(<span class="math inline">\(c, r\)</span>) is not easy. Here we show one that returns the <span class="math inline">\((1 + \epsilon)^2\)</span> approximate nearest neighbor. Let <span class="math inline">\(d_{\max} = \max_{s, s&#39;} d(s, s&#39;)\)</span> and <span class="math inline">\(d_{\min} = \min_{s, s&#39;} d(s, s&#39;)\)</span>. We build a set of structures that answers ANNS(<span class="math inline">\(1 + \epsilon\)</span>, r) queries for the values of <span class="math inline">\(r\)</span>: <span class="math display">\[
d_{\min}, \ d_{\min} (1 + \epsilon ), \ d_{min} (1 + \epsilon)^2,\ ...,\ d_{\max}
\]</span></p>
<p>Then given the query point <span class="math inline">\(v\)</span>, we do a binary search to find the smallest <span class="math inline">\(r\)</span> that returns a point. This imposes an additional cost of <span class="math inline">\(\ln {\ln \frac{d_{\max} }{d_{\min} } \over \ln (1 + \epsilon) }\)</span>.</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\text{NNS} \longrightarrow (1+\epsilon) \text{NNS} \longrightarrow \text{ANNS}(c, r) \longrightarrow (r, cr, p_1, p_2)\text{-LSH} \longrightarrow \text{Boosting Probability}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">The Problem Reduction Chain</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<h3 id="r-cr-p_1-p_2-locality-sensitive-hashing-family"><span class="math inline">\((r, cr, p_1, p_2)\)</span>-Locality Sensitive Hashing Family</h3>
<p>Now we show how to solve the ANNS<span class="math inline">\((c, r)\)</span> problem with hashing. Designing a perfecting hashing that solves the problem directly is not easy. It is desirable to have some hashing which successes with some probability and then boost its probability systematically. To achieve this, we introduce the idea of <span class="math inline">\((r, cr, p_1, p_2)\)</span>-locality sensitive hashing family.</p>
<p><strong><em>Given a set of point <span class="math inline">\(V\)</span>, a metric <span class="math inline">\(d(\cdot , \cdot)\)</span> defined on <span class="math inline">\(V\)</span>, a collection of hash function <span class="math inline">\(\mathcal{H} = \{ h: V \rightarrow Z\}\)</span> is called <span class="math inline">\((r, cr, p_1, p_2)\)</span> locality sensitive if for any <span class="math inline">\(v, u \in V\)</span> and an <span class="math inline">\(h\)</span> sampled uniformly from <span class="math inline">\(\mathcal{H}\)</span>, it holds that</em></strong></p>
<ol type="1">
<li>If <span class="math inline">\(d(v, u) &lt; r\)</span>, then <span class="math inline">\(\Pr_{h \in \mathcal{H} } [h(v) = h(u)] \ge p_1\)</span>.</li>
<li>If <span class="math inline">\(d(v, u) \ge cr\)</span>, then <span class="math inline">\(\Pr_{h \in \mathcal{H} } [h(v) = h(u)] \le p_2\)</span></li>
</ol>
<p>where <span class="math inline">\(p_2 &lt; p_1 \le 1\)</span>. Intuitively, pairs near to each other should be more likely to collide. Hence <span class="math inline">\(p_1 = p_2^{\rho}\)</span> for some <span class="math inline">\(\rho = \log p_1 / \log p_2 &lt; 1\)</span>.</p>
<p>Ideally, we have <span class="math inline">\(p_1 \approx 1\)</span> and <span class="math inline">\(p_2 \approx 0\)</span>. For other cases we can magnify the gap between <span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_2\)</span> and boost <span class="math inline">\(p_1\)</span> to approximate <span class="math inline">\(1\)</span> and <span class="math inline">\(p_2\)</span> to approximate <span class="math inline">\(0\)</span>. The hardness of the boosting highly depends on the value of <span class="math inline">\(c\)</span>.</p>
<h4 id="example">Example</h4>
<p>Suppose that <span class="math inline">\(U = \{0, 1\}^d\)</span>, <span class="math inline">\(d(u, v) = u \oplus v = |u - v|_1\)</span> and <span class="math inline">\(\mathcal{H} = \{ h_i (u) = u_i \}_{i \in [d]}\)</span>, where <span class="math inline">\(h_i\)</span> selects the <span class="math inline">\(i\)</span>th bit of <span class="math inline">\(u\)</span>. Picking an <span class="math inline">\(h\)</span> uniformly from <span class="math inline">\(\mathcal{H}\)</span> and applying <span class="math inline">\(h\)</span> to <span class="math inline">\(u\)</span> is equivalent to selecting a bit uniformly from <span class="math inline">\(u\)</span>. Therefore,</p>
<ol type="1">
<li>If <span class="math inline">\(d(v, u) &lt; r\)</span> (<span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> has less then <span class="math inline">\(r\)</span> common bits), then <span class="math inline">\(\Pr_{h \in \mathcal{H} } [h(v) = h(u)] \ge \frac{d - r}{d} = 1 - \frac{r}{d} = p_1\)</span>.</li>
<li>If <span class="math inline">\(d(v, u) \ge cr\)</span>, then <span class="math inline">\(\Pr_{h \in \mathcal{H} } [h(v) = h(u)] \le \frac{d - cr}{d} = 1 - \frac{cr}{d} = p_2\)</span></li>
</ol>
<p>Now <span class="math inline">\(p_1 \approx \exp(- r / d)\)</span> and <span class="math inline">\(p_2 \approx \exp(- cr / d)\)</span>. Hence <span class="math inline">\(\rho \approx \frac{1}{c}\)</span>. Indeed it can be proven rigorously that <span class="math display">\[
\rho = \frac{\ln (1 - \frac{r}{d}) }{ \ln (1 - \frac{cr}{d}) } \le \frac{1}{c}
\]</span></p>
<p>as <span class="math inline">\(( 1 - \frac{r}{d})^c \ge 1 - \frac{cr}{d}\)</span>. There are many ways to prove this. Since we are dealing with probability, we give a probabilistic interpretation of this inequality. Suppose that are <span class="math inline">\(c\)</span> independent events each happening with probability <span class="math inline">\(\frac{r}{d}\)</span>. Then the probability that at least one of them happens is given by <span class="math display">\[
1 - \Pr[\textbf{none of them happens } ] = 1 - (1 - \frac{r}{d})^c
\]</span></p>
<p>On the other hand, by union bound, this is upper bounded by <span class="math inline">\(\frac{cr}{d}\)</span>.</p>
<h3 id="boosting-the-probabilities">Boosting the Probabilities</h3>
<p>We would like the boost the probability such that <span class="math inline">\(p_1 \approx 1\)</span> and <span class="math inline">\(p_2 \approx 0\)</span>. We follow a two-step approach. First we sample <span class="math inline">\(k\)</span> (to be determined) hash functions independently from <span class="math inline">\(\mathcal{H}\)</span> can concatenate them as a single hash function <span class="math inline">\(g\)</span>: <span class="math display">\[
g(v) = [h_1(v),  h_2(v), ... ,h_k(v)]
\]</span></p>
<p>Here <span class="math inline">\(g\)</span> hash a point <span class="math inline">\(v\)</span> to a <span class="math inline">\(k\)</span> dimensional vector. After this, <span class="math inline">\(g(v) = g(u)\)</span> happens only if <span class="math inline">\(h_i(v) = h_i(u)\)</span> for all <span class="math inline">\(i \in [k]\)</span>. By independence of <span class="math inline">\(h_i\)</span>'s,</p>
<ol type="1">
<li><p>If <span class="math inline">\(d(v, u) \ge cr\)</span>, the collision probability of <span class="math inline">\(u\)</span> with <span class="math inline">\(v\)</span> drops to <span class="math inline">\(p_2^k\)</span>: <span class="math display">\[
 \Pr [ g(v) = g(u) ] \le p_2^k
 \]</span></p></li>
<li><p>On the other hand, if <span class="math inline">\(d(v, u) &lt; r\)</span>, the collision probability also drops to <span class="math inline">\(p_1^k = (p_2^k)^\rho\)</span> <span class="math display">\[
 \Pr [ g(v) = g(u) ] \ge  p_1^k = p_2^{\rho k} = (p_2^{k})^\rho
 \]</span> which is relatively small and not desirable.</p></li>
</ol>
<p>We need a second level of boosting to increase the collision probability of similar pairs. Instead of using only one function <span class="math inline">\(g\)</span>, we use a collection of independent copies: <span class="math display">\[
g_1, g_2, ..., g_l
\]</span></p>
<p>where <span class="math inline">\(l\)</span> is the number to be determined. Now,</p>
<ul>
<li>If <span class="math inline">\(d(v, u) &lt; r\)</span>, the probability that at least one of the <span class="math inline">\(g_i(u)\)</span> equals to <span class="math inline">\(g_i(v)\)</span> is given by <span class="math display">\[
  \begin{aligned}
      \Pr \left[ \exists i \in [l], \ s.t., \ g_i(u) = g_i(v) \right] 
          &amp;= 1 - (1 - p_1^k)^l  \\
          &amp;= 1 - (1 - (p_2^k)^\rho)^l \\
          &amp;\ge 1 - \exp( - (p_2^k)^\rho l )
  \end{aligned}
  \]</span></li>
</ul>
<p>We can take</p>
<ol type="1">
<li><p><span class="math inline">\(p_2^k = \frac{1}{n}\)</span>, i.e., <span class="math inline">\(k = \frac{\log n }{ \log 1 / p_2 }\)</span>.</p></li>
<li><p><span class="math inline">\(\exp( - (p_2^k)^\rho l ) = \frac{1}{n}\)</span>, i.e., <span class="math inline">\(l = \frac{1}{(p_2^k)^\rho } \ln n = n^\rho \ln n\)</span>.</p></li>
</ol>
<p>For a fixed query point <span class="math inline">\(q\)</span> and for any fixed <span class="math inline">\(i \in [l]\)</span>, by linearity of expectation, the expected number of dissimilar collision is given by</p>
<p><span class="math display">\[
\begin{aligned}
    E \left[ |\{ u \in S: d(q, u) \ge cr \wedge g_i(q) = g_i(u)  \}| \right] 
        &amp;= \sum_{ u \in S : \  d(q, u) \ge cr } \Pr[g_i(v)= g_i(u)] \\
        &amp;\le n \cdot \frac{1}{n} = 1
\end{aligned}
\]</span></p>
<p>Therefore, there are <span class="math inline">\(l\)</span> of dissimilar collisions over all <span class="math inline">\(i \in [l]\)</span>. This implies an expected overhead of <span class="math inline">\(l\)</span> examinations of dissimilar points. However, by Markov inequality, the number of such points is less than <span class="math inline">\(2l\)</span> with probability at least <span class="math inline">\(1 / 2\)</span>. The time for examination of dissimilar point is <span class="math inline">\(O(ld) = O(d n^\rho \ln n)\)</span>.</p>
<h3 id="time-and-space">Time and Space</h3>
<p>Now, given a query point <span class="math inline">\(q\)</span>, computing <span class="math inline">\(g_i(q)\)</span> for a fixed <span class="math inline">\(i\)</span> takes <span class="math inline">\(O(k)\)</span> time. Computing <span class="math inline">\(l\)</span> of them takes <span class="math inline">\(O(kl)\)</span> time. In expectation, there are <span class="math inline">\(l\)</span> dissimilar collision points with <span class="math inline">\(q\)</span>. Checking one collision point takes <span class="math inline">\(O(d)\)</span> time. Therefore, the expected query time is given by (note that we stop upon finding the first ANN of <span class="math inline">\(q\)</span>):</p>
<p><span class="math display">\[
\begin{aligned}
    O(kl + dl) 
    &amp;= O(\frac{\ln n}{\ln \frac{1}{p_2}} n^\rho \ln n + d n^\rho \ln n) \\
    &amp;= O(n^{ \rho} \ln^2 n / \ln \frac{1}{p_2} + d n^\rho \ln n) \\
    &amp;= \tilde{O}( n^\rho )
\end{aligned}
\]</span></p>
<p>As for the space usage, for each point <span class="math inline">\(u\)</span> in <span class="math inline">\(S\)</span>, we need to compute <span class="math inline">\(g_i(u)\)</span> and store this value (we need to store this, because <span class="math inline">\(g_i(u)\)</span> is self could be a large number and when putting <span class="math inline">\(\{ g_i(u) : u \in S\}\)</span> into a hash table, we need to treat <span class="math inline">\(g_i(u)\)</span> as the key and store it for later collision comparison. But is it possible that when there is a collision, we re-compute this value again to avoid storing it ?). We need to repeat this for <span class="math inline">\(l\)</span> hash functions. Therefore, the space usage is given by <span class="math display">\[
O(nkl) = O(n^{1 + \rho} \ln^2 n / \ln \frac{1}{p_2})
\]</span></p>
<h3 id="another-boosting-scheme">Another Boosting Scheme</h3>
<p>In last section, we have a scheme that checks <span class="math inline">\(O(n^\rho \ln n)\)</span> dissimilar points in expectation. In this section we achieve it with high probability.</p>
<ol type="1">
<li>First, to reduce the collision probability of dis-similar pairs, we concatenate <span class="math inline">\(k\)</span> functions from <span class="math inline">\(\mathcal{H}\)</span>. This gives a <span class="math display">\[
     (r, cr, p_1^k, p_2^k)
\]</span> locative sensitive hash function. We determine the value of <span class="math inline">\(k\)</span> later. <!-- We pick $k = \frac{\ln n}{\ln \frac{1}{p_2} }$, such that $p_2^k = 1 / n$. In expectation, at most $1$ dis-similar collision occurs.  --></li>
<li>Second, to boost the collision probability of similar pairs, we use <span class="math inline">\(l\)</span> concatenated hash functions independently. The probability at least one collision occurs is given by <span class="math display">\[
     1 - (1 - p_1^k)^l \ge 1 - e^{-p_1^k \cdot l} 
\]</span> We require this to happen with constant probability <span class="math inline">\(1 - \frac{1}{e}\)</span>, hence we need to set <span class="math inline">\(l = \frac{1}{p_1^k} = (\frac{1}{p_2^k})^\rho\)</span>. <!-- where $l = n^\rho$. The final equality holds since $p_1^k \cdot l = p_2^{k \cdot \rho} \cdot l = n^{-\rho} \cdot l = 1$ --></li>
<li>Now consider a query point <span class="math inline">\(q\)</span>. We compute <span class="math inline">\(g_1(q), g_2(q), ..., g_l(q)\)</span> and check the points <span class="math inline">\(u\)</span>'s such that <span class="math inline">\(g_i(u) = g_i(q)\)</span> for some <span class="math inline">\(i \in [l]\)</span>. Note that we check at most the first <span class="math inline">\(4 n p_2^k l + 1\)</span> points we found. Why <span class="math inline">\(4 n p_2^k l + 1\)</span>? In expectation, there are <span class="math inline">\(n p_2^k l\)</span> dissimilar collisions. By Markov inequality, the probability of dissimilar collisions is no more than <span class="math inline">\(4l\)</span> is at most <span class="math inline">\(1 / 4\)</span>. By union bound, <span class="math display">\[
 \begin{aligned}
     &amp;\Pr[\exists \text{ more than } 4l \text{ bad collision } \vee \nexists \text{ good collision }] \\
     &amp;\le \frac{1}{e} + \frac{1}{4} \\
     &amp;\le \frac{1}{2.5} + \frac{1}{4} \\
     &amp;= \frac{5}{16}
 \end{aligned}
 \]</span></li>
</ol>
<p>Therefore, the boosting strategy successes with constant probability. Now consider the running time of such boosting strategy. When a query point <span class="math inline">\(q\)</span> comes, we need to compute <span class="math inline">\(g_1(q), g_2(q), ..., g_l(q)\)</span>, which takes time <span class="math inline">\(kl\)</span>. Further, the strategy checks at most <span class="math inline">\(4 n p_2^k l + 1\)</span> points and checking each point takes <span class="math inline">\(O(d)\)</span> time. The overall time used is <span class="math display">\[
O(kl + (4 n p_2^k l + 1)d)
\]</span></p>
<p>To minimize the running time, we need to choose proper value of <span class="math inline">\(k\)</span>, such that <span class="math display">\[
k = 4np_2^k d \rightarrow \ln k + k \ln \frac{1}{p_2} = \ln (4nd) 
\]</span></p>
<p>It suffice to take <span class="math inline">\(k = \frac{\ln 4nd}{ \ln \frac{1}{p_2} }\)</span>. It follows that <span class="math display">\[
p_2^k = \frac{1}{4nd} \\
l = \left( \frac{1}{p_2^k} \right)^\rho = (4nd)^\rho 
\]</span></p>
<p>and the running time is given by <span class="math display">\[
O\left( (4nd)^\rho \frac{\ln (4nd)}{\ln \frac{1}{p_2} } \right)
\]</span></p>
<p>As <span class="math inline">\(n \succ d\)</span>, this is equivalent to <span class="math display">\[
O\left( (4nd)^\rho \frac{\ln n}{\ln \frac{1}{p_2} } \right)
\]</span></p>
<p>We can repeat the above steps by <span class="math inline">\(\ln n / \ln \frac{16}{5}\)</span> times, to boost the success probability to <span class="math inline">\(1 - \frac{1}{n}\)</span>. The overall running time is given by <span class="math display">\[
O\left( (4nd)^\rho \frac{\ln^2 n}{\ln \frac{1}{p_2} } \right)
\]</span></p>
<h3 id="reference">Reference</h3>
<ol type="1">
<li>Indyk, P. and Motwani, R., 1998, May. Approximate nearest neighbors: towards removing the curse of dimensionality. In Proceedings of the thirtieth annual ACM symposium on Theory of computing (pp. 604-613).</li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/03/23/Working-Set-BST/" rel="prev" title="Working Set BST">
      <i class="fa fa-chevron-left"></i> Working Set BST
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/03/31/Sampling-With-Or-Without-Replacement/" rel="next" title="Sampling With Or Without Replacement">
      Sampling With Or Without Replacement <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#hashing"><span class="nav-number">1.</span> <span class="nav-text">Hashing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#r-cr-p_1-p_2-locality-sensitive-hashing-family"><span class="nav-number">2.</span> <span class="nav-text">\((r, cr, p_1, p_2)\)-Locality Sensitive Hashing Family</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#example"><span class="nav-number">2.1.</span> <span class="nav-text">Example</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#boosting-the-probabilities"><span class="nav-number">3.</span> <span class="nav-text">Boosting the Probabilities</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#time-and-space"><span class="nav-number">4.</span> <span class="nav-text">Time and Space</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#another-boosting-scheme"><span class="nav-number">5.</span> <span class="nav-text">Another Boosting Scheme</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#reference"><span class="nav-number">6.</span> <span class="nav-text">Reference</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">125</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WOW</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
