<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="WOW">
<meta property="og:url" content="http://example.com/page/26/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/26/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>WOW</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">WOW</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">你生之前悠悠千載已逝<br>未來還會有千年沉寂的期待</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/02/07/Simplex/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/07/Simplex/" class="post-title-link" itemprop="url">Simplex</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-07 10:03:19" itemprop="dateCreated datePublished" datetime="2020-02-07T10:03:19+11:00">2020-02-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-02-18 12:10:34" itemprop="dateModified" datetime="2020-02-18T12:10:34+11:00">2020-02-18</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Simplex is the first systematically method for solving linear program via a sequence of Gaussian eliminations. It was invented by George Dantzig in 1947 [1]. Algebraically, it converts the linear program from one slack form into to an equivalent one whose objective value does not decrease and possibly increase. It keeps going until the optimal is reached. Geometrically, it is a greedy search strategy that moves from a vertex of the feasible region to another one, with the objective value at the new vertex as least as good as or possibly improved over the previous one. It is an exponential algorithm, although most of time it does a lot better. In this blog we walk through a simple example to illustrate this.</p>
<p>In this case we are operating a factory with two products. Both product have 1 unit of profit. Making the products needs to use two kind of machine. Product one uses 1 hour of machine one and product two uses 2 hours of machine one. Further, product one uses 2 hours of machine two and product two uses 1 hour of machine two. Both machines operate at most 6 hours each day. We want to maximize our profit: <span class="math display">\[
\begin{aligned}
&amp;\max   &amp; x_1 + x_2 \\
&amp;s.t.   &amp; x_1 + 2x_2 \le 6 \\
&amp;       &amp; 2x_1 + x_2 \le 6 \\
&amp;       &amp;   x_1, x_2 \ge 0
\end{aligned}
\]</span></p>
<p>It can be represented concisely in matrix form: <span class="math display">\[
\begin{aligned}
&amp;\max   &amp; c^T x \\
&amp;s.t.   &amp; A x \le b \\
&amp;       &amp; x \ge 0
\end{aligned}
\]</span></p>
<p>where <span class="math display">\[
\begin{aligned}
A = \left[ 
    \begin{matrix}
        1 &amp; 2 \\
        2 &amp;  1
    \end{matrix} 
    \right], 
\quad 
b = \left[ 
    \begin{matrix}
        6 \\
        6 
    \end{matrix} 
    \right], 
\quad 
c = \left[ 
    \begin{matrix}
        1 \\
        1 
    \end{matrix} 
    \right], 
\quad 
x = \left[ 
    \begin{matrix}
        x_1 \\
        x_2 
    \end{matrix} 
    \right],
\end{aligned}
\]</span></p>
<p><em>We call the set of points that satisfy the constraints of the optimization problem the feasible region</em> <span class="math display">\[
P = \{x : Ax \le b, x \ge 0\}
\]</span></p>
<p>It is obvious that the optimal is obtained at <span class="math inline">\((2, 2)\)</span>, which gives the objective value <span class="math inline">\(4\)</span>. It is a <em>vertex</em> of the feasible region.</p>
<h4 id="slack-form">Slack Form</h4>
<p>In general, it might not be obvious what the optimal point is. But if the elements of <span class="math inline">\(b\)</span> are non-negative, the origin is a feasible point, from which we can begin our search. To make the search easier, we are going to introduce an additional number of variables, the slack variables <span class="math inline">\(s_1, s_2\)</span> and <span class="math inline">\(z\)</span> that correspond to the constraints and objective value. <span class="math display">\[
\begin{aligned}
z =     &amp;   &amp; x_1       &amp;+x_2   \\
s_1 =   &amp;6  &amp; -x_1      &amp;-2x_2  \\
s_2 =   &amp;6  &amp; -2x_1     &amp;-x_2   \\
\end{aligned}
\]</span></p>
<p>rewrite the optimization into <em>slack form</em>: <span class="math display">\[
\begin{aligned}
&amp;\max   &amp; x_1   &amp;+x_2       &amp;       &amp;           &amp;= z\\
&amp;s.t.   &amp; x_1   &amp;+2x_2      &amp;+s_1   &amp;           &amp;= 6 \\
&amp;       &amp; 2x_1  &amp;+x_2       &amp;       &amp;+s_2       &amp;= 6 \\
&amp;       &amp; x_1,  &amp;x_2,       &amp;s_1    &amp;,s_2       &amp;\ge 0
\end{aligned}
\]</span></p>
<p>They are called slacks variables because they correspond how much slack you have in the inequalities in the original problem. For this slack form, we also call <span class="math inline">\(s_1\)</span> and <span class="math inline">\(s_2\)</span> basic variables, and the original variables non-basic variables.</p>
<p>Now the feasible region <span class="math inline">\(F\)</span> is considered as the intersection of the two subspaces <span class="math display">\[
F = \{x : Ax = b \} \cap \{ x \ge 0 \}
\]</span></p>
<p>We can represent the LP in <em>slack form</em> even more concisely in a table: <span class="math display">\[
\begin{aligned}
    1   &amp;&amp;  2   &amp;&amp;  1   &amp;&amp;  0   &amp;&amp; \mid 6 \\
    2   &amp;&amp;  1   &amp;&amp;  0   &amp;&amp;  1   &amp;&amp; \mid 6 \\ 
    \hline 
    1   &amp;&amp;  1   &amp;&amp;  0   &amp;&amp;  0   &amp;&amp; \mid 0 \\
\end{aligned}
\]</span></p>
<p>where the last column denotes the objective function. This example has a trivial starting point : <span class="math inline">\((0, 0, 6, 6)\)</span>. It is called a basic solution in which all non-basic variables are set to zero. It can be read from the tabular form: the identity matrix correspond to basic variables, and <span class="math inline">\((s_1, s_2) = b\)</span>.</p>
<h4 id="pivoting">Pivoting</h4>
<p>Look at the original LP: <span class="math display">\[
\begin{aligned}
&amp;\max   &amp; x_1   &amp;+x_2       &amp;       &amp;           &amp;= z\\
&amp;s.t.   &amp; x_1   &amp;+2x_2      &amp;+s_1   &amp;           &amp;= 6 \\
&amp;       &amp; 2x_1  &amp;+x_2       &amp;       &amp;+s_2       &amp;= 6 \\
&amp;       &amp; x_1,  &amp;x_2,       &amp;s_1    &amp;,s_2       &amp;\ge 0
\end{aligned}
\]</span></p>
<p>As we would like to maximize the objective, we would like to increase the value of <span class="math inline">\(x_1\)</span> or <span class="math inline">\(x_2\)</span> as much as possible. Suppose we just increase one variable at a time. For example, we can increase variable <span class="math inline">\(x_1\)</span> and keep the value of <span class="math inline">\(x_2\)</span> to be <span class="math inline">\(0\)</span>.</p>
<p>How much can we increase <span class="math inline">\(x_1\)</span>? After increasing <span class="math inline">\(x_1\)</span>, we need to maintain the inequality constraints: <span class="math display">\[
x_1 + s_1 = 6 \\
2 x_1 + s_2 = 6
\]</span></p>
<p>The values of <span class="math inline">\(s_1\)</span> and <span class="math inline">\(s_2\)</span> decrease as <span class="math inline">\(x_1\)</span> increases. By they can be drop below <span class="math inline">\(0\)</span>. The maximum possible increases of <span class="math inline">\(x_1\)</span> is bounded by <span class="math inline">\(6 / 2 = 3\)</span>. If we set <span class="math inline">\(x_1 = 3\)</span>, <span class="math inline">\(s_1 = 6 - x_1 = 3\)</span> and <span class="math inline">\(s_2 = 6 - 2x_1 = 0\)</span>.</p>
<p>Note that <span class="math inline">\(x_1\)</span> increases from <span class="math inline">\(0\)</span> to <span class="math inline">\(3\)</span> and <span class="math inline">\(s_2\)</span> decreases from <span class="math inline">\(6\)</span> to <span class="math inline">\(0\)</span>. This process is called <em>pivoting</em>.</p>
<p>How do we perform pivoting in the tabular form? By the replacement we have just performed -- normalizing the second row, and using it to eliminate all other elements in the first column.</p>
<p>Recall the original table: <span class="math display">\[
\begin{aligned}
    1   &amp;&amp;  2   &amp;&amp;  1   &amp;&amp;  0   &amp;&amp; \mid 6 \\
    2   &amp;&amp;  1   &amp;&amp;  0   &amp;&amp;  1   &amp;&amp; \mid 6 \\ 
    \hline 
    1   &amp;&amp;  1   &amp;&amp;  0   &amp;&amp;  0   &amp;&amp; \mid 0 \\
\end{aligned}
\]</span></p>
<p>We divide the second row by a factor of 2 to normalize it, and subtract the first and third row by the second row <span class="math display">\[
\begin{aligned}
    0   &amp;&amp;  3/2 &amp;&amp;  1   &amp;&amp; -1/2 &amp;&amp; \mid 3 \\
    1   &amp;&amp;  1/2 &amp;&amp;  0   &amp;&amp;  1/2 &amp;&amp; \mid 3 \\ 
    \hline 
    0   &amp;&amp;  1/2 &amp;&amp;  0   &amp;&amp; -1/2 &amp;&amp; \mid -3 \\
\end{aligned}
\]</span></p>
<p>Observe the first two rows of the tabular form: <span class="math display">\[
\begin{aligned}
    0   &amp;&amp;  3/2 &amp;&amp;  1   &amp;&amp; -1/2 &amp;&amp; \mid 3 \\
    1   &amp;&amp;  1/2 &amp;&amp;  0   &amp;&amp;  1/2 &amp;&amp; \mid 3 \\ 
\end{aligned}
\]</span> If we set <span class="math inline">\(x_2 = 0\)</span> and <span class="math inline">\(s_2 = 0\)</span>, the constraints they implies becomes <span class="math display">\[
s_1 = 3 \\
x_1 = 3 
\]</span> Again the unity columns correspond to non-zero elements and we can read the solution from the tabular form.</p>
<h4 id="correctness-of-pivoting">Correctness of Pivoting</h4>
<p>Before we continue our search on the tabular form, we need to show that pivoting is correct in the sense that, after pivoting, the tabular form represents the same optimization.</p>
<p>In particular, we need to guarantee that the feasible regions are the same and the objective function are equivalent defined on the feasible regions.</p>
<p>We focus on the extended matrix that represents the constraints: <span class="math display">\[
\bar A = [A, b] = 
\left[\begin{aligned}
    1   &amp;&amp;  2   &amp;&amp;  1   &amp;&amp;  0   &amp;&amp; \mid 6 \\
    2   &amp;&amp;  1   &amp;&amp;  0   &amp;&amp;  1   &amp;&amp; \mid 6 \\
\end{aligned}\right]
\]</span> <em>FACT 1.</em> Doing a row replacement on <span class="math inline">\(\bar A\)</span> does not change <span class="math inline">\(F\)</span>, where row replacement is defined as <span class="math display">\[
\bar A[i: ] \leftarrow \bar A[i: ] + k \cdot \bar A[j: ]
\]</span> i.e., adding <span class="math inline">\(k\)</span> times the <span class="math inline">\(j\)</span>-th row to the <span class="math inline">\(i\)</span>-th row, for <span class="math inline">\(i \neq j, k \in R\)</span>.</p>
<p>To see this, denote <span class="math inline">\(F\)</span> and <span class="math inline">\(F&#39;\)</span> the sets before and after the replacement respectively. <span class="math inline">\(F = F&#39;\)</span> implies that each point <span class="math inline">\(x\)</span> belonging to <span class="math inline">\(F\)</span> belongs to <span class="math inline">\(F&#39;\)</span>, and vice-versa. Specifically, the row replacement corresponds to left multiplying <span class="math inline">\(\bar A\)</span> by a matrix</p>
<p><span class="math display">\[
\begin{aligned}
E_{(i,j), k} \doteq 
    \left[ \begin{matrix}
        1 &amp; \\ 
          &amp; 1 \\
          &amp;     &amp; \quad...      \\
          &amp;     &amp; k     &amp; 1     \\
          &amp;     &amp;       &amp;       &amp;    ...  \\
          &amp;     &amp;       &amp;       &amp;           &amp;    1
    \end{matrix} \right]
\end{aligned}
\]</span></p>
<p>which is a diagonal matrix with an additional <span class="math inline">\(k\)</span> in the <span class="math inline">\((i, j)\)</span> position. It is invertible with inverse matrix <span class="math display">\[
\begin{aligned}
E_{(i,j), -k} \doteq 
    \left[ \begin{matrix}
        1 &amp; \\ 
          &amp; 1 \\
          &amp;     &amp; \quad...      \\
          &amp;     &amp; -k    &amp; 1     \\
          &amp;     &amp;       &amp;       &amp;    ...  \\
          &amp;     &amp;       &amp;       &amp;           &amp;    1
    \end{matrix} \right]
\end{aligned}
\]</span></p>
<p>The previous claim becomes <span class="math inline">\(\{ x : E_{(i, j), k} A x = E_{(i, j), k} b \} = \{ x : A x = b \}\)</span>.</p>
<p>But wait. Why do we subtract the last row from the second one? <em>Fact 1</em> has justified the replacement operation on <span class="math inline">\(\bar A\)</span>, but not on the objective coefficients <span class="math inline">\(c\)</span> (the last row in the tabular form). To illustrate the meaning of the operation, recall that <span class="math display">\[
x_1 + x_2 + 0 \cdot s_1 + 0 \cdot s_2 = z
\]</span> Hence <span class="math inline">\(z\)</span> is the value of the objective function. After normalizing the second row, it becomes <span class="math display">\[
x_1 + 1 / 2 x_2 +  0 s_1 + 1/2 s_2 = 3 \\
\]</span></p>
<p>The constraint holds for any feasible point of the linear programming. Therefore, <span class="math display">\[
\begin{aligned}
z - 3 
    &amp;= (x_1 + x_2 + 0 s_1 + 0 s_2)  - (x_1 + 1 / 2 x_2 +  0 s_1 + 1/2 s_2) \\ 
    &amp;= 0x_1 + 1/2x_2 + 0s_1 - 1/2 s_2 \\
    &amp;\Leftrightarrow \\
    z 
    &amp;= 0x_1 + 1/2x_2 + 0s_1 - 1/2 s_2 + 3 
\end{aligned}
\]</span></p>
<p>The last <span class="math inline">\(-3\)</span> in the table is the inverse constant in the objective functions after the replacement of variable.</p>
<h4 id="back-to-our-search">Back to our search</h4>
<p>To improve the current solution further, we note that the coefficient of <span class="math inline">\(x_2\)</span> is positive. We can increase the value of <span class="math inline">\(x_2\)</span>. The maximum increase is given by <span class="math inline">\(\min \{ 3 / (1 / 2), 3 / (3/ 2) \} = 2\)</span>, determined by the first row: <span class="math display">\[
\begin{aligned}
    0   &amp;&amp;  3/2 &amp;&amp;  1   &amp;&amp; -1/2 &amp;&amp; \mid 3 \\
    1   &amp;&amp;  1/2 &amp;&amp;  0   &amp;&amp;  1/2 &amp;&amp; \mid 3 \\ 
    \hline 
    0   &amp;&amp;  1/2 &amp;&amp;  0   &amp;&amp; -1/2 &amp;&amp; \mid -3 \\
\end{aligned}
\]</span> To make the change explicitly, we perform elimination by the first row <span class="math display">\[
\begin{aligned}
    0   &amp;&amp;  1   &amp;&amp;  2/3 &amp;&amp; -1/3 &amp;&amp; \mid 2 \\
    1   &amp;&amp;  0   &amp;&amp; -1/3 &amp;&amp;  2/3 &amp;&amp; \mid 2 \\ 
    \hline 
    0   &amp;&amp;  0   &amp;&amp; -1/3 &amp;&amp; -1/3 &amp;&amp; \mid -4 \\
\end{aligned}
\]</span> which give solution <span class="math inline">\(x = (2, 2, 0, 0)\)</span> and objective value <span class="math inline">\(4\)</span>. It is indeed optimal solution for the problem, as all coefficients of the optimization are non-positive.</p>
<h4 id="optimality-condition-and-strong-duality">Optimality Condition and Strong Duality</h4>
<p>We investigate the result deeper by viewing the initial tabular form in abbreviation as <span class="math display">\[
\left[ \begin{matrix}
A \quad I \mid b \\ c^T  \quad 0 \mid 0
\end{matrix} \right]
\]</span> The series of <span class="math inline">\(m\)</span> Gaussian elimination can be interpreted as left multiplying a matrix: <span class="math display">\[
\begin{aligned}
\left[ \begin{matrix}
    &amp; R     &amp; 0 \\
    &amp; -y^T  &amp; 1 \\
\end{matrix} \right] \doteq E_m...E_3 E_2 E_1
\end{aligned}
\]</span> where each <span class="math inline">\(E_j\)</span> ( <span class="math inline">\(1 \le j \le m\)</span>) matrix is invertible and represents a Gaussian elimination, i.e., if we left multiple a matrix by <span class="math inline">\(E_j\)</span>, it is equivalent to perform Gaussian elimination on the matrix. The matrix product <span class="math inline">\(E_m...E_3 E_2 E_1\)</span> has the form <span class="math display">\[
\begin{aligned}
\left[ \begin{matrix}
    &amp; R     &amp; 0 \\
    &amp; -y^T  &amp; 1 \\
\end{matrix} \right] 
\end{aligned}
\]</span> because we never use the last row to eliminate the other rows.</p>
<p>Now: <span class="math display">\[
\begin{aligned}
\left[ \begin{matrix}
    &amp; R     &amp; 0 \\
    &amp; -y^T  &amp; 1 \\
\end{matrix} \right]
\left[ \begin{matrix}
    &amp; A &amp; I \mid    b \\ 
    &amp; c^T  &amp; 0 \mid 0
\end{matrix} \right] 
=
\left[ \begin{matrix}
    &amp; RA            &amp; R     &amp; \mid &amp; Rb \\ 
    &amp; -y^TA+c^T     &amp; -y^T  &amp;\mid &amp; -y^T b
\end{matrix} \right]
\end{aligned}
\]</span> In our example, <span class="math display">\[
\begin{aligned}
    1   &amp;&amp;  2   &amp;&amp;  1   &amp;&amp;  0   &amp;&amp; \mid 6 \\
    2   &amp;&amp;  1   &amp;&amp;  0   &amp;&amp;  1   &amp;&amp; \mid 6 \\ 
    \hline 
    1   &amp;&amp;  1   &amp;&amp;  0   &amp;&amp;  0   &amp;&amp; \mid 0 \\
\end{aligned}
\Rightarrow ... \Rightarrow
\begin{aligned}
    0   &amp;&amp;  1   &amp;&amp;  2/3 &amp;&amp; -1/3 &amp;&amp; \mid 2 \\
    1   &amp;&amp;  0   &amp;&amp; -1/3 &amp;&amp;  2/3 &amp;&amp; \mid 2 \\ 
    \hline 
    0   &amp;&amp;  0   &amp;&amp; -1/3 &amp;&amp; -1/3 &amp;&amp; \mid -4 \\
\end{aligned}
\]</span> we have <span class="math display">\[
R = \begin{aligned}
\left[ \begin{matrix}
    2 / 3 &amp; -1 / 3 \\
    -1 / 3 &amp; 2 /3 
\end{matrix} \right] 
\end{aligned}
\qquad 
y^T = [ -1 / 3, -1  / 3]
\]</span></p>
<p>The optimality condition of simplex algorithm implies that <span class="math display">\[
\begin{aligned}
-y^T A + c^T &amp;\le 0 \\
y^T &amp;\le 0 \\
y^T b &amp;= c^T x
\end{aligned}
\]</span></p>
<p>This is the optimal solution for the dual program of the primal: <span class="math display">\[
\min \ b^T y, \qquad s.t.,  A^T y \ge c, \quad y^T \ge 0
\]</span></p>
<p>If simplex algorithm stops, it implies strong duality holds:</p>
<ul>
<li>The optimal value of the primal program equals to the optimal one of the dual program, assuming that both values exist and are bounded.</li>
</ul>
<h4 id="geometric-interpretation">Geometric Interpretation</h4>
<p>In the beginning we claim that the simplex algorithm move from one vertex to another. We prove it rigorously in this section. First we need a few definitions:</p>
<h5 id="vertex">Vertex</h5>
<p><em>A vertex is a point <span class="math inline">\(v \in F\)</span>, such that <span class="math inline">\(\nexists v_1, v_2 \in F, v_1 \neq v_2\)</span> and <span class="math inline">\(\lambda \in (0, 1)\)</span>, s.t., <span class="math inline">\(v = \lambda v_1 + (1 - \lambda) v_2\)</span>.</em></p>
<p>In other words, <span class="math inline">\(v\)</span> is a vertex of <span class="math inline">\(F\)</span> if it is not contained in a line segment of <span class="math inline">\(P\)</span>.</p>
<p><strong>Theorem.</strong> If LP has an optimal solution, then it has an optimal solution that is a vertex of its feasible set.</p>
<p><em>Proof.</em> Denote <span class="math inline">\(v\)</span> the optimal solution of the LP with maximum number of zero components. If <span class="math inline">\(v\)</span> is not a vertex, then <span class="math inline">\(\exists v_1, v_2 \neq v, v_1, v_2 \in F\)</span> and <span class="math inline">\(\lambda &gt; 0\)</span>, such that <span class="math inline">\(\lambda v_1 + (1 - \lambda) v_2 = v\)</span>.</p>
<p>As <span class="math inline">\(v\)</span> is optimal, we have <span class="math inline">\(c^T v \ge c^T v_1\)</span> and <span class="math inline">\(c^T v \ge c^T v_2\)</span>. By <span class="math inline">\(\lambda v_1 + (1 - \lambda) v_2 = v\)</span>, it concludes that <span class="math inline">\(c_T v = c^T v_1 = c^T v_2\)</span>.</p>
<p>Define <span class="math inline">\(I = \{ i : v[i] &gt; 0 \}\)</span>. As <span class="math inline">\(v_1 \ge 0, v_2 \ge 0\)</span> and <span class="math inline">\(\lambda v_1 + (1 - \lambda) v_2 = v\)</span> so that for <span class="math inline">\(i \neq I\)</span>, <span class="math inline">\(v_1[i] = v_2[i] = v[i] = 0\)</span>.</p>
<p>But <span class="math inline">\(A_I v_1[I] = A_I v_2[I] = b\)</span>. Let <span class="math inline">\(x = \epsilon (v_1 - v_2) + v\)</span>.</p>
<ol type="1">
<li><span class="math inline">\(x\)</span> is feasible, for small enough <span class="math inline">\(\epsilon\)</span>.</li>
<li><span class="math inline">\(x\)</span> is optimal, since <span class="math inline">\(c^T x= \epsilon c^T (v_1 - v_2) + c^T v = c^T v\)</span>.</li>
<li><span class="math inline">\(x_i = 0\)</span> for <span class="math inline">\(i \notin I\)</span>.</li>
</ol>
<p>We can find some <span class="math inline">\(\epsilon\)</span> (either positive or false) to make <span class="math inline">\(x_i = 0\)</span> for some <span class="math inline">\(i \in I\)</span>. Now <span class="math inline">\(x\)</span> contains more zeros than <span class="math inline">\(v\)</span>, a contradiction. <span class="math inline">\(\square\)</span></p>
<h5 id="basic-solution">Basic Solution</h5>
<p><em>A solution <span class="math inline">\(x\)</span> of <span class="math inline">\(Ax = b\)</span> is called a basic solution if <span class="math inline">\(\{A_i : x_i \neq 0 \}\)</span> (columns in <span class="math inline">\(A\)</span> that correspond to non-zero components in <span class="math inline">\(x\)</span> ) are linearly independent.</em></p>
<h5 id="basic-feasible-solution">Basic Feasible Solution</h5>
<p><em>A basic solution <span class="math inline">\(x\)</span> is called basic feasible solution if <span class="math inline">\(x \ge 0\)</span>, i.e., <span class="math inline">\(x \in \{ x : Ax = b\} \cap \{ x \ge 0 \}\)</span>.</em></p>
<p>With respect to the feasible region of LP in slack form, the <em>vertices</em> have have following property:</p>
<p><em>Lemma:</em>. A point <span class="math inline">\(v \in F = \{x : Ax = b\} \cap \{ x: x \ge 0\}\)</span> is a vertex of <span class="math inline">\(F\)</span> if and only if it is a basic feasible solution. Here <span class="math inline">\(A \in R^{m \times n}, x \in R^n, b \in R^{m}\)</span> and <span class="math inline">\(rank(A) = m\)</span> (otherwise some row constraints of the <span class="math inline">\(Ax = b\)</span> are redundant).</p>
<p><em>Proof</em>: Denote <span class="math inline">\(S\)</span> the set of indices of positive components in <span class="math inline">\(v\)</span> and <span class="math inline">\(A_S\)</span> the set of</p>
<p><em>Only if:</em> If <span class="math inline">\(A_S\)</span> does not have full column rank, then <span class="math inline">\(\exists u \in R^{|S|}\)</span>, such that <span class="math inline">\(A_S u = 0\)</span>. Then for small enough <span class="math inline">\(\epsilon \in R, \epsilon &gt; 0\)</span>, both <span class="math inline">\(v + \epsilon u\)</span> and <span class="math inline">\(v - \epsilon u\)</span> are feasible point in <span class="math inline">\(F\)</span>. Now <span class="math inline">\(v = 0.5(v + \epsilon u) + 0.5(v - \epsilon u)\)</span>, a contradiction.</p>
<p><em>If:</em> As columns of <span class="math inline">\(A_S\)</span> are linearly independent, the only solution of to <span class="math inline">\(A_S x_S = 0\)</span> is given by <span class="math inline">\(x_S = 0\)</span>. Hence, <span class="math inline">\(v_S\)</span> is now the unique solution to <span class="math inline">\(A_S v_S = b\)</span>. If <span class="math inline">\(v\)</span> is not a vertex, <span class="math inline">\(\exists v_1, v_2, \lambda\)</span>, such that <span class="math inline">\(v = \lambda v_1 + (1 - \lambda) v_2\)</span>. But in this case we must have <span class="math inline">\(v_1 = v_2 = v\)</span>, as <span class="math inline">\((v_1)_S = (v_2)_S = v_S\)</span> and <span class="math inline">\((v_1)_{\bar S} = (v_2)_{\bar S} = v_{\bar S} = 0\)</span>. A contradiction.</p>
<p><span class="math inline">\(\blacksquare\)</span>.</p>
<p><em>Corollary:</em> The simplex algorithm moves from vertex to vertex.</p>
<p><em>Proof:</em> The positive components in the solution correspond to the columns in the identity matrix in the tabular form of simplex, which are linearly independent.</p>
<h4 id="correctness-of-simplex-to-finish">Correctness of Simplex (TO FINISH)</h4>
<p>Though not shown in the example, there are two issue associated with simplex algorithm.</p>
<ol type="1">
<li>How do we find an initial solution? If there are negative component in <span class="math inline">\(b\)</span>, then <span class="math inline">\(x = 0 \wedge s = b\)</span> is not a feasible solution.</li>
<li>How do we guarantee that simplex terminates?</li>
</ol>
<p>In the previous example, at each step we choose to increase the variable with largest coefficient. In some rare cases, this results in a loop of the algorithm.</p>
<p>One method for avoiding looping is called Bland's rule:</p>
<ol type="1">
<li>If there is a positive coefficient in the objective function, choose the one with largest coefficient.</li>
<li>If there are multiple rows with tight constraints, choose the one with largest coefficient.</li>
</ol>
<p><em>Theorem.</em> Blands' rule guarantees that the algorithm stops.</p>
<p><em>Proof.</em> Suppose that on the contrary, the algorithm loops. Denote <span class="math inline">\(B_1, B_2, ..., B_k\)</span> the set of basis in the loop. In each base, there is entering variable and one leaving variable. Every variable that leaves the base must enter another base later. We called these variable <em>fickle variables</em>. Denote <span class="math inline">\(x_t\)</span> the fickle variable with the largest index.</p>
<ol type="1">
<li><p><span class="math inline">\(D\)</span> the dictionary that <span class="math inline">\(x_t\)</span> leaves the base, and <span class="math inline">\(x_e\)</span> the variable that enters the base.</p></li>
<li><p><span class="math inline">\(D&#39;\)</span> the dictionary that <span class="math inline">\(x_t\)</span> enters the base again. <span class="math display">\[
D = 
\begin{aligned}
 I   &amp;&amp;  A_N &amp;&amp; \mid b \\
 \hline 
 0   &amp;&amp;  c_N &amp;&amp; \mid \alpha \\
\end{aligned}
\Rightarrow ... \Rightarrow
D&#39; = 
\begin{aligned}
 R   &amp;&amp;  R A_N   &amp;&amp; \mid R b \\
 \hline 
 y^T &amp;&amp;  y^T A_N + c_N   &amp;&amp; \mid y^T b + \alpha \\
\end{aligned}
\]</span> We have <span class="math display">\[
c_e&#39; = c_e + y^T A_N[:, e]
\]</span></p></li>
<li><p><span class="math inline">\(x_e\)</span> is the entering variable in <span class="math inline">\(D\)</span>, therefore <span class="math inline">\(c_e &gt; 0\)</span>.</p></li>
<li><p><span class="math inline">\(x_t\)</span> is the entering variable in <span class="math inline">\(D&#39;\)</span>, and <span class="math inline">\(e &lt; t\)</span>, by the definition of <span class="math inline">\(x_t\)</span>, we have <span class="math inline">\(x_e&#39; \le 0\)</span>.</p></li>
<li><p>Hence, <span class="math inline">\(y^T A_N[:, e] = c_e&#39; - c_e &lt; 0\)</span>.</p></li>
<li><p><span class="math inline">\(\exists i, s.t., y_i A_{i, e} &lt; 0\)</span>. Then <span class="math inline">\(y_i \neq 0\)</span>, and <span class="math inline">\(x_i\)</span> is fickle. By definition, <span class="math inline">\(i &lt; t\)</span>. But <span class="math inline">\(x_i\)</span> is not entering <span class="math inline">\(D&#39;\)</span>, we know that <span class="math inline">\(y_i &lt; 0\)</span>.</p></li>
<li><p><span class="math inline">\(A_{i, e} &gt; 0\)</span>. But since <span class="math inline">\(x_i\)</span> is fickle, we have <span class="math inline">\(b_i = 0\)</span>. In this case, <span class="math inline">\(x_i\)</span> is chosen in preference to <span class="math inline">\(x_t\)</span>. A contradiction.</p></li>
</ol>
<h1 id="reference">Reference</h1>
<p>[1]. Dantzig, George B. "Origins of the simplex method." A history of scientific computing. 1990. 141-151.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/01/30/LP%20-%20Weak%20duality,%20Complementary%20Slackness,%20Strong%20Duality/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/30/LP%20-%20Weak%20duality,%20Complementary%20Slackness,%20Strong%20Duality/" class="post-title-link" itemprop="url">LP - Dual Program, Weak Duality, Complementary Slackness, Strong Duality</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-01-30 11:47:54" itemprop="dateCreated datePublished" datetime="2020-01-30T11:47:54+11:00">2020-01-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-02-01 11:26:59" itemprop="dateModified" datetime="2020-02-01T11:26:59+11:00">2020-02-01</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="dual-program-and-weak-duality">Dual Program and Weak Duality</h1>
<p>Linear programming studies the optimization problems in which both its objective function and feasible region are represented by linear relationship.</p>
<p>Every linear program can be converted into Canonical form</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \max &amp; c^T x \\
&amp; s.t., &amp; Ax \le b \\
&amp;&amp; x \ge 0
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(c, x \in \mathcal{R}^n\)</span>, <span class="math inline">\(A \in \mathcal{R}^{m \times n}\)</span> and <span class="math inline">\(b \in \mathcal{R}^m\)</span>.</p>
<p>Suppose we have a conic combination (<span class="math inline">\(y \in \mathcal{R}^m\)</span> and <span class="math inline">\(y \ge 0\)</span>) of the linear constraints: <span class="math display">\[
y^T (Ax) \le y^T b
\]</span></p>
<p>Such that <span class="math inline">\(y^T A \ge c^T\)</span>, then <span class="math inline">\(y^T b\)</span> gives an upper bound of the original program. We want to find a <span class="math inline">\(y\)</span>, such that the bound is as tight as possible. This gives rise to another linear program: <span class="math display">\[
\begin{aligned}
&amp; \min &amp; y^T b \\
&amp; s.t., &amp; y^T A \ge c^T \\
&amp;&amp; y \ge 0
\end{aligned}
\]</span></p>
<p>We call the original program the primal and the derived program its dual.</p>
<p>The philosophy of dual program is to use the combination of primal constraints to construct a bound of its objective function. More formally, the goal is that the <em>weak duality</em> holds:</p>
<p><span class="math display">\[
c^T x \le (y^T A) x = y^T A x = y^T (Ax) \le y^T b 
\]</span></p>
<p>Note that <span class="math inline">\(c^T x \le (A^T y)^T x\)</span> is true because <span class="math inline">\(y^T A \ge c\)</span> and <span class="math inline">\(x \ge 0\)</span>. And <span class="math inline">\(y^T (Ax) \le y^T b\)</span> follows from <span class="math inline">\(Ax \le b\)</span> and <span class="math inline">\(y^T \ge 0\)</span>.</p>
<p><em>Corollary 1:</em> If the primal is unbounded, then the dual is infeasible. If the dual is unbounded, then the primal is infeasible.</p>
<p>In general, the primal may not be given in Canonical form and can be formulated as</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \max &amp; c^T x + \bar c^T \bar x + \hat c^T \hat x \\
&amp; s.t., &amp; Ax + \bar A \bar x + \hat A \hat x \le b \\
&amp;&amp; Bx + \bar B \bar x + \hat B \hat x =  \bar b \\ 
&amp;&amp; Cx + \bar C \bar x + \hat C \hat x \ge \hat b \\
&amp;&amp; x \ge 0 \\
&amp;&amp; \hat x \le 0
\end{aligned}
\]</span></p>
<p>Note that the <span class="math inline">\(\bar x\)</span>'s are unconstrained variables. Guided by similar philosophy, we hope to derive an upper bound by using the constraints: <span class="math display">\[
\begin{aligned}
    c^T x + \bar c^T \bar x + \hat c^T \hat x 
        &amp; \le y^T (Ax + \bar A \bar x + \hat A \hat x) \\
        &amp; + \bar y^T (Bx + \bar B \bar x + \hat B \hat x) \\
        &amp; + \hat y^T (Cx + \bar C \bar x + \hat C \hat x) \\
        &amp;\le y^T b + \bar y^T \bar b + \hat y^T \hat b
\end{aligned}
\]</span></p>
<ol type="1">
<li><p>The first inequality implies that (by proper rearranging): <span class="math display">\[
 \begin{aligned}
     c^T x + \bar c^T \bar x + \hat c^T \hat x 
         &amp; \le (y^T A + \bar y^T B + \hat y^T C)x \\
         &amp; + (y^T \bar A + \bar y^T \bar B + \hat y^T \bar C) \bar x \\
         &amp; + (y^T \hat A + \bar y^T \hat B + \hat y^T \hat C) \hat x
 \end{aligned}
 \]</span></p>
<p>As <span class="math inline">\(x \ge 0\)</span>, <span class="math inline">\(\bar x\)</span> unconstrained and <span class="math inline">\(\hat x \le 0\)</span>, a sufficient condition for the inequality to become true is <span class="math display">\[
 \begin{aligned}
     c^T      &amp; \le (y^T A + \bar y^T B + \hat y^T C) \\
     \bar c^T &amp; =   (y^T \bar A + \bar y^T \bar B + \hat y^T \bar C) \\
     \hat c^T &amp; \ge (y^T \hat A + \bar y^T \hat B + \hat y^T \hat C) \\
 \end{aligned}
 \]</span></p>
<p>That gives the first set of constraints the dual variables <span class="math inline">\(y\)</span>, <span class="math inline">\(\bar y\)</span> and <span class="math inline">\(\hat y\)</span> need to satisfies. We have just seen that the sign of the primal variable determines the type of constraint in the dual.</p>
<p>Of particular interest is the inequality constraint, which we will dive into details in the next section.</p></li>
<li><p>By similar argument, the second inequality is true if <span class="math inline">\(y^T \ge 0\)</span>, <span class="math inline">\(\bar y^T\)</span> unconstrained, <span class="math inline">\(\hat y^T \le 0\)</span>. That is, the type of constraint in the primal determines the sign of variable in the dual.</p></li>
</ol>
<p>Finally, the rules of obtaining dual are summarized as follows:</p>
<p><span class="math display">\[
\begin{aligned}    
\hline
&amp;&amp;&amp; \text{Primal}       &amp;&amp;&amp;                    \max   \quad                      &amp;&amp;&amp; \qquad \qquad                      \min                    &amp;&amp;&amp;  \text{Dual}        &amp;&amp;&amp; \\
\hline
&amp;&amp;&amp; Constraints     &amp;&amp;&amp;      \begin{matrix} \le b_i \\ \ge b_i \\ = b_i  \end{matrix} \quad     &amp;&amp;&amp; \qquad \quad \begin{matrix} \ge 0 \\ \le 0 \\ \text{Both sides} \end{matrix}    &amp;&amp;&amp;  Variables      &amp;&amp;&amp; \\
\hline
&amp;&amp;&amp;  Variables      &amp;&amp;&amp;\qquad \begin{matrix} \ge 0 \\ \le 0 \\ \text{Both sides} \end{matrix}   &amp;&amp;&amp; \qquad \qquad  \begin{matrix}   \ge c_j \\ \le c_i \\ = c_j   \end{matrix}  &amp;&amp;&amp; Constraints     &amp;&amp;&amp; \\
\hline
\end{aligned}
\]</span></p>
<h1 id="complementary-slackness">Complementary Slackness</h1>
<p>The strong duality states that, if both primal and dual are feasible, then the objective function values of their optimal solutions equal.</p>
<p>If we expand the weak duality expression for the standard form, we get <span class="math display">\[
\sum_{i = 1}^n c_i x_i \le \sum_{i = 1}^n \left( \sum_{j = 1}^m y_j A_{i, j} \right) x_i =  \sum_{j = 1}^m  y_j \left( \sum_{i = 1}^n A_{i, j} x_i \right) \le \sum_{j = 1}^m y_j b_j 
\]</span></p>
<p>Then <span class="math inline">\(c^T x= y^T b\)</span> implies <span class="math display">\[
\sum_{i = 1}^n c_i x_i = \sum_{i = 1}^n \left( \sum_{j = 1}^m y_j A_{i, j}  \right) x_i \\  
\sum_{j = 1}^m  y_j \left( \sum_{i = 1}^n A_{i, j} x_i \right)  = \sum_{j = 1}^m b_j y_j
\]</span></p>
<p>i.e., <span class="math display">\[
\sum_{i = 1}^n \left( \sum_{j = 1}^m y_j A_{i, j} - c_i \right) x_i  = 0\\  
\sum_{j = 1}^m  y_j \left( b_j - \sum_{i = 1}^n A_{i, j} x_i \right) = 0
\]</span></p>
<p>As <span class="math inline">\(\sum_{j = 1}^m A_{i, j} y_j - c_i \ge 0\)</span>, <span class="math inline">\(x_i \ge 0\)</span> for all <span class="math inline">\(i\)</span> and <span class="math inline">\(b_j - \sum_{i = 1}^n A_{i, j} x_i \ge 0\)</span> and <span class="math inline">\(y_j \ge 0\)</span> for all <span class="math inline">\(j\)</span>, we conclude that</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\sum_{j = 1}^m y_j A_{i, j}  - c_i = 0 &amp;\vee &amp;&amp;    x_i = 0 &amp; \forall i \\ 
&amp;b_j - \sum_{i = 1}^n A_{i, j} x_i = 0 &amp;\vee &amp;&amp;     y_j  = 0, &amp; \forall j
\end{aligned}
\]</span></p>
<p>Or more compactly <span class="math display">\[
(y^T A - c^T) x = 0 \\y^T (b - Ax) = 0
\]</span></p>
<p>If the primal is in canonical form, then the fact that <span class="math inline">\(A^T \ge c, x \ge 0, y \ge 0, b - Ax \ge 0\)</span> implies that <span class="math display">\[
\begin{aligned}
&amp;(y^T A - c^T)_i = 0  &amp;&amp;\vee &amp;&amp; x_i = 0         &amp;&amp;&amp;\forall \ i \\
&amp;y_j = 0            &amp;&amp;\vee   &amp;&amp; (b - Ax)_j = 0  &amp;&amp;&amp;\forall \ j
\end{aligned}
\]</span> where <span class="math inline">\((y^T A - c^T)\)</span> is a vector and <span class="math inline">\((y^T A - c^T)_i\)</span> is its <span class="math inline">\(i\)</span>-th coordinate.</p>
<p>This is known as complementary slackness.</p>
<h1 id="strong-duality">Strong Duality</h1>
<p>Question to ponder: what is the geometric interpretation of complementary slackness?</p>
<h2 id="special-case">Special Case</h2>
<p>To illustrate its underlying meaning, first consider the special case <span class="math display">\[
\begin{aligned}
&amp; \min &amp; y^T b \\
&amp; s.t., &amp; y^T A = c^T 
\end{aligned}
\]</span></p>
<p>whose dual form is given by <span class="math display">\[
\begin{aligned}
&amp; \max &amp; c^T x \\
&amp; s.t., &amp; Ax = b 
\end{aligned}
\]</span></p>
<p>First note that <span class="math inline">\(y^T A = c^T\)</span> means that <span class="math inline">\(c^T\)</span> is a linear combination of rows of <span class="math inline">\(A\)</span>. The primal is feasible if <span class="math inline">\(c\)</span> is in the row space of <span class="math inline">\(A\)</span>.</p>
<p>In this special case, if both primal and dual are feasible, then for any feasible solutions <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, strong duality holds, since <span class="math inline">\(c^T x = (y^T A) x = y^T (Ax) = y^T b\)</span>.</p>
<p>The dual search for some <span class="math inline">\(x\)</span> such that <span class="math display">\[
Ax = b
\]</span></p>
<p>If we can find such <span class="math inline">\(x\)</span>, it implies that <span class="math inline">\(b\)</span> lies in the column space of <span class="math inline">\(A\)</span>, denoted as <span class="math inline">\(C(A)\)</span> (the subspace in <span class="math inline">\(\mathcal{R}^n\)</span> spanned by the row vectors of <span class="math inline">\(A\)</span>). What if not? We can decompose <span class="math inline">\(b\)</span> into two part: <span class="math inline">\(b = b_1 + b_2\)</span>, such that <span class="math inline">\(b_1 \in C(A)\)</span> and <span class="math inline">\(0 \neq b_2 \in N(A^T)\)</span> (the subspace orthogonal to <span class="math inline">\(C(A)\)</span>). Here is the problem: if <span class="math inline">\(y\)</span> is a feasible solution for the primal, then we can decrease <span class="math inline">\(y\)</span> by arbitrary amount along the direction orthogonal to <span class="math inline">\(C(A)\)</span>, while maintaining its feasibility. In particular, if we add <span class="math inline">\(k \cdot b_2\)</span> to <span class="math inline">\(y\)</span> (<span class="math inline">\(k &gt; 0\)</span>), then <span class="math inline">\((y - k b_2)\)</span> is still feasible as <span class="math inline">\((y - k b_2)^T A = y^T A - k b_2^T A = c^T\)</span>. But now <span class="math inline">\((y - k \cdot b_2)^T b = y^T b - k b_2^T b_2 &lt; y^T b\)</span>, which implies that the primal is unbounded.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/StrongDualitySpecialCase.jpg" /></p>
<h2 id="general-case">General Case</h2>
<p>Now we return our discussion to the more general form: <span class="math display">\[
\begin{aligned}
&amp; \min &amp; y^T b \\
&amp; s.t., &amp; y^T A \ge c^T
\end{aligned}
\]</span></p>
<p>Its dual is given by <span class="math display">\[
\begin{aligned}
&amp; \max &amp; c^T x \\
&amp; s.t., &amp; Ax = b \\
&amp;&amp; x \ge 0
\end{aligned}
\]</span></p>
<p>Every LP can be converted into standard form.</p>
<p>The weak duality states that <span class="math display">\[
c^T x \le y^T A x = y^T b
\]</span></p>
<p>If both primal and dual are feasible, then strong duality reduce to show that the first inequality holds with equality, that is, <span class="math inline">\(\exists\)</span> feasible <span class="math inline">\(x, y\)</span>, s.t., <span class="math inline">\(c^T x = y^T A x\)</span>. In particular, complementary slackness, this is equivalent to proving that <span class="math display">\[
\begin{aligned}
&amp;(y^T A - c^T)_i = 0  &amp;&amp;\vee &amp;&amp;x_i = 0      &amp;&amp;\forall \ i \\
\end{aligned}
\]</span></p>
<p>We begin by assuming that <span class="math inline">\(y\)</span> is the optimal solution for the dual. We claim that <span class="math inline">\(y\)</span> can not be an interior point of the feasible region. Otherwise, <span class="math inline">\(y\)</span> can move along arbitrary direction by a little while maintaining feasibility. If it moves along the direction pointed by <span class="math inline">\(-b\)</span>, then the objective function value decreases, contradicting <span class="math inline">\(y\)</span> being optimal.</p>
<p>Therefore, <span class="math inline">\(y\)</span> must be on the boundary of the feasible region.</p>
<h4 id="question-to-ponder-prove-the-existence-of-optimal-solution-of-the-primal-assuming-feasibility-of-the-dual."><em>Question to ponder: prove the existence of optimal solution of the primal, assuming feasibility of the dual.</em></h4>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/MinimizeYB.jpg" /></p>
<p>The boundary <span class="math inline">\(y\)</span> touches are specified by tight constraints. The intuition behind is that, <span class="math inline">\(b\)</span> must be the positive combination of the normal vector of the tight constraints. Otherwise, we can find some direction that decreases objective function value while maintaining feasibility.</p>
<p>Denote <span class="math inline">\(S \subset [m]\)</span> the set of indexes, such that <span class="math inline">\(\forall i \in S\)</span>, <span class="math inline">\(y^T A_i = c_i\)</span>, where <span class="math inline">\(A_i\)</span> is the <span class="math inline">\(i\)</span>-th column of matrix <span class="math inline">\(A\)</span> and <span class="math inline">\(c_i\)</span> is the <span class="math inline">\(i\)</span>-th coordinator of vector <span class="math inline">\(c\)</span>. In other words, <span class="math inline">\(S\)</span> is the set of indexes for which the inequality is tight.</p>
<p>We claim that <span class="math inline">\(b\)</span> is in the conic hull of columns of <span class="math inline">\(A_s\)</span>. That is, <span class="math inline">\(\exists x_S \in R^{|S|}\)</span>, such that 1. <span class="math inline">\(A_S x_S = b\)</span>. 2. <span class="math inline">\(x_S \ge 0\)</span>.</p>
<p>Such <span class="math inline">\(x_S\)</span> gives a feasible solution to the primal, by setting <span class="math inline">\(x_{\bar S} = 0\)</span> and <span class="math inline">\(x = x_S \cup x_{\bar S}\)</span>. Further, strong duality holds as <span class="math inline">\(c^T x = y^T A x = y^T b\)</span>.</p>
<p><em>Proof:</em></p>
<p>It suffices to show that <span class="math inline">\(b\)</span> is a conic combination of columns of <span class="math inline">\(A_S\)</span>. Suppose not. Then by <a target="_blank" rel="noopener" href="https://wuhao-wu-jiang.github.io/2019/01/17/Farkas-Lemma/">Farkas' Lemma</a>, <span class="math inline">\(\exists v \in \R^m\)</span>, such that</p>
<ol type="1">
<li><span class="math inline">\(v^T A_S \ge 0\)</span>.</li>
<li><span class="math inline">\(v^T b &lt; 0\)</span>.</li>
</ol>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FarkasLemma3.jpg" /></p>
<p>Then we can move the vector <span class="math inline">\(y\)</span> along the direction of <span class="math inline">\(v\)</span>. But this time we need to be careful, in order not to violate the constraints.</p>
<p>For each inequality constraint <span class="math inline">\(y^T A_i &gt; c_i\)</span> (<span class="math inline">\(i \in \bar S\)</span>), <span class="math inline">\(\exists t_i &gt; 0\)</span>, such that <span class="math inline">\((y + t_i v)^T A_i &gt; c_i\)</span>. Denote <span class="math inline">\(t = \min_{i \in \bar S} t_i\)</span>.</p>
<p>As <span class="math inline">\((y + t v)^T A_S = c_S + t v^T A_S \ge c_S\)</span>, <span class="math inline">\((y + t v)\)</span> is still feasible. But <span class="math inline">\((y + t v)^T b &lt; y^T b\)</span>. A contradiction.</p>
<h4 id="question-to-ponder-relate-the-above-discussion-to-lagrange-multiplier-and-k.k.t-condition.">Question to ponder: relate the above discussion to Lagrange multiplier and <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions">K.K.T condition</a>.</h4>
<h1 id="reference.">Reference.</h1>
<ol type="1">
<li>David P. Williamson, ORIE 6300 Mathematical Programming I, <a target="_blank" rel="noopener" href="https://people.orie.cornell.edu/dpw/orie6300/Lectures/lec08.pdf">Lecture 8</a><br />
</li>
<li>Boyd, S. and Vandenberghe, L., 2004. Convex optimization. Cambridge university press.</li>
</ol>
<!-- 1. $A_S x_S = b$:   
   We first show $b$ in the linear hull of $A_S$, i.e., $\exists x_S$, s.t., $A_S x_S = b$. Otherwise, the case is similar to the first example we have just discussed. We decompose $b = b_1 + b_2$, where $b_2$ is orthogonal to $C(A_S)$. Then we can move the vector $y$ along the reverse direction of $b_2$. But this time we need to be careful, in order not to violate the inequality constraints. 

    For each inequality constraint $y^T A_i > c_i$ ($i \in \bar S$), $\exists t_i > 0$, such that $(y - t_i b_2)^T A_i > c_i$. Denote $t = \min_{i \in \bar S} t_i$. 
    
    As $(y - tb_2)^T A_S = c_S$, $(y - tb_2)$ is still feasible. But $(y - tb_2)^T b < y^T b$. A contradiction.

1. $x_S \ge 0$. 
   
    For simplicity, consider just the case where the columns of $A_S$ are linearly independent. If $\exists i \in S$, such that $x_i < 0$, then we can find a better solution as follows. Let $u$ be the projection of $A_i$ to $C(A_{S \setminus [i]})$, the subspace spanned by columns of $A_{S \setminus [i]}$. Define $v = A_i - u$. We have $v \neq 0$ since $A_i$ is not inside $C(A_{S \setminus [i]})$. Further $v$ is orthogonal to columns of $A_{S \setminus [i]}$ and $v^T A_i > 0$. 

    Moreover, $v^T b = v^T A_S x_S = (v^T A_i) x_i < 0$. 

    We can move $y$ along the direction of $v$, before some constraint in $\bar S$ becomes tight. But this decreases the value of the objective function, contradicting $y$ being optimal. 

    Remark: when the columns of $A_S$ are linearly dependent, there are few cases.
    1. If $A_i$ is outside $C(A_{S \setminus [i]})$, then the proof still holds. 
    2. Otherwise, $A_i$ can be expressed by a linear combination by columns in $A_{S \setminus [i]}$.  -->

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/01/14/Sparse-Recovery-with-Count-Sketch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/14/Sparse-Recovery-with-Count-Sketch/" class="post-title-link" itemprop="url">Sparse Recovery with Count-Sketch</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-01-14 22:51:28" itemprop="dateCreated datePublished" datetime="2020-01-14T22:51:28+11:00">2020-01-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-04-09 13:40:52" itemprop="dateModified" datetime="2021-04-09T13:40:52+10:00">2021-04-09</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="background">Background</h1>
<p>A stream of items <span class="math inline">\(S = \{ a_1, a_2, ..., a_m \}\)</span> where <span class="math inline">\(a_i \in [n]\)</span>. Let the frequencies of elements in <span class="math inline">\([n]\)</span> be <span class="math inline">\(f = \left&lt; f_1, f_2, ..., f_n \right&gt;\)</span>, where <span class="math inline">\(f_j = |\{ a_i \in S : a_i = j \}|\)</span>.</p>
<h2 id="count-sketch">Count-Sketch</h2>
<p>It returns an estimation <span class="math inline">\(\hat f\)</span> of <span class="math inline">\(f\)</span> with space <span class="math inline">\(O(\frac{1}{\epsilon^2} \log n)\)</span> words, such that with probability at least <span class="math inline">\(1 - 1 / n\)</span>, for every <span class="math inline">\(i \in [n]\)</span>, <span class="math display">\[
    |\hat f_i - f_i| \le \epsilon \Vert f \Vert_2,
\]</span> where <span class="math inline">\(\Vert f \Vert_2 = \sqrt {\sum_{i = 1}^n f_i^2 }\)</span>.</p>
<h1 id="problem">Problem</h1>
<p>In general, a sketch is a concise representation of <span class="math inline">\(f\)</span>. Suppose that we limit our space usage to <span class="math inline">\(k\)</span> words (i.e., <span class="math inline">\(\Vert \hat f \Vert_0 = k\)</span>). Then the sketch <span class="math inline">\(\hat f\)</span> that minimizes the <span class="math inline">\(\ell_2\)</span> error <span class="math display">\[
    err_2^k (f) \doteq \Vert f - \hat f \Vert_2
\]</span></p>
<p>keeps the set <span class="math inline">\(H\)</span> of <span class="math inline">\(k\)</span> items with highest frequencies. In such case, the error is given by <span class="math display">\[
    err_2^k (f) = \sqrt {\sum_{i \notin H} f_i^2}
\]</span></p>
<p>In practice, however, <span class="math inline">\(S\)</span> is not given offline. As we don't know <span class="math inline">\(H\)</span>, we can only compute an <span class="math inline">\(\hat f\)</span> with <span class="math inline">\(k\)</span> words that is as good as possible. The question is, how far <span class="math inline">\(\Vert f - \hat f \Vert_2\)</span> can be from the minimum possible value, namely <span class="math inline">\(err_2^k(f)\)</span>?</p>
<h1 id="algorithm">Algorithm</h1>
<p>One possible solution, proposed by Cormode and Muthukrishnan [1], is to construct <span class="math inline">\(\hat f\)</span> vis Count-Sketch. In particular,</p>
<ol type="1">
<li>It uses <span class="math inline">\(d = O(\log n)\)</span> hash tables.<br />
</li>
<li>Each hash table has size <span class="math inline">\(w = \frac{3k}{\epsilon^2}\)</span>.</li>
</ol>
<h2 id="frequency-oracle-error">Frequency Oracle Error</h2>
<blockquote>
<p><strong>Lemma 1.</strong> For every <span class="math inline">\(i \in [n]\)</span>, with probability <span class="math inline">\(1 - 1 /n^2\)</span>, <span class="math display">\[
|f_i - \hat f_i| \le \frac{\epsilon}{\sqrt k } err_2^k(f). 
\]</span></p>
</blockquote>
<p><strong>Remark:</strong> <em>If <span class="math inline">\(f\)</span> is <span class="math inline">\(k\)</span> sparse, i.e., the number of non-zero elements of <span class="math inline">\(f\)</span> is at most <span class="math inline">\(k\)</span>, then <span class="math inline">\(err_2^k(f) = 0\)</span> and the algorithm recovers <span class="math inline">\(f\)</span> exactly.</em></p>
<p><strong>Proof:</strong> Consider a fixed <span class="math inline">\(t \in [k]\)</span>. For <span class="math inline">\(i \in [n]\)</span>, let <span class="math inline">\(h_t(i)\)</span> the bucket of item <span class="math inline">\(i\)</span> in the <span class="math inline">\(t\)</span>-th hash table. Define <span class="math display">\[
    A_i : \exist x \in H, \text{ s.t. } h_j(x) = h_j(i),
\]</span> be the event such that some heavy item collides with <span class="math inline">\(i\)</span> in the <span class="math inline">\(t\)</span>-th table. Then by union bound, <span class="math display">\[
    \Pr[A_i] \le \frac{k}{w} = \frac{\epsilon^2}{3}. 
\]</span></p>
<p>Therefore, by the law of total probability and monotonicity of probability, we have <span class="math display">\[
\begin{aligned}
    \Pr \left[ |f_i - h_i(j)| \ge \frac{\epsilon}{\sqrt k } err_2^k(f) \right] 
        &amp;\le \Pr[A_i] + \Pr \left[ |f_i - h_i(j) | \ge  \frac{\epsilon}{\sqrt k } err_2^k(f) \mid \bar A_i \right] \\
        &amp;\le \Pr[A_i] + \frac{ \mathbb{Var} [ f_i - h_i(j)  \mid \bar A_i ] }{ (\frac{\epsilon}{\sqrt k } err_2^k(f) )^2 } \\
        &amp;\le \frac{\epsilon^2}{3} + \frac{(err_2^k(f))^2 / w }{ (\frac{\epsilon}{\sqrt k } err_2^k(f) )^2 } \\
        &amp;\le \frac{\epsilon^2}{3} + \frac{1}{3}
\end{aligned}
\]</span></p>
<p>As long as <span class="math inline">\(\epsilon^2 / 3 &lt; 1 / 6\)</span>, this probability is smaller than <span class="math inline">\(1 / 2\)</span>. We can boost the failure probability to <span class="math inline">\(1/ n^2\)</span> by repeating the hash tables <span class="math inline">\(d = O(\log n)\)</span> times and taking the median as estimation.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<h2 id="sparse-vector-construction">Sparse Vector Construction</h2>
<p>The next step is keep only set <span class="math inline">\(\hat H\)</span> of the <span class="math inline">\(k\)</span> largest items in <span class="math inline">\(\hat f\)</span>. Note that <span class="math inline">\(\hat H\)</span> might not equals to <span class="math inline">\(H\)</span>. To bound the value <span class="math inline">\(\Vert f - \hat f \Vert_2\)</span>, we partition <span class="math inline">\([n]\)</span> into three parts: <span class="math display">\[
    \hat H, \quad H \setminus \hat H, \quad [n] \setminus (H \cup \hat H). 
\]</span></p>
<blockquote>
<p><strong>Lemma 2</strong>. <span class="math inline">\(\sum_{i \in \hat H} (f_i - \hat f_i)^2 \le \epsilon^2 (err_2^k(f))^2\)</span>.</p>
</blockquote>
<p><strong>Proof.</strong> By lemma 1, each term <span class="math inline">\((f_i - \hat f_i)^2\)</span> has error at most <span class="math inline">\(\frac{\epsilon^2}{k} (err_2^k(f))^2\)</span>. The claim then follows from that <span class="math inline">\(|\hat H| = k\)</span>.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<blockquote>
<p><strong>Lemma 3</strong>. <span class="math inline">\(\sum_{i \in H \setminus \hat H} f_i ^2 \le \sum_{j \in \hat H \setminus H} \hat f_j^2 + (2 \epsilon + \epsilon^2) ( err_2^k(f))^2\)</span></p>
</blockquote>
<p><strong>Proof.</strong> <span class="math inline">\(|H| = |\hat H|\)</span>, we have <span class="math inline">\(|H \setminus \hat H| = |\hat H \setminus H|\)</span>.</p>
<p>If <span class="math inline">\(H \setminus \hat H = \emptyset\)</span>, the claim is trivial. Otherwise, we can construct a bijection between <span class="math inline">\(H \setminus \hat H\)</span> and <span class="math inline">\(\hat H \setminus H\)</span>. Then for <span class="math inline">\(i \in H \setminus \hat H\)</span>, let <span class="math inline">\(j\)</span> be its corresponding index in <span class="math inline">\(\hat H \setminus H\)</span>. Then</p>
<p><span class="math display">\[
\begin{aligned}
    f_j &amp;= (f_j - \hat f_j) + (\hat f_j - \hat f_i) + (\hat f_i - f_i) + f_i \\
        &amp;\ge - \frac{\epsilon}{\sqrt k } err_2^k(f) + 0 - \frac{\epsilon}{\sqrt k } err_2^k(f) + f_i
\end{aligned}
\]</span></p>
<p>Therefore, <span class="math display">\[
    f_i \le f_j + \frac{2\epsilon}{\sqrt k } err_2^k(f)
\]</span></p>
<p>and <span class="math display">\[
\begin{aligned}
    \sum_{i \in H \setminus \hat H} f_i^2       
        &amp;\le \sum_{j \in \hat H \setminus H} f_j^2 + \frac{4 \epsilon}{\sqrt k } \left( \sum_{j \in \hat H \setminus H} f_j\right) + 4 \epsilon^2 (err_2^k(f))^2 \\
        &amp;\le \sum_{j \in \hat H \setminus H} f_j^2 + \frac{4 \epsilon}{\sqrt k } err_2^k(f) \left( \sum_{j \in \hat H \setminus H} f_j\right) + 4 \epsilon^2 (err_2^k(f))^2 \\
        &amp;\le \sum_{j \in \hat H \setminus H} f_j^2 + \frac{4 \epsilon}{\sqrt k } err_2^k(f) \left( k \sqrt{ \frac{1}{k} \sum_{j \in \hat H \setminus H} f_j^2 } \right) + 4 \epsilon^2 (err_2^k(f))^2 \\
        &amp;= \sum_{j \in \hat H \setminus H} f_j^2 + 4 \epsilon (err_2^k(f))^2 + 4 \epsilon^2 (err_2^k(f))^2 \\
        &amp;= \sum_{j \in \hat H \setminus H} f_j^2 + (4 \epsilon + 4 \epsilon^2) (err_2^k(f))^2 
\end{aligned}
\]</span></p>
<!-- $$
    f_i = f_i - \hat f_i + \hat f_i - \hat f_j + \hat f_j
$$ -->
<!-- As $\hat H$ contains the largest $k$ items in $\hat f$, it must be that $\hat f_i - \hat f_j \le 0$. Therefore, 

$$
f_i \le f_i - \hat f_i + \hat f_j
$$

By lemma 1, we have $f_i - \hat f_i \le \frac{\epsilon}{\sqrt k } err_2^k(f)$, we have 

$$
f_i \le \frac{\epsilon}{\sqrt k } err_2^k(f) + \hat f_j
$$

Summing over all possible $i$, 

$$
\begin{aligned}
    \sum_{i \in H \setminus \hat H} f_i ^2 
    &\le \sum_{j \in \hat H \setminus H} (\frac{\epsilon}{\sqrt k } err_2^k(f) + \hat f_j)^2 \\
    &= \sum_{j \in \hat H \setminus H} \hat f_j^2  + 2 \left( \sum_{j \in \hat H \setminus H} \hat f_j \right) \frac{\epsilon}{\sqrt k } err_2^k(f) +  \epsilon^2 ( err_2^k(f))^2 \\
    &\le \sum_{j \in \hat H \setminus H} \hat f_j^2  + 2 k \sqrt{ \sum_{j \in \hat H \setminus H} \frac{1}{k} \hat f_j^2} \frac{\epsilon}{\sqrt k } err_2^k(f) +  \epsilon^2 ( err_2^k(f))^2 \\
    &= \sum_{j \in \hat H \setminus H} \hat f_j^2  + 2 \epsilon (err_2^k(f)) \sqrt{ \sum_{j \in \hat H \setminus H} \hat f_j^2} +  \epsilon^2 ( err_2^k(f))^2 \\
    &\le \sum_{j \in \hat H \setminus H} \hat f_j^2  + (2 \epsilon +  \epsilon^2) ( err_2^k(f))^2. 
\end{aligned}
$$ -->
<p><span class="math inline">\(\square\)</span></p>
<h2 id="reference">Reference</h2>
<p>[1] G. Cormode and S. Muthukrishnan. Combinatorial algorithms for Compressed Sensing.<br />
[2] Moses Charikar, Lecture 9, CS 369G: Algorithmic Techniques for Big Data</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/25/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/25/">25</a><span class="page-number current">26</span><a class="page-number" href="/page/27/">27</a><span class="space">&hellip;</span><a class="page-number" href="/page/51/">51</a><a class="extend next" rel="next" href="/page/27/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">152</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WOW</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
