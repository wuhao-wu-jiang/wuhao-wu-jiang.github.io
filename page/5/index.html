<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
<meta property="og:type" content="website">
<meta property="og:title" content="WOW">
<meta property="og:url" content="http://example.com/page/5/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/5/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>WOW</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">WOW</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/02/27/Some-basic-theorems-for-real-numbers/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/02/27/Some-basic-theorems-for-real-numbers/" class="post-title-link" itemprop="url">Reading Notes-Some basic theorems for real numbers</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-02-27 19:55:27" itemprop="dateCreated datePublished" datetime="2019-02-27T19:55:27+11:00">2019-02-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-03-01 02:00:58" itemprop="dateModified" datetime="2019-03-01T02:00:58+11:00">2019-03-01</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="axiom-of-completeness">Axiom of completeness</h3>
<p><em>Any nonempty set of real numbers that is bounded above has an least upper bound.</em></p>
<h4 id="monotone-convergence-theorem">Monotone Convergence Theorem</h4>
<p><em>Let <span class="math inline">\((a_n)\)</span> be an increasing sequence that is bounded above, then it converges.</em></p>
<p><em>Proof:</em></p>
<p>Consider the set of point <span class="math inline">\(\{ a_n : n \in N \}\)</span>. By assumption, it is bounded. By Axiom of Completeness, the set <span class="math inline">\(\{ a_n \}\)</span> has an least upper bound, denoted as <span class="math inline">\(a = \sup \{ a_n : n \in N \}\)</span>. Because <span class="math inline">\(a\)</span> is a least upper bound, <span class="math inline">\(\forall \epsilon &gt; 0\)</span>, there is an element <span class="math inline">\(a_N\)</span>, such that <span class="math inline">\(a_N \ge a - \epsilon\)</span>. But <span class="math inline">\((a_n)\)</span> is an increasing sequence. Therefore, for any <span class="math inline">\(n \ge N\)</span>, we have <span class="math inline">\(a \ge a_n \ge a_N \ge a - \epsilon\)</span>, which implies that <span class="math inline">\((a_n) \rightarrow a\)</span>.</p>
<h5 id="corollary">Corollary:</h5>
<p><em>Let <span class="math inline">\((b_n)​\)</span> be a decreasing sequence that is bounded below, then it converges.</em></p>
<h4 id="nested-interval-property">Nested Interval Property</h4>
<p>Let <span class="math inline">\(I_1 \supset I_2 \supset I_3 ...\)</span> be a collection of closed intervals. Then <span class="math inline">\(\cap_{n} I_n \neq \emptyset\)</span>.</p>
<p><em>Proof 1 (By Axiom of Completeness):</em></p>
<p>Denote <span class="math inline">\(I_n = [a_n, b_n]= \{ x \in R : a_n \le x \le b_n \}\)</span>. By definition, we have <span class="math display">\[
a_1 \le a_2 \le a_3 \le ... a_n \le ... \le b_n \le ... \le b_3 \le b_2 \le b_1
\]</span> We are going to use Axiom of Completeness to produce a single real number <span class="math inline">\(a \in \cap_n I_n\)</span>. The set we consider is<br />
<span class="math display">\[
A \doteq \{ a_1, a_2, ... \}
\]</span> It is bounded above by any <span class="math inline">\(b_n​\)</span> for <span class="math inline">\(n \ge 1​\)</span>. Therefore we are justified in the setting <span class="math inline">\(a = \sup A​\)</span>. Because <span class="math inline">\(a​\)</span> is an upper bound, we have <span class="math inline">\(a_n \le a​\)</span>. The fact <span class="math inline">\(b_n​\)</span> is an upper bound and that <span class="math inline">\(a​\)</span> is the least upper bound implies <span class="math inline">\(a \le b_n​\)</span>. Putting together, <span class="math inline">\(a \in I_n​\)</span> for <span class="math inline">\(n \ge 1​\)</span>. Hence, <span class="math inline">\(a \in \cap_n I_n​\)</span>.</p>
<p><em>Proof 2 (By Monotone Convergence Theorem):</em></p>
<p><span class="math inline">\((a_n)\)</span> is a monotone increasing sequence and bounded above. By Monotone Convergence Theorem, there exists a real number <span class="math inline">\(a = \lim_n a_n\)</span>. Moreover, it holds that <span class="math inline">\(b_m \ge a_n\)</span> for any integer <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span>, which implies that <span class="math inline">\(b_m \ge \lim_n a_n = a\)</span>, as desired.</p>
<h5 id="remark">Remark:</h5>
<p>We may not necessarily choose Axiom of Completeness as our starting point. For example, if we assume that <em>Nested Interval Property</em> is true and <span class="math inline">\(\lim 1/2^n \rightarrow 0\)</span>, it can be used to prove Axiom of Completeness.</p>
<p><em>Proof:</em> Let <span class="math inline">\(A\)</span> be an nonempty set that is bounded above, let <span class="math inline">\(b_1\)</span> be an upper bound and <span class="math inline">\(a_1\)</span> be an element in <span class="math inline">\(A\)</span>. Necessarily, <span class="math inline">\(a_1 &lt; b_1\)</span> and we can define the closed interval <span class="math inline">\(I_1 = [a_1, b_1]\)</span>.</p>
<p>The idea is to construct a sequence of closed intervals and use Nested Interval Property. Now we bisect <span class="math inline">\(I_1\)</span> into two closed intervals of equal length let <span class="math inline">\(c_1\)</span> be the midpoint. If <span class="math inline">\(c_1\)</span> is an upper bound for <span class="math inline">\(A\)</span>, we define <span class="math inline">\(I_2 = [a_1, c_1]\)</span>. Otherwise, let <span class="math inline">\(I_2 = [c_1, b_1]\)</span>. In general, we construct <span class="math inline">\(I_n = [a_n, b_n]\)</span> by taking the half from <span class="math inline">\(I_{n - 1}\)</span> such that, <span class="math inline">\(a_n\)</span> is no greater than any upper bound of <span class="math inline">\(A\)</span> and <span class="math inline">\(b_n\)</span> is no less than any element of <span class="math inline">\(A\)</span>.</p>
<p>By Nested Interval Property, there exists <span class="math inline">\(a \in \cap_n I_n\)</span>. Also we notice that the length of <span class="math inline">\(I_n \rightarrow 0\)</span>, which implies <span class="math inline">\(\lim a_n = \lim b_n = s\)</span>.</p>
<p>Because for all <span class="math inline">\(n \in N\)</span>, and any element <span class="math inline">\(a \in A\)</span>, we have <span class="math inline">\(a \le b_n\)</span>. Taking limit of the right hand side, we obtain <span class="math inline">\(a \le s\)</span>, which shows <span class="math inline">\(s\)</span> is an upper bound for <span class="math inline">\(A\)</span>.</p>
<p>Moreover, for any upper bound <span class="math inline">\(l\)</span> for <span class="math inline">\(A\)</span>, we have <span class="math inline">\(a_n \le l\)</span>. Again taking limit of the left hand side, we conclude <span class="math inline">\(s \le l\)</span>, which shows that <span class="math inline">\(s\)</span> is the least upper bound.</p>
<h4 id="bolzano-weierstrass-theorem">Bolzano-Weierstrass Theorem</h4>
<p>Let <span class="math inline">\((a_n)\)</span> be a bounded sequence, then it has a convergent sub-sequence.</p>
<p><em>Proof:</em><br />
Since <span class="math inline">\((a_n)\)</span> is bounded there exists <span class="math inline">\(M &gt; 0\)</span> such that <span class="math inline">\(|a_n| \le M\)</span> for all <span class="math inline">\(n \in N\)</span> . Define <span class="math inline">\(I_0 = [-M, M]\)</span>. Then at least one of the intervals <span class="math inline">\([-M, 0]\)</span> and <span class="math inline">\([0, M]\)</span> contains infinite number of terms from the sequence <span class="math inline">\((a_n)\)</span>. Select such half interval and label it <span class="math inline">\(I_1\)</span>. Let <span class="math inline">\(a_{n_1}\)</span> be some term from <span class="math inline">\((a_n)\)</span> belonging to <span class="math inline">\(I_1\)</span>.</p>
<p>Next, we continue to bisect <span class="math inline">\(I_1\)</span> into two closed intervals of equal length. Choose the half that contains infinite number of terms from <span class="math inline">\((a_n)\)</span> and label it as <span class="math inline">\(I_2\)</span>. We can select an element <span class="math inline">\(a_{n_2} \in I_2\)</span> from <span class="math inline">\((a_n)\)</span> with <span class="math inline">\(n_2 \ge n_1\)</span>. In general, we construct <span class="math inline">\(I_k\)</span> by taking the half from <span class="math inline">\(I_{k - 1}\)</span> that contains infinite number of terms of <span class="math inline">\((a_n)\)</span> and then choose <span class="math inline">\(a_{n_k} \in I_k\)</span> so that <span class="math inline">\(n_k &gt; n_{k - 1} &gt; ... &gt; n_2 &gt; n_1\)</span>. The sets <span class="math inline">\(\{ I_n : n \in N \}\)</span> forms a sequence of nested closed intervals <span class="math display">\[
I_1 \supset I_2 \supset I_3 ...
\]</span> By Nested Interval Property, there is at least on point <span class="math inline">\(a \in \cap_n I_n\)</span>. On the other hand, the lengths of the intervals shrink to <span class="math inline">\(0\)</span>, which implies that <span class="math inline">\(a_{n_k} \rightarrow a\)</span>, as desired.</p>
<h4 id="cauchy-criterion">Cauchy Criterion</h4>
<p>Let <span class="math inline">\((a_n)​\)</span> be a sequence which satisfies <span class="math display">\[
\forall \epsilon &gt; 0, \exists N \in \mathbf{N}, s.t., \forall n \ge m \ge N \rightarrow |a_n - a_m| \le \epsilon
\]</span> Then <span class="math inline">\((a_n)​\)</span> converges.</p>
<p><em>Proof:</em></p>
<p>Step 1: <span class="math inline">\((a_n)\)</span> is bounded. To see this, let <span class="math inline">\(N_1\)</span> be the integer that for <span class="math inline">\(n \ge N\)</span>, we have <span class="math inline">\(|a_n - a_{N_1} | \le 1\)</span> and so <span class="math inline">\(|a_n| \le |a_{N_1} | + 1\)</span>. It can be verified <span class="math inline">\(\max \{ |a_1|, |a_2|, ..., |a_{N_1 - 1} |, |a_{N_1} | + 1 \}\)</span> is an upper bound for the sequence <span class="math inline">\(( a_n )​\)</span>.</p>
<p>Step 2: Now, by Bolzano-Weierstrass Theorem, <span class="math inline">\((a_n)\)</span> has an convergent sub-sequence <span class="math inline">\(( a_{n_k} ) \rightarrow a\)</span>. We show that <span class="math inline">\((a_n)\)</span> converges to the same limit. Let <span class="math inline">\(\epsilon &gt; 0\)</span>, because <span class="math inline">\((a_n)\)</span> is Cauchy, <span class="math display">\[
\exists N &gt; 0,s.t., \forall n \ge m \ge N \rightarrow |a_n - a_m| \le \epsilon / 2
\]</span> We also know <span class="math inline">\((a_{n_k}) \rightarrow a\)</span>, so choose a term <span class="math inline">\(a_{n_k}\)</span>, with <span class="math inline">\(n_k &gt; N\)</span> and <span class="math display">\[
|a_{n_k} - a| \le \epsilon / 2
\]</span> Putting together, <span class="math display">\[
\forall n &gt; N, |a_n - a| \le |a_n - a_{n_k} | + |a_{n_k} - a| \le \epsilon
\]</span> as desired.</p>
<h5 id="remark-1">Remark:</h5>
<p><em>Cauchy Criterion</em> can be used to prove <em>Bolzano-Weierstrass</em> Theorem. The key is to construct a sequence of nested closed intervals <span class="math inline">\(I_1 \supset I_2 \supset I_3 ...\)</span> as before and obtain a sub-sequence <span class="math inline">\((a_{n_k})\)</span>. Then, instead of using Nested Interval Property, we observe that <span class="math inline">\((a_{n_k})\)</span> is Cauchy as the length of <span class="math inline">\(I_k\)</span> shrinks to zero. We know <span class="math inline">\((a_{n_k})\)</span> converges by Cauchy Criterion.</p>
<p><strong>Reference:</strong> Stephen Abbott, <em>Understanding Analysis</em></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/02/27/Convergence-Tests/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/02/27/Convergence-Tests/" class="post-title-link" itemprop="url">Convergence Tests</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2019-02-27 16:20:18 / Modified: 22:44:25" itemprop="dateCreated datePublished" datetime="2019-02-27T16:20:18+11:00">2019-02-27</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="ration-test">Ration Test</h3>
<p>Given a series <span class="math inline">\(s_n = \sum_{k = 1}^n a_n\)</span> with <span class="math inline">\(a_n \neq 0\)</span>, the Ratio Test states that if <span class="math inline">\((a_n)\)</span> satisfies <span class="math display">\[
\lim \left| \frac{a_{n + 1} }{ a_n } \right| = r \le 1
\]</span></p>
<p>then <span class="math inline">\((s_n)\)</span> converges absolutely.</p>
<p><em>Proof</em>: The condition implies that <span class="math display">\[
\exists N &gt; 0, s.t., \exists r \le r&#39; &lt; 1, \forall n \ge N, a_{n + 1} \le r&#39; a_n 
\]</span></p>
<p>It follows that for <span class="math inline">\(n &gt; m \ge N\)</span>, <span class="math display">\[
\begin{aligned}
|s_n - s_m| 
&amp;= | a_{m + 1} + a_{m + 1} + ... + a_n| \\
&amp;\le |a_N| \sum_{k = 0}^{n - m - 1} (r&#39;)^{m - N + k} \\
&amp;\le |a_N| \sum_{k = 0}^{ \infty } (r&#39;)^{m - N + k} \\
&amp;\le \frac{|a_N| }{1 - (r&#39;) } (r&#39;)^{m - N}
\end{aligned}
\]</span></p>
<p>If <span class="math inline">\(m\)</span> is sufficient large, then <span class="math inline">\(|s_n - s_m|\)</span> is arbitrary small. It concludes that <span class="math inline">\((s_n)\)</span> is Cauchy sequence.</p>
<h3 id="abels-test">Abel's Test</h3>
<p>If the series <span class="math inline">\(s_n = \sum_{k = 1}^n a_n\)</span> converges and if <span class="math inline">\((b_n)\)</span> is a sequence satisfying <span class="math display">\[
b_1 \ge b_2 \ge b_3 \ge ... \ge 0
\]</span> then the series <span class="math inline">\(\sum_{k = 1}^\infty a_k b_k\)</span> converges.</p>
<h5 id="lemma-partial-sum">Lemma: Partial Sum</h5>
<p>Define <span class="math inline">\(s_0 = 0\)</span>, then <span class="math display">\[
\sum_{k = 1}^n x_k y_k 
= \sum_{k = 1}^n (s_k - s_{k - 1}) b_k 
= \sum_{k = 1}^n s_k b_k - \sum_{k = 1}^{n - 1} s_k b_{k + 1} 
= s_n b_n + \sum_{k = 1}^{n - 1} s_k (b_k - b_{k + 1})
\]</span></p>
<p><em>Proof:</em> <span class="math inline">\((b_n)\)</span> is monotone and bounded, therefore <span class="math inline">\((b_n)\)</span> converges. Since both <span class="math inline">\((s_n)\)</span> and <span class="math inline">\((b_n)\)</span> converges, <span class="math inline">\((s_n b_n)\)</span> converges.</p>
<p>It remains to prove <span class="math inline">\(\sum_{k = 1}^{n - 1} s_k (b_k - b_{k + 1})\)</span> converges. We show it is a Cauchy sequence. We know the convergent sequence <span class="math inline">\((s_n)\)</span> is bounded. Let <span class="math inline">\(| s_n | \le M\)</span>. Thus, for <span class="math inline">\(n &gt; m\)</span>, <span class="math display">\[
|\sum_{k = m}^{n - 1} s_k (b_k - b_{k + 1})| \le M \sum_{k = m}^{n - 1} (b_k - b_{k + 1} ) = M (b_m - b_n)
\]</span></p>
<p>The fact <span class="math inline">\((b_n)\)</span> converges implies that <span class="math inline">\(b_m - b_n \rightarrow 0\)</span> for large <span class="math inline">\(m\)</span> and so, <span class="math inline">\(|\sum_{k = m}^{n - 1} s_k (b_k - b_{k + 1})| \rightarrow 0\)</span>.</p>
<h3 id="dirichlets-test">Dirichlet's Test</h3>
<p>If the series <span class="math inline">\(s_n = \sum_{k = 1}^n a_n\)</span> is bounded (but not necessary convergent), and if <span class="math inline">\((b_k)\)</span> is a sequence satisfying <span class="math display">\[
\begin{cases}
b_1 \ge b_2 \ge b_3 \ge ... \ge 0 \quad and \\
\lim b_k = 0
\end{cases}
\]</span> then the series <span class="math inline">\(\sum_{k = 1}^\infty a_k b_k\)</span> converges.</p>
<p><em>Proof:</em> Let <span class="math inline">\(|s_n| \le M\)</span>. As <span class="math inline">\((b_n) \rightarrow 0\)</span>, <span class="math inline">\((s_n b_n) \rightarrow 0\)</span>. The proof for the convergence of <span class="math inline">\(\sum_{k = 1}^{n - 1} s_k (b_k - b_{k + 1})\)</span> is exactly the same as that of Abel's test.</p>
<p><strong>Reference</strong>: Stephen Abbott, <em>Understanding Analysis, Second Edition.</em></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/02/21/Hahn-s-Lemma/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/02/21/Hahn-s-Lemma/" class="post-title-link" itemprop="url">Hahn's Lemma</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2019-02-21 15:26:50 / Modified: 23:51:39" itemprop="dateCreated datePublished" datetime="2019-02-21T15:26:50+11:00">2019-02-21</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><em>Hahn's Lemma.</em> Let <span class="math inline">\(\mu​\)</span> be a signed measure on the measurable space <span class="math inline">\((X, M)​\)</span> and <span class="math inline">\(E​\)</span> a measurable set for which <span class="math inline">\(0 &lt; \mu(E) &lt; \infty​\)</span>. Then there is a measurable subset <span class="math inline">\(A​\)</span> of <span class="math inline">\(E​\)</span> that is positive and of positive measure.</p>
<p><em>Proof</em>. The high level idea is to iteratively take the measurable subset in <span class="math inline">\(E\)</span> with most negative measure and remove it from <span class="math inline">\(E\)</span>. If all measurable subsets are of non-negative measure, then the proof is complete. The technical hurdle is that we may not be able to find the subset with most negative measure. We relax the condition by finding a subset with "almost" most negative measure.</p>
<p>If <span class="math inline">\(E\)</span> itself is positive, then the proof is trivial. Otherwise, <span class="math inline">\(E\)</span> contains sets of negative measure. Now, consider the perfect case that we can find a set <span class="math inline">\(E_1\)</span> such that <span class="math inline">\(\lambda_1 = \mu(E_1) = \inf \{ \mu(S) \mid S \subset E \wedge S \in M \} &lt; 0\)</span>. Let <span class="math inline">\(n\)</span> be a natural number for which <span class="math inline">\(\lambda_1, ..., \lambda_n\)</span> and measurable sets <span class="math inline">\(E_1, ..., E_n\)</span> have been chosen such that, for <span class="math inline">\(1 \le k \le n\)</span>, <span class="math inline">\(\lambda_k = \inf \{ \mu(S) \mid S \subset E - \cup_{i=1}^{k - 1} E_i \wedge S \in M \} &lt; 0\)</span> and <span class="math inline">\(E_k\)</span> is a subset for which <span class="math inline">\(\mu(E_k) = \lambda_k​\)</span> (we consider the perfect case first).</p>
<p>If the selection process terminates for some positive number <span class="math inline">\(n\)</span>, then <span class="math inline">\(A = E - \cup_{k = 1}^n E_i\)</span> is exactly what we want. Otherwise, define <span class="math display">\[
A = E - \cup_{k = 1}^\infty E_i
\]</span></p>
<p>Therefore, <span class="math inline">\(A \cup E_1 \cup E_2 \cup ...\)</span> is a partition of <span class="math inline">\(E\)</span>. By countable additivity of <span class="math inline">\(\mu\)</span>,</p>
<p><span class="math display">\[
\mu(E) = \mu(A) + \mu(\cup_{k = 1}^\infty E_k)
\]</span></p>
<p>Since <span class="math inline">\(|\mu(E)| &lt; \infty\)</span>, <span class="math display">\[
-\infty &lt; \mu(\cup_{k = 1}^\infty E_k) = \sum_{k = 1}^\infty \mu(E_k) = \sum_{k = 1}^\infty \lambda_k &lt; 0
\]</span></p>
<p>Thus <span class="math inline">\(\lim_{k \rightarrow \infty} \lambda_k = 0\)</span> and <span class="math inline">\(\mu(A) = \mu(E) - \mu(\cup_{k = 1}^\infty E_k) &gt; 0\)</span>. It remains to show that <span class="math inline">\(A\)</span> is a positive set. Indeed, if <span class="math inline">\(B \subset A \wedge B \in M\)</span>, then for each <span class="math inline">\(k\)</span>,</p>
<p><span class="math display">\[
B \subset A \subset E - \cup_{i = 1}^k E_k 
\]</span></p>
<p>and so, by the definition of <span class="math inline">\(\lambda_k\)</span>, <span class="math inline">\(\mu(B) \ge \lambda_k\)</span>. As <span class="math inline">\(k \rightarrow \infty\)</span>, <span class="math inline">\(\lambda_k \rightarrow 0\)</span>, we have <span class="math inline">\(\mu(B) \ge 0\)</span>. Thus <span class="math inline">\(A\)</span> is positive set.</p>
<p><em>Remark:</em> For a given <span class="math inline">\(\lambda_k = \inf \{ \mu(S) \mid S \subset E - \cup_{i=1}^{k - 1} E_i \wedge S \in M \} &lt; 0\)</span> as defined in the proof, we may not always be able to find a set <span class="math inline">\(E_k\)</span> such that <span class="math inline">\(\mu(E_k) = \lambda_k\)</span>. There are two possible cases.</p>
<ol type="1">
<li><p>In the first case, <span class="math inline">\(0&gt; \lambda_k &gt; -\infty\)</span> for all <span class="math inline">\(k = 1, 2, ...\)</span>. By definition of <span class="math inline">\(\lambda_k\)</span>, we can always find a set <span class="math inline">\(E_k\)</span> such that <span class="math inline">\(\lambda_k&#39; = \mu(E_k) &lt; \lambda_k / 2\)</span>.</p></li>
<li><p>It is more tricky if <span class="math inline">\(\lambda_k = -\infty\)</span> for some <span class="math inline">\(k\)</span> (is this case possible?). In this case we just take an <span class="math inline">\(E_k\)</span> such that <span class="math inline">\(\lambda_k&#39; = \mu(E_k) \le - 1\)</span>.</p></li>
</ol>
<p>In a similar manner we have <span class="math inline">\(-\infty &lt; \mu(\cup_{k = 1}^\infty E_k) = \sum_{k = 1}^\infty \mu(E_k) = \sum_{k = 1}^\infty \lambda_k&#39; &lt; 0\)</span> and <span class="math inline">\(\lambda_k&#39; \rightarrow 0\)</span>. For large enough <span class="math inline">\(k\)</span>, <span class="math inline">\(-1 &lt; \lambda_k&#39; &lt; 0\)</span>. By the definition of <span class="math inline">\(\lambda_k\)</span> and the choice of <span class="math inline">\(\lambda_k&#39;\)</span>, for any <span class="math inline">\(B \subset A \wedge B \in M\)</span>, we have <span class="math inline">\(B \subset A \subset E - \cup_{i = 1}^k E_k\)</span> and <span class="math inline">\(\mu(B) \ge \lambda_k \ge 2 \mu(E_k) \ge 2 \lambda_k&#39;\)</span>. Therefore, <span class="math inline">\(\mu(B) \ge \lim_{k \rightarrow \infty} 2\lambda_k&#39; = 0\)</span>.</p>
<p><em>Reference</em>：H. Royden, P. Fitzpatrick Real Analysis</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/01/19/Strong-Duality/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/01/19/Strong-Duality/" class="post-title-link" itemprop="url">Strong Duality</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-01-19 23:22:08" itemprop="dateCreated datePublished" datetime="2019-01-19T23:22:08+11:00">2019-01-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-01-28 11:51:36" itemprop="dateModified" datetime="2020-01-28T11:51:36+11:00">2020-01-28</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>We prove strong duality of linear program by Farkas Lemma. Let the primal be</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\max &amp;c^T x &amp; \\
&amp;s.t., &amp;Ax &amp; = b \\
&amp;&amp;x &amp; \ge 0
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(A \in R^{m \times n}, c, b, x \in R^n\)</span>. The dual is given by</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\min &amp;y^T b&amp; \\
&amp;s.t., &amp;y^T A&amp; \ge c^T \\
\end{aligned}
\]</span> where <span class="math inline">\(y \in R^m\)</span>.</p>
<p><strong><em>Theorem</em></strong>. If both primal and dual are feasible, then <span class="math inline">\(\max = \min\)</span>.</p>
<p>Note that by weak duality, we have <span class="math display">\[
c^T x \le (y^T A) x = y^T (A x) = y^T b
\]</span></p>
<p>It suffices to prove the first inequality holds as equality.</p>
<p><em>Proof</em>. Assume that the dual is feasible and <span class="math inline">\(\min = \alpha\)</span>. By weak duality, <span class="math inline">\(\max \le \alpha\)</span>. It suffices to prove <span class="math inline">\(\max \ge \alpha\)</span>. We are searching for an <span class="math inline">\(x\)</span> satisfying</p>
<p><span class="math display">\[
\begin{aligned}
Ax &amp; = b \\
c^T x &amp; \ge \alpha \\
 x&amp; \ge 0
\end{aligned}
\]</span></p>
<p>Consider the convex and closed set <span class="math inline">\(P = \{(z_1, z_2) \in R^{m + 1} : z_1 = Ax, z_2 \le c^T x, x \in R^n \wedge x \ge 0\}\)</span>. If <span class="math inline">\((b, \alpha) \notin P\)</span>, the <span class="math inline">\(\exists z = (z&#39;_1, z&#39;_2)\)</span> that minimizes the distance from <span class="math inline">\((b, \alpha)\)</span> to points in <span class="math inline">\(P\)</span>. Define <span class="math inline">\(\bar y^T = (y, s) = (z&#39;_1, z&#39;_2) - (b, \alpha)\)</span>, and the separation plane <span class="math inline">\(\bar y^T (z - z&#39;) = 0\)</span>. As <span class="math inline">\(0 \in P\)</span> and <span class="math inline">\(2 z&#39; \in P\)</span>, we have <span class="math inline">\(\bar y^T (-z&#39;) \ge 0\)</span> and <span class="math inline">\(\bar y^T (z&#39;) \ge 0\)</span>, which implies that <span class="math inline">\(\bar y^T z&#39; = 0\)</span>. Hence <span class="math inline">\(\bar y^T z \ge 0\)</span> for all <span class="math inline">\(z \in P\)</span>. But</p>
<p><em>Lemma</em>: <span class="math inline">\(\bar y^T z \ge 0 \forall z \in P\)</span> if and only if <span class="math display">\[
\begin{aligned}
\bar y^T \left[ \begin{matrix} A \\ c^T \end{matrix} \right] = y^T A + sc^T \ge 0
\end{aligned}
\]</span></p>
<p>Moreover, we have <span class="math inline">\(\bar y^T (b, \alpha) &lt; 0\)</span>, hence <span class="math inline">\(y^T b + s \alpha &lt; 0\)</span>. Finally, we claim that <span class="math inline">\(s &lt; 0\)</span>. To see, this, note that for any <span class="math inline">\(k &gt; 0\)</span>, <span class="math inline">\((0, -k) \in P\)</span>, as <span class="math inline">\(0 = A 0, -k \le c^T 0\)</span>. Now <span class="math inline">\(\bar y^T (0, -k) = -k s &gt; 0\)</span>, taking <span class="math inline">\(k = 1\)</span> proves the result.</p>
<p>An alternative way to see this is by converting the primal into an equivalent one: <span class="math display">\[
\begin{aligned}
Ax &amp; = b \\
c^T x  - z &amp;= \alpha \\
 x,z &amp; \ge 0
\end{aligned}
\]</span></p>
<p>or more concisely, <span class="math display">\[
\begin{aligned}
\bar A \bar x &amp;= \bar b\\
\bar x &amp; \ge 0
\end{aligned}
\]</span></p>
<p>where <span class="math display">\[
\begin{aligned}
\bar A = 
\left[ \begin{matrix}
    A,   &amp; 0 \\
    c^T, &amp; -1
\end{matrix} \right], 
\bar x = \left[\begin{matrix} x \\ z \end{matrix} \right],
\bar b = \left[\begin{matrix} b \\ \alpha \end{matrix} \right]
\end{aligned}
\]</span></p>
<p>No feasible solution implies that <span class="math inline">\((b, \alpha)\)</span> lies outside the conic combination of columns of <span class="math inline">\(\bar A\)</span>. Therefore, <span class="math inline">\(\exists \bar y\)</span>, such that <span class="math inline">\(\bar y^T \bar A \ge 0\)</span>. In particular, <span class="math inline">\(\bar y^T \bar A[:, -1] &gt; 0\)</span>, which implies the last dimension of <span class="math inline">\(\bar y\)</span> is non-negative.</p>
<p>See the following example in 2 dimensions.</p>
<p><img src="https://pic2.zhimg.com/80/v2-8d0e896dbf81dfc276c356ec0074866d_hd.jpg" /></p>
<p>In this example, <span class="math inline">\(A[:, 1] = (-2, 1)\)</span>, <span class="math inline">\(A[:, 2] = (-1, 2)\)</span>, <span class="math inline">\(c = (1, 1)\)</span>, <span class="math inline">\(\bar A [:, 1] = (-2, 1, 1), \bar A[:, 2] = (-1, 2, 1)\)</span>. <span class="math inline">\(\{ Ax = b, x \ge 0 \}\)</span> is feasible implies that <span class="math inline">\(b\)</span> is inside the cone spanned by <span class="math inline">\(A[:, 1], A[:, 2]\)</span>. <span class="math inline">\(\{ \bar A \bar x = \bar b, x \ge 0 \}\)</span> implies that <span class="math inline">\(\bar b = (b, \alpha)\)</span> is outside the cone formed by <span class="math inline">\(\bar A[:, 1], \bar A[:, 2], [0, 0, -1]\)</span>. The <span class="math inline">\(z\)</span>-dimension of vector <span class="math inline">\(y\)</span> must be negative.</p>
<p>Rigorously, we can use Farkas' lemma to derive: <span class="math inline">\(\exists y, s\)</span>, s.t, <span class="math display">\[
\begin{aligned}
A^T y - s c &amp;\ge 0\\
s &amp; \ge 0 \\
b^T y - s \alpha &amp;&lt; 0 \\
\end{aligned}
\]</span> <!-- y, s, & \ge 0 --></p>
<p>If <span class="math inline">\(s = 0\)</span>, then <span class="math inline">\(\{ y^T A \ge 0, b^T y &lt; 0 \}\)</span> implies that dual is unbounded and hence <span class="math inline">\(\{ Ax = b, x \ge 0 \}\)</span> is infeasible, a contradiction. If <span class="math inline">\(s &gt; 0\)</span>, then scaling <span class="math inline">\(s\)</span> to <span class="math inline">\(1\)</span> gives <span class="math inline">\(\{ A^T y \ge c, b^T y &lt; \alpha \}\)</span>, contradicting <span class="math inline">\(\min = \alpha\)</span>.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/01/17/Farkas-Lemma/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/01/17/Farkas-Lemma/" class="post-title-link" itemprop="url">Farkas' Lemma</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-01-17 22:42:53" itemprop="dateCreated datePublished" datetime="2019-01-17T22:42:53+11:00">2019-01-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-01-31 17:31:04" itemprop="dateModified" datetime="2020-01-31T17:31:04+11:00">2020-01-31</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Given <span class="math inline">\(A \in R^{m \times n}\)</span> and <span class="math inline">\(b \in R^n\)</span>, the Farkas Lemma states that exactly one of the following holds:</p>
<ol type="1">
<li><span class="math inline">\(\exists x \in R^n​ : Ax = b\)</span>, <span class="math inline">\(x \ge 0\)</span>,</li>
<li><span class="math inline">\(\exists y \in R^m : y^T A \le 0\)</span>, <span class="math inline">\(y^T b &gt; 0\)</span>.</li>
</ol>
<p>Geometrically, the first statements says that <span class="math inline">\(b\)</span> is a non-negative linear combination of columns of <span class="math inline">\(A\)</span>. Denote the conic combination of columns of <span class="math inline">\(A\)</span> as <span class="math inline">\(P = \{ Ax: \forall x \ge 0\} \subset R^m\)</span>. Note that it is a subset of the columns space of <span class="math inline">\(A\)</span>.</p>
<p>If <span class="math inline">\(b \notin P\)</span>, the second statement is equivalent to that</p>
<ol start="3" type="1">
<li><span class="math inline">\(\exists y \in R^m\)</span>, such that <span class="math inline">\(y^T b &gt; 0\)</span> and <span class="math inline">\(\forall z \in P\)</span>, we have <span class="math inline">\(y^T z \le 0\)</span>.</li>
</ol>
<p>When (3) holds, clearly (2) holds, as columns of <span class="math inline">\(A\)</span> belong to <span class="math inline">\(P\)</span>. On the other hand, every element in <span class="math inline">\(P\)</span> is conic combination of columns of <span class="math inline">\(A\)</span>, then <span class="math inline">\(\forall z = Ax \in P\)</span>, then <span class="math inline">\(y^T z = y^T (A x) = (y^T A) x \le 0\)</span> by the fact that <span class="math inline">\(y^T A \le 0 \wedge x \ge 0\)</span>.</p>
<figure>
<img src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/Farkas&#39;%20Lemma.jpg?raw=true" alt="" /><figcaption>Geometry Interpretation</figcaption>
</figure>
<p>The existence of <span class="math inline">\(y\)</span> is justified as follows: as <span class="math inline">\(P\)</span> is convex and closed, the <a target="_blank" rel="noopener" href="https://wuhao-wu-jiang.github.io/2018/12/01/Separation-Plane-Theorem/">Separation Theorem</a> states that we can find a point <span class="math inline">\(z^* = A x^*\)</span> in <span class="math inline">\(P\)</span> that satisfies</p>
<p><span class="math display">\[
(b - z^*)^T(z - z^*) \le 0​
\]</span></p>
<p>Let <span class="math inline">\(y = (b - z^*) \in R^m\)</span>. Note that <span class="math inline">\(y &gt; 0\)</span> as <span class="math inline">\(b \notin P\)</span> and <span class="math inline">\(P\)</span> is closed. Consider the plane <span class="math inline">\(y^T (x - z^*) = 0\)</span>. It has the following properties:</p>
<ol type="1">
<li>Points in <span class="math inline">\(P\)</span> lies on the negative side of the plane, that is <span class="math inline">\(z \in P\)</span>, we have <span class="math inline">\(y^T (z - z^*) \le 0\)</span>.</li>
<li><span class="math inline">\(b\)</span> is on the positive side of the plane. As <span class="math inline">\(y^T (b - z^*) = y^T y &gt; 0\)</span>.</li>
<li>It holds that <span class="math inline">\(y^T z^* = 0\)</span>, which implies that either <span class="math inline">\(z^* = 0\)</span> or <span class="math inline">\(y\)</span> is normal to <span class="math inline">\(z^*\)</span>. To verify this, we move along the line that pass through the vector <span class="math inline">\(z^*\)</span> and note that for any <span class="math inline">\(k \ge 0\)</span>, we have <span class="math inline">\(kz^* \in P\)</span>, hence <span class="math inline">\(y^T (kz^* - z^*) \le 0\)</span>. Replace <span class="math inline">\(k\)</span> with <span class="math inline">\(0\)</span> and <span class="math inline">\(2\)</span> respectively, we have the desired result.</li>
<li>It concludes that <span class="math inline">\(z \in P\)</span>, <span class="math inline">\(y^T z \le 0\)</span> and <span class="math inline">\(y^T b &gt; 0\)</span>.</li>
</ol>
<p>An equivalent form states that</p>
<ol type="1">
<li><span class="math inline">\(\exists x \in R^n : Ax \le b\)</span></li>
<li><span class="math inline">\(\exists y \in R^m : y^T A = 0\)</span>, <span class="math inline">\(y^T b &gt; 0\)</span>, <span class="math inline">\(y \le 0\)</span>.</li>
</ol>
<p>We can prove this by converting statement (2) into an equivalent one:</p>
<ol start="3" type="1">
<li><span class="math inline">\(\exists y \in R^m : y^T A = 0\)</span>, <span class="math inline">\(y^T b = 1\)</span>, <span class="math inline">\(y \le 0\)</span>.</li>
</ol>
<p>and hence</p>
<ol start="4" type="1">
<li><span class="math inline">\(\exists y \in R^m : (-y)^T [A, b] = [0, -1]\)</span>, <span class="math inline">\(-y \ge 0\)</span>.</li>
</ol>
<p>If this doesn't hold, by previous result, we have <span class="math inline">\(\exists (x, \lambda) \in R^{n + 1}\)</span>, s,t., <span class="math inline">\([A, b] (x, \lambda) = Ax + \lambda b \le 0\)</span> and <span class="math inline">\([0, 1](x, -\lambda) = -\lambda &gt; 0\)</span>, which implies that<span class="math inline">\(A \frac{x}{-\lambda} \le b\)</span>.</p>
<p>But this can also be verified via their geometrical meanings. We are not going to give all details here, just an example in <span class="math inline">\(R^2\)</span>:</p>
<figure>
<img src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/Farkas&#39;%20Lemma%202.jpg?raw=true" alt="" /><figcaption>Geometry Interpretation 2</figcaption>
</figure>
<p>Another equivalent form of Farkas Lemma is written as</p>
<ol type="1">
<li><span class="math inline">\(\exists x \in R^n : Ax \le b\)</span>, <span class="math inline">\(x \ge 0\)</span>.</li>
<li><span class="math inline">\(\exists y \in R^m : y^T A \le 0\)</span>, <span class="math inline">\(y^T b &gt; 0\)</span>, <span class="math inline">\(y \le 0\)</span>.</li>
</ol>
<p>Define <span class="math inline">\(P = \{ z \mid \exists x \in R^n : z \ge Ax, x \ge 0\} \subset R^m\)</span>.</p>
<ol type="1">
<li>Statement 1 says <span class="math inline">\(b \in Z\)</span>.</li>
<li>Otherwise, as <span class="math inline">\(P\)</span> is convex and closed
<ul>
<li><p><span class="math inline">\(z_1, z_2 \in P \rightarrow \exists x_1, x_2 \ge 0, z_1 \ge Ax_1, z_2 \ge Ax_2\)</span>, then <span class="math inline">\(\mu_1 z_1 + \mu_2 z_2 \ge A(\mu_1 x_1 + \mu_2 x_2), \forall \mu_1, \mu_2 \ge 0, \mu_1 + \mu_2 = 1\)</span>,</p></li>
<li><p>Closeness follows from <span class="math inline">\(\ge\)</span> in the definition of <span class="math inline">\(P\)</span>. There is a unique point <span class="math inline">\(z^*\)</span> that minimize <span class="math inline">\(||z - b||\)</span> for <span class="math inline">\(z \in Z\)</span>. Let <span class="math inline">\(y = (b - z^*) \neq 0\)</span>. Then it holds <span class="math inline">\(y^T (b - z^*) = y^T y &gt; 0\)</span> and <span class="math inline">\(y^T(z - z^*) \le 0\)</span> for any <span class="math inline">\(z \in Z\)</span>.</p></li>
<li><p>Similarly, <span class="math inline">\(z^* \in P \rightarrow \exists x \ge 0, z^* \ge Ax \rightarrow k \ge 0, k z^* \ge A (kx) \rightarrow kz \in P\)</span>. Then <span class="math inline">\(0 \in P\)</span> and <span class="math inline">\(2z^* \in P\)</span>, which implies <span class="math inline">\(- y^T z^* \le 0\)</span> and <span class="math inline">\(y^T z^* \le 0\)</span>. Hence <span class="math inline">\(y^T z^* = 0\)</span> and <span class="math inline">\(y^T b = y^T y + y^T z^* &gt; 0\)</span>.</p></li>
<li><p>Further, the fact <span class="math inline">\(z^* + e_i \in Z\)</span> gives <span class="math inline">\(y^T e_i \le 0\)</span> for arbitrary <span class="math inline">\(i\)</span>. Therefore <span class="math inline">\(y \le 0\)</span>. The <span class="math inline">\(y^T b &lt; 0\)</span> and <span class="math inline">\(y^T A \le 0\)</span> follow from the same proof given above.</p></li>
</ul></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/12/13/Complex-Integration/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/12/13/Complex-Integration/" class="post-title-link" itemprop="url">Complex Integral</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-12-13 22:26:11" itemprop="dateCreated datePublished" datetime="2018-12-13T22:26:11+11:00">2018-12-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-13 16:24:32" itemprop="dateModified" datetime="2019-12-13T16:24:32+11:00">2019-12-13</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>In this article are going to walk through complex integral and establish it step by step. First, we review the classical Riemann integral and see how this motivates complex integral.</p>
<h1 id="riemann-sums">Riemann Sums</h1>
<p>Intuitively, given a interval <span class="math inline">\([a, b]\)</span> and a function <span class="math inline">\(f\)</span> defined on that, the Riemann integral is obtained by dividing <span class="math inline">\([a, b]\)</span> into many small intervals and summing over the product of the length of each interval and function value at a arbitrary chosen point on the interval. Such a sum is well-defined if it converges to some fixed value when the partition chosen is "refined" enough.</p>
<p><em>DEFINITION.</em><br />
Let <span class="math inline">\(f(x)\)</span> be a function defined on a closed interval <span class="math inline">\([a, b]\)</span>. We say a number <span class="math inline">\(J\)</span> is the definite integral of <span class="math inline">\(f\)</span> over <span class="math inline">\([a, b]\)</span> and that <span class="math inline">\(J\)</span> is the limit of the Riemann sums <span class="math inline">\(\sum_{k = 1}^n f(c_k) \Delta_{k}\)</span> if the following condition is satisfied:</p>
<p>Given any number <span class="math inline">\(\epsilon &gt; 0\)</span>, there is a corresponding number <span class="math inline">\(\delta &gt; 0\)</span> such that for every partition <span class="math inline">\(P = \{x_0, x_1, ..., x_n \}\)</span> of <span class="math inline">\([a, b]\)</span> with <span class="math inline">\(||P|| &lt; \delta\)</span> （where <span class="math inline">\(||P|| \doteq \max_{1 \le i \le n} \Delta_i\)</span> and <span class="math inline">\(\Delta_i \doteq x_i - x_{i - 1}\)</span>) and any choice of <span class="math inline">\(c_k\)</span> in <span class="math inline">\([x_{k - 1}, x_k]\)</span>, we have<br />
<span class="math display">\[
\left| \sum_{k = 1}^n f(c_k) \Delta_k - J \right| &lt; \epsilon
\]</span> When the limit exists we write it as the definite integral<br />
<span class="math display">\[
J = \lim_{||P|| \rightarrow 0} \sum_{k = 1}^n f(c_k) \Delta_{k}
\]</span> There is a specified notation for this limit of Riemann sums <span class="math display">\[
\int_a^b f(x) dx = \lim_{||P|| \rightarrow 0} \sum_{k = 1}^n f(c_k) \Delta_{k}
\]</span></p>
<h1 id="complex-integral">Complex Integral</h1>
<h2 id="real-to-complex-function">Real to complex function</h2>
<p>How do we extend integral in real line to complex plane. The most simplest extension is of a real to complex function <span class="math inline">\(\gamma(t) = x(t) + i y(t)\)</span>, whose integral on a interval is obtained by integrating its real part and imaginary part respectively.</p>
<p><em>DEFINITION</em> If <span class="math inline">\(\gamma : D \rightarrow C\)</span> is simply a function on a real interval <span class="math inline">\(D = [a, b]\)</span>, then the integral <span class="math inline">\(\int_a^b \gamma(t) dt\)</span> is defined as <span class="math display">\[
\int_a^b \gamma(t) dt = \int_a^b x(t) dt + i\int_a^b y(t) dt,
\]</span> where <span class="math inline">\(\gamma(t) = x(t) + i y(t)\)</span>.</p>
<h2 id="complex-to-complex-function">Complex to complex function</h2>
<p>Another natural idea is to consider a smooth path <span class="math inline">\(C\)</span> with endpoints <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> on the complex plane and a complex function <span class="math inline">\(f\)</span> whose domain contains the path.</p>
<p>Note we do not even require <span class="math inline">\(a \neq b\)</span>; but in case <span class="math inline">\(a = b\)</span>, we must specify an orientation for the closed path <span class="math inline">\(C\)</span>.</p>
<p>Next, we repeat the partition and product idea: let <span class="math inline">\(P = \{z_0, z_1, ..., z_n\}\)</span> be a partition of the curve such that <span class="math inline">\(z_0 = a\)</span> and <span class="math inline">\(z_n = b\)</span>. A Riemann sum associated with <span class="math inline">\(P\)</span> is just what it is in the real case: <span class="math inline">\(J\)</span> is the limit of the <span class="math inline">\(\sum_{k = 1}^n f(z_k) \Delta_{k}\)</span> (where <span class="math inline">\(\Delta \doteq |z_k - z_{k - 1}| = \sqrt{Re(z_k - z_{k - 1})^2 + Im(z_k - z_{k - 1})^2}\)</span>) if the following condition is satisfied</p>
<p>Given any number <span class="math inline">\(\epsilon &gt; 0\)</span>, there is a corresponding number <span class="math inline">\(\delta &gt; 0\)</span> such that for every partition <span class="math inline">\(P = \{z_0, z_1, ..., z_n\}\)</span> of <span class="math inline">\([a, b]\)</span> with <span class="math inline">\(||P|| &lt; \delta\)</span> and any choice of <span class="math inline">\(d_k\)</span> in <span class="math inline">\([z_{k - 1}, z_k]\)</span>, we have<br />
<span class="math display">\[
|\sum_{k = 1}^n f(d_k) \Delta_{k} - J| &lt; \epsilon
\]</span> When the limit exists we write it as the definite integral<br />
<span class="math display">\[
J = \lim_{||P|| \rightarrow 0} \sum_{k = 1}^n f(d_k) \Delta_{k}
\]</span> There is a specified notation for this limit of Riemann sums <span class="math display">\[
\int_C f(x) dx = \lim_{||P|| \rightarrow 0} \sum_{k = 1}^n f(d_k) \Delta_{k}
\]</span></p>
<h2 id="rules-satisfied-by-the-integrals">Rules satisfied by the integrals</h2>
<ol type="1">
<li>Constant Multiple: <span class="math inline">\(\int_C k f(x) dx = k \int_C f(x) dx\)</span>.</li>
<li>Sum: <span class="math inline">\(\int_C f(x) + g(x) dx = \int_C f(x) dx + \int_C g(x) dx\)</span></li>
</ol>
<p><em>Proof:</em> For any partition <span class="math inline">\(P\)</span> of <span class="math inline">\(C\)</span> and for every choice of the points <span class="math inline">\(z_k\)</span>,<br />
<span class="math display">\[
\sum_{j = 1}^n kf(z_j) \Delta_{z_j} = k \sum_{j = 1}^n f(z_j) \Delta_{z_j} \\
\sum_{j = 1}^n (f(z_j) + g(z_j))\Delta_{z_j} = \sum_{j = 1}^n f(z_j) \Delta_{z_j} + \sum_{j = 1}^n g(z_j) \Delta_{z_j}
\]</span> Taking limit of both side, we get the desired answer. Remark: given two sequence <span class="math inline">\(\{ a_1, a_2, ..., \}\)</span> and <span class="math inline">\(\{b_1, b_2, ..., \}\)</span>, if <span class="math inline">\(a_i = b_i\)</span> for arbitrary <span class="math inline">\(i \ge 0\)</span> and <span class="math inline">\(\lim_i b_i = S\)</span>, then <span class="math inline">\(\lim_i a_i\)</span> exits and <span class="math inline">\(\lim_i a_i = S\)</span>.</p>
<h2 id="evaluation">Evaluation</h2>
<p>To evaluate such integral, we can choose a description <span class="math inline">\(\gamma(t) = x(t) + i y(t) : [a, b] \rightarrow C\)</span> of curve <span class="math inline">\(C\)</span>. We partition <span class="math inline">\(C\)</span> by partitioning the interval <span class="math inline">\([a, b]\)</span> in usual way <span class="math inline">\(P_t = \{ a = t_0 &lt; t_1&lt; ... &lt; t_n = b \}\)</span>. Then <span class="math inline">\(\gamma(P_t) \doteq \{ \gamma(t_0), \gamma(t_1), ..., \gamma(t_n) \}\)</span> is a partition of <span class="math inline">\(C\)</span>.</p>
<p>If <span class="math inline">\(\gamma\)</span> is continuous, it is uniformly continuous on <span class="math inline">\([a, b]\)</span>. Therefore, as <span class="math inline">\(||P_t|| \rightarrow 0\)</span>, <span class="math inline">\(||\gamma(P_t)|| \rightarrow 0\)</span>. If <span class="math inline">\(\int_C f(z) dz\)</span> exists, then</p>
<p><span class="math display">\[
\int_C f(z) dz = \lim_{||P_t|| \rightarrow 0} \sum_{j = 1}^n f(\gamma(e_j)) \big(\gamma(t_j) - \gamma(t_{j - 1}) \big)
\]</span></p>
<p>for arbitrary choice <span class="math inline">\(e_j \in [t_{j - 1}, t_j]\)</span>.</p>
<p>When the derivative of <span class="math inline">\(\gamma\)</span> exists and is continuous, it is uniformly continuous on the closed bounded interval <span class="math inline">\([a, b]\)</span>. We now can rewrite the Riemann sum as</p>
<p><span class="math display">\[
\sum_{j = 1}^n f(\gamma(e_j)) \frac{\gamma(t_j) - \gamma(t_{j - 1})}{t_j - t_{j - 1} }(t_j - t_{j - 1})  
= \sum_{j = 1}^n f(\gamma(e_j)) \frac{x(t_j) - x(t_{j - 1})+ i (y(t_j) - y_(t_{j - 1}))}{t_j - t_{j - 1} }(t_j - t_{j - 1})
\]</span></p>
<p>By intermediate value theorem, as <span class="math inline">\(x&#39;(t)\)</span> and <span class="math inline">\(y&#39;(t)\)</span> exist, there are some <span class="math inline">\(e_j&#39; \in [t_{j - 1}, t_j]\)</span> and <span class="math inline">\(e_j&#39;&#39; \in [t_{j - 1}, t_j]\)</span>, such that</p>
<p><span class="math display">\[
\frac{x(t_j) - x(t_{j - 1})}{t_j - t_{j - 1} } = x&#39;(e_j&#39;) \quad \wedge \frac{y(t_j) - y(t_{j - 1})}{t_j - t_{j - 1} } = x&#39;(e_j&#39;&#39;)
\]</span></p>
<p>On the other hand, as <span class="math inline">\(x&#39;(t)\)</span> and <span class="math inline">\(y&#39;(t)\)</span> are uniformly continuous, for arbitrary <span class="math inline">\(\epsilon &gt; 0\)</span>, there is a <span class="math inline">\(\delta\)</span> such that if <span class="math inline">\(||P_t|| &lt; \delta\)</span>, <span class="math inline">\(|x&#39;(e_j&#39;) - x&#39;(e_j)| &lt; \epsilon\)</span> and <span class="math inline">\(|y&#39;(e_j&#39;&#39;) - y&#39;(e_j)| &lt; \epsilon\)</span>. It follows that</p>
<p><span class="math display">\[
 \frac{x(t_j) - x(t_{j - 1})+ i (y(t_j) - y_(t_{j - 1}))}{t_j - t_{j - 1} } = x&#39;(e_j) + i y&#39;(e_j) \pm \epsilon(1 + i)\\
 \sum_{j = 1}^n f(\gamma(e_j)) \frac{\gamma(t_j) - \gamma(t_{j - 1})}{t_j - t_{j - 1} }(t_j - t_{j - 1})  
 = \sum_{j = 1}^n f(\gamma(e_j)) \gamma&#39;(e_j) (t_j - t_{j - 1}) \pm \epsilon (1 + i)|C|
\]</span></p>
<p>where <span class="math inline">\(|C|\)</span> is the length of the path <span class="math inline">\(C\)</span>.</p>
<p>Taking the limit of <span class="math inline">\(||P_t|| \rightarrow 0\)</span>, we get<br />
<span class="math display">\[
\int_C f(z) dz = \int_a^b f(\gamma(t))\gamma&#39;(t) dt
\]</span></p>
<p><strong>Remark 1:</strong> <em>Can we relax the condition that <span class="math inline">\(\gamma&#39;(t)\)</span> is continuous and that <span class="math inline">\([a, b]\)</span> is a closed interval?</em></p>
<p><strong>Remark 2:</strong> <em>We have also showed that the integration is independent of the choice of <span class="math inline">\(\gamma\)</span>, i.e., any representation of <span class="math inline">\(C\)</span> that is continuously differentiable gives the same integration value</em>.</p>
<h2 id="anti-derivative">Anti-derivative</h2>
<p>Now suppose that <span class="math inline">\(F(z) = u(x, y) + i v(x, y)\)</span> and <span class="math inline">\(F&#39;(z) = f(z)\)</span>. We claim that <span class="math inline">\(\int_C f(z) dz = F(b) - F(a)\)</span>.</p>
<p>First, <span class="math inline">\(F&#39;(\gamma(t)) = \frac{\partial u}{\partial x} \frac{\partial x}{\partial t} + \frac{\partial u}{\partial y} \frac{\partial y}{\partial t} + i ( \frac{\partial v}{\partial x} \frac{\partial x}{\partial t} + \frac{\partial v}{\partial y} \frac{\partial y}{\partial t} )\)</span>. Therefore,<br />
<span class="math display">\[
\int_C f(z) dz = \int_a^b (\frac{\partial u}{\partial x} \frac{\partial x}{\partial t} + \frac{\partial u}{\partial y} \frac{\partial y}{\partial t}) dt + i \int_a^b (  \frac{\partial v}{\partial x} \frac{\partial x}{\partial t} + \frac{\partial v}{\partial y} \frac{\partial y}{\partial t}  ) dt
\]</span></p>
<p>But<br />
<span class="math display">\[
\begin{aligned}
u(x(b), y(b)) - u(x(a), y(a)) 
&amp;= \sum_{j = 1}^n [u(x(t_j), y(t_j)) - u(x(t_{j - 1}), y(t_{j - 1}))] \\
&amp;= \sum_{j = 1}^n [u(x(t_j), y(t_j)) - u(x(t_j), y(t_{j - 1})) + u(x(t_j), y(t_{j - 1})) - u(x(t_{j - 1}), y(t_{j - 1}))] \\
&amp;= \sum_{j = 1}^n \frac{u(x(t_j), y(t_j) ) - u(x(t_j), y(t_{j - 1} ) ) }{y(t_j) - y(t_{j - 1} ) } \frac{y(t_j) - y(t_{j - 1} )}{ t_j - t_{j - 1} }(t_j - t_{j - 1})\\
&amp;\quad +\sum_{j = 1}^n \frac{u(x(t_j), y(t_{j - 1})) - u(x(t_{j - 1}), y(t_{j - 1}))}{x(t_j) - x(t_{j - 1})} \frac{x(t_j) - x(t_{j - 1}) }{t_j - t_{j - 1} } (t_j - t_{j - 1}) \\
&amp;= \sum_{j = 1}^n [u_y&#39; (x(t_j), y^*_j) y&#39;(e_j&#39;) + u_x&#39; (x^*_j, y(t_{j - 1})) x&#39;(e_j&#39;&#39;)] (t_j - t_{j - 1})\\
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(y^*_j \in [ y( t_{j - 1} ), y( t_j ) ]\)</span>, <span class="math inline">\(x^*_j \in [ x( t_{j - 1} ), x( t_j ) ]\)</span>, <span class="math inline">\(e_j&#39;, e_j&#39;&#39; \in [ t_{j - 1}, t_j ]\)</span>. If <span class="math inline">\(u&#39;_x, u&#39;_y, x&#39;(t), y&#39;(t)\)</span> are continuous, then as <span class="math inline">\(||P_t|| \rightarrow 0\)</span>, <span class="math inline">\(\sum_{j = 1}^n [u_y&#39; ( x( t_j ), y( t_j ) ) y&#39;( t_j ) + u_x&#39; ( x( t_j ), y( t_j ) ) x&#39;( t_j ) ] ( t_j - t_{j - 1} ) = \sum_{j = 1}^n \frac{\partial u}{\partial t} ( t_j - t_{j - 1} ) \rightarrow u(x(b), y(b) ) - u(x(a), y(a) )\)</span>. An immediately consequence is that</p>
<p><span class="math display">\[
F(\gamma(b)) - F(\gamma(a)) = \int_C F&#39;(\gamma(t)) dt
\]</span></p>
<p>On the other hand, since <span class="math inline">\(F(z)\)</span> is differential, <span class="math inline">\(\lim_{h \rightarrow 0} \frac{F(z + h) - F(z) }{h} = \frac{\partial u}{\partial x} + i \frac{\partial v}{\partial x} = \lim_{ih \rightarrow 0} \frac{F(z + ih) - F(z) }{ih} = -i \frac{\partial u}{\partial y} + \frac{\partial v}{\partial y}\)</span>. It holds that <span class="math inline">\(\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y}\)</span> and <span class="math inline">\(\frac{\partial v}{\partial x} = -\frac{\partial u}{\partial y}\)</span>. Therefore,<br />
<span class="math display">\[
F&#39;(\gamma(t)) = \frac{\partial u}{\partial x} \frac{\partial x}{\partial t} - \frac{\partial v}{\partial x} \frac{\partial y}{\partial t} + i (  \frac{\partial v}{\partial x} \frac{\partial x}{\partial t} + \frac{\partial u}{\partial x} \frac{\partial y}{\partial t}  ) = (\frac{\partial u}{\partial x} + i \frac{\partial v}{\partial x}) ( \frac{\partial x}{\partial t} + i \frac{\partial y}{\partial t} ) = F&#39;(\gamma(t)) \gamma&#39;(t) = f(\gamma(t)) \gamma&#39;(t)
\]</span> and<br />
<span class="math display">\[
F(\gamma(b)) - F(\gamma(a)) = \int_C f(\gamma(t)) \gamma&#39;(t) dt
\]</span></p>
<p>Remark: That <span class="math inline">\(u_x&#39;, u_y&#39;\)</span> are continuous is a strong condition. What we need in the proof is just that *</p>
<p><span class="math display">\[
\begin{aligned}
u(x(t_j), y(t_j))  
&amp;= u(x(t_{j - 1}), y(t_{j - 1})) \\
&amp;+ u_x&#39;(x(t_{j - 1}), y(t_{j - 1})) (x(t_j) -  x(t_{j - 1})) \\
&amp;+ u_y&#39;(x(t_{j - 1}), y(t_{j - 1})) (y(t_j) -  y(t_{j - 1})) \\
&amp;+ o(x(t_j) -  x(t_{j - 1}), y(t_j) -  y(t_{j - 1}))
\end{aligned}
\]</span></p>
<p>or</p>
<p><span class="math display">\[
\begin{aligned}
u(x(t_{j - 1}) + \delta_x, y(t_{j - 1}) + \delta_y)  
&amp;= u(x(t_{j - 1}), y(t_{j - 1})) \\
&amp;+ u_x&#39;(x(t_{j - 1}), y(t_{j - 1})) \delta_x \\
&amp;+ u_y&#39;(x(t_{j - 1}), y(t_{j - 1})) \delta_y \\
&amp;+ o(\delta_x, \delta_y)
\end{aligned}
\]</span></p>
<p><em>i.e., <span class="math inline">\(u\)</span> is differentiable at every point in the domain.</em></p>
<p>Question: Is is possible that <span class="math inline">\(u\)</span> is differentiable but its partial derivatives are not continuous? The answer is NO. First we consider an one dimension counter example:<br />
<span class="math display">\[
f(x) =  
\begin{cases}
x^2 \sin \frac{1}{x} \quad \forall x \neq 0, \\
0, \quad if \quad x = 0
\end{cases}
\]</span> To show <span class="math inline">\(f(x)\)</span> is differential at <span class="math inline">\(0\)</span>, we use the definition of derivative:<br />
<span class="math display">\[
f&#39;(0) = \lim_{h \rightarrow } \frac{f(h) - f(0)}{h - 0} = \lim_{h \rightarrow 0} h \sin \frac{1}{h} = 0
\]</span> On the other hand, <span class="math inline">\(f(x)\)</span> is always differentiable from <span class="math inline">\(0\)</span>:<br />
<span class="math display">\[
f&#39;(x) = 2x \sin \frac{1}{x} + x^2 ( -1 / x^2) cos \frac{1}{x} = 2x \sin \frac{1}{x} -cos \frac{1}{x}
\]</span> Hence, <span class="math inline">\(f(x)\)</span> is differentiable everywhere, but <span class="math inline">\(f&#39;(x)\)</span> is not continuous at <span class="math inline">\(0\)</span>.</p>
<p>The above example can be easily extended to two dimension case:<br />
<span class="math display">\[
f(x, y) =  
\begin{cases}
(x^2 + y^2) \sin \frac{1}{ \sqrt{x^2 + y^2} } \quad \forall (x, y) \neq (0, 0) \\
0 \qquad \qquad \qquad \qquad \quad if \quad  (x, y) = (0, 0)  
\end{cases}
\]</span> By definition, <span class="math inline">\(f(x, y)\)</span> is differential at <span class="math inline">\((0, 0)\)</span>,<br />
<span class="math display">\[
\lim_{||(x, y)|| \rightarrow 0} \frac{||f(x, y) - f(0) - (0,0) \cdot (x, y)||}{||(x, y)||} \le \lim_{||(x, y)|| \rightarrow 0} \frac{||x^2 + y^2||}{||(x, y)||} = \lim_{||(x, y)|| \rightarrow 0} ||(x, y)||= 0
\]</span> However, it partial derivative from <span class="math inline">\((0, 0)\)</span> <span class="math display">\[
\frac{\partial f}{\partial x} = 2x \sin \frac{1}{ \sqrt{x^2 + y^2} } + (x^2 + y^2) (-\frac{ 2x }{ \sqrt{ x^2 + y^2 }^{3} }) \cos \frac{1}{ \sqrt{x + y} } = 2x \sin \frac{1}{ \sqrt{x^2 + y^2} } - \frac{ 2x }{ \sqrt{ x^2 + y^2 } } \cos \frac{1}{ \sqrt{x^2 + y^2 } }
\]</span> and<br />
<span class="math display">\[
\frac{\partial f}{\partial x}(0, 0) = \lim_{h \rightarrow} \frac{h^2 \sin \frac{1}{|h|} }{h} = 0
\]</span> Therefore, <span class="math inline">\(\partial f / \partial x\)</span> is not continuous.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/12/01/Separation-Plane-Theorem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/12/01/Separation-Plane-Theorem/" class="post-title-link" itemprop="url">Separation Plane Theorem</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-12-01 20:17:53" itemprop="dateCreated datePublished" datetime="2018-12-01T20:17:53+11:00">2018-12-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-14 11:02:01" itemprop="dateModified" datetime="2019-12-14T11:02:01+11:00">2019-12-14</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Given a convex and closed set <span class="math inline">\(S\)</span> and a point <span class="math inline">\(p\)</span>, if <span class="math inline">\(p\)</span> does not belongs to <span class="math inline">\(S\)</span>, then the <em>Separation Theorem</em> states that there is a separation plane between <span class="math inline">\(S\)</span> and <span class="math inline">\(p\)</span>.</p>
<p>To prove it, define <span class="math inline">\(\delta = \min \{ ||s - p|| \mid s \in S \}\)</span>, where <span class="math inline">\(||\cdot ||\)</span> is the <span class="math inline">\(l_2\)</span> norm.</p>
<p><em>Lemma</em>: There is indeed a point <span class="math inline">\(s^* \in S\)</span> that achieves <span class="math inline">\(||s^* - p || = \delta\)</span>.</p>
<p><em>Proof</em>:</p>
<ol type="1">
<li>Pick arbitrary point <span class="math inline">\(s \in S\)</span>. Denote <span class="math inline">\(r = ||s - p||\)</span>. Define <span class="math inline">\(S&#39; = S \cap \{||x - p|| \le r \}\)</span>. By definition <span class="math inline">\(S&#39;\)</span> is nonempty, bounded, and closed.</li>
<li>Define a function <span class="math inline">\(f: S&#39; \rightarrow R\)</span> by <span class="math inline">\(f(s) = ||s - p||\)</span>. <span class="math inline">\(f\)</span> is a continuous function. Combining with the fact <span class="math inline">\(S&#39;\)</span> is bounded and closed, there exists a point <span class="math inline">\(s^*\)</span> that minimizes <span class="math inline">\(f(s)\)</span>.</li>
<li>We claim that <span class="math inline">\(f(s^*) = \delta\)</span>. Otherwise, there is a point <span class="math inline">\(s&#39;&#39; \in S\)</span>, s.t., <span class="math inline">\(f(s^*) &gt; ||s&#39;&#39; - p|| &gt; \delta\)</span>. But this implies <span class="math inline">\(s&#39;&#39; \in S&#39;\)</span>, a contradicting <span class="math inline">\(s^* = \min_{s \in S&#39;} f(s)\)</span>.</li>
</ol>
<p><em>Lemma:</em> <span class="math inline">\(s^*\)</span> is unique.</p>
<p><em>Proof:</em> The uniqueness results from the convexity of <span class="math inline">\(S\)</span>. If not, let <span class="math inline">\(s&#39;&#39;\)</span> be another optimal point. Now <span class="math inline">\(||q - s&#39;|| = \delta\)</span> and <span class="math inline">\(||q - s&#39;&#39;|| = \delta\)</span>. The middle point between <span class="math inline">\(s&#39;\)</span> and <span class="math inline">\(s&#39;&#39;\)</span> is clearly closer to <span class="math inline">\(p\)</span> than both <span class="math inline">\(s&#39;\)</span> and <span class="math inline">\(s&#39;&#39;\)</span>, as<br />
<span class="math display">\[
||p - (s&#39; + s&#39;&#39;) / 2|| = || (p - s&#39;) / 2 + (p - s&#39;&#39;) / 2|| \le 1/2 ||p - s&#39;|| + 1/2 ||p - s&#39;&#39;|| = \delta
\]</span> The inequality is tight if <span class="math inline">\(s&#39; \neq s&#39;&#39;\)</span>. Therefore, we use <span class="math inline">\(s^*\)</span> to indicate the unique point.</p>
<!---
To see this, let $s_i$ be  a sequence such that $\lim_i ||s_i - p|| = \delta$.  Let $N$ be a number such that $\forall i, j \ge N$, $||s_i - p|| \le \delta + \epsilon$ and $||s_j - p|| \le \delta + \epsilon$. This implies that $s_i$ and $s_j$ are located between the ball $B(p, \delta)$ and $B(p, \delta + \epsilon)$. Does this necessarily means that $s_i$ and $s_j$ are close? Without the condition of $S$ being convex, the answer is no. $s_i$ and $s_j$ can lie on a line that passes through $p$ and their distance can be as far as $2\delta + 2\epsilon$. Is $S$ is convex, things become completely different. The line segment that connects $s_i$ and $s_j$ can not intersect with $B(p, \delta)$, otherwise the distance between $p$ and $S$ is smaller. This imposes restriction on the possible locations of $s_i$ and $s_j$. Given $s_i$, what is the longest distance between $s_j$ and $s_i$, conditioning on that $\delta \le ||p - s_j|| \le \delta + \epsilon$ and $S$ being convex? This is given by 
$$
||s_i - s_j|| \le 2\sqrt{(\delta + \epsilon)^2 - \delta^2}=2\sqrt{2\delta\epsilon + \epsilon^2}
$$

It follows that $\{s_i\}$ is a *[Cauchy sequence](https://en.wikipedia.org/wiki/Cauchy_sequence)* there is a limit $s' = \lim_i s_i$. As $S$ is a closed set, $s' \in S$. 




Moreover, $s'$ is unique. If not, let $s''$ be another optimal point. Now $||q - s'|| = \delta$ and $||q - s''|| = \delta$. The middle point between $s'$ and $s''$ is clearly closer to $p$ than both $s'$ and $s''$, as  
$$
||p - (s' + s'') / 2|| = || (p - s') / 2 + (p - s'') / 2|| \le 1/2 ||p - s'|| + 1/2 ||p - s''|| = \delta
$$
The inequality is tight if $s' \neq s''$. Therefore, we use $s^*$ to indicate the unique point. 
-->
<p><em>Theorem</em>: <span class="math inline">\((p - s^*)^T(x - s^*) = 0\)</span> is a separation plane between <span class="math inline">\(S\)</span> and <span class="math inline">\(p\)</span>.</p>
<p><em>Proof</em>.</p>
<ol type="1">
<li><p><span class="math inline">\((p - s^*)^T(p - s^*) = \delta^2 &gt; 0\)</span> since <span class="math inline">\(p \notin S\)</span> and <span class="math inline">\(S\)</span> is closed.</p></li>
<li><p>We claim that <span class="math inline">\(\forall s \in S​\)</span>, <span class="math inline">\((p - s^*)^T(s - s^*) \le 0​\)</span>. Consider any real number <span class="math inline">\(t \in (0, 1)​\)</span>, by convexity, <span class="math inline">\(s^* + t(s - s^*) \in S​\)</span>. By the definition of <span class="math inline">\(s^*​\)</span>, <span class="math display">\[
||t(s - s^*) + s^* - p||^2 = ||p - s||^2 - 2t(p - s^*)^T(s - s^*) + t^2||s - s^*||^2 \ge ||p - s^*||^2
\]</span> Therefore, <span class="math inline">\(\frac{t}{2}||s - s^*||^2 \ge (p - s^*)^T(s - s^*)\)</span>. As <span class="math inline">\(t\rightarrow 0\)</span>, we obtained the desired result.</p></li>
</ol>
<!---

Otherwise, suppose that there is another point $s^+ \in S$  such that $\gamma \doteq (p  - s^*)^T (s^+ - s^*) > 0$, then $s^*$ is not the closest point from $S$ to $p$. To see why, consider the points in the line segment spanned by $s^*$ and $s^+$. Such a point must belong to the convex set $S$ and can be expressed as $s^* + t (s^+ - s^*) $ for $t \in (0, 1)$, whose distance to $p$ is given by 
$$
\begin{aligned}
&(s^* + t(s^+ - s^*) - p)^T(s^* + t(s^+ - s^*) - p) \\
=& (s^* - p)^T(s^* - p) + 2t(s^+ - s^*)(s^* - p) + t^2(s^+ - s^*)^T(s^+ - s^*) \\
=& \delta^2 -2\gamma t + ||s^+ - s^*||^2 t^2
\end{aligned}
$$
As a function of $t$, the distance has value $\delta^2$ and negative derivative when $t = 0$. Therefore, there must be a point whose distance is close to $p$ in $S$, a contradiction. 

-->
<!---

The separation plane is given by $(p - s^*)^T(x - s^*) \ge 0$. We claim that the points in $S$ lie on the where $(p - s^*)^T(x - s^*) \le 0$ while $p$ is on the side with $(p - s^*)^T(p - s^*) > 0$. The second part is easy to prove: as $(p - s^*)^T(p - s^*) \ge 0$ and $p \notin S$, it must be the case $(p - s^*)^T(p - s^*) > 0$. For the first part, suppose that there is another point $s^+ \in S$  such that $\gamma \doteq (p  - s^*)^T (s^+ - s^*) > 0$, then $s^*$ is not the closest point from $S$ to $p$. To see why, consider the points in the line segment spanned by $s^*$ and $s^+$. Such a point must belong to the convex set $S$ and can be expressed as $s^* + t (s^+ - s^*) $ for $t \in (0, 1)$, whose distance to $p$ is given by 
$$
\begin{aligned}
&(s^* + t(s^+ - s^*) - p)^T(s^* + t(s^+ - s^*) - p) \\
=& (s^* - p)^T(s^* - p) + 2t(s^+ - s^*)(s^* - p) + t^2(s^+ - s^*)^T(s^+ - s^*) \\
=& \delta^2 -2\gamma t + ||s^+ - s^*||^2 t^2
\end{aligned}
$$
As a function of $t​$, the distance has value $\delta^2​$ and negative derivative when $t = 0​$. Therefore, there must be a point whose distance is close to $p​$ in $S​$, a contradiction. 

-->

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/11/21/RSA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/11/21/RSA/" class="post-title-link" itemprop="url">RSA</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-11-21 21:52:18" itemprop="dateCreated datePublished" datetime="2018-11-21T21:52:18+11:00">2018-11-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-04 20:52:46" itemprop="dateModified" datetime="2019-12-04T20:52:46+11:00">2019-12-04</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>We discuss the problem of sending a message secretly over the internet. Suppose the original message is a sequence <span class="math inline">\(x\)</span>, the encrypt message is <span class="math inline">\(y\)</span>.</p>
<p>One solution is to perform XOR operation. Suppose there is a key <span class="math inline">\((k)_2\)</span> that is known both to the sender the receiver. Then the sender encrypt the message by <span class="math display">\[
(y)_2 = (x)_2 \oplus k
\]</span> The receiver can decrypt the message by <span class="math display">\[
(x)_2 = (y)_2 \oplus k
\]</span> Given <span class="math inline">\(x\)</span> with length <span class="math inline">\(n\)</span>, if <span class="math inline">\(k\)</span> is chosen uniformly at random from <span class="math inline">\(\{0, 1\}^n\)</span>, then <span class="math inline">\((y)_2\)</span> is a sequence uniformly at random from <span class="math inline">\(\{0, 1\}^n\)</span>. If the message is sent only one time, the eavesdropper can't get more information about <span class="math inline">\(x\)</span> after seeing <span class="math inline">\(y\)</span>.</p>
<p>Two drawbacks exists. First, how can the sender exchange the key <span class="math inline">\(k\)</span> with the receiver without meeting each other. Second, if the many messages are sent, there are frequency pattern associated with <span class="math inline">\(y\)</span>, making it breakable.</p>
<p>RSA encryption algorithm overcomes the first issue by generating two keys for the receiver: the secrete key and the public key. The public key is distributed across the internet. The sender encrypts the message <span class="math inline">\(x\)</span> with the public key. Only the receiver who has the secret key can decrypt the message. The mathematics behind is explained as follows.</p>
<p>Question to ponder: can we attack RSA by the frequency pattern?</p>
<p>First generate two prime number <span class="math inline">\(p, q\)</span> and let <span class="math inline">\(N = pq\)</span>. Further, we find a integer <span class="math inline">\(e\)</span>, such that</p>
<ol type="1">
<li><span class="math inline">\(e\)</span> is coprime to <span class="math inline">\((p - 1)(q - 1)\)</span>, i.e., <span class="math inline">\(\exists d\)</span>, such that <span class="math inline">\(ed \equiv 1 \mod (p - 1)(q - 1)\)</span>.</li>
<li><span class="math inline">\(e \neq p\)</span>, <span class="math inline">\(e \neq q\)</span>.</li>
</ol>
<p>Question to ponder: does such <span class="math inline">\(e\)</span> exists?</p>
<p>Answer: YES. There are <span class="math inline">\(O(\frac{(p - 1)(q - 1) }{ \log (p - 1)(q - 1) } - \frac{ \sqrt{ (p - 1)(q - 1) } }{ \log \sqrt { (p - 1)(q - 1) } } )\)</span> prime numbers in <span class="math inline">\((\sqrt{(p - 1)(q - 1)}, (p - 1)(q - 1))\)</span>, which can not be prime factors of <span class="math inline">\((q - 1)(p - 1)\)</span>.</p>
<p>Then we give out the pair as <em>public key</em>: <span class="math display">\[
(n, e)
\]</span></p>
<p>And keep in secrete the triple as <em>private key</em>: <span class="math display">\[
(p, q, d)
\]</span></p>
<p>The algorithm for encryption and decryption is as follows:</p>
<p>Encryption: <span class="math display">\[
y = f(x) = x^e \pmod N
\]</span></p>
<p>Decryption: <span class="math display">\[
g(y) = y^d \pmod N
\]</span></p>
<p>The key theorem states:</p>
<p><em>Theorem</em>: <span class="math display">\[
g(y) = x
\]</span></p>
<p><em>Proof 1:</em> the first proof relies on a result derived from the Chinese Reminder Theorem, which i that for any integer <span class="math inline">\(a &lt; b\)</span>, we have <span class="math display">\[
a \equiv b \mod p \vee a \equiv b \mod q
\]</span> Then, <span class="math inline">\(p | (b - a)\)</span> and <span class="math inline">\(q | (b - a)\)</span>. If follows that <span class="math inline">\(N | (b - a)\)</span>, since <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> are primes and <span class="math inline">\(N\)</span> is their least common multiple.</p>
<p>Now define <span class="math inline">\(m = x^{ed} = x^{k(p - 1)(q - 1) + 1}\)</span>. By Fermat's Little Theorem, <span class="math display">\[
m \equiv x  \mod p \wedge m \equiv x \mod q
\]</span></p>
<p>Hence <span class="math inline">\(N | (m - x)\)</span> and <span class="math inline">\(m \equiv x \mod N\)</span>.</p>
<p><em>Proof 2:</em> <span class="math display">\[
y^d = x^{ed} = x^{k(p - 1)(q - 1) + 1} \pmod N
\]</span></p>
<p>Case 1: this is the easy case in which <span class="math inline">\(x\)</span> is coprime to <span class="math inline">\(N\)</span>. Then by Fermat-Euler theorem, <span class="math inline">\(x^{\varphi(N)} = 1 \pmod N\)</span>. It follows immediately that <span class="math inline">\(x^{ed} = x \pmod N\)</span>.</p>
<p>Case 2: otherwise, <span class="math inline">\(x = lp\)</span> for some <span class="math inline">\(1 \le l \le q\)</span> or <span class="math inline">\(x = lq\)</span> for some <span class="math inline">\(1\le l \le p\)</span>. WLOG, we just consider the former case. Now <span class="math inline">\(y^d = (lp)^{k(p - 1)(q - 1) + 1} \pmod N\)</span>. On the other hand, as <span class="math inline">\((lp)^{k(p - 1)}\)</span> is relative prime to <span class="math inline">\(q\)</span>, we conclude that <span class="math inline">\(((lp)^{k(p-1)})^{q- 1} = mq + 1\)</span> for some integer <span class="math inline">\(m\)</span>, by Fermat's little theorem. Therefore, <span class="math inline">\(y^d = (mq + 1) x = (mq + 1) (lp) = mlpq + lp = lp = x \pmod N\)</span> , which finishes our proof.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/11/20/Fermat-s-Little-Theorem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/11/20/Fermat-s-Little-Theorem/" class="post-title-link" itemprop="url">Fermat's Little Theorem</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-11-20 22:55:39" itemprop="dateCreated datePublished" datetime="2018-11-20T22:55:39+11:00">2018-11-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2018-11-28 02:39:47" itemprop="dateModified" datetime="2018-11-28T02:39:47+11:00">2018-11-28</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Fermat's Little Theorem is of fundamental importance in cryptography. It states that given arbitrary prime number <span class="math inline">\(p\)</span> and any positive integer <span class="math inline">\(a \in N^+\)</span>, we have <span class="math display">\[
a^{p - 1} = 1 \quad \pmod p
\]</span> Indeed, it suffices to show the theorem holds for any number that belongs to <span class="math inline">\([p]^+ \doteq \{ 1, 2, ..., p - 1\}\)</span>. There are several proofs for this fundamental theorem.</p>
<h5 id="proof-one">Proof One</h5>
<p>Consider the function <span class="math inline">\(f : [p]^+ \rightarrow [p]^+\)</span> such that <span class="math inline">\(f(x) = ax \mod p\)</span>. Note for any <span class="math inline">\(x, x&#39; \in [p]^+\)</span>, <span class="math inline">\(ax = ax&#39; \mod p\)</span> implies that <span class="math inline">\(x = x&#39;\)</span>, since <span class="math inline">\(p\)</span> is a prime. It immediately follows that <span class="math inline">\(f\)</span> is a bijection. Therefore, the set of numbers <span class="math inline">\(\{f(1), f(2), ..., f(p - 1)\}\)</span> is exactly the same as <span class="math inline">\([p]^+\)</span> (might be in different order). Now we take product of all number in <span class="math inline">\([p]^+\)</span>, <span class="math display">\[
(p - 1)! = \prod_{i = 1}^{p - 1} (ai) = a^{p - 1} (p - 1)! \pmod p
\]</span> As <span class="math inline">\(p\)</span> is a prime, every non-zero integer has a multiplicative inverse mod <span class="math inline">\(p\)</span>. Therefore we can cancel out <span class="math inline">\((p - 1)!\)</span> from both side by multiplying its inverse and get <span class="math inline">\(1 = a^{p - 1} \pmod p\)</span>, which finishes the proof.</p>
<p>Remark: an extension of the above proof gives Fermat-Euler theorem which relaxes the condition that <span class="math inline">\(p\)</span> is prime to p being any positive integer and states for any positive integer <span class="math inline">\(a \in N^+\)</span> such that <span class="math inline">\(gcd(a, p) = 1\)</span> (i.e., <span class="math inline">\(a\)</span> and <span class="math inline">\(p\)</span> are coprime) , it holds that <span class="math display">\[
a^{\varphi(p)} = 1 \pmod p
\]</span> where <span class="math inline">\(\varphi(p)\)</span> is the number of elements that are coprime to <span class="math inline">\(p\)</span> between <span class="math inline">\(\{1, 2, .., p - 1\}\)</span>. When <span class="math inline">\(p\)</span> is prime, <span class="math inline">\(\varphi(p) = p - 1\)</span>. Clearly, Fermat-Euler is a generation of Fermat's Little Theorem. The proof is similar to the previous by observing that: let <span class="math inline">\(S \subset [p]^+\)</span> be the set of elements that are coprime to <span class="math inline">\(p\)</span>, then <span class="math inline">\(f: S \rightarrow S\)</span> given by <span class="math inline">\(f(x) = ax \pmod p\)</span> is a bijection. Therefore, <span class="math inline">\(\prod_{x \in S} x = a^{\varphi(p)} \prod_{x \in S} x \pmod p\)</span>. Cancelling out the factor <span class="math inline">\(\prod_{x \in S} x\)</span> gives the desired result.</p>
<h5 id="proof-two">Proof Two</h5>
<p>This proof uses the binomial expansion as follows: <span class="math display">\[
\begin{aligned}
(a + 1)^p 
&amp;= a^p + \binom{p}{1} a^{p - 1} + ... + \binom{p}{p - 1} a + 1  &amp;\pmod p \\
&amp;= a^{p} + 1 &amp;\pmod p \\
&amp;= (a - 1)^{p} + 1 + 1 &amp;\pmod p \\
&amp;= ... \\
&amp;= \begin{matrix} \underbrace{1 + 1 + ... + 1} \\ a + 1 \end{matrix} &amp;\pmod p  \\
&amp;= a + 1 &amp;\pmod p
\end{aligned}
\]</span> The second equality holds since for <span class="math inline">\(1 \le i \le p - 1\)</span>, the coefficient <span class="math inline">\(\binom{p}{i} = \frac{p (p - 1) ... (p - i + 1)}{i !}\)</span> divides <span class="math inline">\(p\)</span>, as <span class="math inline">\(p\)</span> is relative prime to all integers <span class="math inline">\(1, 2, ..., i\)</span>. The third equality follows from respectively applying the previous expansion. Finally, we get Fermat's Little Theorem by multiplying both sides of <span class="math inline">\((a + 1)^p = (a + 1) \pmod p\)</span> by the inverse of <span class="math inline">\(a + 1\)</span> module <span class="math inline">\(p\)</span>.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/11/08/Some-elementary-results-of-number-theory/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/11/08/Some-elementary-results-of-number-theory/" class="post-title-link" itemprop="url">Some elementary results of number theory</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-11-08 20:08:51" itemprop="dateCreated datePublished" datetime="2018-11-08T20:08:51+11:00">2018-11-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2018-11-11 02:11:57" itemprop="dateModified" datetime="2018-11-11T02:11:57+11:00">2018-11-11</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="multiplicative-inverse">Multiplicative Inverse</h4>
<p>Given positive integers <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, <span class="math inline">\(z\)</span> is called the multiplicative inverse of <span class="math inline">\(x\)</span> module <span class="math inline">\(y\)</span> if <span class="math inline">\(xz \equiv 1 \mod y\)</span>.</p>
<p><strong>Theorem</strong>.<br />
<span class="math inline">\(x\)</span> has a multiplicative inverse module <span class="math inline">\(y\)</span> iff <span class="math inline">\(gcd(x, y) = 1\)</span>.<br />
<em>Proof.</em><br />
Consider the set <span class="math inline">\(S = \{ ax + by \mid a, b \in Z\}\)</span>. Let <span class="math inline">\(s^* = a^* x + b^* y\)</span> be the smallest positive integer in <span class="math inline">\(S\)</span>. Our proof relies on the following lemma.</p>
<p><em>Lemma</em>: <span class="math inline">\(gcd(x,y) = s^*\)</span>.<br />
First notice that every element is <span class="math inline">\(S\)</span> is a linear combination of both <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, therefore a multiple of <span class="math inline">\(gcd(x, y)\)</span>. We have <span class="math inline">\(gcd(x, y) | s^*\)</span> and <span class="math inline">\(gcd(x, y) \le s^*\)</span>. Now we claim that <span class="math inline">\(s^* | x\)</span> and <span class="math inline">\(s^* | y\)</span>.</p>
<p>To verify the above claim, suppose <span class="math inline">\(s^* \nmid x\)</span>. Then <span class="math inline">\(x\)</span> can be decomposed into <span class="math inline">\(x = k s^* + l\)</span> for some positive integers <span class="math inline">\(k\)</span> and <span class="math inline">\(l \in [1, s^*)\)</span>. It follows that <span class="math inline">\(l = x - k s^* = (1 - a^*) x + (-b^*) y \in S\)</span>, contradicting <span class="math inline">\(s^*\)</span> being the smallest positive element in <span class="math inline">\(S\)</span>. Similarly argument holds for <span class="math inline">\(s^* | y\)</span>.</p>
<p>Therefore, <span class="math inline">\(s^*\)</span> is a common divisor of both <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> and <span class="math inline">\(s^* \le gcd(x, y)\)</span>.</p>
<p>It concludes that <span class="math inline">\(s^*\)</span> equals to <span class="math inline">\(gcd(x, y)\)</span>.</p>
<p>The proof of the above theorem immediately follows from the lemma.</p>
<ol type="1">
<li><p><span class="math inline">\(gcd(x, y) = 1 \rightarrow x\)</span> has a multiplicative inverse.<br />
In this case, <span class="math inline">\(s^* = a^* x + b^* y = 1\)</span>. <span class="math inline">\(a^*\)</span> is th multiplicative inverse of <span class="math inline">\(x\)</span> module <span class="math inline">\(y\)</span>.</p></li>
<li><p><span class="math inline">\(x\)</span> has a multiplicative inverse <span class="math inline">\(\rightarrow gcd(x, y) = 1\)</span>.<br />
If <span class="math inline">\(x\)</span> has a multiplicative inverse, there exists some <span class="math inline">\(z\)</span> and <span class="math inline">\(l\)</span>, such that <span class="math inline">\(zx = ly + 1\)</span>.</p></li>
</ol>
<p><strong>Theorem</strong>.<br />
If <span class="math inline">\(x\)</span> has a multiplicative inverse module <span class="math inline">\(y\)</span>, it must be unique (module <span class="math inline">\(y\)</span>).<br />
<em>Proof.</em><br />
Let <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> both be the multiplicative inverse of <span class="math inline">\(x\)</span> module <span class="math inline">\(y\)</span>, i.e., <span class="math inline">\(a x \equiv 1 \mod y\)</span> and <span class="math inline">\(bx \equiv 1 \mod y\)</span>. It turns out that <span class="math inline">\(a \equiv a \cdot 1 \equiv a (xb) \equiv (ax) b \equiv b \mod y\)</span>.</p>
<h4 id="euclids-algorithm">Euclid's Algorithm</h4>
<p>Euclid's algorithm computes <span class="math inline">\(gcd(x, y)\)</span> as follows:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int gcd(int x, int y) &#123;</span><br><span class="line">    if(y &#x3D;&#x3D; 0) return x;</span><br><span class="line">    return gcd(y, x mod y);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> When <span class="math inline">\(y == 0\)</span>, clearly <span class="math inline">\(gcd(x, y) = x\)</span>. If <span class="math inline">\(x &lt; y\)</span>, <span class="math inline">\(x mod y = x\)</span>. The algorithm exchanges the value of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> after the first recursion. It suffices to consider only the case where <span class="math inline">\(x \ge y &gt; 0\)</span>.</p>
<p><em>Lemma</em>: if <span class="math inline">\(x \ge y &gt; 0\)</span>, then <span class="math inline">\(gcd(x, y) = gcd(y, x \mod y)\)</span>.<br />
We show that any common divisor <span class="math inline">\(d\)</span> of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> is a common divisor of <span class="math inline">\(y\)</span> and <span class="math inline">\(x \mod y\)</span>. Suppose <span class="math inline">\(x = k d\)</span> and <span class="math inline">\(y = l d\)</span>, then <span class="math inline">\(x - y = (k - l) d\)</span>. It follows from induction <span class="math inline">\(d\)</span> divides <span class="math inline">\(x \mod y\)</span>, since <span class="math inline">\(x \mod y = x - y - ... - y\)</span>. The other direction follows in a similar manner.</p>
<p>We can modify the Euclid's algorithm to return explicitly values of <span class="math inline">\(a^*, b^*\)</span> s.t. <span class="math inline">\(gcd(x, y) = s^* = a^* x + b^* y\)</span>.</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[] gcd(int x, int y) &#123;</span><br><span class="line">    if(y &#x3D;&#x3D; 0) return (x, 1, 0);</span><br><span class="line">    (s, a&#39;, b&#39;) &#x3D; gcd(y, x mod y);</span><br><span class="line">    return (s, b&#39;, a&#39; - b&#39;(x &#x2F; y));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> To verify the correctness of the algorithm, suppose <span class="math inline">\(s = a&#39; y + b&#39; (x \mod y)\)</span>. Then <span class="math inline">\(s = a&#39; y + b&#39;(x - \lfloor x / y \rfloor y) =b&#39; x + (a&#39; - b&#39; \lfloor x / y \rfloor) y\)</span>. This is why the algorithm work.</p>
<p><em>Example:</em><br />
<span class="math display">\[
\begin{aligned}
&amp; gcd(9, 6) = (3, 1, -1)  \quad [-1 = 0 - 1 * 9 / 6] \\
&amp; \rightarrow gcd(6, 3) = (3, 0, 1) \quad [1 = 1 - 0 * 6 / 3]\\
&amp; \quad \rightarrow gcd(3, 0) = (3, 1, 0) \\
\end{aligned}
\]</span></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/10/26/Bellman-Ford/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/10/26/Bellman-Ford/" class="post-title-link" itemprop="url">Bellman Ford</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-10-26 22:13:41" itemprop="dateCreated datePublished" datetime="2018-10-26T22:13:41+11:00">2018-10-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2018-10-27 02:06:16" itemprop="dateModified" datetime="2018-10-27T02:06:16+11:00">2018-10-27</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Here we discuss the Bellman Ford algorithm for computing shortest path or negative cycle in an undirected weighted graph <span class="math inline">\(G = (V, E, W)\)</span> that contains negative edges.</p>
<p>Recall the Dijkstra algorithm bases on the induction of the number of vertices. The Bellman Ford algorithm, on the other hand, bases on the induction of the number of edges of the shortest path.</p>
<p>Let <span class="math inline">\(P_k = (s, v_1, v_2, .., v_k, t)\)</span> be the shortest path between <span class="math inline">\(s\)</span> and <span class="math inline">\(t\)</span>. If we finds the shortest <span class="math inline">\(P_{k - 1} = (s, v_1, v_2, ..., v_{k - 1})\)</span>, then we can easily find the path <span class="math inline">\(P_k\)</span>. To this end, we define dist[v] the distance from source node <span class="math inline">\(s\)</span> to vertex <span class="math inline">\(v\)</span>.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">std::vector&lt;int&gt; dist(n, INT_MAX); </span><br><span class="line">std::vector&lt;int&gt; pred(n, 0);</span><br><span class="line">dist[s] &#x3D; 0;</span><br><span class="line">for(int i &#x3D; 0; i &lt; n - 1; ++i) &#123;</span><br><span class="line">    for each edge (u, v) &#123;</span><br><span class="line">        if(dist[u] + w(u, v) &lt; dist[v]) &#123;</span><br><span class="line">            dist[v] &#x3D; dist[u] + w(u, v);</span><br><span class="line">            pred[v] &#x3D; u;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>If the graph does not contain a negative cycle, the above code compute the shortest path correctly. On the other hand, to check the existence of a negative, we could execute an additional iteration after the above code</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">bool check_negative_cycle() &#123;</span><br><span class="line">     for each edge (u, v) &#123;</span><br><span class="line">        if(dist[u] + w(u, v) &lt; dist[v]) &#123;</span><br><span class="line">            dist[v] &#x3D; dist[u] + w(u, v);</span><br><span class="line">            pred[v] &#x3D; u;</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;    </span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>The correctness can be verified as follows: if the graph does not contain negative cycle, the any shortest path contains at most <span class="math inline">\((n - 1)\)</span>-th edges. The value of <span class="math inline">\(dist[v]\)</span> should not change in this <span class="math inline">\(n\)</span>-th iteration.</p>
<p>To return a negative cycle, when we find an edge <span class="math inline">\((u, v)\)</span> such that <span class="math inline">\(dist[u] + w(u, v) &lt; dist[v]\)</span> (in this <span class="math inline">\(n\)</span>-th iteration), we can trace the predecessor of <span class="math inline">\(v\)</span> until we encounter a cycle. Notice that this cycle may not necessarily contains <span class="math inline">\(v\)</span>. But we claim that this cycle must be negative.</p>
<h4 id="theorem">Theorem</h4>
<p>Let <span class="math inline">\(C = (v_1, v_2, ..., v_j)\)</span> be the cycle we found, such that <span class="math inline">\(pred[v_i] = pred[v_{i - 1}], \forall 2 \le i \le j\)</span> and <span class="math inline">\(pred[v_1] = v_j\)</span>. WLOG, let <span class="math inline">\(v_1\)</span> be the vertex whose value <span class="math inline">\(pred[v_1]\)</span> is updated latest among <span class="math inline">\(pred[v_1], pred[v_2], ..., pred[v_j]\)</span>. It holds that</p>
<p><span class="math display">\[
\begin{aligned}
dist[v_2] &gt; dist[v_1] + w(v_1, v_2) \\
\text{this holds with strict inequality since we update } pred[v_1] \text{ lastly }\\
dist[v_3] \ge dist[v_2] + w(v_1, v_2) \\
... \\
dist[v_1] = dist[v_j] + w(v_1, v_2) \\
\end{aligned}
\]</span></p>
<p>It follows that <span class="math inline">\(\sum_{i = 1}^j dist[v_i] &gt; \sum_{i = 1}^j dist[v_i] dist[v_i] + \sum_{i = 2}^j w(v_{i - 1}, v_i) + w(v_j, v_1)\)</span>, which implies that <span class="math inline">\(\sum_{i = 2}^j w(v_{i - 1}, v_i) + w(v_j, v_1) &lt; 0\)</span>.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/10/18/Fully-Binary-Tree/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/10/18/Fully-Binary-Tree/" class="post-title-link" itemprop="url">Fully Binary Tree</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-10-18 23:23:51" itemprop="dateCreated datePublished" datetime="2018-10-18T23:23:51+11:00">2018-10-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2018-10-19 02:30:30" itemprop="dateModified" datetime="2018-10-19T02:30:30+11:00">2018-10-19</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>A binary tree is called a fully binary tree if each non-leaf node has two children. Suppose there are <span class="math inline">\(n\)</span> leaf nodes. Then the number of non-leaf nodes is <span class="math inline">\(n - 1\)</span>. To see this, we remove a pair of leaves that shares the same parent repeatedly until there are 3 nodes left. Each time we remove such a pair of nodes, both the number of leaf nodes and the number of non-leaf nodes decreases by one. Therefore the difference between the number of leaf and non-leaf node remains. By induction we see that the difference is exactly one.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/09/16/Max-Cut/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/09/16/Max-Cut/" class="post-title-link" itemprop="url">Max Cut</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2018-09-16 17:10:22 / Modified: 23:01:31" itemprop="dateCreated datePublished" datetime="2018-09-16T17:10:22+10:00">2018-09-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Given an undirected graph <span class="math inline">\(G = (V, E)\)</span>, the maximum cut problem asks for a subset <span class="math inline">\(S \subset V\)</span> that maximizes the number of edges which cross <span class="math inline">\(S\)</span>, i.e., <span class="math inline">\(S = \arg \max_{S&#39; \subset S} \delta(S)\)</span>, where <span class="math inline">\(\delta(S) = |\{ \ (i, j) \ \mid \ (i, j) \in E \wedge i \in S, j \notin S\}|\)</span>.</p>
<h5 id="programming-formulation">Programming Formulation</h5>
<p>To solve the problem, we can assign each vertex <span class="math inline">\(i \in V\)</span> a binary variable <span class="math inline">\(x_i \in \{-1, 1\}\)</span>, which serves as an indicator of whether <span class="math inline">\(i\)</span> belongs to <span class="math inline">\(S\)</span>. WLOG, we can specify here that <span class="math inline">\(i \in S\)</span> if <span class="math inline">\(x_i = 1\)</span>. Now the value of <span class="math inline">\(\delta(S)\)</span> can be expressed as</p>
<p><span class="math display">\[
\delta(S) = \sum_{(i,j) \in E} \frac{1 - x_i x_j}{2}
\]</span></p>
<p>The correctness of the expression can be verified as follows: (1) if <span class="math inline">\(i, j \in V\)</span> belongs to the same partition, i.e, <span class="math inline">\(i, j \in S\)</span> or <span class="math inline">\(i, j \in V - S\)</span>, then <span class="math inline">\(x_i x_j = 1\)</span> and <span class="math inline">\(\frac{1 - x_i x_j}{2} = 0\)</span>. (2) Otherwise, <span class="math inline">\(x_i x_j = -1\)</span> and <span class="math inline">\(\frac{1 - x_i x_j}{2} = 1\)</span>.</p>
<h5 id="convex-relaxation">Convex Relaxation</h5>
<p>We consider a relaxation of the above programming: <span class="math display">\[
\begin{aligned}
&amp;&amp;\max &amp;&amp;\sum_{(i,j) \in E} \frac{1 - x_i^T x_j}{2} \\
&amp;&amp;s.t., &amp;&amp; x_i^T x_i = 1 &amp;&amp;\forall i \in V \\
&amp;&amp;      &amp;&amp; x_i \in R^n   &amp;&amp;\forall i \in V
\end{aligned}
\]</span></p>
<p>Note that this can be transformed into a convex optimization: <span class="math display">\[
\begin{aligned}
&amp;&amp;\max &amp;&amp;\sum_{(i,j) \in E} \frac{1 - y_{i,j}}{2} &amp;&amp;\\
&amp;&amp;s.t., &amp;&amp; y_{i,i} = 1 &amp;&amp;\forall i \in V \\
&amp;&amp;      &amp;&amp; y_{i,j} = y_{j,i} &amp;&amp;\forall i, j \in V \\
&amp;&amp;      &amp;&amp; Y = (y_{i,j}) \succcurlyeq 0
\end{aligned}
\]</span></p>
<p>The above problem can be solved within <span class="math inline">\(\epsilon\)</span> additive error in polynomial time in terms of input size and <span class="math inline">\(\log 1/\epsilon\)</span>.</p>
<h5 id="rounding">Rounding</h5>
<p>To round the fractional solution to integral solution, we take a random unit vector <span class="math inline">\(v\)</span> from <span class="math inline">\(R^n\)</span>. For each vertex <span class="math inline">\(i\)</span>, if <span class="math inline">\(v^T x_i \ge 0\)</span> we set <span class="math inline">\(x_i&#39; = 1\)</span> otherwise we set <span class="math inline">\(x_i&#39; = 0\)</span>. For any pair <span class="math inline">\(i, j \in V\)</span>, denote the angle between <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_j\)</span> as <span class="math inline">\(\theta_{i,j} = \arccos x_i^T x_j\)</span>. Notice that <span class="math inline">\(\sum_{(i,j) \in E} \frac{1 - x_i x_j}{2} = \sum_{(i,j) \in E} \frac{1 - \cos \theta_{i,j}}{2}\)</span>. Furthermore, the probability that <span class="math inline">\(x_i&#39;\)</span> and <span class="math inline">\(x_j&#39;\)</span> are assigned different values is given by <span class="math inline">\(\theta_{i,j} / \pi\)</span>. By linearity of expectation, the expected cut value is</p>
<p><span class="math display">\[
E[\sum_{(i,j) \in E} \frac{1 - x_i&#39; x_j&#39;}{2}] = \sum_{(i,j) \in E} \frac{\theta_{i,j}}{\pi}
\]</span></p>
<p>As <span class="math inline">\(\max_{0 \le \theta \le \pi} \frac{\pi}{\theta}\frac{1 - \cos \theta}{2} \approx 1.138\)</span>, <span class="math inline">\(E[\sum_{(i,j) \in E} \frac{1 - x_i&#39; x_j&#39;}{2}]\)</span> is greater approximately <span class="math inline">\(1/1.138 = 0.878\)</span> <span class="math inline">\(\sum_{(i,j) \in E} \frac{1 - x_i x_j}{2}\)</span>.</p>
<!-- 
<p align="center">
  <img https://imglf6.nosdn0.126.net/img/Y1FUYmVJRmJqaTNNVk15SFhyTUZHalJjMStjRE4wYXV4aEtMazNHMHJieFdDdDM4L29PcTl3PT0.png?imageView&thumbnail=500x0&quality=96&stripmeta=0%7Cwatermark&type=2&text=wqkgbHdwaGlsZSAvIGx3cGhpbGUubG9mdGVyLmNvbQ==&font=bXN5aA==&gravity=southwest&dissolve=30&fontsize=240&dx=8&dy=10&stripmeta=0>
</p> -->
<figure>
<img src="http://imglf6.nosdn0.126.net/img/Y1FUYmVJRmJqaTNNVk15SFhyTUZHalJjMStjRE4wYXV4aEtMazNHMHJieFdDdDM4L29PcTl3PT0.png?imageView&amp;thumbnail=500x0&amp;quality=96&amp;stripmeta=0%7Cwatermark&amp;type=2&amp;text=wqkgbHdwaGlsZSAvIGx3cGhpbGUubG9mdGVyLmNvbQ==&amp;font=bXN5aA==&amp;gravity=southwest&amp;dissolve=30&amp;fontsize=240&amp;dx=8&amp;dy=10&amp;stripmeta=0" alt="" /><figcaption><span class="math inline">\(\max_{0 \le \theta \le \pi} \frac{\pi}{\theta}\frac{1 - \cos \theta}{2} \approx 1.138\)</span></figcaption>
</figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/09/14/Facility-Location-Problem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/09/14/Facility-Location-Problem/" class="post-title-link" itemprop="url">Facility Location Problem</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-09-14 10:58:58" itemprop="dateCreated datePublished" datetime="2018-09-14T10:58:58+10:00">2018-09-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-13 16:58:50" itemprop="dateModified" datetime="2020-05-13T16:58:50+10:00">2020-05-13</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong><em>Update on May/7th/2020.</em></strong></p>
<p>Suppose we have a set of facilities <span class="math inline">\(F\)</span> and a set of clients <span class="math inline">\(C\)</span>. We would like to open some facilities from $F $ to serve the clients. The cost consists of two parts: 1) the one for opening the selected facilities; 2) the one for connecting each client to its closest facility.</p>
<p>Formally, denote <span class="math inline">\(f_i\)</span> the cost of facility <span class="math inline">\(i \in F\)</span> and <span class="math inline">\(c_{i,j}\)</span> the distance from a client <span class="math inline">\(j \in C\)</span> to a facility <span class="math inline">\(i \in F\)</span>. Let <span class="math inline">\(S \subset F\)</span> be a subset of facilities, and let <span class="math inline">\(\mu : C \rightarrow S\)</span> be the corresponding function that assigns each client <span class="math inline">\(j \in C\)</span> to a facility in <span class="math inline">\(S\)</span>, i.e., <span class="math display">\[
\mu(j) \doteq \arg\min_{i \in S} c_{i,j}
\]</span></p>
<p>The cost of <span class="math inline">\(S\)</span> is given by <span class="math display">\[
\sum_{i \in S} f_i + \sum_{j \in C} c_{\mu(j), j}
\]</span></p>
<p>The problem is to find a set <span class="math inline">\(S\)</span> that minimizes this cost.</p>
<h2 id="lp-formulation"><strong><em>LP Formulation</em></strong></h2>
<p>It can be formulated as linear program and then relaxed as as a linear one:</p>
<p><span class="math display">\[
\begin{array}{lrllr}
\text{Primal:}
    &amp;&amp;\min  &amp; \sum_{i \in F, j \in C} c_{i, j} x_{i, j} + \sum_{i \in F} f_i y_i &amp; &amp;  \\
    &amp;&amp;s.t., &amp; \sum_{i \in F} x_{i j} \ge 1  &amp; \forall j \in C  &amp; (1) \\
    &amp;&amp;      &amp; y_i - x_{i,j} \ge 0           &amp; \forall i \in F, j \in C &amp; (2)
\end{array}
\]</span></p>
<p>The first constraint says that each client is assigned to at least one facility. The second one can be interpreted as that a facility must be open if there is a client assigned to it.</p>
<p>To obtain the dual, let <span class="math inline">\(\alpha_j\)</span> be the dual variable associated with constraint (1) and <span class="math inline">\(\beta_{i,j}\)</span> be the one with constraint (2). We need to ensure that weak duality holds.</p>
<h3 id="weak-duality"><em>Weak Duality</em></h3>
<p><span class="math display">\[
\begin{array}{rl}
    \sum_{j \in C} \alpha_j 
        &amp;= \sum_{j \in C} \alpha_j \cdot 1 + \sum_{i \in F, j \in C} \beta_{i,j} \cdot 0 \\
        &amp;\le \sum_{j \in C} \alpha_j \cdot (\sum_{i \in F} x_{i,j} ) + \sum_{i \in F, j \in C} \beta_{i,j} \cdot (y_i - x_{i,j}) \\
        &amp;= \sum_{i \in F, j \in C} (\alpha_j - \beta_{i,j}) \cdot x_{i,j}  + \sum_{i \in F} \left( \left( \sum_{j \in C} \beta_{i,j} \right) \cdot y_i \right) \\
        &amp;\le \sum_{i \in F, j \in C} c_{i, j} x_{i, j} + \sum_{i \in F} f_i y_i
\end{array}
\]</span> The dual can be formulated such that the above inequalities hold.</p>
<h3 id="dual-program"><em>Dual Program</em></h3>
<p><span class="math display">\[
\begin{array}{lllr}    
    \text{Dual:} \qquad
    &amp;\max &amp; \sum_{j \in C} \alpha_j \\
    &amp;s.t.,&amp; \alpha_j - \beta_{i,j} \le c_{i,j} &amp; \forall i \in F, \forall j \in C\\
    &amp;     &amp; \sum_{j \in C} \beta_{i,j} \le f_i  &amp; \forall i \in F\\
\end{array}
\]</span></p>
<p>Here we give a more intuitive way of deriving the dual. First, we notice that <span class="math inline">\(\sum_{j \in C} \min_{i \in F} c_{i,j}\)</span> is a trivial lower bound of the primal programming. In this case, each client is assigned to its nearest facility. However we ignore facility cost entirely.</p>
<p>To incorporate the facility cost, for each facility <span class="math inline">\(i\)</span> we divide its cost <span class="math inline">\(f_i\)</span> among the clients, such that client <span class="math inline">\(j\)</span> needs to pay <span class="math inline">\(\beta_{i, j}\)</span> if it is assigned facility <span class="math inline">\(i\)</span>. Note that <span class="math inline">\(\beta_{i, j}\)</span> can be arbitrary non-negative number as long as it satisfies that <span class="math inline">\(\sum_{j \in C} \beta_{i,j} = f_i\)</span> for all <span class="math inline">\(i \in F\)</span>.</p>
<p><strong><em>Theorem.</em></strong> For any solution <span class="math inline">\(S\)</span> and <span class="math inline">\(\mu\)</span>, it holds that <span class="math display">\[
\begin{aligned}
    \sum_{j \in C} (c_{\mu(j), j} + \beta_{\mu(j), j} ) 
        &amp;\le \sum_{i \in S} f_i + \sum_{j \in C} c_{\mu(j) , j}
\end{aligned}
\]</span></p>
<p><em>Proof.</em> <span class="math display">\[
\begin{aligned}
    \sum_{j \in C} (c_{\mu(j), j} + \beta_{\mu(j), j} ) 
        &amp;=  \sum_{i \in F} \sum_{j \in \mu^{-1}(i) } ( \beta_{ i, j} ) + \sum_{j \in C} c_{\mu(j) , j} \\ 
        &amp;\le  \sum_{i \in F} \sum_{j \in C } ( \beta_{ i, j} ) + \sum_{j \in C} c_{\mu(j) , j} \\ 
        &amp;= \sum_{i \in S} f_i + \sum_{j \in C} c_{\mu(j) , j}
\end{aligned}
\]</span> <span class="math inline">\(\blacksquare\)</span></p>
<p>If we define <span class="math display">\[
\alpha_j = \min_{i \in F} (c_{i,j} + \beta_{i, j})
\]</span></p>
<p>Then <span class="math inline">\(\sum_{j \in F} \alpha_j\)</span> constitutes a lower bound for the cost of any solution. In particular, it is a lower bound of the cost of the optimal integral solution <span class="math inline">\(F^*\)</span> (its corresponding assignment function is denoted as <span class="math inline">\(\mu^*\)</span>):</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \sum_{j \in C} \alpha_j 
    \le \sum_{i \in F^*} f_i + \sum_{j \in C} c_{\mu^* (j), j} \\
\end{aligned}
\]</span></p>
<p>The idea of determining a set of <span class="math inline">\(\beta_{i,j}\)</span>'s that maximizes the lower bound <span class="math inline">\(\sum_{j \in C} \alpha_j\)</span> gives the dual program.</p>
<h3 id="complementary-slackness"><em>Complementary Slackness</em></h3>
<p>Let <span class="math inline">\(x^*, y^*\)</span> and <span class="math inline">\(\alpha^*, \beta^*\)</span> be the optimal primal and dual solution respectively. For these set of variables, weak duality holds with equalities. By complementary slackness, it holds that</p>
<ol type="1">
<li><span class="math inline">\(\alpha^*_j = 0\)</span> or <span class="math inline">\(\sum_{i \in F} x^*_{i,j} = 1\)</span></li>
<li><span class="math inline">\(\beta^*_{i,j} = 0\)</span> or <span class="math inline">\(y^*_i - x^*_{i,j} = 0\)</span></li>
</ol>
<p>and</p>
<ol start="3" type="1">
<li><span class="math inline">\(\alpha^*_j - \beta^*_{i,j} = c_{i,j}\)</span> or <span class="math inline">\(x^*_{i,j} = 0\)</span></li>
<li><span class="math inline">\(\sum_{j \in C} \beta^*_{i,j} = f_i\)</span> or <span class="math inline">\(y^*_i = 0\)</span></li>
</ol>
<h2 id="lp-rounding"><strong><em>LP Rounding</em></strong></h2>
<p>We show how to construct a integral solution <span class="math inline">\(x\)</span> from the optimal solution <span class="math inline">\(x^*, y^*\)</span>, <span class="math inline">\(\alpha^*\)</span> and <span class="math inline">\(\beta^*\)</span> to the primal and dual LP. First we construct a derived graph <span class="math inline">\(G = (V, E)\)</span> from primal LP.</p>
<p><strong><em>Definition.</em></strong> A derived graph from the optimal LP consists of the follows:</p>
<ol type="1">
<li>The vertex set <span class="math inline">\(V = F \cup C\)</span>;</li>
<li>The edge set <span class="math inline">\(E = \{ (i, j) : x^*_{i,j} &gt; 0, \forall i \in F, j \in C\}\)</span>. That is, the edge set <span class="math inline">\(E\)</span> contains all facility-client pairs <span class="math inline">\((i, j)\)</span> such that <span class="math inline">\(x^*_{i,j} &gt; 0\)</span>.</li>
</ol>
<p>In the graph <span class="math inline">\(G\)</span>, the neighbors a client <span class="math inline">\(j\)</span> can only be facilities.</p>
<p><strong><em>Definition.</em></strong> <em>For a client <span class="math inline">\(j \in C\)</span>, denote <span class="math inline">\(N(j)\)</span> the set of facilities that are adjacent to <span class="math inline">\(j\)</span> in <span class="math inline">\(G\)</span>.</em></p>
<p>Similarly, we define two hop neighbor of a client <span class="math inline">\(j\)</span>, as the client who connects to <span class="math inline">\(j\)</span> via a intermediate facility.</p>
<p><strong><em>Definition.</em></strong> *For a client <span class="math inline">\(j \in C\)</span>, its two hop neighbors are the set of client whose distance to <span class="math inline">\(j\)</span> is 2 in <span class="math inline">\(G\)</span>: <span class="math display">\[
N^2(j) =\{ j&#39; \in C: \exists i \in F, s.t., x^*_{i,j&#39;} &gt;0 \wedge   x^*_{i,j} &gt; 0 \}
\]</span></p>
<p>Below is an example. The cycles represent clients and the squares are for facilities. Associated each client and each facility are the <span class="math inline">\(\alpha_j^*\)</span> value and opening cost respectively.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm1.1.png" /></p>
<p>An important property of this graph is that</p>
<blockquote>
<p>If <span class="math inline">\((i,j) \in E\)</span>, then <span class="math inline">\(x^*_{i,j} &gt;0\)</span>, which implies that <span class="math inline">\(\alpha^*_j =c_{i,j} + \beta^*_{i,j}\)</span> by complementary slackness. It concludes that <span class="math inline">\(\alpha^*_j \ge c_{i,j}\)</span> if there is an edge <span class="math inline">\((i,j)\)</span> in <span class="math inline">\(G\)</span>.</p>
</blockquote>
<h3 id="deterministic-rounding-1"><strong><em>Deterministic Rounding [1]</em></strong></h3>
<p>As a warm up, we introduce the first constant factor approximation algorithm for the un-capacitated facility location problem, proposed in 1997 [1]. It is a deterministic rounding algorithm.</p>
<blockquote>
<p>Algorithm 1:<br />
1. <span class="math inline">\(S \leftarrow \emptyset\)</span>.<br />
2. <span class="math inline">\(D \leftarrow \emptyset\)</span>.<br />
2. While there exists some client not assigned to any facility<br />
3. <span class="math inline">\(\quad\)</span> Let <span class="math inline">\(j\)</span> be the unassigned one with smallest <span class="math inline">\(\alpha^*_j\)</span>, add it to <span class="math inline">\(D\)</span>.<br />
5. <span class="math inline">\(\quad\)</span> Open the cheapest facility <span class="math inline">\(i\)</span> in <span class="math inline">\(N(j)\)</span>, add it to <span class="math inline">\(S\)</span>.<br />
6. <span class="math inline">\(\quad\)</span> Assign <span class="math inline">\(j\)</span> to <span class="math inline">\(i\)</span>: <span class="math inline">\(\mu(j) \leftarrow i\)</span><br />
6. <span class="math inline">\(\quad\)</span> For each un-assigned client <span class="math inline">\(j&#39; \in N^2(j)\)</span> do<br />
8. <span class="math inline">\(\quad\)</span> <span class="math inline">\(\quad\)</span> <span class="math inline">\(\quad\)</span> Assign <span class="math inline">\(j&#39;\)</span> to <span class="math inline">\(i\)</span>: <span class="math inline">\(\mu(j&#39;) \leftarrow i\)</span></p>
</blockquote>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm1.2.png" /></p>
<p>The example above shows one iteration of the algorithm. The vertex with minimum value of <span class="math inline">\(\alpha^*_j\)</span> (i.e. 1) is opened, highlighted by the red cycle. There are two facilities connected to it, the cheap opening cost of which is 1. Then all un-assigned clients neighboring these two facilities are assigned to the cost 1 facility, as shown by the purple dashed arrows.</p>
<p>Intuitively, each iteration of the algorithm creates a clusters, which contains three kinds of vertices:</p>
<ol type="1">
<li>The selected un-assigned client <span class="math inline">\(j\)</span> with minimum <span class="math inline">\(\alpha^*_j\)</span>.</li>
<li>All <span class="math inline">\(j\)</span>'s neighboring facilities.<br />
</li>
<li>All un-assigned clients neighboring to these facilities.</li>
</ol>
<p>It is left to analyze the cost of the solution returned.</p>
<h4 id="facility-cost">Facility Cost</h4>
<p>At each iteration, a client <span class="math inline">\(j\)</span> is selected. In the primal LP, constraint (1) requires that <span class="math display">\[
\sum_{i \in F} x^*_{i,j} \ge 1
\]</span></p>
<p>Note that although <span class="math inline">\(j\)</span> can assigned to a client fractionally, the total amount of assignment must be at least 1. Further, although a facility can be fractionally open in primal LP, the constraint (2) <span class="math display">\[
y^*_i \ge x^*_{i, j}
\]</span> implies that the open amount must be at least the amount a client assign to it. By the selection of <span class="math inline">\(\mu(j)\)</span>, we conclude that <span class="math display">\[
\begin{array}{llr}
    f( \mu_S(j) ) 
        &amp;\le f( \mu(j) ) \cdot \sum_{i \in N(j)} x^*_{i, j} \\
        &amp;\le \sum_{i \in N(j)} x^*_{i, j} f_i \\
        &amp;\le \sum_{i&#39; \in N(j)} y^*_{i} f_{i}
\end{array}
\]</span></p>
<p>The neighbor sets <span class="math inline">\(N(j)\)</span>'s of the selected clients <span class="math inline">\(j \in D\)</span> are dis-joint.</p>
<p>Therefore, summing over <span class="math inline">\(j \in D\)</span>, the total facility cost is bounded by</p>
<p><span class="math display">\[
\sum_{j \in D} \sum_{i \in N(j)} y^*_{i} f_{i} \le \sum_{i \in F} y^*_i f_i \le OPT
\]</span></p>
<h4 id="connection-cost">Connection Cost</h4>
<p>Now we analyze the assignment cost. When a client <span class="math inline">\(j\)</span> with smallest <span class="math inline">\(\alpha^*_j\)</span> is selected and assigned to the cheapest facility <span class="math inline">\(i\)</span> in <span class="math inline">\(N(j)\)</span>. Unassigned clients <span class="math inline">\(j&#39; \in N^2(j)\)</span> are also assigned to <span class="math inline">\(i\)</span>. There are two possible cases:</p>
<ol type="1">
<li><p>There is an edge <span class="math inline">\((i, j&#39;)\)</span> in <span class="math inline">\(G\)</span>, i.e., <span class="math inline">\(j&#39; \in N(i)\)</span>. Then the assign cost is <span class="math inline">\(c_{i, j&#39;} \le \beta^*_{j&#39;}\)</span>.</p></li>
<li><p>There is no edge between <span class="math inline">\(i\)</span> and <span class="math inline">\(j&#39;\)</span> in <span class="math inline">\(G\)</span>. In this case, there exists some other facility <span class="math inline">\(i&#39; \in N(j)\)</span>, such that <span class="math inline">\((i&#39;,j&#39;) \in E\)</span>. By triangle inequality, we have <span class="math display">\[
 c_{i , j&#39;} \le c_{i, j} + c_{i&#39;, j} + c_{i&#39;, j&#39;} \le \alpha^*_{j} + \alpha^*_j + \alpha^*_{j&#39;} \le 3\alpha^*_{j&#39;}
 \]</span></p>
<p>The last inequality holds since <span class="math inline">\(\alpha^*_{j&#39;} \le \alpha^*_j\)</span>.</p></li>
</ol>
<p>Combing assignment cost and facility cost, algorithm 1 is 4-approximation.</p>
<p>How happy are we with the 4-approximation algorithm? Probably not. In the previous example, when a facility is opened, only one client contributes to its opening cost. However, in the primal solution, many other clients assigned to it do not contribute to the opening cost, which implies that the current analysis may not be tight.</p>
<h3 id="randomized-rounding-3"><strong><em>Randomized Rounding</em></strong> [3]</h3>
<h4 id="approximation-rounding"><strong><em>3-Approximation Rounding</em></strong></h4>
<p>In the section, we improve the approximation ratio of 4 to an expected value of 3. In the previous rounding, we bound the opening cost as <span class="math display">\[
\sum_{j \in D} \min_{i \in N(j) } f_i \le OPT
\]</span></p>
<p>which is not tight. Define the assignment cost for client <span class="math inline">\(j\)</span> in the optimal primal LP solution as <span class="math inline">\(A_j = \sum_{i \in F} x^*_{i,j} c_{i,j}\)</span>. Indeed, it is affordable to bound <span class="math display">\[
\sum_{j \in D} \sum_{i \in N(j) } x^*_{i,j} f_i +  \sum_{j \in C} A_j \le OPT
\]</span></p>
<p>It is possible to devise a randomized rounding algorithm that incorporates this cost and improve the approximation ratio to 3. The only differences compared to the first rounding algorithm are</p>
<ol type="1">
<li>We pick a client that minimize <span class="math inline">\(\alpha^*_j + A_j\)</span>;</li>
<li>We pick a facility with probability <span class="math inline">\(x^*_{i,j}\)</span>.</li>
</ol>
<p>Below is the algorithm.</p>
<blockquote>
<p>Algorithm 2:<br />
1. <span class="math inline">\(S \leftarrow \emptyset\)</span>.<br />
2. <span class="math inline">\(D \leftarrow \emptyset\)</span>.<br />
2. While there exists un-assigned client<br />
3. <span class="math inline">\(\quad\)</span> Let <span class="math inline">\(j\)</span> be the unassigned one with smallest <span class="math inline">\(\alpha^*_j + A_j\)</span>, add <span class="math inline">\(j\)</span> to <span class="math inline">\(D\)</span>.<br />
5. <span class="math inline">\(\quad\)</span> Sample a facility <span class="math inline">\(i\)</span> in <span class="math inline">\(N(j)\)</span> with probability <span class="math inline">\(x^*_{i,j}\)</span>, add it to <span class="math inline">\(S\)</span>.<br />
6. <span class="math inline">\(\quad\)</span> Assign <span class="math inline">\(j\)</span> to <span class="math inline">\(i\)</span>: <span class="math inline">\(\mu(j) \leftarrow i\)</span><br />
6. <span class="math inline">\(\quad\)</span> For each un-assigned client <span class="math inline">\(j&#39; \in N^2(j)\)</span> do<br />
8. <span class="math inline">\(\quad\)</span> <span class="math inline">\(\quad\)</span> <span class="math inline">\(\quad\)</span> Assign <span class="math inline">\(j&#39;\)</span> to <span class="math inline">\(i\)</span>: <span class="math inline">\(\mu(j&#39;) \leftarrow i\)</span></p>
</blockquote>
<h5 id="facility-cost-1">Facility Cost</h5>
<p>The analysis of expected facility cost is almost the same as before. It is guaranteed that the <span class="math inline">\(N(j)\)</span>'s for selected clients <span class="math inline">\(j \in D\)</span> are disjoint. Therefore, the expected opening cost is bounded by<br />
<span class="math display">\[
\sum_{j \in D} \sum_{i \in N(j) } x^*_{i,j} f_i \le \sum_{j \in D} \sum_{i \in N(j) } y^*_i f_i 
\]</span></p>
<h5 id="connection-cost-1">Connection Cost</h5>
<p>Now we analyze the assignment cost. When a client <span class="math inline">\(j\)</span> and a facility <span class="math inline">\(i\)</span> in <span class="math inline">\(N(j)\)</span> is sampled, unassigned clients <span class="math inline">\(j&#39; \in N^2(j)\)</span> are assigned to <span class="math inline">\(i\)</span>. As <span class="math inline">\(j&#39; \in N^2(j)\)</span>, there exists some other facility <span class="math inline">\(i&#39; \in N(j)\)</span>, such that <span class="math inline">\((i&#39;,j&#39;) \in E\)</span>. By triangle inequality, the expected connection cost is at most <span class="math display">\[
\begin{aligned}
c_{i, j&#39;} 
&amp;\le \sum_{i \in N(j)} x^*_{i,j} c_{i, j} + c_{i&#39;, j} + c_{i&#39;, j} \\
&amp;\le A_j + \alpha^*_{j} + \alpha^*_j \\
&amp;\le A_{j&#39;} + 2\alpha^*_{j&#39;}
\end{aligned}
\]</span></p>
<p>Summing over all clients, the cost is at most <span class="math display">\[
\sum_{j \in D} \sum_{i \in N(j) } x^*_{i,j} f_i + \sum_{i \in F, j \in C} c_{i, j} x^*_{i, j} + 2\sum_{j \in C} \alpha^*_j \le 3 \cdot OPT
\]</span></p>
<p><strong><em>Remark</em></strong>: there is still room for improvement. When a client <span class="math inline">\(j\)</span> is selected and a facility <span class="math inline">\(i\)</span> is sampled, <span class="math inline">\(j&#39; \in N^2(j)\)</span> is assigned to <span class="math inline">\(i\)</span>. On the other hand, <span class="math inline">\(j&#39;\)</span> itself may contributes to the opening cost of some other facility not open. To make the expected opening cost tight, we may consider opening facilities directly with respect to probability <span class="math inline">\(y^*_i\)</span>.</p>
<h4 id="e-approximation-rounding-3"><strong><em><span class="math inline">\((1 + 3/e)\)</span>-Approximation Rounding</em></strong> [3]</h4>
<!-- To have an intuition of the rounding technique, we illustrate a wrong but instructive rounding technique. Here we assume that $x^*_{i,j} = y^*_i$ for all $i \in F, j \in C$. If we select each facility $i$ independently with probability $y^*_i$, then for a client $j$, the probability that none of its neighbor is selected is 
$$
\prod_{i \in N(j) } (1 - y^*_i) \le e^{-\sum_{i \in N(j) } y^*_i} \le e^{ - \sum_{i \in N(j) } x^*_{i,j} } = e^{-1}
$$

The problem here is that, if none of $j$'s neighbors is sampled, the connection cost of $j$ might be unacceptable large. We need some backup mechanism. For example, if we can somehow combine Algorithm 1 and bound the connection cost to $3 v^*_j$ for this bas case. Let $Z$ be the random variable that represents connection cost for $j$ and $Y_i$ ($i \in N(j)$) indicator random variable of whether $i$ is sampled.
$$
Z \le Z' \doteq \min_{i \in N(j), Y_i = 1} \{ c_{i,j} Y_i \} + 3 v^*_j \cdot \mathbb{1}_{[ Y_i = 0, \forall i \in N(j)] }
$$


Therefore, 
$$
\begin{aligned}
    E[Z] 
    &\le E[Z'] \\
    &\le E \left[ \sum_{i \in N(j)}  c_{i,j} Y_i  + 3 v^*_j \cdot \mathbb{1}_{[ Y_i = 0, \forall i \in N(j)] } \right] \\
    &= \sum_{i \in N(j)}  c_{i,j} E[Y_i]  + 3 v^*_j \cdot E\left[ \mathbb{1}_{[ Y_i = 0, \forall i \in N(j)] } \right] \\
    &\le \sum_{i \in N(j) } c_{i,j} x^*_{i,j} + \frac{3}{e} v^*_j
\end{aligned}
$$

The third equality does not even require that $Y_i$'s are independent. Then the total cost is bounded by 
$$
\begin{aligned}
    &\sum_{i \in F} y^*_i f_i + \sum_{j \in C}  x^*_{i,j} c_{i,j} + \frac{3}{e} \sum_{j \in C} v^*_j \\
    =& (1 + \frac{3}{e} ) \cdot  OPT
\end{aligned}
$$


Below we show the actual algorithm that achieves this expected approximation ratio. The facilities are no longer sampled independently. However, we will see that, for facility $i$, it is still selected with probability $y^*_i$. Therefore, the expected cost of opening the facilities is still $\sum_{i \in F} y^*_i f_i$.  -->
<!-- 
> Algorithm 3:     
> 1. $S \leftarrow \emptyset$.  
> 2. $D \leftarrow \emptyset$.  
> 3. $T \leftarrow F$.   
> 2. While there exists un-assigned client   
> 3. $\quad$ Let $j$ be the unassigned one with smallest $\alpha^*_j$, add $j$ to $D$.      
> 5. $\quad$ Sample a facility $i$ in $N(j)$ with probability $x^*_{i,j}$, add it to $S$.    
> 6. $\quad$ $T \leftarrow T \setminus N(j)$.
> 6. $\quad$ Assign $j$ to $i$:  $\mu(j) \leftarrow i$  
> 6. $\quad$ For each un-assigned client $j' \in N^2(j)$ do  
> 8. $\quad$ $\quad$ $\quad$ Assign $j'$ to $i$: $\mu(j')   \leftarrow i$
> 9. Sample each facility $i \in T$ independently with probability $y^*_i$. 
-->
<p>In the previous analysis, we see that a facility may be under-sampled. There are two reasons for this:<br />
1. For a facility <span class="math inline">\(i\)</span>, <span class="math inline">\(\exists j \in N(i)\)</span> such that <span class="math inline">\(j \in D\)</span>. When <span class="math inline">\(j\)</span> is selected, facility <span class="math inline">\(i\)</span> is sampled with probability <span class="math inline">\(x^*_{i,j}\)</span>, which might be smaller than <span class="math inline">\(y^*_i\)</span>.<br />
2. For a facility <span class="math inline">\(i\)</span>, none of its clients <span class="math inline">\(j \in N(i)\)</span> is selected, therefore <span class="math inline">\(i\)</span> is never sampled.</p>
<p>To fix theses issues and based on algorithm 1, we have the following algorithm. The algorithm presented here is a modified version of the one proposed in [3] but guided the same philosophy.</p>
<blockquote>
<p>Algorithm 3:<br />
1. <span class="math inline">\(T \leftarrow F\)</span><br />
2. <span class="math inline">\(k \leftarrow 0\)</span><br />
3. <span class="math inline">\(S_1, S_2, S_3 \leftarrow \emptyset\)</span><br />
2. While there exists un-assigned client<br />
4. <span class="math inline">\(\quad\)</span> <span class="math inline">\(k \leftarrow k + 1\)</span><br />
3. <span class="math inline">\(\quad\)</span> Let <span class="math inline">\(j_k\)</span> be the unassigned one with smallest <span class="math inline">\(\alpha^*_j\)</span><br />
5. <span class="math inline">\(\quad\)</span> Open exactly one facility <span class="math inline">\(i_k \in N( j_k )\)</span> with probability <span class="math inline">\(x^*_{i,j}\)</span><br />
6. <span class="math inline">\(\quad\)</span> <span class="math inline">\(S_1 \leftarrow S_1 \cup \{ i_k \}\)</span><br />
6. <span class="math inline">\(\quad\)</span> For each <span class="math inline">\(i \in N(j_k) - \{ i_k \}\)</span> 7. <span class="math inline">\(\qquad\)</span> Open <span class="math inline">\(i\)</span> with probability <span class="math inline">\((y^*_{i} - x^*_{i,j } ) / ( 1- x^*_{i,j} )\)</span><br />
8. <span class="math inline">\(\qquad \quad\)</span> <span class="math inline">\(S_2 \leftarrow S_2 \cup \{ i \}\)</span> 6. <span class="math inline">\(\quad\)</span> <span class="math inline">\(T \leftarrow T - N(j_k)\)</span><br />
6. <span class="math inline">\(\quad\)</span> Assign <span class="math inline">\(j\)</span> to <span class="math inline">\(i_k\)</span>, for <span class="math inline">\(\forall j \in \{ j_k \} \cup N^2( j_k )\)</span><br />
9. For each facility <span class="math inline">\(i \in T\)</span> 10. <span class="math inline">\(\quad\)</span> Open <span class="math inline">\(i\)</span> with probability <span class="math inline">\(y^*_i\)</span><br />
10. <span class="math inline">\(\qquad\)</span> <span class="math inline">\(S_3 \leftarrow S_3 \cup \{ i \}\)</span> 10. Re-assign each <span class="math inline">\(j \in C\)</span> to its nearest open facility.</p>
</blockquote>
<p>When the algorithm stops, denote <span class="math inline">\(S = S_1 \cup S_2 \cup S_3\)</span> the set of open facilities and <span class="math inline">\(D = \{j_1, j_2, ..., j_{|D| } \}\)</span> the set of selected facilities by line 5. The following lemma shows that Algorithm 3 fully samples each facility and therefore never loses to Algorithm 1.</p>
<h5 id="facility-cost-2">Facility Cost</h5>
<p><strong><em>Lemma 1.</em></strong> For each <span class="math inline">\(i \in F\)</span>, it is opened with probability <span class="math inline">\(y^*_i\)</span>.<br />
<em>Proof.</em> Note the facilities are not open independently. The claim is trivially true if a facility is is sampled in line 10. Otherwise, <span class="math inline">\(\exists j \in D\)</span>, s.t., <span class="math inline">\(i \in N(j)\)</span>. The probability of <span class="math inline">\(i\)</span> being open is <span class="math display">\[
x^*_{i,j} + (1 - x^*_{i,j} ) \frac{y^*_{i} - x^*_{i,j} }{ 1- x^*_{i,j} } = y^*_i
\]</span> <span class="math inline">\(\blacksquare\)</span></p>
<p><strong><em>Corollary.</em></strong> By linearity of expectation, the expected facility opening cost is <span class="math inline">\(\sum_{i \in F} y^*_i f_i\)</span>.</p>
<h5 id="connection-cost-2">Connection Cost</h5>
<p>What is not trivial is the analysis of the assignment cost. Given <span class="math inline">\(S\)</span>, assigning <span class="math inline">\(j \in C\)</span> to its nearest facility in <span class="math inline">\(S\)</span> minimizes the assignment cost. To bound this cost, we investigate a sub-optimal assignment based on <span class="math inline">\(S\)</span>. For each <span class="math inline">\(j \in C\)</span> we select a subset <span class="math inline">\(S(j) \subset S\)</span> and assign it to a closest facility in <span class="math inline">\(S(j)\)</span>. This leads to a possibly increase in the expected assignment cost.</p>
<p>Let <span class="math inline">\(Z\)</span> be the random variable of the assignment cost for client <span class="math inline">\(j\)</span> and <span class="math inline">\(X_i\)</span> (<span class="math inline">\(i \in N(j)\)</span>) be the indicator random variable of <span class="math inline">\(i\)</span> being in <span class="math inline">\(S(j)\)</span>. As when none of the facility in <span class="math inline">\(N(j)\)</span> is selected into <span class="math inline">\(S(j)\)</span>, then assignment cost is bounded by <span class="math inline">\(3 \cdot v^*_j\)</span>, the value of <span class="math inline">\(Z\)</span> is therefore at most <span class="math display">\[
Z \le \min_{i \in N(j), X_i = 1} \{ c_{i,j} X_i \} + 3 v^*_j \cdot \mathbb{1}_{[ Y_i = 0, \forall i \in N(j)] }
\]</span></p>
<p>The goal is to provide a method for generating <span class="math inline">\(S(j)\)</span>, such that</p>
<ol type="1">
<li><span class="math inline">\(\Pr[X_i = 1] = x^*_{i,j}\)</span>, for <span class="math inline">\(\forall i \in N(j)\)</span>;</li>
<li><span class="math inline">\(\Pr[\mathbb{1}_{[ Y_i = 0, \forall i \in N(j)]} = 1 ] \le 1/e\)</span>.</li>
</ol>
<p>Any such generation method satisfies to bound the assignment cost of client <span class="math inline">\(j\)</span>: <span class="math display">\[
\begin{aligned}
    E[Z] 
    &amp;\le E \left[ \sum_{i \in N(j)}  c_{i,j} X_i  + 3 v^*_j \cdot \mathbb{1}_{[ X_i = 0, \forall i \in N(j)] } \right] \\
    &amp;= \sum_{i \in N(j)}  c_{i,j} E[X_i]  + 3 v^*_j \cdot E\left[ \mathbb{1}_{[ X_i = 0, \forall i \in N(j)] } \right] \\
    &amp;\le \sum_{i \in N(j) } c_{i,j} x^*_{i,j} + \frac{3}{e} v^*_j
\end{aligned}
\]</span></p>
<p>Note that the inequality here may not be tight, as we replace the <span class="math inline">\(\min\)</span> operation into <span class="math inline">\(\sum\)</span>. But it suffices to prove the expected approximation ratio. When combined with the expected facility opening cost, we know that total expected cost is bounded by <span class="math display">\[
\sum_{i \in F} y^*_i f_i + \sum_{j \in C} \sum_{i \in N(j) } c_{i,j} x^*_{i,j} + \frac{3}{e} v^*_j = \left( 1 + \frac{3}{e} \right) \cdot OPT
\]</span></p>
<p>The <span class="math inline">\(S(j)\)</span> is generated as follows. If <span class="math inline">\(j \in D\)</span>, then we let <span class="math inline">\(S(j) = S\)</span>. Otherwise, we initialize <span class="math inline">\(S(j)\)</span> with <span class="math inline">\(S - N(j)\)</span>, and for facility <span class="math inline">\(i \in N(j) \cap S\)</span>, we perform some carefully designed operations to ensure that <span class="math inline">\(\Pr[i \in S(j) ]= x^*_{i,j}\)</span>.</p>
<ol type="1">
<li>If <span class="math inline">\(i \in S_3\)</span>, we keep it in <span class="math inline">\(S(j)\)</span> with probability <span class="math inline">\(\frac{x^*_{i,j} } {y^*_i}\)</span>. Therefore, <span class="math display">\[
 \Pr[i \in S(j)] = \Pr[i \in S(j) \mid i \in S] \cdot \Pr[i \in S] = x^*_{i,j}
 \]</span></li>
<li>Otherwise, <span class="math inline">\(\exists j_k \in D\)</span>, such that <span class="math inline">\(i \in N(j_k)\)</span>. There are two possible cases
<ol type="1">
<li><p>Case 1: <span class="math inline">\(x^*_{i,j_k} \ge x^*_{i,j}\)</span>, the probability of selecting <span class="math inline">\(i\)</span> is defined as follows: <span class="math display">\[
 \Pr[i \in S(j) \mid i \in S] =
 \begin{cases}
     \begin{array}{lr}
         {x^*_{i,j} } / { x^*_{i,j_k} },   &amp;i \in S_1 \\
         0,                                 &amp;
         i \in S_2
     \end{array}
 \end{cases}
 \]</span> Therefore, <span class="math display">\[
 \begin{array}{ll}
     \Pr[i \in S(j)] 
         &amp;= \Pr[i \in S(j) |i \in S_1 ] \cdot \Pr[ i \in S_1 ] + \Pr[i \in S(j) |i \in S_2 ] \cdot \Pr[ i \in S_2 ] \\
         &amp;= x^*_{i,j}  /  x^*_{i,j_k}  \cdot  x^*_{i,j_k}  \\
         &amp;= x^*_{i,j} 
 \end{array}
 \]</span></p></li>
<li><p>Case 2: <span class="math inline">\(x^*_{i,j_k} &lt; x^*_{i,j}\)</span>, the probability of selecting <span class="math inline">\(i\)</span> is defined as follows: <span class="math display">\[
 \Pr[i \in S(j) \mid i \in S] =
 \begin{cases}
     \begin{array}{lr}
         1,   &amp;i \in S_1 \\
         (x^*_{i,j} - x^*_{i, j_k}  ) \cdot ( 1 - x^*_{i,j_k } ) / (y^*_{i} - x^*_{i,j_k } ),                                 &amp; i \in S_2
     \end{array}
 \end{cases}
 \]</span></p>
<p>The probability is well defined as <span class="math inline">\(y^*_i \ge x^*_{i,j}\)</span>. It follows</p>
<p><span class="math display">\[
 \begin{array}{ll}
     \Pr[i \in S(j)] 
         &amp;= \Pr[i \in S(j) |i \in S_1 ] \cdot \Pr[ i \in S_1 ]  + \Pr[i \in S(j) |i \in S_2 ] \cdot \Pr[ i \in S_2  ] \\
         &amp;=  x^*_{i,j_k}  +  (x^*_{i,j} - x^*_{i, j_k}  ) \cdot ( 1 - x^*_{i,j_k } ) / (y^*_{i} - x^*_{i,j_k } ) \cdot (y^*_{i} - x^*_{i,j_k } ) / (x^*_{i,j} - x^*_{i, j_k}  )\\
         &amp;= x^*_{i,j} 
 \end{array}
 \]</span></p></li>
</ol></li>
</ol>
<p>It is left to show that <span class="math inline">\(\Pr[\mathbb{1}_{[ Y_i = 0, \forall i \in N(j)]} = 1 ] \le 1/e\)</span>. For <span class="math inline">\(j \in D\)</span>, this holds trivially. If not, we prove the following lemma.</p>
<p><strong><em>Lemma 2.</em></strong> For any client <span class="math inline">\(j \in C \setminus D\)</span>, the probability that none of facility in <span class="math inline">\(N(j)\)</span> belongs to <span class="math inline">\(S(j)\)</span> is bounded by <span class="math inline">\(1/ e\)</span>.</p>
<p><strong><em>Proof.</em></strong></p>
<p>Observe that <span class="math display">\[
N(j_1) \cup N(j_2) \cup ... \cup N(j_{|D| } ) \cup T = F
\]</span></p>
<p>constitutes a partition of <span class="math inline">\(F\)</span>. For any client <span class="math inline">\(j\)</span>, define <span class="math inline">\(R_k = N(j_k) \cap N(j)\)</span>, where <span class="math inline">\(1 \le k \le |D|\)</span>. Further, let <span class="math inline">\(R_{|D| + 1} = T \cap N(j)\)</span>. Then <span class="math inline">\(\{ R_k \}_{k \in [|D| + 1]}\)</span> is a partition of <span class="math inline">\(N(j)\)</span>.</p>
<p>Consider facilities in <span class="math inline">\(N(j_k)\)</span> (<span class="math inline">\(k \in [|D|]\)</span>). The probability of none of them being in <span class="math inline">\(S(j)\)</span> is <span class="math display">\[
\begin{aligned}
    &amp;\left( 1 - \sum_{i \in R_k \wedge x^*_{i, j_k} &lt; x^*_{i,j} } x^*_{i, j_k}   - \sum_{i \in R_k \wedge x^*_{i, j_k} \ge x^*_{i,j} } x^*_{i, j_k} \cdot \frac{x^*_{i,j} }{ x^*_{i, j_k} }     \right)
     \cdot \prod_{i \in R_k \wedge x^*_{i, j_k} &lt; x^*_{i,j} } \left(1 - \frac{y^*_{i} - x^*_{i,j } }{ 1- x^*_{i,j}} 
    \frac{ 1- x^*_{i,j}}{y^*_{i} - x^*_{i,j } } (x^*_{i,j} - x^*_{i, j_k}  )
    \right) \\
    &amp;\le \exp \left( - \sum_{i \in R_k \wedge x^*_{i, j_k} &lt; x^*_{i,j} } x^*_{i, j_k}  - \sum_{i \in R_k \wedge x^*_{i, j_k} \ge x^*_{i,j} } x^*_{i,j}\right) 
    \cdot \prod_{i \in R_k \wedge x^*_{i, j_k} &lt; x^*_{i,j} } \left(1 -  (x^*_{i,j} - x^*_{i, j_k}  )
    \right) \\
    &amp;\le \exp \left( - \sum_{i \in R_k \wedge x^*_{i, j_k} &lt; x^*_{i,j} } x^*_{i, j_k}  - \sum_{i \in R_k \wedge x^*_{i, j_k} \ge x^*_{i,j} } x^*_{i,j}\right) 
    \cdot \exp \left( -\sum_{i \in R_k \wedge x^*_{i, j_k} &lt; x^*_{i,j} } (x^*_{i,j} - x^*_{i, j_k}  )
    \right) \\
    &amp;= \exp \left( { - \sum_{i \in R_k} x^*_{i, j} } \right) 
\end{aligned}
\]</span></p>
<p>The relation holds even if <span class="math inline">\(R_k = \emptyset\)</span>, in which <span class="math inline">\(\sum_{i \in R_k} x^*_{i, j} = 0\)</span>.</p>
<p>For <span class="math inline">\(k = |D| + 1\)</span>, the probability that none of the facility in <span class="math inline">\(R_k\)</span> is sampled is given by <span class="math display">\[
\prod_{i \in R_{k + 1} } \left( 1 - y^*_i \frac{x^*_{i,j} } {y^*_i}  \right) \le e^{- \sum_{i \in R_{k + 1} } x^*_{i,j} } 
\]</span></p>
<p>Therefore, taking product over all the events, we know that <span class="math display">\[
\begin{aligned}
    \prod_{k \in [|D| + 1] } e^{- \sum_{i \in R_k } x^*_{i,j} } 
        &amp;= e^{ - \sum_{i \in N(j) } x^*_{i,j} } \\
        &amp;= \frac{1}{e}
\end{aligned}
\]</span> <span class="math inline">\(\blacksquare\)</span></p>
<!-- #### ***$(1 + 2/e)$-Approximation Rounding***

> Algorithm 4:     
> 1. $S \leftarrow \emptyset$.  
> 2. $D \leftarrow \emptyset$.  
> 3. $T \leftarrow F$.   
> 2. While there exists un-assigned client   
> 3. $\quad$ Let $j$ be the unassigned one with smallest $\alpha^*_j + A_j$, add $j$ to $D$.        
> 5. $\quad$ Sample a facility $i$ in $N(j)$ with probability $x^*_{i,j}$, add it to $S$.    
> 6. $\quad$ $T \leftarrow T \setminus N(j)$.
> 6. $\quad$ Assign $j$ to $i$:  $\mu(j) \leftarrow i$  
> 6. $\quad$ For each un-assigned client $j' \in N^2(j)$ do  
> 8. $\quad$ $\quad$ $\quad$ Assign $j'$ to $i$: $\mu(j')   \leftarrow i$
> 9. Sample each facility $i \in T$ independently with probability $y^*_i$.

***Theorem.*** For any client $j$, the expected assignment cost is give by $(1 - p_j) A_j + p_j (2v^*_j + A_j)$.

***Proof*** -->
<h2 id="primal-dual-algorithm-2"><strong><em>Primal-Dual Algorithm</em></strong> [2]</h2>
<p>In this section we show a primal-dual algorithm that is purely combinatorial.</p>
<ol type="1">
<li>Initially we have a set of dual variables <span class="math inline">\(\alpha_j\)</span>'s and <span class="math inline">\(\beta_{i,j}\)</span>'s that are set to 0. Note that they are feasible.<br />
</li>
<li>Then we try to optimize this set of variables by increasing all <span class="math inline">\(\alpha_j\)</span>'s in parallel until some <span class="math inline">\(\alpha_j\)</span>'s are blocked.</li>
</ol>
<p>Why are they blocked? Because the dual constraint <span class="math display">\[
\alpha_j \le c_{i,j} + \beta_{i,j}
\]</span></p>
<p>becomes tight for some facilities <span class="math inline">\(i \in F\)</span>. If we increase <span class="math inline">\(\alpha_j\)</span> further, the variables are no longer dual feasible. However, we can modify our strategy by increasing these <span class="math inline">\(\beta_{i,j}\)</span> simultaneously with <span class="math inline">\(\alpha_j\)</span> until facility <span class="math inline">\(i\)</span> is <em>blocked</em>, i.e., <span class="math display">\[
\sum_{j \in C} \beta_{i,j} = f_i
\]</span></p>
<p>Before we proceed, for a given facility <span class="math inline">\(i\)</span>, we define its neighbors <span class="math inline">\(N(i)\)</span> as to be the clients such that <span class="math inline">\(\alpha_j \ge c_{i,j}\)</span>.</p>
<blockquote>
<p>Algorithm: Dual Variable Increment.<br />
1. <span class="math inline">\(U \leftarrow C\)</span>: the set of un-blocked clients.<br />
2. <span class="math inline">\(B \leftarrow \emptyset\)</span>: the set of blocked facilities.<br />
3. <em>while</em> <span class="math inline">\(U \neq \emptyset\)</span> <em>do</em><br />
4. <span class="math inline">\(\quad\)</span> <em>For</em> <span class="math inline">\(\forall j \in U\)</span><br />
5. <span class="math inline">\(\qquad\)</span> Increase all <span class="math inline">\(\alpha_j\)</span> (if necessary, <span class="math inline">\(\beta_{i,j}\)</span> for some <span class="math inline">\(i\)</span> ) simultaneously<br />
6. <span class="math inline">\(\quad\)</span> <em>Until</em> either<br />
7. <span class="math inline">\(\qquad\)</span> * some facility <span class="math inline">\(i \notin B\)</span> is blocked:<br />
8. <span class="math inline">\(\qquad\quad\)</span> <span class="math inline">\(B \leftarrow B \cup \{i \}\)</span><br />
9. <span class="math inline">\(\qquad\quad\)</span> <span class="math inline">\(U \leftarrow U \setminus N(i)\)</span><br />
10. <span class="math inline">\(\qquad\)</span> * some client <span class="math inline">\(j\)</span> neighbors a blocked facility <span class="math inline">\(i \in B\)</span>:<br />
11. <span class="math inline">\(\qquad\quad\)</span> <span class="math inline">\(U \leftarrow U \setminus \{ j \}\)</span></p>
</blockquote>
<p><em>Question to ponder</em>: what is the running time for the <em>Dual Variable Increment</em> algorithm:</p>
<p>After running the algorithm above, we get a set of maximal variable which we can't simultaneously increase any more. It has the following property</p>
<blockquote>
<p><em>Property.</em> Each client <span class="math inline">\(j \in C\)</span> neighbors at least one block facility.</p>
</blockquote>
<p>If not, the algorithm will increase the <span class="math inline">\(\alpha_j\)</span> further.</p>
<p>We show how to construct an approximate solution from the maximal dual variables. First we construct a derived graph <span class="math inline">\(G = (V, E)\)</span> from primal LP.</p>
<ol type="1">
<li>The vertex set <span class="math inline">\(V = B \cup C\)</span>.</li>
<li>The edge set <span class="math inline">\(E = \{ (i, j) : \beta_j \ge c_{i,j}, \forall i \in B, j \in C\}\)</span>.</li>
</ol>
<p>Moreover, if <span class="math inline">\(\beta_{i,j} &gt; 0\)</span> for some <span class="math inline">\(i \in F\)</span>, <span class="math inline">\(j \in C\)</span>, we say that <span class="math inline">\(j\)</span> contributes to <span class="math inline">\(i\)</span>. Given a facility <span class="math inline">\(i\)</span>, we are particular interested in the set of clients that contributes to it, denoted as <span class="math inline">\(N_+(i)\)</span>.</p>
<blockquote>
<p>Algorithm: Facility Selection and Client Assignment<br />
1. <span class="math inline">\(S \leftarrow \emptyset\)</span>. 2. <em>while</em> <span class="math inline">\(B \neq \emptyset\)</span> <em>do</em><br />
3. <span class="math inline">\(\quad\)</span> Let <span class="math inline">\(i \in B\)</span> be the earliest blocked facility.<br />
4. <span class="math inline">\(\quad\)</span> <span class="math inline">\(S \leftarrow S \cup \{ i \}\)</span><br />
5. <span class="math inline">\(\quad\)</span> <span class="math inline">\(B \leftarrow B \setminus \{ i \}\)</span><br />
8. <span class="math inline">\(\quad\)</span> // Assign all <span class="math inline">\(j \in C\)</span> that contributes to both <span class="math inline">\(i\)</span>. 8. <span class="math inline">\(\quad\)</span> <span class="math inline">\(\mu_S(j) \leftarrow i\)</span> for all <span class="math inline">\(j \in N_+(i)\)</span>. 8. <span class="math inline">\(\quad\)</span> // Remove all facilities <span class="math inline">\(i&#39;\)</span> if <span class="math inline">\(\exists j \in C\)</span> that contributes to both <span class="math inline">\(i\)</span> and <span class="math inline">\(i&#39;\)</span>. 9. <span class="math inline">\(\quad\)</span> <span class="math inline">\(B \leftarrow B \setminus \{ i&#39; \in B : N_+(i) \cap N_+(i&#39;) \neq \emptyset \}\)</span>. 10. Assign each unassigned client to its closest facility in <span class="math inline">\(S\)</span>.</p>
</blockquote>
<p>The figure below shows an example of dual variable increment algorithm. <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm2.2.png" /></p>
<p>The figure below shows the corresponding derived graph. <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm2.3.png" /></p>
<p>The figure below shows an example of facility selection. The selected facilities are marked with dark green. The clients contributing to theses facilities are connected to them red lines. <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm2.4.png" /></p>
<h4 id="facility-cost-3">Facility Cost</h4>
<p>We can show by induction that when a blocked facility is selected, its opening cost is fully covered by all clients contributing to this facility. Note that if any other blocked facility is connected to any of these clients, it is removed from the candidate set. Therefore, when a new blocked facility <span class="math inline">\(i\)</span> is selected, the clients in <span class="math inline">\(N_+(i)\)</span> can contribute to any previous selected facility.</p>
<p>The cost of open facilities in <span class="math inline">\(S\)</span>, plus the cost of connecting clients in <span class="math inline">\(N_+(i)\)</span> for <span class="math inline">\(i \in S\)</span>, is given by <span class="math display">\[
\sum_{i \in S} (f_i + \sum_{j \in N_+(i)} c_{ij}) = \sum_{i \in S} (\sum_{j \in N_+(i)} \beta_{ij} + \sum_{j \in N_+(i)} c_{ij}) = \sum_{i \in S} \sum_{j \in N_+(i)} \alpha_j
\]</span></p>
<h4 id="connection-cost-3">Connection Cost</h4>
<p>It is left to analyze the connection of other clients. If a client <span class="math inline">\(j \in C\)</span> is in <span class="math inline">\(N(i)\)</span> for some <span class="math inline">\(i \in S\)</span>, then the connection cost if <span class="math display">\[
c_{ij} \le \alpha_j
\]</span> Otherwise, by the property of the algorithm, <strong><em>we know that there exists a facility <span class="math inline">\(i\)</span> that stops <span class="math inline">\(\alpha_j\)</span> from increasing</em></strong>. The reason that <span class="math inline">\(i\)</span> is not selected is that when some other facility <span class="math inline">\(i&#39;\)</span> is selected into <span class="math inline">\(S\)</span>, <span class="math inline">\(i\)</span> is removed from the candidate set <span class="math inline">\(B\)</span> because <span class="math inline">\(N_+(i) \cap N_+(i&#39;) \neq \emptyset\)</span> . Let <span class="math inline">\(j&#39; \in N_+(i) \cap N_+(i&#39;) \neq \emptyset\)</span>. We claim</p>
<blockquote>
<p><span class="math inline">\(\alpha_{j&#39;} \le \alpha_{j}\)</span></p>
</blockquote>
<p>To see this, when <span class="math inline">\(i\)</span> stops <span class="math inline">\(\alpha_j\)</span>, we know that either <span class="math inline">\(\alpha_{j&#39;}\)</span> has stopped from increasing or <span class="math inline">\(\alpha_j\)</span> stops simultaneously with <span class="math inline">\(j\)</span>, as <span class="math inline">\(j&#39;\)</span> contributes to <span class="math inline">\(i\)</span>.</p>
<p>Therefore, the cost of assigning <span class="math inline">\(j\)</span> to <span class="math inline">\(i&#39;\)</span> is at most <span class="math display">\[
c_{i&#39;j} \le c_{i&#39;j&#39;} + c_{ij&#39;} + c_{ij} \le 2 \alpha_{j&#39;} + \alpha_j \le 3 \alpha_j
\]</span> <em>Question to ponder</em>: what is the running time of the algorithm?</p>
<p>Finally we show another example where the edge weight between (b,y) is changed to 1.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm2.5.png" /></p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm2.6.png" /></p>
<p>Note that compared to the previous example, only facility <span class="math inline">\(x\)</span> is selected (marked by dark green), because we can use <span class="math inline">\(b\)</span> to contribute only one facility. Now facility <span class="math inline">\(y\)</span> is the one that stops <span class="math inline">\(\alpha_c\)</span> and <span class="math inline">\(\alpha_d\)</span> from increasing.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm2.7.png" /></p>
<h3 id="reference.">Reference.</h3>
<p>[1] Shmoys DB, Tardos É, Aardal K. Approximation algorithms for facility location problems. InProceedings of the twenty-ninth annual ACM symposium on Theory of computing 1997 May 4 (pp. 265-274).</p>
<p>[2] Jain K, Vazirani VV. Primal-dual approximation algorithms for metric facility location and k-median problems. In 40th annual symposium on foundations of computer science (Cat. No. 99CB37039) 1999 Oct 17 (pp. 2-13). IEEE.</p>
<p>[3] Chudak FA, Shmoys DB. Improved approximation algorithms for the uncapacitated facility location problem. SIAM Journal on Computing. 2003;33(1):1-25.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/09/11/Confidence-Interval-of-Berstein-Inequality/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/09/11/Confidence-Interval-of-Berstein-Inequality/" class="post-title-link" itemprop="url">Confidence Interval of Berstein Inequality</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-09-11 21:07:20" itemprop="dateCreated datePublished" datetime="2018-09-11T21:07:20+10:00">2018-09-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-02 19:57:23" itemprop="dateModified" datetime="2019-12-02T19:57:23+11:00">2019-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>(Berstein inequality).<br />
Let <span class="math inline">\(X_1, ..., X_n\)</span> be random variables with range <span class="math inline">\([0, 1]\)</span> and <span class="math display">\[
\sum_{t = 1}^n Var[X_t \mid X_{t - 1}, ..., X_1] = \sigma^2
\]</span></p>
<p>Let <span class="math inline">\(S_n = X_1 + ... + X_n\)</span>. Then for all <span class="math inline">\(a \ge 0\)</span> <span class="math display">\[
\Pr[S_n \ge E[S_n] + an] \le \exp\left(- \frac{n^2 a^2 / 2}{\sigma^2 + n a / 2} \right)
\]</span></p>
<p>Suppose we would like to calculate the confidence interval with probability <span class="math inline">\(\delta\)</span>, then we need to solve the following equation: <span class="math display">\[
\exp\left( -\frac{n^2 a^2 / 2}{\sigma^2 + n a / 2} \right) = \delta 
\]</span></p>
<p>After transformation, we get <span class="math display">\[
n^2 a^2 - n a \ln \frac{1}{\delta} - 2 \sigma^2 \ln \frac{1}{\delta} = 0
\]</span></p>
<p>Therefore, <span class="math display">\[
a = \frac{n \ln \frac{1}{\delta} + \sqrt{n^2 \ln^2 \frac{1}{\delta} + 8 \sigma^2 n^2 \ln \frac{1}{\delta}} }{2n^2 } = \frac{\ln \frac{1}{\delta} + \sqrt{\ln^2 \frac{1}{\delta} + 8 \sigma^2 \ln \frac{1}{\delta}} }{2n }
\]</span></p>
<p>But <span class="math display">\[
\sqrt{\ln^2 \frac{1}{\delta} + 8 \sigma^2 \ln \frac{1}{\delta}} \le \sqrt{\ln^2 \frac{1}{\delta}}  + \sqrt{8\sigma^2 \ln \frac{1}{\delta}} = \ln \frac{1}{\delta} + 2\sigma \sqrt{2 \ln \frac{1}{\delta}}
\]</span></p>
<p>It follows that <span class="math display">\[
a = \frac{\ln \frac{1}{\delta} }{n} + \frac{\sigma \sqrt{2\ln \frac{1}{\delta} } }{n}
\]</span></p>
<p><strong>Corollary:</strong> If <span class="math inline">\(X_1, ..., X_n\)</span> are i.i.d. random variables and <span class="math display">\[
\sum_{t = 1}^n Var[X_t \mid X_{t - 1}, ..., X_1] = n Var[X_1]
\]</span> Then <span class="math display">\[
a = \frac{\ln \frac{1}{\delta}}{n} + \sqrt{\frac{2 Var[X_1] \ln \frac{1}{\delta}}{n}}
\]</span></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/09/02/Interval-Estimate/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/09/02/Interval-Estimate/" class="post-title-link" itemprop="url">Interval Estimate</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-09-02 19:23:25" itemprop="dateCreated datePublished" datetime="2018-09-02T19:23:25+10:00">2018-09-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2018-09-16 19:52:14" itemprop="dateModified" datetime="2018-09-16T19:52:14+10:00">2018-09-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Let <span class="math inline">\(X\)</span> be a Bernoulli random variable with unknown probability <span class="math display">\[
\begin{aligned}
P[X = 1] &amp;= \mu. \\
P[X = 0] &amp;= 1 - \mu
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\frac{1}{n} \le \mu \le 1\)</span> for some integer <span class="math inline">\(n &gt; 0\)</span>. The goal is to estimate <span class="math inline">\(\mu\)</span> (denoted by <span class="math inline">\(\tilde \mu\)</span>) via sampling.</p>
<p>By law of large number, <span class="math inline">\(\tilde \mu\)</span> converges to <span class="math inline">\(\mu\)</span> when we sample enough numbers of <span class="math inline">\(X\)</span>. The convergence behavior is captured by Chernoff inequality and <span class="math inline">\(O(\frac{1}{\delta^2 \mu}\log{1 \over p_{fail} })\)</span> samples are needed to get an estimation <span class="math inline">\(\tilde \mu\)</span> such that <span class="math inline">\(P [ \tilde \mu \in (1 \pm \delta) \mu] \ge 1 - p_{fail}\)</span> (See Exercise 1). Such an <span class="math inline">\(\tilde \mu\)</span> is called an <span class="math inline">\((\delta, p_{fail})\)</span>-estimation of <span class="math inline">\(\mu\)</span>.</p>
<p>As <span class="math inline">\(\mu \ge \frac{1}{n}\)</span>, <span class="math inline">\(O(\frac{n}{\delta^2}\log{1 \over p_{fail} })\)</span> samples are enough. The problem is, if <span class="math inline">\(\mu\)</span> is much larger than <span class="math inline">\(1/n\)</span>, we waste a lot of samples. E.g., when <span class="math inline">\(n = 1000\)</span> and <span class="math inline">\(\mu = \frac{1}{2}\)</span>, <span class="math inline">\(\frac{1}{\delta^2 \mu}\log{1 \over p_{fail} }\)</span> gives us <span class="math inline">\(\frac{2}{\delta^2}\log{1 \over p_{fail} }\)</span> while <span class="math inline">\(\frac{n}{\delta^2}\log{1 \over p_{fail} }\)</span> equals to <span class="math inline">\(\frac{1000}{\delta^2}\log{1 \over p_{fail} }\)</span>.</p>
<p>Can we obtain an <span class="math inline">\((\delta, p_{fail})\)</span>-estimation <span class="math inline">\(\tilde \mu\)</span> with just <span class="math inline">\(O(\frac{1}{\delta^2 \mu}\log{1 \over p_{fail} })\)</span> samples, even though <span class="math inline">\(\mu\)</span> itself is unknown?</p>
<p>Yes we can (with the lost of a factor <span class="math inline">\(\log \log n\)</span>, which is almost negligible). First we relax the goal a little bit -- finding a <span class="math inline">\(\tilde \mu \in [\mu/2, 2 \mu]\)</span> instead of a <span class="math inline">\(\tilde \mu \in (1 \pm \delta) \mu\)</span>. We show how to achieve this with <span class="math inline">\(O(\frac{1}{\mu}\log{\log n \over p_{fail} })\)</span> samples.</p>
<p>The high level idea is to divide <span class="math inline">\([\frac{1}{n}, 1]\)</span> into a set of intervals <span class="math display">\[
\{ [\frac{1}{n}, \frac{1}{2^{ \log n  -1} }], ..., [\frac{1}{2^{i} }, \frac{1}{2^{i - 1} }], ...,, [\frac{1}{4}, \frac{1}{2}],   [\frac{1}{2}, 1]\}
\]</span> Let <span class="math inline">\([\frac{1}{2^{j} }, \frac{1}{2^{j - 1} }]\)</span> <span class="math inline">\((j \in N)\)</span> be the interval that <span class="math inline">\(u\)</span> belongs to.</p>
<figure>
<img src="http://imglf6.nosdn.127.net/img/Y1FUYmVJRmJqaTNrbC9RWmRCdlpzYVQyNS9OR00wSUwzdGgwRU9rZGV0anhzUlpaMVhBWVB3PT0.jpg?imageView&amp;thumbnail=1969y285&amp;type=jpg&amp;quality=96&amp;stripmeta=0&amp;type=jpg" alt="" /><figcaption>Figure</figcaption>
</figure>
<p>Given an integer <span class="math inline">\(i\)</span>, such that <span class="math inline">\(i \le j - 2\)</span> or <span class="math inline">\(i \ge j + 1\)</span>, we can determine whether <span class="math inline">\(\mu \ge \frac{1}{2^i}\)</span> with high probability. We generate <span class="math inline">\(O(2^i \log \frac{\log n}{p_{fail} })\)</span> samples and test whether their average (i.e., <span class="math inline">\(\tilde \mu\)</span>) is greater than <span class="math inline">\(\frac{1}{2^i}\)</span>. If <span class="math inline">\(\tilde \mu &gt; \frac{1}{2^i}\)</span>, by Chernoff inequality, <span class="math inline">\(\mu &gt; \frac{1}{2^i}\)</span> with high probability and the test returns true.</p>
<p>To search for the interval <span class="math inline">\([\frac{1}{2^{j} }, \frac{1}{2^{j - 1} }]\)</span> that <span class="math inline">\(\mu\)</span> belongs to, we perform the test for increasing values of <span class="math inline">\(i = 1, 2, ...\)</span> until we find the first <span class="math inline">\(i\)</span>, such that the test for <span class="math inline">\(\mu \ge \frac{1}{2^i}\)</span> returns true. We claim that with high probability, <span class="math inline">\(i\)</span> takes one of the following values: <span class="math inline">\(\{j - 1, j, j + 1 \}\)</span>. The reason is that the test returns false (with high probability) when <span class="math inline">\(i \le j - 2\)</span>. The results for <span class="math inline">\(i = j - 1\)</span> and <span class="math inline">\(j\)</span> are undetermined. Even if the test fails to return true for both <span class="math inline">\(i = j - 1\)</span> and <span class="math inline">\(j\)</span>, it returns true for <span class="math inline">\(i = j + 1\)</span> with high probability.</p>
<p>Finally, after we find an <span class="math inline">\(i \in \{j - 1, j, j + 1 \}\)</span>, we know that <span class="math inline">\(\mu \ge \frac{1}{2 \cdot 2^i}\)</span>. Therefore, <span class="math inline">\(O(2^i \log \frac{\log n}{p_{fail} })\)</span> samples gives an <span class="math inline">\((\delta, p_{fail})\)</span>-estimate of <span class="math inline">\(\mu\)</span>.</p>
<p>Then the total number of samples we generate is at most: <span class="math display">\[
\sum_{k = 1}^{j+1}O(2^k\log \frac{\log n}{p_{fail} }) = O(2^{j+2}\log \frac{\log n}{p_{fail} }) = O(\frac{1}{\mu}\log \frac{\log n}{p_{fail} })
\]</span></p>
<p>The procedure code is shown by Algorithm 1.</p>
<blockquote>
<p><strong>Algorithm 1</strong></p>
<ol type="1">
<li><strong>for</strong> <span class="math inline">\(i \leftarrow 1\)</span> to <span class="math inline">\(\log n - 1\)</span> <strong>do</strong></li>
<li><span class="math inline">\(\quad\)</span> Let <span class="math inline">\(\theta = 6 \cdot 2^i \log \frac{\log n}{p_{fail} }\)</span>.</li>
<li><span class="math inline">\(\quad\)</span> Let <span class="math inline">\(Y = 0\)</span></li>
<li><span class="math inline">\(\quad\)</span> <strong>for</strong> <span class="math inline">\(j \leftarrow 1\)</span> to <span class="math inline">\(\theta\)</span> <strong>do</strong></li>
<li><span class="math inline">\(\quad\)</span><span class="math inline">\(\quad\)</span> Generate a sample of <span class="math inline">\(X\)</span>, denoted by <span class="math inline">\(X_j\)</span>.</li>
<li><span class="math inline">\(\quad\)</span><span class="math inline">\(\quad\)</span> <span class="math inline">\(Y = Y + X_j\)</span>.</li>
<li><span class="math inline">\(\quad\)</span> <strong>if</strong> <span class="math inline">\(\frac{Y}{\theta} &gt; \frac{1}{2^i}\)</span> <strong>then</strong></li>
<li><span class="math inline">\(\quad\)</span> <span class="math inline">\(\quad\)</span> <strong>return</strong> <span class="math inline">\(\frac{Y}{\theta}\)</span></li>
<li><strong>return</strong> <span class="math inline">\(\frac{1}{n}\)</span></li>
</ol>
</blockquote>
<p>To analyse Algorithm 1, we use the following Chernoff Bounds.</p>
<p><strong>Chernoff Bound</strong></p>
<blockquote>
<p>Let <span class="math inline">\(X_1, X_2, ..., X_\theta\)</span> be <span class="math inline">\(i.i.d.\)</span> Bernoulli random variables with mean <span class="math inline">\(\mu\)</span> and <span class="math inline">\(Y = \frac{1}{\theta} \sum_{k =1}^\theta X_k\)</span>. Then</p>
<ol type="1">
<li><span class="math inline">\(P[Y \ge (1 + \delta) \mu] \le \exp(- \frac{\delta^2}{\delta + 2} \theta \mu)\)</span>.</li>
<li><span class="math inline">\(P[Y \le (1 - \delta) \mu] \le \exp(- \frac{\delta^2}{2} \theta \mu)\)</span></li>
</ol>
</blockquote>
<p>Corollary</p>
<blockquote>
<p>For an integer <span class="math inline">\(k \ge 1\)</span>,</p>
<ol type="1">
<li><span class="math inline">\(P[Y \ge 2^k \mu] \le \exp (- \frac{(2^k -1)^2}{2^k + 1} \theta \mu) \le \exp(- \frac{2^{2k - 2} }{2^k + 1} \theta \mu) = \exp(-\frac{2^k}{4(1+ {1} / {2^k})} \theta \mu) \le \exp(-\frac{2^k}{6} \theta \mu)\)</span></li>
<li><span class="math inline">\(P[Y \le \frac{1}{2^k}\mu] \le \exp(-\frac{(1-\frac{1}{2^k})^2}{2} \theta \mu) \le \exp(-\frac{1}{8}\theta \mu)\)</span></li>
</ol>
</blockquote>
<p><strong>Theorem</strong></p>
<blockquote>
<p>Let <span class="math inline">\(X_1, X_2, ..., X_\theta\)</span> be <span class="math inline">\(i.i.d.\)</span> Bernoulli random variables with mean <span class="math inline">\(\mu \in [\frac{1}{2^j}, \frac{1}{2^{j - 1} }]\)</span> and <span class="math inline">\(Y = \frac{1}{\theta} \sum_{k =1}^\theta X_k\)</span>. Suppose <span class="math inline">\(\theta = 6 \cdot 2^i \log \frac{\log n}{p_{fail} }\)</span> for some <span class="math inline">\(i\)</span>, then</p>
<ol type="1">
<li><span class="math inline">\(P[Y \ge \frac{1}{2^i}] \le \frac{p_{fail} }{\log n}\)</span>, if <span class="math inline">\(i \le j - 2\)</span>,</li>
<li><span class="math inline">\(P[Y \le \frac{1}{2^i}] \le \frac{p_{fail} }{2^{i - j - 1} \log n}\)</span>, if <span class="math inline">\(i \ge j + 1\)</span>.</li>
</ol>
</blockquote>
<p>Proof: First consider <span class="math inline">\(i \le j - 2\)</span>. Then <span class="math inline">\(\frac{1}{2^i} \ge 2^{j - 1 - i} \mu\)</span> , <span class="math inline">\(2^{j - 1} \mu \ge 1\)</span> and <span class="math display">\[
\begin{aligned}
P[Y \ge \frac{1}{2^i}] 
&amp;\le P[Y \ge 2^{j - 1 - i} \mu] \\
&amp;\le \exp(-\frac{2^{j- 1 - i} }{6}\theta \mu) \\
&amp;= \exp(-\frac{2^{j - 1} \mu \cdot 2^{-i}\theta}{6}) \\
&amp;\le\exp(-\frac{2^{-i}\theta}{6}) \\
&amp;\le \frac{p_{fail} }{\log n}
\end{aligned}
\]</span></p>
<p>For <span class="math inline">\(i \ge j + 1\)</span>, we have <span class="math inline">\(\frac{1}{2^{i} } \le \frac{1}{2^{i - j} } \mu\)</span> , <span class="math inline">\(i - j \ge 1\)</span> and <span class="math display">\[
\begin{aligned}
P[ Y \le \frac{1}{2^{i} }] &amp;\le P [Y \le \frac{1}{2^{i - j} } \mu] \\
&amp;\le \exp(-\frac{\mu \theta}{8}) \\
&amp;\le \exp(-\frac{2^{-j}\theta }{8}) \\
&amp;\le \frac{p_{fail} }{2^{i - j -1}\log n}
\end{aligned}
\]</span></p>
<p>It follows that by union bound the test fails for all <span class="math inline">\(i = 1, 2, ..., j - 2, j + 1\)</span> is at most <span class="math inline">\(\frac{p_{fail} }{\log n} \cdot (j - 1) \le p_{fail}\)</span>.</p>
<h5 id="exercise">Exercise</h5>
<ol type="1">
<li>Given a Bernoulli random variable <span class="math inline">\(X\)</span> with mean <span class="math inline">\(\mu\)</span>, prove that (with Chernoff bound) if we generate <span class="math inline">\(\Omega(\frac{1}{\delta^2 \mu}\log{1 \over p_{fail} })\)</span> independent samples, we get an estimate of <span class="math inline">\(X\)</span> with relative error <span class="math inline">\(\delta\)</span> with probability <span class="math inline">\(1 - p_{fail}\)</span>.</li>
</ol>
<h5 id="reference">Reference:</h5>
<ol type="1">
<li>Tang Youze, Xiaokui Xiao, and Yanchen Shi. "Influence maximization: Near-optimal time complexity meets practical efficiency." <em>Proceedings of the 2014 ACM SIGMOD international conference on Management of data</em>. ACM, 2014.</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/09/01/Vertex-Cover/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/09/01/Vertex-Cover/" class="post-title-link" itemprop="url">Vertex Cover</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-09-01 08:59:27" itemprop="dateCreated datePublished" datetime="2018-09-01T08:59:27+10:00">2018-09-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2018-09-04 01:32:44" itemprop="dateModified" datetime="2018-09-04T01:32:44+10:00">2018-09-04</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Given an undirected graph <span class="math inline">\(G = &lt;V, E&gt;\)</span> in which each vertex <span class="math inline">\(i\)</span> is associated with a weight <span class="math inline">\(w_i\)</span>, vertex cover asks for the subset of vertices with minimum weight such that every each in <span class="math inline">\(G\)</span> is incident to at least one vertex in the set. The problem can be formulate as integer program and relaxed as linear program: let <span class="math inline">\(x_i \in [0, 1]\)</span> be a variable associated with the <span class="math inline">\(i\)</span> vertex, <span class="math inline">\(n\)</span> be the number of vertices and <span class="math inline">\(m\)</span> the number of edges,</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\min  &amp; \sum_{i = 1}^n w_i x_i &amp;  &amp;\\
&amp;s.t., &amp; x_i + x_j \ge 1 &amp; &amp; \forall e = (i,j) \in E \\
&amp;      &amp; x_i \ge 0       &amp; &amp; \forall i \in [n] 
\end{aligned}
\]</span></p>
<p>Its dual is given by</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\max  &amp; \sum_{e \in E} y_e &amp;  &amp;\\
&amp;s.t., &amp; \sum_{(i, j) \in E} y_{i, j} \le w_i &amp; &amp; \forall i \in [n] \\
&amp;      &amp; y_{i, j} \ge 0       &amp; &amp; \forall e = (i, j) \in e
\end{aligned}
\]</span></p>
<p>By weak duality, <span class="math display">\[
\sum_{(i, j) \in E} y_{i, j} \le \sum_{(i,j) \in E} (x_i + x_j ) y_{i, j} = \sum_{i = 1}^n \left( \sum_{(i, j) \in E} y_{i, j}\right) x_i \le \sum_{i = 1}^n w_i x_i
\]</span></p>
<p>Let <span class="math inline">\(x^*\)</span> and <span class="math inline">\(y^*\)</span> denotes the primal and dual optimal solutions respectively. By strong duality, the complementary slackness states that <span class="math display">\[
\begin{aligned}
&amp; x_i + x_j = 1 &amp;\vee &amp;&amp; y_{i, j} = 0 &amp;&amp; (1)\\
&amp; \sum_{(i, j) \in E} y^*_{i, j} = w_i &amp;\vee &amp;&amp; x^* = 0 &amp;&amp; (2)
\end{aligned}
\]</span></p>
<p>Now we show how to use this condition to construct an approximate primal solution. We begin with an initial values of <span class="math inline">\(x = (0, 0, ..., 0)\)</span> and <span class="math inline">\(y = (0, 0, ..., 0)\)</span>. Note that <span class="math inline">\(y\)</span> is a dual feasible solution and condition <span class="math inline">\((2)\)</span> holds. However <span class="math inline">\(x\)</span> is not a primal feasible solution. In the following we give an algorithm that maintains the feasibility of <span class="math inline">\(y\)</span> and condition <span class="math inline">\((2)\)</span> while restores the feasibility of <span class="math inline">\(x\)</span>.</p>
<blockquote>
<p>Algorithm 1 -- an 2 approximation algorithm<br />
while <span class="math inline">\(\exists (i, j) \in E, s.t., x_i + x_j &lt; 1\)</span><br />
<span class="math inline">\(\quad\)</span> increase <span class="math inline">\(y_{i, j}\)</span> as much as possible until either &gt; <span class="math inline">\(1. \quad \sum_{(i, k) \in E} y_{i, k} = w_i\)</span>, then set <span class="math inline">\(x_i = 1\)</span><br />
&gt; <span class="math inline">\(2. \quad \sum_{(j, k) \in E} y_{j, k} = w_j\)</span>, then set <span class="math inline">\(x_j = 1\)</span></p>
</blockquote>
<p>Note that in the inner loop, if two conditions hold simultaneously, we need only set one of <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_j\)</span> to 1.</p>
<p>Now we analyze the algorithm. It is apparent that <span class="math inline">\(\sum_{(i, j) \in E} y_{i,j} \le w_i \forall i \in [i]\)</span> holds throughout the algorithm. Moreover, for <span class="math inline">\(i \in [i]\)</span>, <span class="math inline">\(x_i = 0\)</span> or <span class="math inline">\(x_i = 1\)</span>. In the latter case, we must have <span class="math inline">\(\sum_{(i, k) \in E} y_{i, k} = w_i\)</span>. We conclude that when the algorithm terminates,</p>
<p><span class="math display">\[
\sum_{(i, j) \in E} y_{i, j} \le \sum_{i = 1}^n w_i x_i =  \sum_{i = 1}^n \left( \sum_{(i, j) \in E} y_{i, j}\right) x_i  = \sum_{(i,j) \in E} (x_i + x_j ) y_{i, j}  
\]</span></p>
<p>But <span class="math inline">\(x_i + x_j\)</span> is at most <span class="math inline">\(2\)</span>, therefore <span class="math inline">\(\sum_{(i, j) \in E} y_{i, j} \le \sum_{i = 1}^n w_i x_i \le 2\sum_{(i, j) \in E} y_{i, j}\)</span>.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/08/28/Heavy-Hitter/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/08/28/Heavy-Hitter/" class="post-title-link" itemprop="url">Heavy Hitter</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-08-28 14:03:26" itemprop="dateCreated datePublished" datetime="2018-08-28T14:03:26+10:00">2018-08-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-06-05 00:38:04" itemprop="dateModified" datetime="2019-06-05T00:38:04+10:00">2019-06-05</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Given a sequence of numbers <span class="math inline">\(S = \{ x_1, x_2, ..., x_n \}\)</span> where each element comes from a finite domain <span class="math inline">\(U\)</span>, the heavy hitter problem asks for the element that appears at least <span class="math inline">\(\frac{n}{k + 1} + 1\)</span> times in the sequence. Note that there could be at most <span class="math inline">\(k\)</span> such elements.</p>
<h2 id="deterministic">Deterministic</h2>
<p>If false positive is allowed, we have a deterministic algorithm that has <span class="math inline">\(O(k)\)</span> space overhead.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">L = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> S:</span><br><span class="line">    <span class="keyword">if</span> x <span class="keyword">in</span> L:</span><br><span class="line">        L[x] = L[x] + <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">len</span>(L) &lt; k:</span><br><span class="line">        L[x] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        decrement the value of every elements <span class="keyword">in</span> L by <span class="number">1</span></span><br><span class="line">        delete elements <span class="keyword">in</span> L <span class="keyword">with</span> value = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>To see the correctness of the algorithm, we give each element in <span class="math inline">\(S\)</span> a token. There are <span class="math inline">\(n\)</span> tokens in total. If a element is not added to the list <span class="math inline">\(L\)</span>, <span class="math inline">\(k + 1\)</span> token are throw away. If an elements appears more than <span class="math inline">\(\frac{n}{k + 1}\)</span> times, it must appears in <span class="math inline">\(L\)</span> when the algorithm terminates.</p>
<p>Another way to prove this is that, each time an element is thrown away, it is not in the counter and the sum of counter decremented is <span class="math inline">\(k\)</span>. Let <span class="math inline">\(f_x\)</span> be the frequency of an element <span class="math inline">\(x\)</span>. Then the maximum number of times <span class="math inline">\(x\)</span> is thrown away is bounded by <span class="math inline">\(k f_x \le n - f_x\)</span>, which implies that <span class="math inline">\(f_x \le \frac{n}{k + 1}\)</span>.</p>
<h2 id="randomized">Randomized</h2>
<p>An alternate approach is randomized algorithm. In high level, we would like to maintain a set of <span class="math inline">\(m\)</span> bins and assign each element in <span class="math inline">\(U\)</span> uniformly at random one of the bins. Then we put each number in <span class="math inline">\(S\)</span> into the <span class="math inline">\(m\)</span> bins according which bin it is assigned to. In expectation, each bin will receive <span class="math inline">\(\frac{n}{m}\)</span> elements. To estimate the number of time an element <span class="math inline">\(x\)</span> appears in <span class="math inline">\(S\)</span>, we just return the number of elements of the bin <span class="math inline">\(x\)</span> is assigned. Note that we might overestimate <span class="math inline">\(x\)</span>'s frequency, whose expectation is at most <span class="math inline">\(\frac{n}{m}\)</span>. We might repeat this several time to reduce variance.</p>
<p>The tools to achieve the idea are <span class="math inline">\(t\)</span> hash functions <span class="math inline">\(h_1, h_2, ..., h_t : S \rightarrow [m]\)</span>. Initially, we have <span class="math inline">\(l\)</span> list (denoted as <span class="math inline">\(L_1, L_2, .., L_t\)</span>) where each list has size <span class="math inline">\(m\)</span>. Then we go through elements in <span class="math inline">\(S\)</span>. For each element <span class="math inline">\(x\)</span>, we increment the <span class="math inline">\(L_i[h_i(x)]\)</span> by 1 for all <span class="math inline">\(i \in [t]\)</span>. Finally for an element <span class="math inline">\(x\)</span>, we use the minimum value <span class="math inline">\(\min_i \{ L_i[h_i(x)] \}\)</span> as its frequency estimation.</p>
<p><span class="math display">\[
\begin{aligned}
E[L_i[h_i(x)]] 
&amp;= f_x + \sum_{y \in S, y \neq x} P [h_i (y) \\
&amp;= f_x + \frac{(n - f_x)}{m} \\
&amp;\le f_x + \frac{n}{m}
\end{aligned}
\]</span></p>
<p>By Markov inequality,<br />
<span class="math display">\[
P[ L_i[h_i(x)] -  f_x &gt;  2 \frac{n}{m}] \le \frac{E[L_i[h_i(x)] - f_x]}{ 2 \frac{n}{m} }  \le \frac{ \frac{n}{m} }{ 2 \frac{n}{m} }  \le \frac{1}{2}
\]</span></p>
<p>Therefore,<br />
<span class="math display">\[
P[ \min_i \{ L_i[h_i(x)] \} - f_x &gt; 2 \frac{n}{m}] \le \frac{1}{2^t}
\]</span></p>
<p>which decreases exponentially with respect to the size of <span class="math inline">\(t\)</span>. If we would like the failure probability to be <span class="math inline">\(\delta\)</span>, we need to set <span class="math inline">\(t = O(\log \frac{1}{\delta})\)</span>.</p>
<p>In conclusion, we can return the estimation of frequency of elements, such that <span class="math inline">\(\forall x \in U\)</span>, <span class="math inline">\(\tilde{f_x} \le f_x + 2\frac{n}{m}\)</span>, with probability at least <span class="math inline">\(1 - \delta\)</span> and space overhead <span class="math inline">\(O(m \log \frac{1}{\delta})\)</span>.</p>
<p>Reference:</p>
<ol type="1">
<li>MIT 6.854/18.415: Advanced Algorithms, Spring 2016, Lecture 4</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/08/27/Consistent-Hashing/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/08/27/Consistent-Hashing/" class="post-title-link" itemprop="url">Consistent Hashing</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2018-08-27 19:55:06 / Modified: 22:25:55" itemprop="dateCreated datePublished" datetime="2018-08-27T19:55:06+10:00">2018-08-27</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Suppose that we would like to implement a distributed file system. There are <span class="math inline">\(m\)</span> files and <span class="math inline">\(n\)</span> servers to store the file. We want to spread the work load to the servers so that each one keeps approximate <span class="math inline">\(\frac{m}{n}\)</span> files. One way to achieve this is by hashing. Let <span class="math inline">\(p \gg m\)</span> be a prime number. Then <span class="math display">\[
h(x) = ax + b \mod p \mod n
\]</span> gives us the desired property if <span class="math inline">\(a \in \{1, 2, ..., p -1\}\)</span> and <span class="math inline">\(b \in \{0, 1, 2, ..., p - 1\}\)</span> are selected uniformly at random.</p>
<p>The problem is that what if <span class="math inline">\(n\)</span> changes constantly?</p>
<p>Consider mapping the <span class="math inline">\(n\)</span> servers uniformly and independently to real numbers in <span class="math inline">\([0, 1]\)</span>. Let's divide <span class="math inline">\([0, 1]\)</span> into <span class="math inline">\(n\)</span> equally sized intervals <span class="math inline">\([0, 1/n]\)</span>, <span class="math inline">\([1/n, 2/n]\)</span>, ..., <span class="math inline">\([(n - 1)/n, 1]\)</span>. Now, for an interval that a particular server belongs, the probability that no server maps to the <span class="math inline">\(2 \log n\)</span> intervals to the left of this interval is given by</p>
<p><span class="math display">\[
(1 - \frac{2 log n}{n})^{n - 1} \le e^{-\frac{2 log n}{n} (n - 1)} = \frac{1}{n^2} e^{\frac{2 log n}{n}} \le \frac{e}{n^2}
\]</span></p>
<p>By union bound, this happens to some server is bounded by <span class="math inline">\(\frac{e}{n}\)</span>.</p>
<p>What is the probability that the interval between some pair of servers is <span class="math inline">\(O(1 / n^2)\)</span>. If we divide <span class="math inline">\([0, 1]\)</span> into <span class="math inline">\(\Theta(n^2)\)</span> equally size intervals, by Birthday's Paradox, there is high probability that some interval contains two servers.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/08/26/Birthday-Paradox/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/08/26/Birthday-Paradox/" class="post-title-link" itemprop="url">Birthday Paradox</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-08-26 11:29:30" itemprop="dateCreated datePublished" datetime="2018-08-26T11:29:30+10:00">2018-08-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-12-09 18:34:28" itemprop="dateModified" datetime="2020-12-09T18:34:28+11:00">2020-12-09</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Suppose that we throw <span class="math inline">\(m\)</span> balls into <span class="math inline">\(n\)</span> bins uniformly at random, where <span class="math inline">\(n\)</span> is a fixed number. What is the probability that some pair of balls are placed in the same bin?</p>
<p>Define <span class="math inline">\(X_{i, j}\)</span> be the indicator variable that the <span class="math inline">\(i\)</span>-th ball and the <span class="math inline">\(j\)</span>-th ball go to the same bin. Its expectation is given by</p>
<p><span class="math display">\[
E[X_{i,j}] = 1\cdot P[ X_{i,j} = 1] + 0 \cdot P[X_{i,j} = 0] = \frac{1}{n}.
\]</span></p>
<p>By linearity of expectation, we have <span class="math display">\[
E[\sum_{1 \le i &lt; j \le m} X_{i,j}] = \sum_{1 \le i &lt; j \le m} E[X_{i,j}] = \frac{m (m - 1)}{2n}.
\]</span></p>
<p>When <span class="math inline">\(m \approx \sqrt{2n}\)</span>, in expectation, there is a pair of ball going to the same bin. However, this estimate is too loose.</p>
<p>Define <span class="math inline">\(p(m, n)\)</span> the exact probability that no ball goes to the same bin. Then</p>
<p><span class="math display">\[
p(m, n) = \prod_{i = 0}^m \frac{n - i}{n} = \prod_{i = 0}^m (1 - \frac{i}{n}).
\]</span></p>
<p>By inequality <span class="math inline">\(1 - \frac{i}{n} \le e^{- \frac{i}{n} }\)</span>, we have a upper bound for the above probability: <span class="math display">\[
p(m, n) \le  e^{- \frac{m (m - 1)}{2n} }. 
\]</span></p>
<p>Therefore, the probability that there is at least one collision is lower bounded by <span class="math display">\[
1 - e^{- \frac{m (m - 1)}{2n} }. 
\]</span></p>
<p>If <span class="math inline">\(m = \sqrt n\)</span>, we get <span class="math inline">\(e^{- \frac{m (m - 1)}{2n} } \approx e^{-\frac{1}{2} } \approx 0.6\)</span>. If <span class="math inline">\(m = 2 \sqrt n\)</span>, we get <span class="math inline">\(e^{- \frac{m (m - 1)}{2n} } \approx e^{-2} \approx 0.14\)</span>.</p>
<p>In the case <span class="math inline">\(n = 365\)</span>, we say that if there are <span class="math inline">\(\sqrt n \approx 19\)</span> people, <span class="math inline">\(40\%\)</span> of times some pair of them share the same birthday. If there are <span class="math inline">\(36\)</span> people, the probability is over <span class="math inline">\(80\%\)</span>.</p>
<p><em>Remark:</em> let's play some math to bound <span class="math inline">\(p(m, n)\)</span> asymptotically. First, when <span class="math inline">\(x \le 1 / 2\)</span>, we have <span class="math display">\[
e^x = \sum_{i = 0}^\infty x^i / i! \le 1 + x + \frac{x^2}{2} \left( \sum_{i = 0}^\infty ( \frac{1}{2})^i \right) \le 1 + 2 x.
\]</span></p>
<p>Hence, <span class="math display">\[
p(m, n) \le  e^{- \frac{m (m - 1)}{2n} } \le \exp( -\frac{m^2}{2n} ) \cdot (1 + \frac{m}{n} ). 
\]</span></p>
<p>On the other hand, for <span class="math inline">\(k \in \mathbb{N}^+\)</span>, <span class="math display">\[
(1 - x) ( \sum_{i = 0}^k  x^k) = 1 - x^{k + 1}.
\]</span></p>
<p>when <span class="math inline">\(|x| &lt; 1\)</span>, <span class="math display">\[
(1 - x) ( \sum_{i = 0}^\infty  x^i) = \lim_{k \rightarrow \infty} (1 - x^{k + 1} ) = 1.
\]</span></p>
<p>Therefore, when <span class="math inline">\(|x| &lt; 1\)</span>, <span class="math display">\[
\frac{1}{1 - x} = \sum_{i = 0}^\infty x^i. 
\]</span></p>
<p>Replacing <span class="math inline">\(x\)</span> with <span class="math inline">\(-x\)</span>, we get <span class="math display">\[
\frac{1}{1 + x} = \sum_{i = 0}^\infty (-1)^i x^i = 1 - x + x^2 - x^3 + ...
\]</span></p>
<p>By <span class="math inline">\((\ln (1 + x) )&#39; = \frac{1}{1 + x}\)</span>, we get <span class="math display">\[
\ln (1 + x) = x - \frac{x^2}{2} + \frac{x^3}{3} - ...
\]</span></p>
<p>and <span class="math display">\[
\ln (1 - x) = - x - \frac{x^2}{2} - \frac{x^3}{3} - ...
\]</span></p>
<p>When <span class="math inline">\(x \le 1 / 2\)</span>, we get <span class="math display">\[
\ln (1 - x) \ge - x - \frac{x^2}{2}( \sum_{i = 0}^\infty (\frac{1}{2})^i ) = -x - x^2.
\]</span></p>
<p>So, when <span class="math inline">\(m &lt; n / 2\)</span>, <span class="math display">\[
\begin{aligned}
    p(m, n) 
        &amp;= \prod_{i = 0}^m (1 - \frac{i}{n}) \\
        &amp;\ge \exp( - \sum_{i = 0}^m \frac{i}{n} - \sum_{i = 0}^m \frac{i^2}{n^2}) \\
        &amp;\ge \exp( - \frac{m (m - 1)}{2n} ) ( 1 - \sum_{i = 0}^m \frac{i^2}{n^2}) \\
        &amp;\ge \exp( - \frac{m^2}{2n} ) ( 1 - O( \frac{m^3}{n^2} ) ). 
\end{aligned}
\]</span></p>
<p>Combined, we get <span class="math display">\[
\exp( - \frac{m^2}{2n} ) ( 1 - O( \frac{m^3}{n^2} ) ) \le p(m, n) \le \exp( - \frac{m^2}{2n} ) ( 1 - m / n ). 
\]</span></p>
<p>If <span class="math inline">\(m &lt; \sqrt n\)</span>, then <span class="math inline">\(m^3 / n^2 &lt; m / n\)</span>. In this case, <span class="math display">\[
p(m, n) = \Theta \left( \exp( - \frac{m^2}{2n} ) ( 1 - m / n ) \right). 
\]</span></p>
<p>Replacing <span class="math inline">\(m = \sqrt{2 n\ln 2}\)</span>, then <span class="math display">\[
p(m, n) = \frac{1}{2} + \Theta( \frac{1}{\sqrt n}). 
\]</span></p>
<h3 id="reference.">Reference.</h3>
<p>[1]. Ryan O'Donnell, Lecture 3, CS Theory Toolkit, CARNEGIE MELLON UNIVERSITY</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/4/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/6/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description">你生之前悠悠千載已逝，未來還會有千年沉寂的期待</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">125</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WOW</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
