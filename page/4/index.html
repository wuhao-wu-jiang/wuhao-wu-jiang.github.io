<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
<meta property="og:type" content="website">
<meta property="og:title" content="WOW">
<meta property="og:url" content="http://example.com/page/4/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/4/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>WOW</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">WOW</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/10/28/Minimax-Theorem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/10/28/Minimax-Theorem/" class="post-title-link" itemprop="url">Minimax Theorem</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2019-10-28 18:54:52 / Modified: 20:00:38" itemprop="dateCreated datePublished" datetime="2019-10-28T18:54:52+11:00">2019-10-28</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>A zero-sum game is a game in which a player's payoff implies the loss of another player. It is specified by a matrix <span class="math inline">\(A \in R^{n \times m}\)</span>. The row player can choose from rows <span class="math inline">\(\{1, 2, ..., n\}\)</span> and the column player chooses from columns <span class="math inline">\(\{1, 2, ..., m\}\)</span>. The entry <span class="math inline">\(a_{ij}\)</span> of <span class="math inline">\(A\)</span> is the payoff when the row player chooses <span class="math inline">\(i\)</span> and the column player chooses <span class="math inline">\(j\)</span>. In such case the column player loses <span class="math inline">\(a_{ij}\)</span>.</p>
<p>If one player makes a choice first and the other play follows, then the second player can always respond according the first player choice, to maximize its payoff or minimize its loss.</p>
<p>To make the game more fair, we require the row player to act with strategy <span class="math inline">\(x \in R^n\)</span>, i.e., a distribution on the the rows, and the column player to act with strategy <span class="math inline">\(y \in R^m\)</span>. At each round, the row player and column player act independently. Then the expected payoff is <span class="math display">\[
x^TAy
\]</span></p>
<p>But what is some player knows the other's strategy? In this scenario, the row player choose its strategy <span class="math inline">\(x\)</span> first and the column player responds by a strategy <span class="math inline">\(y\)</span>, or vise versa. Note that at each round they still act independently according to their strategies. The question is, whether the order of choosing a strategy implies a difference in the expected payoff.</p>
<p>First we write down what the expected payoff is. If the row player commit to a strategy <span class="math inline">\(x\)</span> first, the column player will choose a distribution <span class="math inline">\(y\)</span> minimize it expected loss: <span class="math display">\[
\min_y x^T A y
\]</span> As <span class="math inline">\(x\)</span> is known, this is equivalent to choosing the column with minimum value: <span class="math display">\[
\min_{j \in [m]} x^T A e_j
\]</span></p>
<p>Understanding the expected behavior of the column player, the row player should choose a strategy <span class="math inline">\(x\)</span>, such that in the worst case, its expected payoff is maximized: <span class="math display">\[
\max_{x} (\min_y x^T A y) = \max_{x} (\min_{j \in [m]} x^T A e_j)
\]</span></p>
<p>Similarly, if the column player play first, the expected payoff is <span class="math display">\[
 \min_y (\max_{x} x^T A y) = \min_{y} (\max_{i \in [n]} e_i^T A y)
\]</span></p>
<p>The minimax-theorem states that <span class="math display">\[
\begin{aligned}
&amp;\max_{x} (\min_y x^T A y) 
&amp;= \max_{x} (\min_{j \in [m]} x^T A e_j) \\
= &amp;\min_y (\max_{x} x^T A y) 
&amp;= \min_{y} (\max_{i \in [n]} e_i^T A y)
\end{aligned}
\]</span></p>
<p>The proof is not difficult, by formulating the two optimizing problems as linear programming, and observing that they are dual to each other. If the row player goes first, <span class="math display">\[
\begin{aligned}
&amp;\max v \\
&amp;v  -  \sum_{i = 1}^n a_{ij} x_i \le 0  &amp; \forall j \in [m] \\
&amp;\sum_{i = 1}^n x_i = 1 \\
&amp;x_i \ge 0 &amp; \forall i \in [n]
\end{aligned}
\]</span></p>
<p>To upper bound <span class="math inline">\(v\)</span>, we introduce a variable <span class="math inline">\(u \in R\)</span>. By noticing <span class="math inline">\(\sum_{j = 1}^m y_j = 1\)</span> and <span class="math inline">\(y_j \ge 0\)</span>, we have</p>
<p><span class="math display">\[
\begin{aligned}
u&amp;\ge \sum_{j = 1}^m y_j (v  -  \sum_{i = 1}^n a_{ij} x_i) + u(\sum_{i = 1}^n x_i) \\
&amp;= v (\sum_{j = 1}^m y_j) + \sum_{i = 1}^n x_i( u - \sum_{j = 1}^m a_{ij} y_j) \\
&amp;\ge v
\end{aligned}
\]</span></p>
<p>which gives the dual program: <span class="math display">\[
\begin{aligned}
&amp;\min u \\
&amp;u  -  \sum_{j = 1}^m a_{ij} y_j \ge 0  &amp; \forall i \in [n] \\
&amp;\sum_{i = 1}^m y_j = 1 \\
&amp;y_j \ge 0 &amp; \forall j \in [m]
\end{aligned}
\]</span></p>
<p>Strong duality tells us that the optimal value of the two program equals.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/10/08/Balanced-Binary-Search-Tree/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/10/08/Balanced-Binary-Search-Tree/" class="post-title-link" itemprop="url">Balanced Binary Search Tree</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-10-08 11:49:33" itemprop="dateCreated datePublished" datetime="2019-10-08T11:49:33+11:00">2019-10-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-10-11 12:17:57" itemprop="dateModified" datetime="2019-10-11T12:17:57+11:00">2019-10-11</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>It is the depth of the binary search that affects the performance of it. We say that a binary search tree with <span class="math inline">\(n\)</span> nodes is balanced if its depth is of order <span class="math inline">\(O(\log n)\)</span> (hence we can perform find, insert and delete operations in time <span class="math inline">\(O(\log n)\)</span>).</p>
<p>If a tree is unbalanced, we can maintain the balance by rotation. Further, we need some criteria to guide the rotation. In what's follows we discuss some of the popular design of the criteria.</p>
<h4 id="by-the-number-of-elements-of-the-subtree.">By the number of elements of the subtree.</h4>
<p>Denote a note <span class="math inline">\(v\)</span> and its left and right child <span class="math inline">\(v.left\)</span> and <span class="math inline">\(v.right\)</span> respectively. Define the size of <span class="math inline">\(v\)</span> (<span class="math inline">\(s(v)\)</span>) the number of elements contained in the subtree rooted at <span class="math inline">\(v\)</span>.</p>
<p>A critical observation is that, if for each node <span class="math inline">\(v\)</span> of the tree, the size of each of it subtrees is at most a constant fraction <span class="math inline">\(\big(\)</span> denoted as <span class="math inline">\(\epsilon \in (\frac{1}{2}, 1)\)</span>; Exercise: why can't we pick <span class="math inline">\(\epsilon \in [0, \frac{1}{2}] \big)\)</span> of its size, i.e., <span class="math display">\[
s(v.left) \le \epsilon s(v) \\
s(v.right) \le \epsilon s(v) 
\]</span> then the depth of the tree is in the order of <span class="math inline">\(O(\log n)\)</span>. The reason is obvious: let <span class="math inline">\(r = v_0, v_1, v_2, ..., v_k\)</span> be any root-to-leaf path of the tree, then <span class="math display">\[
s(v_1) \le \epsilon s(v_0) \\
s(v_2) \le \epsilon s(v_1) \\
...\\
s(v_k) \le \epsilon s(v_{k - 1})
\]</span> it follows that <span class="math inline">\(1 = s(v_k) \le \epsilon^k s(v_0) = \epsilon^k n\)</span> and <span class="math inline">\(k \le \log_\epsilon \frac{1}{n} = O(\log n)\)</span>.</p>
<p>Therefore, we can pick arbitrary <span class="math inline">\(\epsilon \in (\frac{1}{2}, 1)\)</span> and maintain this criteria explicitly and recursively.</p>
<p>WLOG, suppose a new element is inserted into the left subtree of a vertex <span class="math inline">\(v\)</span>. Denote the new size function <span class="math inline">\(s\)</span> as <span class="math inline">\(s&#39;\)</span> after insertion. If after insertion, <span class="math inline">\(s&#39;(v.left) \le \epsilon s&#39;(v)\)</span>, we do nothing and check the balance of <span class="math inline">\(v\)</span>'s parent (if there is any). Otherwise, we may try a right rotation on <span class="math inline">\(v\)</span>: <span class="math display">\[
\begin{aligned}
&amp;\qquad \qquad v \\
&amp;/           &amp;\setminus \\
&amp;v.left      &amp;&amp;v.right \\
/           &amp;\setminus \\
v.left.left &amp; \quad v.left.right
\end{aligned}
\]</span> the subtree transform into: <span class="math display">\[
\begin{aligned}
&amp;\qquad \qquad v.left \\
&amp;/         &amp;\setminus \\
v.left.left     &amp;&amp; v\\
           &amp;&amp;/  &amp;\setminus \\
 &amp;&amp; v.left.right &amp; \quad v.right
\end{aligned}
\]</span> Since before insertion, <span class="math inline">\(s(v.left) \le \epsilon s(v)\)</span>, it holds that <span class="math inline">\(s&#39;(v.left.left) \le \epsilon s&#39;(v.left) = \epsilon (s(v) + 1)\)</span>. Therefore, the left subtree no longer violate the balance constraint. However, the constraint could be violated by the right subtree. Since it is possible that <span class="math display">\[
s&#39;(v.left.right) + s&#39;(v.right) + 1 &gt; \epsilon s&#39;(v.left) = \epsilon (s(v)  + 1)
\]</span> For example, suppose that <span class="math inline">\(\epsilon = 0.8\)</span> and <span class="math inline">\(s(v.left.right) = 0.8 s(v.left) = 0.64 s(v)\)</span> and <span class="math inline">\(s(v.right) = 0.2 s(v) - 1\)</span>, then <span class="math display">\[
s(v.left.right) + s(v.right) + 1 = 0.84 s(v)
\]</span> The reason is that there is so much weight that <span class="math inline">\(v.left.right\)</span> has. Therefore, we don't want to rotate it to the right subtree. An alternative is to perform a left rotate on the left subtree first <span class="math display">\[
\begin{aligned}
&amp;\qquad \qquad v \\
&amp;/           &amp;\setminus \\
&amp;v.left.right      &amp;&amp;v.right \\
/           &amp;\setminus \\
v.left &amp; \quad v.left.right.right \\
/ \setminus &amp; \\
v.left.left &amp; \quad v.left.right.left
\end{aligned}
\]</span> Followed by a right rotation on <span class="math inline">\(v\)</span>: <span class="math display">\[
\begin{aligned}
&amp;\qquad \qquad v.left.right  \\
&amp;/           &amp;\setminus \\
&amp;v.left     &amp;&amp;v \\
/ &amp;\setminus   &amp;&amp;/ \setminus\\
v.left.left &amp;\quad v.left.right.left&amp; \quad v.left.right.right &amp;\quad v.right\\ 
\end{aligned}
\]</span></p>
<p>To satisfy the balance requirement, we require that</p>
<ol type="1">
<li><span class="math inline">\(s&#39;&#39;(v.left.right.left) = s&#39;(v.left.right.left) \le \epsilon s&#39;&#39;(v.left) = \epsilon (s&#39;(v.left) - s&#39;(v.left.right.right) -1 )\)</span>.</li>
<li><span class="math inline">\(s&#39;(v.left.left) \le s&#39;(v.left)\)</span></li>
<li><span class="math inline">\(s&#39;(v.left.right.right) + s&#39;(v.right) + 1 \le \epsilon s&#39;(v.left.right)\)</span></li>
</ol>
<p>Condition 1 implies that <span class="math inline">\(s&#39;(v.left.right.right)\)</span> can take up too much weight of <span class="math inline">\(s&#39;(v.left)\)</span>, which imposes an upper bound on <span class="math inline">\(\epsilon\)</span> by <span class="math display">\[
 (1 - \epsilon) \epsilon s&#39;(v.left) - 1 \le \epsilon (s&#39;(v.left) - \epsilon^2s&#39;(v.left) - 1)
\]</span></p>
<h4 id="by-the-height-of-the-subtree-avl-tree">By the height of the subtree (AVL Tree)</h4>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/09/18/Divided-by-Three/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/18/Divided-by-Three/" class="post-title-link" itemprop="url">Divided by Three</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-18 21:51:17" itemprop="dateCreated datePublished" datetime="2019-09-18T21:51:17+10:00">2019-09-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-09-22 11:44:19" itemprop="dateModified" datetime="2019-09-22T11:44:19+10:00">2019-09-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Given a number <span class="math inline">\(x = (x_1x_2x_3...x_n)_{10}\)</span> in decimal form, what is reminder divided by 3.</p>
<p>Note that for any positive integer <span class="math inline">\(k\)</span>, <span class="math display">\[
10^k \equiv 1^k \equiv 1 \mod 3
\]</span></p>
<p>Therefore, <span class="math display">\[
x = x_1 10^{n - 1} + x_2 10^{n - 2} + ... + x^n \equiv x_1 + x_2 + ... + x_n \mod 3
\]</span></p>
<p><span class="math inline">\(\square\)</span>.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/09/03/Primality-Test/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/03/Primality-Test/" class="post-title-link" itemprop="url">Primality Test</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-03 17:15:48" itemprop="dateCreated datePublished" datetime="2019-09-03T17:15:48+10:00">2019-09-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-02 19:56:55" itemprop="dateModified" datetime="2019-12-02T19:56:55+11:00">2019-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Although there is no polynomial algorithm for computing the prime decomposition of an integer, testing primality can be done in polynomial time. The central idea of is to find a certificate that we can verify in polynomial time for the compositeness of an integer.</p>
<p>We begin with Fermat's Test, which gives false positive but works for most cases. It relies on the Fermat's Little Theorem and Lagrange Theorem.</p>
<h3 id="fermats-little-theorem.">Fermat's Little theorem.</h3>
<p>If <span class="math inline">\(n\)</span> is a prime number, then for any <span class="math inline">\(x \in [n - 1]\)</span>, we have <span class="math display">\[
x^{n - 1} \equiv 1 \mod n
\]</span></p>
<p>where throughout the article we use <span class="math inline">\([n - 1]\)</span> to denote the integer set <span class="math inline">\(\{1, 2, ..., n - 1\}\)</span>.</p>
<p><strong>Proof:</strong> Consider the set of numbers <span class="math inline">\(\langle x, 2x, 3x, ..., (n - 1)x \rangle\)</span>. Note that all numbers are different in terms of <span class="math inline">\(\mod n\)</span>. Otherwise <span class="math inline">\(ix \equiv jx \mod n\)</span> implies that <span class="math inline">\((i - j) x \equiv 0 \mod n\)</span>. But <span class="math inline">\(i \neq j\)</span> and <span class="math inline">\(x \neq 0\)</span> concludes that <span class="math inline">\(n\)</span> in not prime, a contradiction. <span class="math inline">\(\blacksquare\)</span></p>
<h4 id="lagrange-theorem">Lagrange Theorem</h4>
<p>If <span class="math inline">\(Z\)</span> is a finite group and <span class="math inline">\(S\)</span> is a subgroup of <span class="math inline">\(Z\)</span>, then the size of <span class="math inline">\(S\)</span> divides that of <span class="math inline">\(Z\)</span>, i.e., <span class="math inline">\(|S| \equiv 0 \mod |Z|\)</span>.</p>
<p><strong>Proof</strong>: Order the elements in <span class="math inline">\(Z\)</span> as <span class="math inline">\(z_1, z_2, ... z_n\)</span>. Consider the sets defined by <span class="math display">\[
z_i S \doteq \{ z \in S, s.t., z = z_i \cdot s, where \quad  s \in S\}
\]</span> We claim <span class="math inline">\(|z_i S| = |S|\)</span>. This is true as for <span class="math inline">\(x \in S, y \in S\)</span> and <span class="math inline">\(x \neq y\)</span>, we have <span class="math inline">\(z_i x \neq z_i y\)</span>.</p>
<p>Now we have the collection of sets <span class="math inline">\(z_1 S, z_2 S, ..., z_n S\)</span>. We remove duplicates among them and keep only one copy of each set. Suppose <span class="math inline">\(m\)</span> sets are left and reorder them as <span class="math inline">\(S_1, S_2, ..., S_m\)</span>, then they constitute a partition of <span class="math inline">\(Z\)</span>.</p>
<ol type="1">
<li>Clearly <span class="math inline">\(S_1 \cup S_2 \cup ... \cup S_m = Z\)</span>.</li>
<li>Moreover, <span class="math inline">\(S_i \cap S_j = \emptyset\)</span>. for <span class="math inline">\(i \neq j\)</span>. Otherwise, let <span class="math inline">\(x \in S_i \cap S_j\)</span>. By definition of <span class="math inline">\(S_i\)</span> and <span class="math inline">\(S_j\)</span>, there exists <span class="math inline">\(z&#39; \in Z\)</span> and <span class="math inline">\(z&#39;&#39; \in Z\)</span>, such that <span class="math inline">\(S_i = z&#39; S\)</span> and <span class="math inline">\(S_j = z&#39;&#39; S\)</span>. Then <span class="math inline">\(x = z&#39; x = z&#39;&#39; y\)</span> for some <span class="math inline">\(x, y \in S\)</span>. It follows that <span class="math inline">\(z&#39; = z&#39;&#39; y x^{-1} \in z&#39;&#39; S\)</span> and <span class="math inline">\(S_i = S_j\)</span>, contradiction the construction of <span class="math inline">\(S_i\)</span> and <span class="math inline">\(S_j\)</span>.</li>
</ol>
<p><span class="math inline">\(\blacksquare\)</span></p>
<p>Before proceeding to the algorithm, we introduce a lemma.</p>
<h4 id="lemma">Lemma</h4>
<p>Given two positive integers <span class="math inline">\(n\)</span> and <span class="math inline">\(m\)</span>, if <span class="math inline">\(gcd(n, m) = k\)</span>, then <span class="math inline">\(\exists a, b \in Z\)</span>, s.t., <span class="math inline">\(an + bm = k\)</span>.</p>
<p><strong>Proof.</strong>. Consider the set <span class="math inline">\(E = \{ an + bm, a, b\in Z\}\)</span> and define <span class="math inline">\(c = \min_{e \in E \wedge e &gt; 0} e\)</span>. Note that <span class="math inline">\(c\)</span> is well-defined -- since both <span class="math inline">\(n\)</span> and <span class="math inline">\(m\)</span> are positive, there are positive integers in <span class="math inline">\(E\)</span>. Further, it holds that <span class="math inline">\(c \le n (a = 1, b = 0)\)</span> and <span class="math inline">\(c \le m (a = 0, b = 1)\)</span>.</p>
<p>We claim that <span class="math inline">\(c \equiv 0 \mod n\)</span> and <span class="math inline">\(c \equiv 0 \mod m\)</span>. WLOG, we prove only the former case. Suppose it is not, let <span class="math inline">\(y \equiv c \mod n\)</span>. There exists integers <span class="math inline">\(x\)</span> s.t., <span class="math inline">\(cx + y = n\)</span> . But now it follows that <span class="math inline">\(y = n - xc \in E\)</span>, contradicting the definition of <span class="math inline">\(c\)</span>.</p>
<p>Now <span class="math inline">\(c\)</span> is common divisor of <span class="math inline">\(n\)</span> and <span class="math inline">\(m\)</span>. It is also the greatest one, since every divisor of <span class="math inline">\(n\)</span> and <span class="math inline">\(m\)</span> divides any element in <span class="math inline">\(E\)</span>.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<h3 id="algorithm-fermats-test.">Algorithm : Fermat's Test.</h3>
<p>The algorithm is relatively easy and shown as follows.</p>
<ol type="1">
<li>Input: an integer <span class="math inline">\(n\)</span>.</li>
<li>Output: whether <span class="math inline">\(n\)</span> is a prime number.</li>
<li>Take a number of <span class="math inline">\(x \in [n - 1]\)</span> uniformly at random.</li>
<li>Check whether <span class="math inline">\(x^{n - 1} \equiv 1 \mod n\)</span>. If not, output "NO".</li>
<li>Repeat steps <span class="math inline">\(3, 4\)</span> a specified number of times.</li>
<li>Output "YES".</li>
</ol>
<p>Now we analyze the algorithm. Given <span class="math inline">\(n\)</span>, denote <span class="math inline">\(Z_n^* = \{ x \in [n - 1] \wedge gcd(x, n) = 1 \}\)</span>, i.e., the set of numbers in <span class="math inline">\([n - 1]\)</span> that are coprime to <span class="math inline">\(n\)</span>. Note that <span class="math inline">\(Z_n^*\)</span> is a group under multiplication:</p>
<ul>
<li><span class="math inline">\(1 \in Z_n^*\)</span>.</li>
<li>If <span class="math inline">\(x \in Z_n^*\)</span>, then <span class="math inline">\(\exists a, b \in Z\)</span>, s.t., <span class="math inline">\(ax + bn = 1\)</span> by definition of <span class="math inline">\(Z_n^*\)</span>. Hence <span class="math inline">\((a \mod n ) \in Z_n^*\)</span> and <span class="math inline">\(x^{-1} = (a \mod n )\)</span>.</li>
<li>If <span class="math inline">\(x, y \in Z_n^*\)</span>, then <span class="math inline">\(gcd(xy, n) = 1\)</span>, therefore <span class="math inline">\(xy \in Z_n^*\)</span>.</li>
<li>Clearly multiplication is associative.</li>
</ul>
<p>On the other hand, consider the set of integers that satisfies Fermat's Little Theorem: <span class="math inline">\(S = \{ x \in [n - 1] \wedge x^{n - 1} \equiv 1 \mod n \}\)</span>. Clearly <span class="math inline">\(S\)</span> is a subset of <span class="math inline">\(Z_n^*\)</span>, since elements in <span class="math inline">\(S\)</span> are invertible module <span class="math inline">\(n\)</span>. Besides, <span class="math inline">\(S\)</span> is itself a group:</p>
<ul>
<li><span class="math inline">\(1 \in S\)</span>.</li>
<li>If <span class="math inline">\(x \in S\)</span>, then <span class="math inline">\(x^{(n - 2)(n - 1)} \equiv x^{(n - 1)(n - 2)} \equiv 1 \mod n\)</span>. It holds that <span class="math inline">\(x^{n - 2} \in S\)</span> and <span class="math inline">\(x^{-1} = x^{n - 2}\)</span>. (The other way to see this is that <span class="math inline">\(1 \equiv x x^{-1} \equiv x^{n - 1} x^{- (n - 1)} \equiv x^{- (n - 1)}\)</span>, hence <span class="math inline">\(x^{-1} \in S\)</span>.)</li>
<li>Clearly multiplication is associative.</li>
<li>If <span class="math inline">\(x, y \in S\)</span>, then <span class="math inline">\((xy)^{n - 1} \equiv x^{n - 1} y^{n - 1} \equiv 1 \mod n\)</span>.</li>
</ul>
<p>Therefore, <span class="math inline">\(S\)</span> is a subgroup of <span class="math inline">\(Z_n^*\)</span>. As <span class="math inline">\(Z_n^*\)</span> is finite, by <em>Lagrange's Theorem</em>,</p>
<p><span class="math display">\[
|Z_n^*| \text{ is a multiple of } |S|
\]</span></p>
<p>If there is an element <span class="math inline">\(x \in Z_n^*\)</span> but <span class="math inline">\(x \notin S\)</span>, then <span class="math inline">\(|Z_n^*| \ge 2 |S|\)</span> and step <span class="math inline">\(3, 4\)</span> successfully reports "NO" with probability at least a half.</p>
<p>However relative rare, systematic error exists. There are numbers such that all numbers coprime to them satisfy Fermat's Little Theorem, i.e., <span class="math inline">\(|Z_n^*| = |S|\)</span>. The smallest one, 561, was found by Carmichael in 1910 and such number are called Carmichael numbers. This motivates the invention of the Rabin/Miller test. The heart lies on finding a pseudo square root of <span class="math inline">\(1\)</span>.</p>
<h5 id="theorem">Theorem</h5>
<p>If <span class="math inline">\(n\)</span> is prime and <span class="math inline">\(x^2 \equiv 1 \mod n\)</span>, then <span class="math inline">\(x = \pm 1 \mod n\)</span>, where <span class="math inline">\(-1 \mod n\)</span> is defined as <span class="math inline">\(n - 1\)</span>.</p>
<p>Proof: <span class="math inline">\(x^2 \equiv 1 \mod n\)</span> implies <span class="math inline">\((x - 1)(x + 1) \equiv 0 \mod n\)</span>. As <span class="math inline">\(n\)</span> is a prime, <span class="math inline">\(x - 1 \equiv 0 \mod n\)</span> or <span class="math inline">\(x + 1 \equiv 0 \mod n\)</span>. <span class="math inline">\(\blacksquare\)</span></p>
<p>Observe that when <span class="math inline">\(n &gt; 2\)</span>, <span class="math inline">\(n - 1 \neq 1\)</span>.</p>
<h3 id="algorithm-2-rabin-miller-test">Algorithm 2: Rabin Miller Test</h3>
<ol type="1">
<li><p>Input: an integer <span class="math inline">\(n\)</span>.</p></li>
<li><p>Output: whether <span class="math inline">\(n\)</span> is a prime number.</p></li>
<li><p>If <span class="math inline">\(n \neq 2\)</span> and <span class="math inline">\(n\)</span> is even, output "NO".</p></li>
<li><p>If <span class="math inline">\(n\)</span> is the power of some integer, output "NO".</p></li>
<li><p>Find the maximum integer <span class="math inline">\(k\)</span>, such that <span class="math inline">\(n - 1 = 2^k m\)</span> for some odd number <span class="math inline">\(m\)</span>.</p></li>
<li><p>Take a number of <span class="math inline">\(x \in [n - 1]\)</span> uniformly at random.</p></li>
<li><p>Check whether <span class="math inline">\(x^{n - 1} \equiv 1 \mod n\)</span>. If not, output "NO". [Now Fermat's Test Is Passed. Need Further Verification.]</p></li>
<li><p>Otherwise, compute the certificate <span class="math display">\[
C = (x^m, x^{2m}, x^{4m}, ..., x^{2^{k - 1}m}, x^{2^km})
\]</span> We must have <span class="math inline">\(x^{2^km} \equiv 1\)</span> since it passes Fermat's test. We check whether <span class="math inline">\(\exists i\)</span>, such that <span class="math inline">\(x^{2^i m} \neq \pm 1\)</span> but <span class="math inline">\(x^{2^{i + 1} m} = 1\)</span>. If so, we find a pseudo square root of unity and output "NO".</p></li>
<li><p>Repeat steps <span class="math inline">\(6 - 8\)</span> a specified number of times.</p></li>
<li><p>Output "YES".</p></li>
</ol>
<p>We claim that line 4 runs in polynomial time. If <span class="math inline">\(n\)</span> is the power of some integer, the smallest integer is <span class="math inline">\(2\)</span>, which gives the power value <span class="math inline">\(\log n\)</span>. Therefore we need only to check for each integer <span class="math inline">\(i \in [\log n]\)</span> whether it holds that <span class="math inline">\(n^{1/i}\)</span> is a integer, which can be computed in polynomial time.</p>
<p>Now we prove the main theorem.</p>
<p><strong>Theorem</strong>: If <span class="math inline">\(n\)</span> is composite, then the algorithm output "YES" with probability at least <span class="math inline">\(1/2\)</span>.</p>
<p>Proof: we call <span class="math inline">\(x \in [n - 1]\)</span> a Rabin Miller witness, if <span class="math inline">\(n\)</span> is a composite and the algorithm outputs "YES" when choosing <span class="math inline">\(x\)</span>. Otherwise we call <span class="math inline">\(x\)</span> a Rabin Miller non-witness. Such <span class="math inline">\(x\)</span>'s satisfies <span class="math display">\[
    x^m \equiv 1 \text{ or } x^{2^i m} \equiv -1 \mod n \text{ for } 0 \le i &lt; k
\]</span></p>
<p>We are going to construct a proper subgroup <span class="math inline">\(S \subset Z_n^*\)</span>, such that all Rabin Miller non-witness belong to <span class="math inline">\(S\)</span>. Then by Lagrange Theorem, it holds that <span class="math display">\[
|\{ \text{Rabin Miller non-witness} \} | \le |S| \le \frac{1}{2} |Z_n^*| \le \frac{n}{2}
\]</span></p>
<p>The construction considers the collection of subsets: <span class="math display">\[
S_r = \{ x \in [n -  1] : x^r \equiv \pm 1 \mod n \}
\]</span> for <span class="math inline">\(r = m, 2m, 4m, ..., 2^k m\)</span>. Define <span class="math display">\[
S = \max_r S_r, s.t., \exists x \in S_r: x^r \equiv -1 \mod n
\]</span> In other words, <span class="math inline">\(S\)</span> is defined to be the set <span class="math inline">\(S_r\)</span> that contains an element whose <span class="math inline">\(r\)</span>-th power equals to <span class="math inline">\(-1\)</span> for the largest <span class="math inline">\(r\)</span>. Such <span class="math inline">\(S\)</span> must exists since <span class="math inline">\(-1 \in S_m\)</span>. <span class="math inline">\(S\)</span> has two important properties:</p>
<ol type="1">
<li>All Rabin Miller non-witness belongs to <span class="math inline">\(S\)</span>.</li>
<li><span class="math inline">\(S\)</span> is subgroup of <span class="math inline">\(Z_n^*\)</span>.</li>
<li><span class="math inline">\(\exists y \in Z_n^*\)</span>, s.t., <span class="math inline">\(y \notin S\)</span>, i.e., <span class="math inline">\(S \neq Z_n^*\)</span></li>
</ol>
<p>Property (1) is obvious by the definition of Rabin Miller non-witness. To show (2), we need to verify <span class="math inline">\(S\)</span> is close under multiplication, each element in <span class="math inline">\(S\)</span> belongs to <span class="math inline">\(Z_n^*\)</span> and is invertible in <span class="math inline">\(S\)</span>:</p>
<ul>
<li>If <span class="math inline">\(x \in S, y \in S\)</span>, then <span class="math inline">\((xy)^r \pm x^r y^r \equiv \pm 1 \mod n\)</span>.</li>
<li>If <span class="math inline">\(x \in S\)</span>, then <span class="math inline">\(x^r \equiv 1 \mod n\)</span> or <span class="math inline">\(x^{2r} \equiv 1 \mod n\)</span>. Clearly <span class="math inline">\(x\)</span> is invertible. Hence <span class="math inline">\(x \in Z_n^*\)</span>.</li>
<li>If <span class="math inline">\(x \in S\)</span>, then <span class="math inline">\(1 \equiv (x x^{-1})^r \equiv x^r x^{-r} \equiv x^{-r} \mod n\)</span>.</li>
</ul>
<p>Finally, we prove Property (3). As <span class="math inline">\(n\)</span> is composite, we can write <span class="math inline">\(n = ab\)</span>, where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are coprime. By definition of <span class="math inline">\(S\)</span>, <span class="math inline">\(\exists x \in S\)</span>, such that <span class="math display">\[
x^r \equiv -1 \mod n
\]</span> By Chinese Remainder Theorem, this is equivalent to <span class="math display">\[
x^r \equiv n-1 \mod a \wedge x^r \equiv n-1 \mod b
\]</span> i.e., <span class="math display">\[
x^r \equiv -1 \mod a \wedge x^r \equiv -1 \mod b
\]</span></p>
<p>However, another use of Chinese Remainder Theorem asserts <span class="math inline">\(\exists y \in [n]\)</span>, such that <span class="math display">\[
y \equiv x \mod a \wedge y \equiv 1 \mod b
\]</span></p>
<p>which implies that <span class="math display">\[
y^r \equiv x^r \equiv -1 \mod a \wedge y^r \equiv 1 \mod b
\]</span></p>
<p>Hence it is impossible that <span class="math inline">\(y^r \equiv \pm 1 \mod n\)</span>. It is left to prove <span class="math inline">\(y\)</span> is invertible module <span class="math inline">\(n\)</span>:</p>
<ul>
<li><span class="math inline">\(y \in Z_n^*\)</span>, as <span class="math inline">\(\gcd(x, n) = \gcd(x, ab) = 1 \rightarrow \gcd(x,a ) = 1 \wedge \gcd(x, b) = 1 \rightarrow \gcd(y, a) = \gcd(x, a) = 1 \rightarrow \gcd(y, ab) = 1\)</span>.</li>
</ul>
<p><span class="math inline">\(\blacksquare\)</span></p>
<h4 id="reference">Reference:</h4>
<ol type="1">
<li><a target="_blank" rel="noopener" href="http://theory.stanford.edu/~valiant/teaching/CS265/primality.pdf">Primality Testing, CS265/CME309, Fall 2017. Gregory Valiant</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/09/03/Less-Communication/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/03/Less-Communication/" class="post-title-link" itemprop="url">Less Communication</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2019-09-03 14:19:55 / Modified: 15:35:25" itemprop="dateCreated datePublished" datetime="2019-09-03T14:19:55+10:00">2019-09-03</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>A set of <span class="math inline">\(k\)</span> servers are receiving requests and they are required to report to a coordinator the numbers of requests they process. An event is trigerrd by the coordinator if the culmulative requests received by the serves reaches a threshold <span class="math inline">\(\tau\)</span>. The goal is to minimized the communicaiton between the coordinator and the servers.</p>
<p>A naive approach asks the servers to send a notificiation to the coordinator each time they process a request, resulting in <span class="math inline">\(O(\tau)\)</span> bits communication in total.</p>
<p>An alternative approach achieves <span class="math inline">\(O(h \log \tau)\)</span> words communication cost. Instead of response to the coordinator every a new request comes, the server reports only after some requests reaches. However, we don't want the coordinator to miss the <span class="math inline">\(\tau\)</span> threshold, i.e., it must triger the event when exactly <span class="math inline">\(\tau\)</span> requests come in total.</p>
<p>Here is the scheme.<br />
1. If <span class="math inline">\(\tau \le 5 \cdot h\)</span>, the server report each time a request comes. 2. The coordinator sends the threshold <span class="math inline">\(\lfloor \frac{\tau}{ 2h} \rfloor\)</span> to each server. This requires <span class="math inline">\(h\)</span> words. 3. Each server sends a report to the coordinator every <span class="math inline">\(\lfloor \frac{\tau}{ 2h} \rfloor\)</span> requests comes. 4. When the coordinator learns that, the servers has processed <span class="math inline">\(\lfloor \tau / 2 \rfloor\)</span> requests (at most <span class="math inline">\(2h\)</span> words communication needed), it collects how many requests are proceed in each servers which are not reported to it (at most <span class="math inline">\(2h\)</span> words communication needed). The number of requests comes is at most <span class="math display">\[
        \lfloor \tau / 2 \rfloor + (h - 1) (\lfloor \tau / 2h \rfloor - 1) &lt; \tau /2 + \tau / 2 = \tau
   \]</span> 5. The number of requests remains to reach the <span class="math inline">\(\tau\)</span> threshold is at most <span class="math inline">\(\tau&#39; \doteq \lceil \tau / 2 \rceil\)</span>. We set <span class="math inline">\(\tau&#39;\)</span> as the new threshold and go to step 1. 6. The overall communication cost is given by <span class="math display">\[
        T(\tau) = T(\lceil \tau / 2 \rceil) + 5 \cdot h
   \]</span> for some constant <span class="math inline">\(k\)</span>. 7. There are at most <span class="math inline">\(2 \log \tau\)</span> recursions. Each recursion requires <span class="math inline">\(k\)</span> words communication, resulting in a total communication cost <span class="math inline">\(O(h \log \tau)\)</span> words.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/08/15/Chinese-Reminder-Theorem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/15/Chinese-Reminder-Theorem/" class="post-title-link" itemprop="url">Chinese-Reminder-Theorem</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-08-15 11:37:18" itemprop="dateCreated datePublished" datetime="2019-08-15T11:37:18+10:00">2019-08-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-03 20:24:48" itemprop="dateModified" datetime="2019-12-03T20:24:48+11:00">2019-12-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Given integers <span class="math inline">\(n_1, n_2,...,n_k\)</span> that are relatively prime, and integers <span class="math inline">\(a_1, a_2, ..., a_k\)</span>, the Chinese-Reminder-Theorem states that there exists an integer <span class="math inline">\(x\)</span> such that <span class="math display">\[
\begin{aligned}
x \equiv a_1 \mod n_1 \\
x \equiv a_2 \mod n_2 \\
... \\
x \equiv a_k \mod n_k
\end{aligned}
\]</span></p>
<p>Now denote <span class="math inline">\(N_i = \frac{\prod_{j = 1}^k n_j}{n_i}\)</span>.</p>
<p>The proof is intuitive. For any <span class="math inline">\(i \in [1, k]\)</span>, <span class="math inline">\(N_i\)</span> is coprime to <span class="math inline">\(n_i\)</span>. Therefore, it has an inverse (<span class="math inline">\(\mod n_i\)</span>). Let the inverse be <span class="math inline">\(M_i\)</span>, i.e., <span class="math inline">\(M_i N_i\equiv 1 \mod n_i\)</span>. It follows that <span class="math inline">\(a_i M_i N_i \equiv a_i \mod n_i\)</span>. Further, as <span class="math inline">\(N_i\)</span> contains <span class="math inline">\(n_j\)</span> (<span class="math inline">\(j \neq i\)</span>) as a factor, <span class="math inline">\(a_i M_i N_i \equiv 0 \mod n_j\)</span>.</p>
<p>It is easy to see that <span class="math display">\[
\sum_{i = 1}^k a_i M_i N_i
\]</span> is a solution to the problem.</p>
<p>Moreover, we claim that any solution has the form <span class="math display">\[
\sum_{i = 1}^k a_i M_i N_i + l \cdot \prod_{i = 1}^k n_i
\]</span> for some integer <span class="math inline">\(l\)</span>. Suppose that <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are two solutions to the problem, then for any <span class="math inline">\(i \in [1, k]\)</span>, <span class="math display">\[
x - y \equiv 0 \mod n_k
\]</span> Hence, <span class="math inline">\(x - y = l \cdot \prod_{i = 1}^k n_i\)</span> for some <span class="math inline">\(l\)</span>. The immediate corollary is that there is a unique solution in <span class="math inline">\([0, \prod_{i = 1}^k n_i - 1]\)</span> for the problem.</p>
<p><em>Proof 2:</em> there is a probability more intuitive proof. First we investigate a simple example of pair <span class="math inline">\(2\)</span> and <span class="math inline">\(3\)</span> and their modules <span class="math display">\[
\begin{aligned}
&amp;       &amp; 0 &amp;&amp; 1 &amp;&amp; 2 &amp;&amp; 3 &amp;&amp; 4 &amp;&amp; \qquad 5 &amp;&amp; ... \\
&amp;\mod 2 &amp; 0 &amp;&amp; 1 &amp;&amp; 0 &amp;&amp; 1 &amp;&amp; 0 &amp;&amp; \qquad 1 &amp;&amp; ... \\
&amp;\mod 3 &amp; 0 &amp;&amp; 1 &amp;&amp; 2 &amp;&amp; 0 &amp;&amp; 1 &amp;&amp; \qquad 2 &amp;&amp; ...
\end{aligned}
\]</span> Note that there is one-to-one correspondence between numbers in <span class="math inline">\(\{0, 1, 2, 3, 4, 5\}\)</span> and pairs in <span class="math inline">\(\{0, 1\} \times \{0, 1, 2\}\)</span>. In general, given integers <span class="math inline">\(n_1, n_2,...,n_k\)</span> that are relatively prime, and two numbers <span class="math inline">\(1 \le x \le y \le \prod_j n_j\)</span>, if <span class="math display">\[
\begin{aligned}
x \equiv y \mod n_1 \\
x \equiv y \mod n_2 \\
... \\
x \equiv y \mod n_k
\end{aligned}
\]</span> then <span class="math inline">\(x = y\)</span>. To see this, we have for any <span class="math inline">\(1 \le j \le k\)</span>, <span class="math display">\[
n_j | (y - x )
\]</span> As the <span class="math inline">\(n_j\)</span>'s are coprime, we have <span class="math inline">\(\prod_j n_j | (y - x)\)</span>, hence <span class="math inline">\(y - x = 0\)</span> and <span class="math inline">\(y = x\)</span>. Then we can define a one-to-one correspondence between <span class="math inline">\([\prod_j n_j]\)</span> and the <span class="math inline">\(k\)</span> dimension vectors <span class="math inline">\([n_1] \times [n_2] \times ... \times [n_k]\)</span>.</p>
<h2 id="applications">Applications</h2>
<p>The theorem has many interesting applications. Here are some:</p>
<p>Theorem 1: Let <span class="math inline">\(\varphi(n)\)</span> be the numbers in <span class="math inline">\([n]\)</span> that are coprime with <span class="math inline">\(n\)</span>. If <span class="math inline">\(n = pq\)</span> for primes <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span>, then <span class="math inline">\(\varphi(n) = (p - 1)(q - 1)\)</span>.</p>
<p>Proof: By Chinese Reminder Theorem, there is a one-to-one correspondence between <span class="math inline">\([n]\)</span> and <span class="math inline">\([p] \times [q]\)</span>. If <span class="math inline">\(x \in [n]\)</span> is not coprime with <span class="math inline">\(n\)</span>, either <span class="math inline">\(p \mid x\)</span> or <span class="math inline">\(q \mid x\)</span>. Therefore, <span class="math inline">\(x\)</span> corresponds to a pair <span class="math inline">\((p, a)\)</span> or <span class="math inline">\((b, q)\)</span> for some <span class="math inline">\(a \in [q]\)</span> or <span class="math inline">\(b \in [p]\)</span>. The number of such pairs is given by <span class="math inline">\(p + q - 1\)</span>. <span class="math inline">\(\blacksquare\)</span></p>
<p>Theorem 2: If <span class="math inline">\(n = pq\)</span> for positive integers <span class="math inline">\(p, q\)</span> and <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> are coprime, then <span class="math inline">\(\varphi(n) = \varphi(p) \varphi(q)\)</span>.</p>
<p>Proof: By Chinese Reminder Theorem, there is a one-to-one correspondence between <span class="math inline">\([n]\)</span> and <span class="math inline">\([p] \times [q]\)</span>. If <span class="math inline">\(x \in [n]\)</span> is coprime with <span class="math inline">\(n\)</span>, it holds that <span class="math inline">\(\gcd(x, p) = 1 \wedge \gcd(x, q) = 1\)</span>. Therefore, <span class="math inline">\(x\)</span> corresponds to a pair for <span class="math inline">\((x \mod p, x \mod q)\)</span> , such that <span class="math inline">\(x \mod p\)</span> is coprime with <span class="math inline">\(p\)</span> and <span class="math inline">\(x \mod q\)</span> is coprime with <span class="math inline">\(q\)</span>. The number of possible values of <span class="math inline">\(x \mod p\)</span> is <span class="math inline">\(\varphi(p)\)</span>, and the number of possible values of <span class="math inline">\(x \mod q\)</span> is <span class="math inline">\(\varphi(q)\)</span> . Hence <span class="math inline">\(\varphi(n) = \varphi(p) \varphi(q)\)</span>. <span class="math inline">\(\blacksquare\)</span></p>
<p>Theorem 3: Let <span class="math inline">\(n = p_1^{k_1} p_2^{k_2} ... p_m ^{k_m}\)</span> be the unique prime factorization of <span class="math inline">\(n\)</span>, then <span class="math inline">\(\varphi(n) = n \prod_{i = 1}^m (1 - 1/p_i)\)</span>.</p>
<p>Proof: <span class="math display">\[
\varphi(n) = \prod_{i = 1}^m \varphi(p_i^{k _i})
\]</span> On the other hand, there are <span class="math inline">\(p_i^{k _i - 1}\)</span> numbers in <span class="math inline">\([p_i^{k _1}]\)</span> there are not coprime with <span class="math inline">\(p_i^{k_i}\)</span>, namely <span class="math display">\[
1\cdot p_i, 2 \cdot p_i, 3 \cdot p_i..., p_i^{k_i - 1} p_i
\]</span> Therefore, <span class="math inline">\(\varphi(p_i^{k_i}) = p_i^{k_i} - p_i^{k_i - 1} = p_i^{k_i}( 1 - 1/p_i)\)</span> and <span class="math display">\[
\varphi(n) = \prod_{i = 1}^m p_i^{k_i} (1 - 1/ p_i) =  n \prod_{i = 1}^m (1 - 1/ p_i)
\]</span></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/06/01/Matrix-Norm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/06/01/Matrix-Norm/" class="post-title-link" itemprop="url">Matrix Norm</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-06-01 19:37:46" itemprop="dateCreated datePublished" datetime="2019-06-01T19:37:46+10:00">2019-06-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-12-23 21:15:20" itemprop="dateModified" datetime="2020-12-23T21:15:20+11:00">2020-12-23</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>A function <span class="math inline">\(f: \mathbb{R}^{m \times n} \rightarrow \mathbb{R}\)</span> is called a matrix norm if it satisfies that <span class="math inline">\(\forall A, B \in \mathbb{R}^{m \times n}\)</span> and <span class="math inline">\(k \in \mathbb{R}\)</span>,</p>
<ol type="1">
<li><span class="math inline">\(f(A) = 0 \rightarrow A = 0\)</span>.<br />
</li>
<li><span class="math inline">\(f(kA) = kf(A)\)</span>.<br />
</li>
<li><span class="math inline">\(f(A + B) \le f(A) + f(B)\)</span>.</li>
</ol>
<h2 id="frobenius-norm">Frobenius Norm</h2>
<p>The Frobenius Norm view a matrix as a vector and is defined as <span class="math inline">\(|A|_F = \sqrt{\sum_{i, j} a_{i,j}^2 }\)</span>, where <span class="math inline">\(a_{i,j}\)</span> is the element in the <span class="math inline">\(i\)</span>-th row and <span class="math inline">\(j\)</span>-th column. Clearly this is a norm.</p>
<h2 id="norm-or-spectral-norm">2-norm or spectral norm</h2>
<p>The 2-norm is defined as <span class="math inline">\(|A|_2 = \sigma_1\)</span>, where <span class="math inline">\(\sigma_1\)</span> is the maximum singular value of <span class="math inline">\(A\)</span>. We prove this is a norm by checking triangle inequality.</p>
<p><em>Proof:</em> First, note that<br />
<span class="math display">\[
|A|_2 = \max_{x \in \mathbb{R}^n \wedge ||x|| = 1 } ||Ax||
\]</span></p>
<p>This can be verified by writing <span class="math inline">\(A\)</span> as its singular value decomposition <span class="math display">\[
A = \sigma_1 u_1 v_1^T + ... + \sigma_r u_r v_r^T
\]</span> where <span class="math inline">\(u_1, ..., u_r \in \mathbb{R}^m\)</span> are orthogonal, <span class="math inline">\(v_1, v_2, ..., v_r \in \mathbb{R}^n\)</span> are orthogonal and <span class="math inline">\(\sigma_1 \ge \sigma_2 \ge ... \ge \sigma_r \ge 0\)</span>.</p>
<p>We augment <span class="math inline">\(v_1, v_2, ..., v_r\)</span> to <span class="math inline">\(v_1, .., v_n\)</span> such that they constitutes an orthogonal base of <span class="math inline">\(\mathbb{R}^n\)</span>. Then we can write <span class="math inline">\(x \in \mathbb{R}^n\)</span> as<br />
<span class="math display">\[
x = x_1 v_1 + x_2 v_2 + ... + x_n v_n
\]</span> where <span class="math inline">\(\sum_{i = 1}^n x_i^2 = 1\)</span>.</p>
<p>Therefore, <span class="math display">\[
||Ax|| = \sqrt{\sum_{i = 1}^r \sigma_i^2x_i^2 }
\]</span></p>
<p>Clearly <span class="math inline">\(||Ax||\)</span> is maximized when <span class="math inline">\(x_1 = 1\)</span> and <span class="math inline">\(x_i = 0\)</span> for <span class="math inline">\(i \neq 1\)</span>: <span class="math display">\[
\max_{x} ||Ax|| =  \sigma_1
\]</span></p>
<p>Now, for any <span class="math inline">\(x \in \mathbb{R}^n\)</span> and <span class="math inline">\(||x|| = 1\)</span>, by triangle inequality of vectors, it holds that<br />
<span class="math display">\[
||(A + B)x|| \le ||Ax|| + ||Bx|| \le |A|_2 + |B|_2
\]</span></p>
<p>Maximizing over the left hand side gives the desired triangle inequality.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/05/29/Kraft-Inequality/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/05/29/Kraft-Inequality/" class="post-title-link" itemprop="url">Kraft Inequality</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-05-29 20:07:02" itemprop="dateCreated datePublished" datetime="2019-05-29T20:07:02+10:00">2019-05-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-05-30 00:56:35" itemprop="dateModified" datetime="2019-05-30T00:56:35+10:00">2019-05-30</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Assume that we would like to encode a set of symbol <span class="math inline">\(S = \{ s_1, s_2, ..., s_n \}\)</span> into binary strings <span class="math inline">\(T = \{ t_1, t_2, ..., t_n : t_i \text{ is a 0, 1 sequence of finite length} \}\)</span>, such that <span class="math inline">\(\forall i \neq j\)</span>, <span class="math inline">\(t_i\)</span> is not a prefix of <span class="math inline">\(t_j\)</span>. Denote the length of <span class="math inline">\(t_i\)</span> as <span class="math inline">\(n_i\)</span>. Then the <em>Kraft Inequality</em> states that<br />
<span class="math display">\[
\sum_{i = 1}^n 2^{-n_i} \le 1
\]</span></p>
<p>For convenience, we write <span class="math inline">\(t_i \ll t_j\)</span> if <span class="math inline">\(t_i\)</span> is a prefix of <span class="math inline">\(t_j\)</span>. Intuitively, we can view a particular sequence <span class="math inline">\(t_i = t_i^1t_i^2 ...t_i^{n_i}\)</span> as the abbreviation of number <span class="math inline">\(0.t_i^1t_i^2 ...t_i^{n_i}\)</span>. The fact that for <span class="math inline">\(j \neq i\)</span>, neither <span class="math inline">\(t_i \ll t_j\)</span> nor <span class="math inline">\(t_j \ll t_i\)</span> implies that <span class="math inline">\(t_j\)</span> does not lies in the interval <span class="math inline">\([0.t_i^1t_i^2 ...t_i^{n_i}, 0.t_i^1t_i^2 ...t_i^{n_i} + 2^{-n_i})\)</span>. As the intervals induced by <span class="math inline">\(t_i\)</span>'s are mutually exclusive, we can easily conclude that <span class="math display">\[
\sum_{i = 1}^n 2^{-n_i} \le 1
\]</span></p>
<p>Indeed, the statement of Kraft Inequality can be made stronger such that the inequality holds as long as <span class="math inline">\(\{ t_1, t_2, ..., t_n \}\)</span> are uniquely decodable. To verify this, note that for any sequence <span class="math inline">\(\tau \in T^*\)</span> with length <span class="math inline">\(k\)</span>, there are at most only <span class="math inline">\(2^k\)</span> possible combinations. Therefore, <span class="math display">\[
(\sum_{i = 1}^n 2^{-n_i})^l = \sum_{k = 1}^{l \cdot n_{max}} C_k 2^{-k}
\]</span> where <span class="math inline">\(n_{max} = \max\{n_1, n_2, ..., \}\)</span> and <span class="math inline">\(C_k \le 2^k\)</span>. Hence <span class="math display">\[
(\sum_{i = 1}^n 2^{-n_i})^l \le l \cdot n_{max} \rightarrow \sum_{i = 1}^n 2^{-n_i} \le l^{1/l} \cdot n_{max}^{1/l}
\]</span></p>
<p>Taking <span class="math inline">\(l\)</span> to infty we get the desired result.</p>
<p>An immediately implication is that Entropy is the lower bound of the encode length of a document. To see this, denote the probability of <span class="math inline">\(s_i\)</span> as <span class="math inline">\(p_i\)</span>. Then<br />
<span class="math display">\[
\begin{aligned}
\sum_{i} p_i \log \frac{1}{p_i} - \sum_{i} p_i n_i  
&amp;= \sum_{i} p_i \log \frac{1}{p_i} \cdot \frac{1}{2^{n_i} } \\
&amp;\le \log \sum_{i} p_i  \frac{1}{p_i} \cdot \frac{1}{2^{n_i} } \\
&amp;\le \log \sum_{i} \frac{1}{2^{n_i} } \\
&amp;\le 0  
\end{aligned}
\]</span></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/05/18/The-Number-of-Distinct-Elements/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/05/18/The-Number-of-Distinct-Elements/" class="post-title-link" itemprop="url">The Number of Distinct Elements</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-05-18 16:09:20" itemprop="dateCreated datePublished" datetime="2019-05-18T16:09:20+10:00">2019-05-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-06-21 21:01:48" itemprop="dateModified" datetime="2020-06-21T21:01:48+10:00">2020-06-21</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>In many network applications, data comes as a stream <span class="math inline">\(S = \{x_1, x_2, ..., x_n \}\)</span>, where each <span class="math inline">\(x_i\)</span> (<span class="math inline">\(1 \le i \le n\)</span>) belongs to the domain <span class="math inline">\(D\)</span>. Suppose each element in <span class="math inline">\(D\)</span> appear at least once in <span class="math inline">\(S\)</span>, we want to evaluate the size of <span class="math inline">\(D\)</span>, i.e., the number of distinct elements in <span class="math inline">\(S\)</span> (denoted as <span class="math inline">\(N = |D|\)</span>).</p>
<p>Potential solutions include</p>
<ol type="1">
<li>We can sort the elements in <span class="math inline">\(S\)</span> and count the number of distinct elements. This requires <span class="math inline">\(O(n \log n)\)</span> time (with quicksort) and <span class="math inline">\(O(n)\)</span> space.<br />
</li>
<li>We can use hashing to count the distinct elements. This can be done in <span class="math inline">\(O(n)\)</span> time and <span class="math inline">\(O(n)\)</span> space with two level hashing.</li>
</ol>
<p>In real world application, <span class="math inline">\(n\)</span> could be extremely large. Therefore, the demand for <span class="math inline">\(O(n)\)</span> space is expansive or even impossible. Can we do this with <span class="math inline">\(O(1)\)</span> space? If we allow some error, this is possible.</p>
<h2 id="solution-1">Solution 1</h2>
<p>The tool we resort to is a set of hash functions <span class="math inline">\(\mathcal{H} = \{ h | h: U \rightarrow [0, 1] \}\)</span> such that<br />
<span class="math display">\[
\begin{aligned}
&amp;\Pr_{h \in \mathcal{H} } [h(x) \in [a, b]] = \frac{1}{b - a}, &amp;\forall x \in U \wedge [a, b] \subset [0, 1]
\end{aligned}
\]</span></p>
<p>That is, given an element <span class="math inline">\(x \in U\)</span>, if we choose an <span class="math inline">\(h\)</span> from <span class="math inline">\(U\)</span> randomly, then <span class="math inline">\(h\)</span> maps <span class="math inline">\(x\)</span> to a number between <span class="math inline">\([0, 1]\)</span> uniformly at random. Further, we assume that <span class="math inline">\(h\)</span> maps different elements in <span class="math inline">\(U\)</span> to <span class="math inline">\([0, 1]\)</span> independently (Remark: to what extend is this possible?).</p>
<p>Further, denote <span class="math inline">\(h(S) = \{ h(x_1), h(x_2), ..., h(x_n)\}\)</span> the image of <span class="math inline">\(S\)</span> under a function <span class="math inline">\(h\)</span>. We claim that, if <span class="math inline">\(h\)</span> is selected randomly from <span class="math inline">\(\mathcal{H}\)</span>, then the minimum expected value of <span class="math inline">\(h(S)\)</span> is <span class="math inline">\(1 / (N + 1)\)</span>: <span class="math display">\[
\underset{h \in \mathcal{H} }{E} [\min h(S)] = \int_{z = 0}^1 z \Pr_{h \in \mathcal{H}} [\min h(S) = z] \ dz = \frac{1}{N + 1}
\]</span></p>
<p>To see this, observe that the probability that <span class="math inline">\(\Pr_{h \in \mathcal{ H } }[\min h(S) \ge z] = (1 - z)^N​\)</span>, therefore <span class="math inline">\(\Pr_{h \in \mathcal{ H } }[\min h(S) \le z] = 1 - (1 - z)^N​\)</span> and the density function is given as <span class="math display">\[
p_{h \in \mathcal{H  } }[\min h(S) = z] = \frac{\partial \Pr_{h \in \mathcal{H}  }[\min h(S) \le z] }{ \partial z} = N (1 - z)^{N - 1}
\]</span></p>
<p>Taking the expectation over <span class="math inline">\(z = 0\)</span> to <span class="math inline">\(1\)</span> gives the desired result.</p>
<p>Another way to prove this is to introduce an additional element <span class="math inline">\(x_{n + 1}\)</span> which is different from any other element in <span class="math inline">\(D\)</span> and let <span class="math inline">\(S&#39; = S \cup \{ x_{n + 1} \}\)</span>. What is the probability that <span class="math inline">\(h(x_{n + 1})\)</span> is the smallest in <span class="math inline">\(h(S&#39;)\)</span>, i.e., <span class="math inline">\(\min h(S&#39;) = h(x_{n + 1})\)</span>? Conditioning on the minimum value of <span class="math inline">\(\{ h(x_1), h(x_2), ..., h(x_n) \}\)</span> (<span class="math inline">\(\min h(S)\)</span>) being some <span class="math inline">\(z\)</span> (<span class="math inline">\(z \in [0, 1]\)</span>), the probability becomes <span class="math display">\[
\begin{aligned}
&amp;\Pr[\min h(S&#39;) = h(x_{n + 1}) \mid \min h(S) = z] \\
= &amp;\Pr[h(x_{n + 1}) \in [0, z] \mid \min h(S) = z] \\
= &amp;z
\end{aligned}
\]</span></p>
<p>Integrating over all possible values of <span class="math inline">\(z\)</span>, we have <span class="math display">\[
\Pr[\min h(S&#39;) = h(x_{n + 1})] = \int_{z = 0}^1 z \Pr[\min h(S) = z] \ dz
\]</span></p>
<p>This is exactly the expectation of <span class="math inline">\(\min h(S)\)</span>. Moreover, by symmetry, <span class="math inline">\(\Pr[\min h(S&#39;) = h(x_{n + 1})] = \frac{1}{N + 1}\)</span>. Therefore, it follows that <span class="math inline">\(E[\min h(S)] = \frac{1}{N + 1}\)</span>.</p>
<p>It is natural to ask how accurate our estimation is. On the one hand, by Markov inequality, <span class="math display">\[
 \Pr_{h \in \mathcal{H} } [\min h(S) \ge 2 \frac{1}{N + 1}] \le \frac{E[\min h(S)]}{2 \frac{1}{N + 1} } = \frac{1}{2}
\]</span></p>
<p>By repeating the algorithm <span class="math inline">\(k\)</span> times, the failure probability drops to <span class="math inline">\(\frac{1}{2^k}\)</span>. However, Markov inequality can not give a lower bound of <span class="math inline">\(\min h(S)\)</span>. What comes to our rescue is Chebyshev's inequality. First, note that <span class="math display">\[
\begin{aligned}
\underset{h \in \mathcal{H} }{E} [ (\min h(S))^2 ]
&amp;= \int_{z = 0}^1 N z^2(1 - z)^{N - 1} dz \\
&amp;= \int_{z = 0}^1 N [(z - 1)^2  + 2(z - 1) + 1] (1 - z)^{N - 1}dz \\
&amp;= -\frac{N}{N + 2}(1 - z)^{N + 2} \mid_{0}^1 + \frac{2N}{N + 1} (1 - z)^{N + 1} \mid_{0}^1 - \frac{N}{N} (1 - z)^{N} \mid_{0}^1  \\  
&amp;= \frac{N}{N + 2} - \frac{2N}{N + 1} + \frac{N}{N} \\
&amp;= \frac{-(N - 1)(N + 2) + N^2 + N}{(N +2)(N + 1)} \\
&amp;= \frac{2}{(N +2)(N + 1)}
\end{aligned}
\]</span></p>
<p>It follows that <span class="math inline">\(\underset{h \in \mathcal{H} }{Var} [ (\min h(S))^2 ] = \frac{2}{(N + 1)(N +2)} - \frac{1}{(N + 1)^2} \le \frac{1}{(N + 1)^2}\)</span>. However, this alone is not enough to give an accurate estimate.</p>
<p><em>Question to ponder: try to apply Chebyshev's inequality directly on this single estimate. Can we get a meaningful lower bound for <span class="math inline">\(\min h(S)\)</span>?</em></p>
<p>Instead, we repeat the algorithm <span class="math inline">\(k\)</span> times, and take the average over the <span class="math inline">\(\min h(S)\)</span>'s. Let <span class="math inline">\(\overline X\)</span> denote this average value. Then <span class="math inline">\(\underset{h \in \mathcal{H} }{Var} [ \overline X ] \le \frac{1}{k (N + 1)^2}\)</span>. Given a parameter <span class="math inline">\(0 &lt; l &lt; 1\)</span> (to be determined later),<br />
<span class="math display">\[
\Pr[ |\overline{X} - \frac{1}{N + 1} | \ge \frac{l}{N + 1}] \le  (\frac{1}{k(N + 1)^2}) / (\frac{l^2}{(N + 1)^2}) = \frac{1}{k l^2}
\]</span></p>
<p>That is, <span class="math inline">\(\overline{X} \in \frac{1}{N + 1}[1 - l, 1 + l]\)</span> with probability <span class="math inline">\(\frac{1}{k l^2}\)</span>. That is <span class="math inline">\(n \in \frac{1}{\overline{X} } [1 - l , 1 + l]\)</span> with probability <span class="math inline">\(\frac{1}{k l^2}\)</span>.</p>
<p><strong>Remark 1</strong>: there exists other analysis for the concentration behavior when we repeat the experiment for <span class="math inline">\(k\)</span> times. Note that for <span class="math inline">\(N \ge 1\)</span>,</p>
<p><span class="math display">\[
\begin{aligned}
\Pr_{h \in \mathcal{ H } }[\min h(S) \ge (1 + \epsilon) \frac{1}{N + 1}]  
&amp;= (1 - \frac{1 + \epsilon}{N + 1})^N \le \exp \left( -\frac{1 + \epsilon}{N + 1}N \right) \le \exp \left( -\frac{1 + \epsilon}{2} \right) = \frac{1}{\sqrt e} e^{-\epsilon / 2}\\
\Pr_{h \in \mathcal{ H } }[\min h(S) \le (1 - \epsilon) \frac{1}{N + 1}]  
&amp;= 1 - (1 -  \frac{1 - \epsilon}{N + 1})^N \le 1 - \exp \left( - \frac{ 1 - \epsilon }{2(N + 1)}N \right) \le 1 - \exp \left( - \frac{ 1 - \epsilon }{2} \right) = 1 - \frac{1}{\sqrt e} e^{ \epsilon / 2}
\end{aligned}
\]</span></p>
<p>We claim that if we take the <span class="math inline">\(\frac{k}{\sqrt e}​\)</span>-th smallest element, our estimate <span class="math inline">\(\overline X​\)</span> satisfies</p>
<p><span class="math display">\[
\left| \overline X - \frac{1}{N + 1} \right| \le \epsilon \frac{1}{N + 1}
\]</span></p>
<p>with high probability.</p>
<p>Denote <span class="math inline">\(z_1, z_2, ..., z_k\)</span> a set of i.i.d Bernoulli variables with mean <span class="math inline">\(\frac{1}{\sqrt e} e^{-\epsilon / 2}\)</span>. Then by Chernoff bound,<br />
<span class="math display">\[
\begin{aligned}
\Pr[ \sum z_i \ge \frac{k}{\sqrt e} ]
&amp;= \Pr[ \sum z_i \ge (1 + (e^{\epsilon / 2} - 1) ) \frac{k}{\sqrt e} e^ {-\epsilon / 2}] \\
&amp;\le \exp \left( -(e^{\epsilon / 2} - 1)^2 \frac{k}{\sqrt e} e^ {-\epsilon / 2} / 3 \right) \\
&amp;= \exp \left( -(e ^\epsilon - 2 e^{\epsilon / 2} + 1) e^ {-\epsilon / 2} \frac{k}{\sqrt e}  / 3 \right) \\
&amp;= \exp \left( -( e^{\epsilon / 2} - 2 + e^ {-\epsilon / 2}) \frac{k}{\sqrt e}  / 3 \right) \\
&amp;\le \exp \left( - \frac{ \epsilon^2 }{4} \frac{k}{\sqrt e}  / 3 \right) \\
&amp; = \delta
\end{aligned}
\]</span></p>
<p>It suffices to set <span class="math inline">\(k = \frac{12 \sqrt e}{\epsilon^2} \ln \frac{1}{\delta}\)</span>.</p>
<p>By symmetry, we can prove the inequality of the other hand.</p>
<p><strong>Remark 2:</strong> Suppose that we have a function <span class="math inline">\(h\)</span> that maps each of the <span class="math inline">\(N\)</span> elements to a non-negative real number according to exponential distribution <span class="math inline">\(\exp(-1)\)</span> independently (the same element is mapped to the same number), then the minimum of these real numbers serves also as an unbiased estimator of <span class="math inline">\(\frac{1}{N}\)</span>. To verify this, <span class="math display">\[
\Pr[ \min h(S) \le z] = 1 - \exp(-zN) 
\]</span></p>
<p>Therefore, <span class="math display">\[
p[\min h(S) = z] = \frac{\partial \Pr[ \min h(S) \le z]}{\partial z} = N \exp(-Nz)
\]</span> and <span class="math display">\[
E[\min h(S)] = \int_{0}^\infty Nz \exp(-Nz) dz = -\int_{0}^\infty z \ d\exp(-Nz) = -z \exp(-Nz) \mid_{0}^\infty + \int_0^\infty \exp(-Nz) dz = \frac{1}{N}
\]</span> Further, <span class="math display">\[
\Pr[\min h(S) \ge (1 + \epsilon)  \frac{1}{N}] = \exp( - 1 - \epsilon) = \frac{1}{e}e^{-\epsilon} \\
\Pr[\min h(S) \le (1 - \epsilon)  \frac{1}{N}] = 1 - \exp( - 1 + \epsilon) = 1 - \frac{1}{e}e^{\epsilon}
\]</span> Similarly, we can show that if we repeat the experiment <span class="math inline">\(k = O(\frac{\ln 1 / \delta }{\epsilon^2 } )\)</span> times, with probability at least <span class="math inline">\(1 - \delta\)</span>, the <span class="math inline">\(\frac{1}{e}\)</span> smallest elements is an <span class="math inline">\(1 \pm \epsilon\)</span> estimator of <span class="math inline">\(\frac{1}{N}\)</span>.</p>
<h2 id="solution-2">Solution 2</h2>
<p>Suppose we only want to know whether <span class="math inline">\(N \ge t​\)</span> or <span class="math inline">\(N \le t / 2​\)</span> for a given integer <span class="math inline">\(t​\)</span>, is this possible?</p>
<p>The answer is yes and the solution is amazingly easy. We hash each element in <span class="math inline">\(D\)</span> uniformly at random into the range <span class="math inline">\([1, 2, 3, ..., t]\)</span>. If <span class="math inline">\(N \ge t\)</span>, the probability that no elements is assigned the value <span class="math inline">\(t\)</span> is given by <span class="math display">\[
(1 - 1 / t)^N \le (1 - 1 / t)^t \le 1/e
\]</span> The second inequality holds since <span class="math inline">\((1 - 1 / t) \le e^{1 / t}\)</span>.</p>
<p>On the other hand, when <span class="math inline">\(N \le t / 2\)</span>, the probability that no element is assigned the value <span class="math inline">\(t\)</span> is greater than <span class="math display">\[
(1 - 1 / t)^N \ge (1 - 1 / t)^{t / 2} \ge 1 / e
\]</span> The second inequality holds since <span class="math inline">\((1 - 1 / t) \ge e^{- 2 / t} = 1 - \frac{2}{t} + \frac{1}{2!}(\frac{2}{t})^2 - \frac{1}{3!}(\frac{2}{t})^3 + ...\)</span> when <span class="math inline">\(1 / t \le 1/ 2\)</span>.</p>
<p>We can boost the probability to some defined threshold <span class="math inline">\(1 - \delta\)</span> by repeating <span class="math inline">\(k = \log 1 / \delta\)</span> times and check whether the majority of the answers are "yes". Note that the expected number of "yes" is more than <span class="math inline">\((1 - 1 / e)k\)</span> and by chernoff bound the probability that less than <span class="math inline">\(0.5 k\)</span> "yes" are returned is given by <span class="math inline">\(\delta\)</span>.</p>
<p>Now, to estimate <span class="math inline">\(N\)</span>, we can set up <span class="math inline">\(\log n\)</span> values of <span class="math inline">\(t: 1, 2, 4, 8, ..., n\)</span> and test for each value of <span class="math inline">\(t\)</span> whether <span class="math inline">\(N \ge t\)</span> or <span class="math inline">\(N \le t / 2\)</span>. We can find an interval <span class="math inline">\([t_1, t_2]\)</span>, such that <span class="math inline">\(N \in [t_1, t_2]\)</span> and <span class="math inline">\(N / 2 \le t_1 \le t_2 \le 2\cdot N\)</span>. The space complexity is <span class="math inline">\(O(\log n \log 1 / \delta)\)</span>.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/05/17/Jaccard-Similarity/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/05/17/Jaccard-Similarity/" class="post-title-link" itemprop="url">Jaccard Similarity</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-05-17 21:41:06" itemprop="dateCreated datePublished" datetime="2019-05-17T21:41:06+10:00">2019-05-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-05-19 00:54:26" itemprop="dateModified" datetime="2019-05-19T00:54:26+10:00">2019-05-19</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>The Jaccard similarity measures the fraction of shared elements between set. In particular, given set <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, the Jaccard similarity between them is defined as<br />
<span class="math display">\[
J(A, B) = \frac{|A \cap B|}{|A \cup B|}
\]</span> The naive calculation of <span class="math inline">\(J(A, B)\)</span> has time complexity <span class="math inline">\(O(|A \cup B|)\)</span> by scanning all elements in the two sets once. Here we discuss how randomization might save time.</p>
<h2 id="lemma-one">Lemma One</h2>
<p>If we select an item <span class="math inline">\(x\)</span> uniformly at random from <span class="math inline">\(|A \cup B|\)</span>, then <span class="math inline">\(\Pr[x \in A \cap B] = \frac{|A \cap B|}{|A \cup B|}\)</span>.</p>
<p>Define the random variable<br />
<span class="math display">\[
X = \begin{cases}
1, \ if \ x \in \ A \cap B \\
0, \ otherwise
\end{cases}
\]</span></p>
<p>Then we see that <span class="math inline">\(X\)</span> is an unbiased estimator of <span class="math inline">\(J(A, B)\)</span>, i.e., <span class="math inline">\(E[X] = J(A, B)\)</span>.</p>
<p>Suppose that we have a sequence of i.i.d. copies of <span class="math inline">\(X\)</span>, denoted <span class="math inline">\(X_1, X_2, ..., X_k\)</span>, then the average <span class="math inline">\(\mu = \frac{1}{k} \sum_{i = 1}^k X_i\)</span> is also an unbiased estimator of <span class="math inline">\(J(A, B)\)</span>. Moreover, by law of large number, <span class="math inline">\(\mu \rightarrow J(A, B)\)</span> as <span class="math inline">\(k \rightarrow \infty\)</span>. The problem is, how many <span class="math inline">\(X_i\)</span>'s are enough.</p>
<p>The answer depends on a few factors:</p>
<ol type="1">
<li>Whether the value of the required error is relative to <span class="math inline">\(J(A, B)\)</span> or independent to <span class="math inline">\(J(A, B)\)</span>.</li>
<li>What is the tolerance of failure probability.</li>
</ol>
<p>In the following discussion we consider only the case of finding an estimator <span class="math inline">\(\mu\)</span> such that <span class="math inline">\(J(A, B) \in [\mu \pm \epsilon]\)</span> with probability at least <span class="math inline">\(1 - \delta\)</span>, where both <span class="math inline">\(\epsilon\)</span> and <span class="math inline">\(\delta\)</span> are given parameters. Then the convergence behavior with respect to the number of samples <span class="math inline">\(k\)</span> can be captured by Hoeffding inequality:<br />
<span class="math display">\[
\Pr[ |\mu - J(A, B)| \ge \epsilon] \le 2\exp \left( -\frac{2\epsilon^2}{k} \right) = \delta
\]</span></p>
<p>Solving the equation gives<br />
<span class="math display">\[
k = \frac{2}{\epsilon^2}\log \frac{2}{\delta}
\]</span></p>
<p>Or equivalent, when we interpret <span class="math inline">\(\epsilon\)</span> as the width of confidence interval, <span class="math display">\[
\epsilon = \sqrt \frac{\log \frac{2}{\delta} }{k}
\]</span> which has order <span class="math inline">\(O(\sqrt \frac{1}{k})\)</span>.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/04/05/Multiplicative-Weight-Updates/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/04/05/Multiplicative-Weight-Updates/" class="post-title-link" itemprop="url">Multiplicative Weight Updates</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-04-05 18:05:10" itemprop="dateCreated datePublished" datetime="2019-04-05T18:05:10+11:00">2019-04-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-12-14 17:48:44" itemprop="dateModified" datetime="2020-12-14T17:48:44+11:00">2020-12-14</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Consider a problem that might arises from many application scenarios. We have a sequence of <span class="math inline">\(T\)</span> binary variables indexed by time <span class="math inline">\(X_1, X_2, ..., X_T\)</span>, where <span class="math inline">\(X_t \in \{0, 1\}, \forall t \in [T]\)</span>. We try to predict the value of <span class="math inline">\(X_t\)</span>, such that we win <span class="math inline">\(1\)</span> dollar if our guess is correct and <span class="math inline">\(0\)</span> dollar otherwise.</p>
<p>We don't make decision on our own. Instead, we resort a group of <span class="math inline">\(n\)</span> experts. At each time <span class="math inline">\(t\)</span>, each expert <span class="math inline">\(i\)</span> gives a prediction <span class="math inline">\(p_i^t\)</span> of <span class="math inline">\(X_t\)</span>. Based on the experts' prediction, we make prediction our prediction <span class="math inline">\(p_A^t\)</span>. The value of <span class="math inline">\(X_t\)</span> is then revealed and we make a mistake if our prediction is wrong. The goal to minimize the number of mistakes.</p>
<h3 id="how-good-can-we-do">How Good Can We Do</h3>
<p>The first question is how good can we do? Define</p>
<ol type="1">
<li><span class="math inline">\(L_i^t:\)</span> the indicator variable of whether the expert <span class="math inline">\(i\)</span> makes a mistake at round <span class="math inline">\(t\)</span>.</li>
<li><span class="math inline">\(L_i = \sum_{t \in [T] } L_i^t:\)</span> the total number of mistakes expert <span class="math inline">\(i\)</span> makes, when <span class="math inline">\(T\)</span> is fixed.</li>
<li><span class="math inline">\(L_A:\)</span> the one made by our algorithm.</li>
</ol>
<p>Ideally, we would like achieve as few mistakes as<br />
<span class="math display">\[
    \sum_{t \in [T] } \min_{i \in [n]} L_i^t. 
\]</span></p>
<p>However, this is impossible. To see this, suppose <span class="math inline">\(X_t\)</span> is a sequence of independent Bernoulli random variable with probability <span class="math inline">\(0.5\)</span> equal to <span class="math inline">\(1\)</span>. No matter what strategy we use, the expected number of mistakes is always <span class="math inline">\(T / 2\)</span>. On the other hand, <span class="math inline">\(\sum_{t \in [T] } \min_{i \in [n]} L_i^t\)</span> could be <span class="math inline">\(0\)</span>.</p>
<p>Despite the negative result, there is hope to achieve as few mistakes as the best expert (up to some constant), that is<br />
<span class="math display">\[
O \left( \min_{i \in [n]} \sum_{t \in [T] } L_i^t \right) = O \left( \min_{i \in [n] } L_i \right). 
\]</span></p>
<h3 id="follow-the-majority">Follow the Majority</h3>
<p>We start with an easy case where there exists an expert who always gives the correct guess. Under this assumption, we can achieve <span class="math display">\[
\min_{i \in [n] } L_i + \log n
\]</span></p>
<p>mistakes. We simply keep track of a set of experts who do not make any mistake so far. Each time we make a decision, we follow the majority of the set.</p>
<blockquote>
<p>Algorithm 1. <strong>Follow the Majority</strong></p>
<ol type="1">
<li>Let <span class="math inline">\(E_0 \leftarrow \{ 1, 2, ..., n \}\)</span> be the set of all experts.<br />
</li>
<li>For <span class="math inline">\(t \leftarrow 1\)</span> to <span class="math inline">\(T\)</span><br />
</li>
<li><span class="math inline">\(\qquad\)</span> Let <span class="math inline">\(S\)</span> be the subset of <span class="math inline">\(E_{t - 1}\)</span> that predicts 0 at time <span class="math inline">\(t\)</span>.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> Let <span class="math inline">\(\bar S\)</span> be the subset of <span class="math inline">\(E_{t - 1}\)</span> that predicts 1 at time <span class="math inline">\(t\)</span>.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> If <span class="math inline">\(|S| &gt; |\bar S|\)</span>, then predict 0 (<span class="math inline">\(p_A^t \leftarrow 0\)</span>);<br />
</li>
<li><span class="math inline">\(\qquad\qquad\qquad\quad\)</span> else predict 1 (<span class="math inline">\(p_A^t \leftarrow 1\)</span>).<br />
</li>
<li><span class="math inline">\(\qquad\)</span> Reveal <span class="math inline">\(X_t\)</span>.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> If <span class="math inline">\(X_t = 0\)</span>, then <span class="math inline">\(E_t \leftarrow S\)</span>;<br />
</li>
<li><span class="math inline">\(\qquad\qquad\qquad\)</span> else <span class="math inline">\(E_t \leftarrow \bar S\)</span>.</li>
</ol>
</blockquote>
<p><em>Theorem. If there is a perfect expert, the algorithm </em>Follow the Majority* makes at most <span class="math inline">\(\log n\)</span> mistakes.*<br />
<em>Proof.</em> Let <span class="math inline">\(M\)</span> be the number of mistakes the algorithm makes. Each time it makes a mistake, the size of <span class="math inline">\(E_{t}\)</span> shrink by half. Hence, <span class="math display">\[
1 \le |E_T| \le |E_1| \frac{1}{2^M}  = \frac{n}{2^M}. 
\]</span></p>
<p>The first inequality follows from the existence of perfect expert. It concludes that <span class="math display">\[
M \le \log n.  
\]</span> <span class="math inline">\(\square\)</span></p>
<h3 id="follow-the-majority-with-reset">Follow the Majority With Reset</h3>
<p>We continue with the case without a perfect expert. By modifying the <em>Follow the Majority</em> a little, we can achieve <span class="math display">\[
\left( \min_{i \in [n] } L_i  + 1 \right) \cdot \log n
\]</span> mistakes. As before, we maintain a set of experts who do not make any mistake so far and we follow the majority of the set to make decisions.</p>
<blockquote>
<p>Algorithm 2. <strong>Follow the Majority With Reset</strong></p>
<ol type="1">
<li>Let <span class="math inline">\(E_0 \leftarrow \{ 1, 2, ..., n \}\)</span> be the set of all experts.<br />
</li>
<li>For <span class="math inline">\(t \leftarrow 1\)</span> to <span class="math inline">\(T\)</span><br />
</li>
<li><span class="math inline">\(\qquad\)</span> Let <span class="math inline">\(S\)</span> be the subset of <span class="math inline">\(E_{t - 1}\)</span> that predicts 0 at time <span class="math inline">\(t\)</span>.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> Let <span class="math inline">\(\bar S\)</span> be the subset of <span class="math inline">\(E_{t - 1}\)</span> that predicts 1 at time <span class="math inline">\(t\)</span>.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> If <span class="math inline">\(|S| &gt; |\bar S|\)</span>, then predict 0 (<span class="math inline">\(p_A^t \leftarrow 0\)</span>);<br />
</li>
<li><span class="math inline">\(\qquad\qquad\qquad\quad\)</span> else predict 1 (<span class="math inline">\(p_A^t \leftarrow 1\)</span>).<br />
</li>
<li><span class="math inline">\(\qquad\)</span> Reveal <span class="math inline">\(X_t\)</span>.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> If <span class="math inline">\(X_t = 0\)</span>, then <span class="math inline">\(E_t \leftarrow S\)</span>;<br />
</li>
<li><span class="math inline">\(\qquad\qquad\qquad\)</span> else <span class="math inline">\(E_t \leftarrow \bar S\)</span>.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> If <span class="math inline">\(E_t = \emptyset\)</span>, then reset <span class="math inline">\(E_t \leftarrow \{1, 2, ..., n\}\)</span>.</li>
</ol>
</blockquote>
<p><em>Theorem. If there isn't a perfect expert, the algorithm </em>Follow the Majority* makes at most <span class="math inline">\(\left( \min_{i \in [n] } L_i + 1 \right) \cdot \log n\)</span> mistakes.*<br />
<em>Proof.</em> Let <span class="math inline">\(M\)</span> be the number of mistakes the algorithm makes. As analysed before, between two consecutive resets of <span class="math inline">\(E_t\)</span>, the algorithm makes at most <span class="math inline">\(\log n\)</span> mistakes while the best expert makes at least one mistake. Therefore, <span class="math display">\[
\frac{M}{ \log n } \le \min_{i \in [n] } L_i + 1\implies M \le \left( \min_{i \in [n]}  L_i  + 1\right) \cdot \log n
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h3 id="follow-the-weighted-majority">Follow the Weighted Majority</h3>
<p>One drawback of the previous approach is that, the algorithm forgets the relative performance of the experts each time it resets <span class="math inline">\(E_t\)</span>. To fix this, we assign each expert <span class="math inline">\(i\)</span> a weight <span class="math inline">\(w_i^t\)</span> and we follow the weighted majority at time <span class="math inline">\(t\)</span>. This reduces the number of mistakes to <span class="math display">\[
    2.41 \cdot ( \min_{i \in [n]} L_i + \log n).
\]</span></p>
<blockquote>
<p>Algorithm 3. <strong>Follow the Weighted Majority</strong></p>
<ol type="1">
<li>Set <span class="math inline">\(w_i \leftarrow 1, \forall i \in [n].\)</span><br />
</li>
<li>For <span class="math inline">\(t \leftarrow 1\)</span> to <span class="math inline">\(T\)</span><br />
</li>
<li><span class="math inline">\(\qquad\)</span> Let <span class="math inline">\(S\)</span> be the set of experts who predict 0.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> Let <span class="math inline">\(\bar S\)</span> be the set of experts who predict 1.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> If <span class="math inline">\(\sum_{i \in S} w_i &gt; \sum_{i \in \bar S} w_i\)</span>, then predict 0 (<span class="math inline">\(p_A^t \leftarrow 0\)</span>);<br />
</li>
<li><span class="math inline">\(\qquad\qquad\qquad\qquad\qquad\qquad\)</span> else predict 1 (<span class="math inline">\(p_A^t \leftarrow 1\)</span>).<br />
</li>
<li><span class="math inline">\(\qquad\)</span> Reveal <span class="math inline">\(X_t\)</span>.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> For each expert <span class="math inline">\(i\)</span> who predicts wrong</li>
<li><span class="math inline">\(\qquad\qquad\)</span> <span class="math inline">\(w_i \leftarrow w_i / 2\)</span></li>
</ol>
</blockquote>
<p><strong><em>Analysis.</em></strong> Let <span class="math inline">\(w_i^t\)</span> be the weight of player <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span> and define <span class="math inline">\(W^t = \sum_{i = 1}^n w_i^t\)</span>. Each time we make a mistake, the experts who make wrong the prediction have sum of weight <span class="math inline">\(\ge \frac{1}{2} W^t\)</span>. Since their weights halve, we have <span class="math display">\[
W^{t + 1} \le W^t ( 1 - \frac{1}{2}\frac{1}{2}) = \frac{3}{4} W^t.
\]</span></p>
<p>Let <span class="math inline">\(M\)</span> be the number of mistakes the algorithm makes. It follows that <span class="math inline">\(\forall i \in [n]\)</span>, <span class="math display">\[
 \left( \frac{1}{2} \right)^{L_i} = w_i^T \le W^T \le \left( \frac{3}{4} \right)^M W_0 = \left( \frac{3}{4} \right)^M n,  
\]</span></p>
<p>which implies <span class="math display">\[
M \le  \frac{1}{ \log \frac{4}{3} } ( L_i + \log n) \le 2.41 \cdot (L_i + \log n).
\]</span></p>
<p><em>Remark:</em> it is not necessary to halve an expert's weight when it makes a mistake. We can decrease it by any factor <span class="math inline">\((1 - \epsilon)\)</span> for <span class="math inline">\(\epsilon \in (0, 1)\)</span>. In such case, we get <span class="math display">\[
\begin{aligned}
    &amp;\qquad (1- \epsilon)^{L_i} \le \left( 1 - \frac{1 - (1 - \epsilon)}{2} \right)^M n \\
    &amp;\implies L_i \cdot \ln (1 -\epsilon) \le M \ln \left( 1 - \frac{\epsilon}{ 2 } \right) + \ln n \\
    &amp;\implies M \le \frac{ L_i \ln \frac{1}{1 - \epsilon} + \ln n}{ \ln \frac{ 2 }{ 2 - \epsilon } }.
\end{aligned}
\]</span></p>
<p>Let <span class="math inline">\(x = \frac{1}{1 - \epsilon} &gt; 0\)</span>, then <span class="math inline">\(1 - \epsilon = \frac{1}{x}\)</span> and <span class="math inline">\(\frac{2 - \epsilon }{ 2 } = \frac{x + 1}{2x}\)</span>. Define <span class="math display">\[
y = \frac{ L_i \ln x + \ln n}{ \ln 2x - \ln ( x + 1  ) }.
\]</span></p>
<p>Then <span class="math display">\[
\begin{aligned}
    y&#39; \ge 0 
        &amp;\implies  \frac{L_i}{x} (\ln 2x - \ln ( x + 1  ) ) - \left( \frac{1}{x} - \frac{1}{x + 1} \right) (L_i \ln x + \ln n ) \ge 0 \\
        &amp;\implies  L_i(x + 1) (\ln 2x - \ln ( x + 1  ) ) - (L_i \ln x + \ln n ) \ge 0 \\
        &amp;\implies  (x + 1) (\ln 2x - \ln ( x + 1  ) ) - \ln x \ge \frac{\ln n}{L_i}
\end{aligned}
\]</span></p>
<p>It is not easy to compute a closed-form solution for <span class="math inline">\(x\)</span>. But observe that the function <span class="math inline">\((x + 1) (\ln 2x - \ln ( x + 1 ) ) - \ln x\)</span> equals to <span class="math inline">\(0\)</span> for <span class="math inline">\(x = 1\)</span> and is increasing for <span class="math inline">\(x &gt; 1\)</span>. Hence, there exists some <span class="math inline">\(x &gt; 1\)</span>, s.t., the value of the functions equal to <span class="math inline">\(\frac{ \ln n }{ L_i }\)</span>.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/MultiplicativeWeightUpdate/MultiplicativeWeightUpdate.png?raw=true" /></p>
<p><span class="math inline">\(\square\)</span></p>
<h3 id="multiplicative-weight-updates">Multiplicative Weight Updates</h3>
<p>We are in good shape so far. Let's extend the problem to more general settings. In this cases, the experts interact with the environment in round-robin fashion. At each round <span class="math inline">\(t\)</span>,</p>
<ol type="1">
<li>The expert <span class="math inline">\(i\)</span> performs action, termed <span class="math inline">\(a_i^t\)</span>.</li>
<li>The environment returns the loss of performing <span class="math inline">\(a_i^t\)</span>, denoted as <span class="math inline">\(l_i^t \in [0, 1]\)</span>.</li>
</ol>
<p>Although there is no restriction of the experts' actions and their losses, we can come up with some strategy the expected loss of which is almost as good as the best expert: <span class="math display">\[
    \min_{i \in [n] } L_i + 2 \sqrt{ T \ln n }, 
\]</span></p>
<p>where <span class="math inline">\(L_i \doteq \sum_{t \in [T] } l_i^t\)</span> is the loss of expert <span class="math inline">\(i\)</span>. This implies that the average expected loss converges at a rate of <span class="math inline">\(\sqrt \frac{1}{T}\)</span> to the best one.</p>
<blockquote>
<p>Algorithm 4. <strong>Multiplicative Weight Update</strong></p>
<ol type="1">
<li>Set <span class="math inline">\(w_i \leftarrow 1, \forall i \in [n].\)</span><br />
</li>
<li>For <span class="math inline">\(t \leftarrow 1\)</span> to <span class="math inline">\(T\)</span><br />
</li>
<li><span class="math inline">\(\qquad\)</span> Let <span class="math inline">\(W = \sum_{i \in [n] } w_i\)</span>.<br />
</li>
<li><span class="math inline">\(\qquad\)</span> Follow action <span class="math inline">\(a_i^t\)</span> with probability <span class="math inline">\(w_i / W\)</span>.</li>
<li><span class="math inline">\(\qquad\)</span> For each expert <span class="math inline">\(i\)</span>:</li>
<li><span class="math inline">\(\qquad\qquad\)</span> <span class="math inline">\(w_i \leftarrow w_i \cdot (1 - \epsilon l_i^t)\)</span></li>
</ol>
</blockquote>
<p><strong><em>Analysis.</em></strong> Let <span class="math inline">\(l_A^t\)</span> be the loss of the algorithm at round <span class="math inline">\(t\)</span> and <span class="math inline">\(L_A \doteq \sum_{t \in [T] } l_A^t\)</span>. Let <span class="math inline">\(w_i^t\)</span> be the weight of expert <span class="math inline">\(i\)</span> and <span class="math inline">\(W^t\)</span> be the sum of weights at round <span class="math inline">\(t\)</span>. Then <span class="math display">\[
\mathbb{E} [ l_A^t ] = \sum_{i \in [n] } \frac{ \epsilon w_i^t l_i^t }{ W^t }. 
\]</span></p>
<p>By the update rule of the <span class="math inline">\(w_i\)</span>'s, we see <span class="math display">\[
W^{t + 1} = \sum_{i \in [n] } w_i^t (1 - \epsilon l_i^t) = W^t ( 1 - \epsilon \mathbb{E} [ l_A^t ] ) \le W^t \exp( - \epsilon \mathbb{E} [ l_A^t ] ). 
\]</span></p>
<p>By induction, we can write <span class="math display">\[
W^T \le W^1 \exp( - \sum_{t \in [T] } \epsilon \mathbb{E} [ l_A^t ] ) = n \cdot \exp( - \epsilon \mathbb{E} [ L_A ] ).
\]</span></p>
<p>To upper bound <span class="math inline">\(\mathbb{E} [ L_A ]\)</span>, we try to lower bound the value of <span class="math inline">\(n \cdot \exp( - \epsilon \mathbb{E} [ L_A ] )\)</span>. We uses that <span class="math inline">\(\forall i \in [n]\)</span>, <span class="math display">\[
    \prod_{t \in [T] } (1 - \epsilon l_i^t) = w_i^T \le W^T. 
\]</span></p>
<p>Using the fact that <span class="math inline">\(\ln(1 - \epsilon ) \ge \epsilon - \epsilon^2\)</span> for <span class="math inline">\(0 &lt; \epsilon &lt; 0.5\)</span>, we know that <span class="math inline">\(\forall i \in [n]\)</span>,</p>
<p><span class="math display">\[
\exp \left( - \sum_{i \in [T] } \epsilon l_i^t  - \sum_{i \in [T] } (\epsilon l_i^t)^2 \right) \le n \cdot \exp ( - \epsilon \mathbb{E} [ l_A^t ] ). 
\]</span></p>
<p>Taking the log, we get <span class="math display">\[
\mathbb{E} [ l_A^t ] \le \frac{1}{\epsilon } \ln n  + L_i + \epsilon \sum_{i \in [T] } (l_i^t)^2. 
\]</span></p>
<p>There are various ways to upper bound <span class="math inline">\(\sum_{i \in [T] } (l_i^t)^2\)</span>. Naively, this is at most <span class="math inline">\(T\)</span>. Hence, <span class="math display">\[
\mathbb{E} [ l_A^t ] \le \frac{1}{\epsilon } \ln n  + L_i + \epsilon T.  
\]</span></p>
<p>Setting <span class="math inline">\(\epsilon = \sqrt{ \frac{ \ln n}{T} }\)</span>, we get <span class="math display">\[
\mathbb{E} [ l_A^t ] \le L_i + 2 \sqrt{ T \ln n}.
\]</span></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<h4 id="last-updated-date-dec-14th-2020.">Last Updated Date: <strong>Dec 14th, 2020</strong>.</h4>
<h3 id="reference">Reference</h3>
<p>[1] Aaron Roth, “The Polynomial Weights Algorithm”, NETS 412: Algorithmic Game Theory,</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/03/24/Monotone-Class/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/24/Monotone-Class/" class="post-title-link" itemprop="url">Monotone Class</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-24 16:06:49" itemprop="dateCreated datePublished" datetime="2019-03-24T16:06:49+11:00">2019-03-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-04-02 02:14:05" itemprop="dateModified" datetime="2019-04-02T02:14:05+11:00">2019-04-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="theorem">Theorem</h1>
<p>If <span class="math inline">\(M\)</span> is a monotone class and <span class="math inline">\(R \subset M\)</span> is a ring, then <span class="math inline">\(M\)</span> contains the <span class="math inline">\(\sigma\)</span>-ring <span class="math inline">\(\sigma(R)\)</span> generated by <span class="math inline">\(R\)</span> and use the following lemma.</p>
<p><strong>Proof:</strong></p>
<p>Consider the monotone class <span class="math inline">\(M_0\)</span> generated by <span class="math inline">\(R\)</span>. By definition <span class="math inline">\(M_0 \subset M\)</span>. The goal is show that <span class="math inline">\(M_0\)</span> is a ring that contains <span class="math inline">\(R\)</span>.</p>
<h2 id="lemma">Lemma</h2>
<p>If <span class="math inline">\(M_0\)</span> is a ring, then it must be a <span class="math inline">\(\sigma\)</span>-ring.</p>
<p><em>Pf:</em> For each countable collection of sets <span class="math inline">\(( E_n )\)</span>, <span class="math inline">\(\cup_{n} E_n = \cup_{n} (\cup_{k = 1}^n E_k)\)</span>. Denote <span class="math inline">\(F_n = \cup_{k = 1}^n E_n\)</span>, and <span class="math inline">\(F = \cup_{n} E_n\)</span>. Clearly <span class="math inline">\(F_n \uparrow F\)</span>, which implies that <span class="math inline">\(F \subset M_0\)</span>.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<p>It immediately follows that <span class="math inline">\(M_0 \supset \sigma(R)\)</span>. Indeed, as <span class="math inline">\(\sigma(R)\)</span> itself is a monotone class and <span class="math inline">\(M_0\)</span> is the smallest monotone class that contains <span class="math inline">\(R\)</span>, we have <span class="math inline">\(\sigma(R) \supset M_0\)</span>. It concludes that <span class="math inline">\(M_0 = \sigma(R)\)</span>.</p>
<p>To show <span class="math inline">\(M_0\)</span> is a ring, we need to verify that <span class="math inline">\(E, F \in M_0\)</span>, <span class="math inline">\(E \cup F = M_0\)</span> and <span class="math inline">\(E \setminus F \in M_0\)</span>.</p>
<p>Define <span class="math inline">\(S_E = \{ F \in M_0 : E \cup F \in M_0, E \setminus F \in M_0 \}\)</span>, the collection of sets that satisfies the conditions. Note that <span class="math inline">\(S_E\)</span> is a monotone class.</p>
<ol type="1">
<li><p><span class="math inline">\((F_n) \subset S_E\)</span>, and <span class="math inline">\((F_n) \uparrow F\)</span>, then <span class="math inline">\(E \cup F = E \cup [\cup_n F_n] = \cup_n [E \cup F_n]\)</span>. By definition of <span class="math inline">\(S_E\)</span>, <span class="math inline">\(E \cup F_n \in M_0\)</span>. As <span class="math inline">\(F_n \uparrow\)</span> and <span class="math inline">\(M_0\)</span> is monotone, <span class="math inline">\(E \cup F \in M_0\)</span>. Hence <span class="math inline">\(F \in M_0\)</span>.</p></li>
<li><p><span class="math inline">\((F_n) \subset S_E\)</span>, and <span class="math inline">\((F_n) \uparrow F\)</span>, then <span class="math inline">\(E \setminus F = E \setminus [\cup_n F_n] = \cap_n [E \cap F_n] \in M_0\)</span>.</p></li>
</ol>
<p>We claim that for each <span class="math inline">\(E \in M_0\)</span>, it holds that <span class="math inline">\(F \in S_E\)</span> for any <span class="math inline">\(F \in M_0\)</span>, i.e., <span class="math inline">\(M_0 \subset S_E\)</span>. But this is equivalent to show <span class="math inline">\(E \in S_F\)</span>. Since <span class="math inline">\(M_0\)</span> is the smallest monotone class that contains <span class="math inline">\(R\)</span>, it suffices to prove <span class="math inline">\(R \subset S_F\)</span>. We need to utilize the following observation.</p>
<p><em>Let <span class="math inline">\(O \subset R\)</span>, then <span class="math inline">\(S_O \supset R\)</span>, which implies that <span class="math inline">\(S_O \supset M_0\)</span>, as <span class="math inline">\(S_O\)</span> is a monotone class.</em></p>
<p>Therefore, <span class="math inline">\(\forall F \in M_0\)</span>, <span class="math inline">\(R \subset S_F\)</span>.</p>
<p><span class="math inline">\(\blacksquare\)</span>.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/03/21/Partial-Derivatives/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/21/Partial-Derivatives/" class="post-title-link" itemprop="url">Partial Derivatives</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-21 19:14:45" itemprop="dateCreated datePublished" datetime="2019-03-21T19:14:45+11:00">2019-03-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-01-08 14:53:45" itemprop="dateModified" datetime="2020-01-08T14:53:45+11:00">2020-01-08</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="theorem-the-mix-derivative">Theorem The Mix Derivative</h1>
<p><em>Theorem (Symmetry of Second Partial Derivative)</em>: If the function <span class="math inline">\(f : R^2 \rightarrow R\)</span> has continuous derivatives <span class="math inline">\(f_{xy}\)</span> and <span class="math inline">\(f_{yx}\)</span> at some point <span class="math inline">\((a, b)\)</span>, then<br />
<span class="math display">\[
f_{xy}(a, b) = f_{yx}(a, b)
\]</span></p>
<p><strong>Proof:</strong></p>
<p>W.L.O.G, for <span class="math inline">\(h &gt; 0, k &gt; 0\)</span>, define<br />
<span class="math display">\[
\Delta = [f(a + h, b + k) - f(a + h, b)] - [f(a, b + h) - f(a, b)]
\]</span></p>
<p>Define <span class="math inline">\(F(x) = f(x, b + k) - f(x, b)\)</span>, which is continuous and differentiable (since <span class="math inline">\(f_x\)</span> exists on <span class="math inline">\(R\)</span>). By mean value theorem, <span class="math inline">\(\exists a_1 \in [a, a + h]\)</span> for which</p>
<p><span class="math display">\[
\Delta = F(a + h) - F(a) = F&#39;(a_1) h = [f_x(a_1, b + k) - f_x(a_1, b)] h
\]</span></p>
<p>Apply again mean value theorem, <span class="math inline">\(\exists b_1 \in [b, b + k]\)</span>, s.t.,</p>
<p><span class="math display">\[
\begin{aligned}
\Delta &amp;= f_{xy}(a_1, b_1) k h
\end{aligned}
\]</span></p>
<p>We can also define <span class="math inline">\(G(y) = f(a + h, y) - f(a, y)\)</span> and rewrite</p>
<p><span class="math display">\[
\Delta = G(b + h) - G(b)
\]</span></p>
<p>Similarly, by applying mean value theorem twice, <span class="math inline">\(\exists b_2 \in [b, b + k], a_2 \in [a, a + h]\)</span>, s.t,</p>
<p><span class="math display">\[
\Delta = f_{yx}(a_2, b_2)hk
\]</span></p>
<p>Putting together</p>
<p><span class="math display">\[
\Delta = f_{xy}(a_1, b_1) k h = f_{yx}(a_2, b_2)hk
\]</span></p>
<p>Because both <span class="math inline">\(f_{xy}\)</span> and <span class="math inline">\(f_{yx}\)</span> are continuous, as <span class="math inline">\(h \rightarrow 0\)</span> and <span class="math inline">\(k \rightarrow 0\)</span>, <span class="math inline">\(f_{xy}(a_1, b_1) \rightarrow f_{xy}(a, b)\)</span> and <span class="math inline">\(f_{yx}(a_2, b_2) \rightarrow f_{yx}(a, b)\)</span>, as desired.</p>
<p><span class="math inline">\(\blacksquare\)</span>.</p>
<h1 id="theorem-the-increment">Theorem The Increment</h1>
<p>If function <span class="math inline">\(f : R^2 \rightarrow R\)</span> has continuous derivative <span class="math inline">\(f_x\)</span> and <span class="math inline">\(f_y\)</span> at some point <span class="math inline">\((a, b)\)</span>, then</p>
<p><span class="math display">\[
f(a + h, b + k) - f(a, b) = f_x(a, b) h + f_y(a, b)k + \epsilon_1 h + \epsilon_2 k
\]</span></p>
<p>where <span class="math inline">\(\epsilon_1, \epsilon_2 \rightarrow 0\)</span> as <span class="math inline">\(h,k \rightarrow 0\)</span>.</p>
<p><strong>Proof:</strong></p>
<p>By mean value theorem, <span class="math inline">\(\exists a_1\)</span> between <span class="math inline">\(a\)</span> and <span class="math inline">\(a + h\)</span>, <span class="math inline">\(\exists b_1\)</span> between <span class="math inline">\(b\)</span> and <span class="math inline">\(b + k\)</span>, s.t.,</p>
<p><span class="math display">\[
\begin{aligned}
f(a + h, b + k) - f(a, b)  
&amp;= f(a + h, b + k) - f(a + h, b) + f(a + h, b) - f(a, b) \\
&amp;= f_y(a + h, b_1)k + f_x(a_1, b)h
\end{aligned}
\]</span></p>
<p>Define <span class="math inline">\(\epsilon_1 = f_x(a_1, b) - f_x(a, b)\)</span> and <span class="math inline">\(\epsilon_2 = f_y(a + h, b_1) - f_y(a, b)\)</span>, we infer that</p>
<p><span class="math display">\[
f(a + h, b + k) - f(a, b) = f_x(a, b) h + f_y(a, b)k + \epsilon_1 h + \epsilon_2 k
\]</span></p>
<p>The claim <span class="math inline">\(\epsilon_1, \epsilon_2 \rightarrow 0\)</span> as <span class="math inline">\(h,k \rightarrow 0\)</span> results from the continuity of <span class="math inline">\(f_x\)</span> and <span class="math inline">\(f_y\)</span>.</p>
<p><span class="math inline">\(\blacksquare\)</span>.</p>
<h1 id="reference">Reference</h1>
<ol type="1">
<li>George B. Thomas, Jr., Maurice D. Weir, Joel Hass, <em>THOMAS’ CALCULUS</em></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/03/19/Lebesgue-s-Theorem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/19/Lebesgue-s-Theorem/" class="post-title-link" itemprop="url">Lebesgue's Theorem</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-19 22:55:49" itemprop="dateCreated datePublished" datetime="2019-03-19T22:55:49+11:00">2019-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-03-22 19:39:19" itemprop="dateModified" datetime="2019-03-22T19:39:19+11:00">2019-03-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Lebesgue showed that a striking result that a monotone function is differentiable almost everywhere on an interval. We begin the discussion from a key concept, Vitali Cover.</p>
<h1 id="definition-vitali-cover">Definition Vitali Cover</h1>
<ol type="1">
<li><span class="math inline">\(F:\)</span> a collection of closed, bounded non-degenerate(of positive length) intervals.<br />
</li>
<li><span class="math inline">\(E:\)</span> a set.<br />
</li>
<li>Then <span class="math inline">\(F\)</span> is a Vitali cover of <span class="math inline">\(E\)</span> if <span class="math inline">\(\forall x \in E\)</span>, <span class="math inline">\(\forall \epsilon &gt; 0\)</span>, <span class="math inline">\(\exists\)</span> interval <span class="math inline">\(I \in F\)</span>, s.t., <span class="math inline">\(x \in I\)</span> and <span class="math inline">\(\mu(I) &lt; \epsilon\)</span>.</li>
</ol>
<h1 id="theorem-vitali-covering-lemma">Theorem Vitali Covering Lemma</h1>
<ol type="1">
<li><p><span class="math inline">\(E\)</span> a set of finite outer measure.<br />
</p></li>
<li><p><span class="math inline">\(F\)</span> a Vitali cover of <span class="math inline">\(E\)</span>.<br />
</p></li>
<li><p><span class="math inline">\(\forall \epsilon &gt; 0\)</span>, <span class="math inline">\(\exists\)</span> a finite disjoint collection of intervals <span class="math inline">\(\{ I_k \} _{k = 1}^n\)</span> of <span class="math inline">\(F\)</span> for which</p>
<p><span class="math display">\[
\mu^*(E \setminus \cup_{k = 1}^n I_k) \le \epsilon
\]</span></p></li>
</ol>
<p><strong>Proof:</strong> Since <span class="math inline">\(E\)</span> is of finite outer measure, there is a open set <span class="math inline">\(O\)</span> of finite measure that contains <span class="math inline">\(E\)</span> for which <span class="math inline">\(\mu(O) \le \mu^*(E) + \epsilon\)</span>. For each <span class="math inline">\(x \in E\)</span>, we have <span class="math inline">\(x \in O\)</span>. As <span class="math inline">\(O\)</span> is open, <span class="math inline">\(\exists \epsilon &gt; 0\)</span>, s.t., <span class="math inline">\(N_\epsilon(x) \subset O\)</span>. Because <span class="math inline">\(F\)</span> is a Vitali cover of <span class="math inline">\(E\)</span>, there exists an interval <span class="math inline">\(I\)</span> that contains <span class="math inline">\(x\)</span> with length <span class="math inline">\(\mu(I) &lt; \epsilon / 2\)</span>. This means <span class="math inline">\(I \subset N_\epsilon(x) \subset O\)</span>. Therefore, we may assume that <span class="math inline">\(F\)</span> contains only intervals within <span class="math inline">\(O\)</span>.</p>
<p>Then we are going to select a disjoint countable (either finite or infinite) sub-collection of intervals from <span class="math inline">\(F\)</span>. Suppose <span class="math inline">\(n\)</span> is a natural number and the collection <span class="math inline">\(\{ I_k \} _{k = 1 }^n\)</span> of <span class="math inline">\(F\)</span> has been chosen. If <span class="math inline">\(\{ I_k \} _{k = 1}^n\)</span> covers <span class="math inline">\(E\)</span>, then we are done. Otherwise, we pick a new interval <span class="math inline">\(I_{k + 1}\)</span> from <span class="math inline">\(F\)</span> according to two criteria:</p>
<ol type="1">
<li><span class="math inline">\(I_{k + 1}\)</span> should be disjoint with the collection <span class="math inline">\(\{ I_k \}_{k = 1}^n\)</span>, i.e., <span class="math inline">\(I_{k + 1} \cap (\cup_{k = 1}^n I_k) = \emptyset\)</span>.<br />
</li>
<li>The length of <span class="math inline">\(I_{k + 1}\)</span> should be as large as possible.</li>
</ol>
<p>Such <span class="math inline">\(I_{k + 1}\)</span> always exists. Let <span class="math inline">\(x \in E \setminus \cup_{k = 1}^n I_k\)</span>. As <span class="math inline">\(\cup_{k = 1}^n I_k\)</span> is closed, <span class="math inline">\(O \setminus \cup_{k = 1}^n I_k\)</span> is open. Therefore, there is an interval in <span class="math inline">\(F\)</span> that is inside that open set and contains <span class="math inline">\(x\)</span>. We can now define the nonempty collection of such intervals in <span class="math inline">\(F\)</span> as <span class="math inline">\(F_n\)</span>:<br />
<span class="math display">\[
F_n \doteq \{ I \in F : I \cap (\cup_{k = 1}^n I_k ) = \emptyset \}
\]</span></p>
<p>As all interval in <span class="math inline">\(F_n\)</span> are contained in <span class="math inline">\(O\)</span> with finite measure,<br />
<span class="math display">\[
\alpha_n \doteq \sup_{I \in F_n} \mu(I)
\]</span> exists and is a real number. Although we may not be able to find an interval <span class="math inline">\(I\)</span> that achieves the maximum length, i.e., <span class="math inline">\(\mu(I) = \alpha_n\)</span>, it suffices to find one that is "a little bit" shorter. The criteria is not unique and for our proof we choose an <span class="math inline">\(I_{k + 1}\)</span> of measure <span class="math inline">\(\mu(I_{k + 1}) &gt; \alpha_n / 2\)</span>.</p>
<p>Now <span class="math inline">\(\{ I_k \}_{k = 1}^\infty\)</span> is a disjoint collection whose union is within <span class="math inline">\(O\)</span>. By the countable additivity and monotonicity of measure,<br />
<span class="math display">\[
\mu(\cup_{k = 1}^\infty I_k) = \sum_{k = 1}^\infty \mu( I_k) \le \mu(O) \le \mu(E) + \epsilon
\]</span></p>
<p>We infer that <span class="math inline">\(\mu(I_k) \rightarrow 0\)</span>. Moreover, <span class="math inline">\(\{ I_k \}_{k = 1}^\infty\)</span> has the following property: for each interval <span class="math inline">\(I \in F\)</span> that contains an element <span class="math inline">\(x \in E\)</span>, either it belongs to or overlaps with <span class="math inline">\(\{ I_k \}_{k = 1}^\infty\)</span>. Otherwise, <span class="math inline">\(I\)</span> is disjoint with <span class="math inline">\(\{ I_k \}_{k = 1}^\infty\)</span>. But the selection process guarantees that <span class="math inline">\(\mu(I) \le 2 \mu(I_k)\)</span> for all <span class="math inline">\(k\)</span>, which implies <span class="math inline">\(\mu(I) = 0\)</span>, a contradiction (any <span class="math inline">\(I \in F\)</span> must have positive length).</p>
<p>We claim that for any natural number <span class="math inline">\(n\)</span>, it holds that<br />
<span class="math display">\[
E \setminus \cup_{k = 1}^n I_k \subset \cup_{k = n + 1}^\infty 5 * I_k
\]</span></p>
<p>As before, for <span class="math inline">\(x \in E \setminus \cup_{k = 1}^n I_k\)</span>, <span class="math inline">\(\exists \ I \in F_n\)</span> for which <span class="math inline">\(x \in I\)</span>. Then <span class="math inline">\(I\)</span> must belongs to or intersect with <span class="math inline">\(\cup_{k = n + 1}^\infty I_k\)</span>. Let <span class="math inline">\(m\)</span> be the first natural number that <span class="math inline">\(I_{m} \cap I \neq \emptyset\)</span>. By the selection process of <span class="math inline">\(I_m\)</span>, <span class="math inline">\(\mu(I_m) \ge \mu(I) / 2\)</span>. This means <span class="math inline">\(I \subset 5 * I_m\)</span>.</p>
<p>Let <span class="math inline">\(\epsilon &gt; 0\)</span>, <span class="math inline">\(\exists N &gt; 0\)</span>, s.t., <span class="math inline">\(\sum_{k = N}^\infty \mu(I_k) &lt; \epsilon / 5\)</span>. This choice of <span class="math inline">\(N\)</span>, together with the fact that <span class="math inline">\(E \setminus \cup_{k = 1}^n I_k \subset (\cup_{k = n + 1}^\infty 5 * I_k)\)</span>, establishes the desired result.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<h1 id="lemma">Lemma</h1>
<p>Let <span class="math inline">\(f : [a, b] \rightarrow R\)</span> be a non-decreasing function, then for each <span class="math inline">\(\alpha &gt; 0\)</span>,<br />
<span class="math display">\[
\alpha \mu^* (\{ x \in [a, b] : \bar D f(x) \ge \alpha \}) \le f(b) - f(a)  
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\mu^*(\{ x \in (a, b) : \bar D f(x) = \infty \}) = 0
\]</span></p>
<p><strong>Proof:</strong><br />
Define <span class="math inline">\(E = \{ x \in [a, b] : \bar D f(x) \ge \alpha \}\)</span>. For each <span class="math inline">\(0 &lt; \lambda &lt; \alpha\)</span>, let <span class="math inline">\(F_{\lambda} = \{ [c, d] \subset [a, b], f(d) - f(c) \ge \lambda (d - c) \}\)</span>. Since <span class="math inline">\(\bar D f \ge \alpha\)</span> on <span class="math inline">\(E\)</span>, <span class="math inline">\(F\)</span> is a Vitali cover of <span class="math inline">\(E\)</span>. By Vitali Covering Theorem, there is a finite disjoint sub-collection of intervals <span class="math inline">\(\{ [c_k, d_k] \}_{k = 1}^n\)</span> of <span class="math inline">\(F\)</span> for which <span class="math display">\[
\mu^*(E \setminus \cup_{k = 1}^n I_k) \le \epsilon
\]</span></p>
<p>Therefore,</p>
<p><span class="math display">\[
\begin{aligned}
\mu^*(E)  
&amp;\le \mu(\cup_{k = 1}^n I_k) + \mu^*(E \setminus \cup_{k = 1}^n I_k) \\
&amp;\le \mu(\cup_{k = 1}^n I_k) + \epsilon \\
&amp;= \sum_{k = 1}^n \mu(I_k) + \epsilon \\
&amp;= \sum_{k = 1}^n (d_k - c_k) + \epsilon \\
&amp;\le \sum_{k = 1}^n \frac{1}{\lambda} [f(d_k) - f(c_k)] + \epsilon \\
&amp;\le \frac{1}{\lambda} [f(d) - f(c)] + \epsilon
\end{aligned}
\]</span></p>
<p>Taking the limit of <span class="math inline">\(\lambda \rightarrow \alpha\)</span>, and <span class="math inline">\(\epsilon \rightarrow 0\)</span>, we proves</p>
<p><span class="math display">\[
\alpha \mu^* (E) \le f(d) - f(c)
\]</span></p>
<p><span class="math inline">\(\blacksquare\)</span>.</p>
<h1 id="theorem-lebesgue">Theorem Lebesgue</h1>
<p>If a function <span class="math inline">\(f\)</span> is monotone on a interval <span class="math inline">\((a, b)\)</span>, then it is differentiable almost everywhere.</p>
<p><strong>Proof:</strong><br />
Without lost of generality, assume <span class="math inline">\(f\)</span> is increasing. The set of non-differentiable points can be written as<br />
<span class="math display">\[
E = \cup_{\alpha, \beta \in Q} \{ x \in (a, b) : \bar D f(x) \ge \alpha &gt; \beta &gt; \underline D f(x) \}
\]</span></p>
<p>where <span class="math inline">\(Q\)</span> is the set of rational numbers. It suffices to consider just <span class="math inline">\(E_{\alpha, \beta} = \{ x \in (a, b) : \bar D f(x) \ge \alpha &gt; \beta &gt; \underline D f(x) \}\)</span>. We prove that <span class="math inline">\(E_{\alpha, \beta}\)</span> has zero measure and therefore by countable additivity <span class="math inline">\(E\)</span> has measure zero.</p>
<p>For fix <span class="math inline">\(E_{\alpha, \beta}\)</span>, choose an open set <span class="math inline">\(O\)</span> for which <span class="math inline">\(E_{\alpha, \beta} \subset O \subset (a, b)\)</span> and <span class="math inline">\(\mu^*(O \setminus E_{\alpha, \beta}) \le \epsilon\)</span>. Let <span class="math inline">\(F_{\beta} = \{ [c, d] \subset O, f(d) - f(c) \le \beta (d - c) \}\)</span> be a Vitali cover of <span class="math inline">\(E_{\alpha, \beta}\)</span>. By Vitali Covering Theorem, there is a finite disjoint sub-collection of intervals <span class="math inline">\(\{ [c_k, d_k] \}_{k = 1}^n\)</span> for which<br />
<span class="math display">\[
\mu^*(E_{\alpha, \beta} \setminus \cup_{k = 1}^n I_k) \le \epsilon
\]</span></p>
<p>Therefore,</p>
<p><span class="math display">\[
\begin{aligned}
\mu^*(E_{\alpha, \beta})  
&amp;\ge \mu(O) - \epsilon \\
&amp;\ge \mu(\cup_{k = 1}^n I_k) - \epsilon \\
&amp;= \sum_{k = 1}^n \mu(I_k) - \epsilon \\
&amp;= \sum_{k = 1}^n (d_k - c_k) - \epsilon \\
&amp;\ge \sum_{k = 1}^n \frac{1}{\beta} [f(d_k) - f(c_k)] - \epsilon \\
\end{aligned}
\]</span></p>
<p>On the other hand, for each interval <span class="math inline">\([c_k, d_k]\)</span>, by the previous lemma,<br />
<span class="math display">\[
f(d_k) - f(c_k) \ge \alpha \mu(\{x \in [c_k, d_k] \cap E_{\alpha, \beta} \})
\]</span></p>
<p>Together with sub-additivity of outer measure,</p>
<p><span class="math display">\[
\begin{aligned}
\mu^*(E_{\alpha, \beta})  
&amp;\le \mu^*(\cup_{k = 1}^n I_k \cap E_{\alpha, \beta}) + \mu^*(E_{\alpha, \beta} \setminus \cup_{k = 1}^n I_k) \\
&amp;\le \mu(\cup_{k = 1}^n I_k \cap E_{\alpha, \beta}) + \epsilon \\
&amp;\le \sum_{k = 1}^n \frac{1}{\alpha} [f(d_k) - f(c_k)] + \epsilon \\
\end{aligned}
\]</span></p>
<p>Combined, we obtained<br />
<span class="math display">\[
\sum_{k = 1}^n \frac{1}{\beta} [f(d_k) - f(c_k)] - \epsilon  \le \mu^*(E_{\alpha, \beta}) \le \sum_{k = 1}^n \frac{1}{\alpha} [f(d_k) - f(c_k)] + \epsilon
\]</span></p>
<p>By arbitrariness of <span class="math inline">\(\epsilon\)</span>, it holds that <span class="math display">\[
\beta \mu^*(E_{\alpha, \beta}) \ge \alpha \mu^*(E_{\alpha, \beta})
\]</span></p>
<p>It concludes that <span class="math inline">\(\mu^*(E_{\alpha, \beta}) = 0\)</span>.</p>
<p><span class="math inline">\(\blacksquare\)</span>.</p>
<h1 id="reference">Reference</h1>
<ol type="1">
<li>H.L.Royden, P.M. Fitzpatrick, <em>Real Analysis</em></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/03/18/Fundamental-Theorem-of-Calculus/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/18/Fundamental-Theorem-of-Calculus/" class="post-title-link" itemprop="url">Fundamental Theorem of Calculus</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-18 20:03:31" itemprop="dateCreated datePublished" datetime="2019-03-18T20:03:31+11:00">2019-03-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-03-22 19:45:50" itemprop="dateModified" datetime="2019-03-22T19:45:50+11:00">2019-03-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>The relation between integration and differentiation constitutes the key study of calculus.</p>
<h1 id="fundamental-theorem-of-calculus">Fundamental Theorem of Calculus</h1>
<ol type="1">
<li>If <span class="math inline">\(f : [a, b] \rightarrow\)</span> is bounded and Riemann integrable, and <span class="math inline">\(F(x) = \int_a^x f(t) \ dt\)</span> for <span class="math inline">\(x \in [a, b]\)</span>, then <span class="math inline">\(F(x)\)</span> is uniformly continuous and <span class="math inline">\(F&#39;(x)\)</span> exists for all <span class="math inline">\(x\)</span> where <span class="math inline">\(f(x)\)</span> is continuous and <span class="math inline">\(F&#39;(x) = f(x)\)</span>.<br />
</li>
<li>If <span class="math inline">\(F: [a, b] \rightarrow R\)</span> is differentiable and <span class="math inline">\(f: [a, b] \rightarrow R\)</span> is integrable. Suppose <span class="math inline">\(F&#39;(x) = f(x)\)</span> for all <span class="math inline">\(x \in [a, b]\)</span>, then</li>
</ol>
<p><span class="math display">\[
F(b) - F(a) = \int_a^b f(t) \ dt
\]</span></p>
<p><strong>Remark:</strong></p>
<ol type="1">
<li><p>Claim one require the condition that <span class="math inline">\(f\)</span> is bounded. Can we omit the condition?</p></li>
<li><p>The condition <span class="math inline">\(f\)</span> is integrable is necessary.</p></li>
</ol>
<p><strong>Proof:</strong></p>
<ol type="1">
<li><p>As <span class="math inline">\(f\)</span> is bounded, we assume that <span class="math inline">\(\sup_{t \in [a, b]} |f(t)| \le M\)</span>. For any <span class="math inline">\(x \in [a, b]\)</span> and <span class="math inline">\(x + h \in [a, b]\)</span>,</p>
<p><span class="math display">\[
 \left| F(x + h) - F(x) \right| = \left| \int_x^{x + h} f(t) \ dt \right| \le M|h|
 \]</span></p>
<p>This show that <span class="math inline">\(F(x)\)</span> is uniformly continuous.</p>
<p>Now, assume that <span class="math inline">\(f(x)\)</span> is continuous at point <span class="math inline">\(x\)</span>. <span class="math inline">\(\forall \epsilon &gt; 0\)</span>, <span class="math inline">\(\exists \delta &gt; 0\)</span>, s.t., <span class="math inline">\(\forall t \in (x \pm \delta)\)</span>, <span class="math inline">\(|f(t) - f(x)| \le \epsilon\)</span>. We see that</p>
<p><span class="math display">\[
 \begin{aligned}
 \left| F(x + h) - F(x) - f(x) h  \right|  
 &amp;= \left| \int_x^{x + h} f(t) \ dt - \int_x^{x + h} f(x) \ dt \right| \\
 &amp;= \left| \int_x^{x + h} [f(t) - f(x)] \ dt \right| \\
 &amp;\le \int_x^{x + h} \left| f(t) - f(x) \right| \ dt \\
 &amp;\le \epsilon h
 \end{aligned}
 \]</span></p>
<p>As desired.</p></li>
<li><p>For partition <span class="math inline">\(P = \{ a = x_0 &lt; x_1 &lt; x_2 &lt; ... &lt; x_n = b \}\)</span> of <span class="math inline">\([a, b]\)</span>, apply the mean value theorem to <span class="math inline">\(F\)</span> on a sub-interval. <span class="math display">\[
 F(x_k) - F(x_{k - 1}) = F&#39;(t_k) (x_k - x_{k -1})  \quad t_k \in [x_{k - 1}, x_k] \quad \forall \ 1 \le k \le n,
 \]</span> Let <span class="math inline">\(U(f, P), L(f, )\)</span> be the upper sum and lower sum of the partition respectively, <span class="math display">\[
 \begin{aligned}
 F(b) - F(a)  
 &amp;= \sum_{k = 1}^n F(x_k) - F(x_{k - 1}) \\
 &amp;= \sum_{k = 1}^n F&#39;(t_k) (x_k - x_{k -1}) \\
 &amp;= \sum_{k = 1}^n f(t_k) (x_k - x_{k -1}) \\
 &amp;\in [L(f, P), U(f, P)]
 \end{aligned}
 \]</span> This is independent of the choice of <span class="math inline">\(P\)</span>. Taking the limit of upper sum and lower sum, we conclude that <span class="math inline">\(F(b) - F(a) \in [\sup_P L(f, P), \inf_P U(f, P)] = \left[ \int_a^b f(t) \ dt, \int_a^b f(t) \ dt \right]\)</span>.</p></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/03/14/Radon-Nikodym-Theorem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/14/Radon-Nikodym-Theorem/" class="post-title-link" itemprop="url">Radon Nikodym Theorem</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-14 20:17:37" itemprop="dateCreated datePublished" datetime="2019-03-14T20:17:37+11:00">2019-03-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-03-22 00:07:56" itemprop="dateModified" datetime="2019-03-22T00:07:56+11:00">2019-03-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>We consider a measure space <span class="math inline">\((X, \Omega, \mu)\)</span>, where <span class="math inline">\(X\)</span> is a set of elements, <span class="math inline">\(\Omega\)</span> is a collection of measurable sets and <span class="math inline">\(\mu : \Omega \rightarrow R\)</span> a <span class="math inline">\(\sigma\)</span>-finite measure defined on <span class="math inline">\(\Omega\)</span>.</p>
<h1 id="theorem.-the-radon-nikodym-theorem">Theorem. The Radon-Nikodym Theorem</h1>
<p>Let <span class="math inline">\(\nu\)</span> be a <span class="math inline">\(\sigma\)</span>-finite signed measure with domain <span class="math inline">\(\Omega\)</span> and absolutely continuous with respect to <span class="math inline">\(\mu\)</span> (<span class="math inline">\(\nu \ll \mu\)</span>). Then there exists a real-valued measurable function <span class="math inline">\(f\)</span> on <span class="math inline">\(\Omega\)</span> such that<br />
<span class="math display">\[
\nu(E) = \int_E f \ d \mu
\]</span> for every measurable set <span class="math inline">\(E\)</span> for which <span class="math inline">\(|\nu|(E) &lt; \infty\)</span>. If <span class="math inline">\(g\)</span> is another function such that <span class="math inline">\(\nu(E) = \int_E g \ d \mu\)</span> for any measurable set <span class="math inline">\(E\)</span> for which <span class="math inline">\(|\nu|(E) &lt; \infty\)</span>, then <span class="math inline">\(f = g \ a.e.\)</span> with respect to <span class="math inline">\(\nu\)</span>.</p>
<p><strong>Proof:</strong></p>
<p>Since both <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\nu\)</span> are <span class="math inline">\(\sigma\)</span>-finite, it suffices to consider the case in which <span class="math inline">\(\mu(X) &lt; \infty\)</span> and <span class="math inline">\(|\nu| (X) &lt; \infty\)</span>. Further, we may assume that <span class="math inline">\(\nu\)</span> is a measure, otherwise we can consider the Hahn decomposition of <span class="math inline">\(\nu\)</span> separately.</p>
<p>Define the collection of functions</p>
<p><span class="math display">\[
D = \left\{ f \text{ is measurable and } \nu(E) \ge \int_E f \ d \mu \quad \forall E \in \Omega \right\}
\]</span></p>
<p>Note that <span class="math inline">\(D\)</span> is non-empty, since at least <span class="math inline">\(f \equiv 0\)</span> satisfies the conditions and belongs to <span class="math inline">\(D\)</span>. Consider the supremum of integrals of function in <span class="math inline">\(D\)</span></p>
<p><span class="math display">\[
\left( \alpha \doteq \sup_{f \in D} \int f \ d \mu \right) \le \nu(X)
\]</span></p>
<p>Then <span class="math inline">\(\exists \{ g_n \} \subset D\)</span>, a sequence of functions whose integral approaches the supremum</p>
<p><span class="math display">\[
\lim_n \int g_n \ d \mu  = \alpha  
\]</span> Define <span class="math inline">\(f_n = \max_{1 \le i \le n} g_i\)</span>. It has the following properties:</p>
<ol type="1">
<li><p><span class="math inline">\(f_n \in D\)</span>. To verify this, for any measurable set <span class="math inline">\(E\)</span>, consider <span class="math inline">\(F_{n,i} = \{ x \in E : f_n(x) = g_i(x) \}\)</span>. Rewrite <span class="math inline">\(E_{n, i} = F_{n,i} \setminus \cup_{j = 1}^{n - 1} F_{n,j}\)</span> as a collection of mutually exclusive sets. For <span class="math inline">\(1 \le k \le n\)</span>,</p>
<p><span class="math display">\[
 \begin{aligned}
 \int_E f_n \ d \mu  
 &amp;= \sum_{i = 1}^n \int_{E_{n,i}} f_n \ d \mu  \\
 &amp;= \sum_{i = 1}^n \int_{E_{n,i}} g_i \ d \mu  \\
 &amp;\le \sum_{i = 1}^n \nu(E_{n,i}) \\
 &amp;= \nu( \cup_{i = 1}^n E_{n,i} ) \\
 &amp;= \nu(E)
 \end{aligned}
 \]</span></p></li>
<li><p><span class="math inline">\(\{ f_n \}\)</span> is monotone increasing and <span class="math display">\[
 \alpha = \lim_k \int g_k \ d \mu \le \lim_n \int f_n \ d \mu \le \alpha  
 \]</span> We must have <span class="math inline">\(\lim_n \int f_n \ d \mu = \alpha\)</span>.</p></li>
</ol>
<p>Let <span class="math inline">\(f = \lim_n f_n\)</span>. According to Monotone Convergence Theorem, <span class="math inline">\(f\)</span> is integrable <span class="math display">\[
\alpha = \lim_n \int f_n \ d \mu= \int f \ d \mu
\]</span></p>
<p>It is left to show that <span class="math inline">\(\lambda(E) = \int_E f\)</span> for each measurable set <span class="math inline">\(E\)</span>. Define function <span class="math inline">\(\lambda : \Omega \rightarrow R\)</span> as</p>
<p><span class="math display">\[
\lambda(E) = \nu(E) - \int_E f \ d \mu  
\]</span></p>
<p>We complete the proof by showing that <span class="math inline">\(\lambda(E) \equiv 0\)</span>.</p>
<p>It is easy to verify that <span class="math inline">\(\lambda\)</span> is a measure (<span class="math inline">\(\lambda \ge 0\)</span>) as <span class="math inline">\(\nu(E) \ge \int_E f d \mu\)</span>. Further, <span class="math inline">\(\int_E f \ d \mu \ll \mu\)</span> and <span class="math inline">\(\nu \ll \mu\)</span> imply that <span class="math inline">\(\lambda \ll \mu\)</span>.</p>
<p>Suppose <span class="math inline">\(\lambda \ne 0\)</span>. By assumption <span class="math inline">\(\mu(X) &lt; \infty\)</span>, then there exists <span class="math inline">\(\epsilon &gt; 0\)</span>, such that <span class="math inline">\(\lambda(X) - \epsilon \mu(X) &gt; 0\)</span>. Let <span class="math inline">\(\{ A, B\}\)</span> be the Hahn decomposition of <span class="math inline">\(\lambda - \epsilon \mu\)</span> such that <span class="math inline">\(A\)</span> is positive. Let <span class="math inline">\(g = f + \epsilon \chi_{A}\)</span>. It satisfies</p>
<ol type="1">
<li><p><span class="math inline">\(g \in D\)</span>, since <span class="math inline">\(\forall E \in \Omega\)</span>,<br />
<span class="math display">\[
\lambda(E) - \int_E g \ d  \mu = \lambda(E) - \int_E f \ d \mu - \int_E \epsilon \chi_{A} \ d \mu \ge 0
\]</span></p></li>
<li><p><span class="math inline">\(\int g \ d \mu \ge \alpha\)</span>,<br />
<span class="math display">\[
 \int g \ d \mu = \int f + \epsilon \chi_{A} \ d \mu = \int f \ d \mu + \int \epsilon \chi_A \ d \mu = \alpha + \epsilon \mu(A) \ge \alpha
 \]</span></p></li>
</ol>
<p>If follows that <span class="math inline">\(\mu(A) = 0\)</span>. Now <span class="math inline">\(0 &lt; (\lambda - \epsilon \mu)(X) = (\lambda - \epsilon \mu)(A) + (\lambda - \epsilon \mu)(B) = 0 + (\lambda - \epsilon \mu)(B) \le 0\)</span>. Contradiction. We thus have proved that <span class="math inline">\(\lambda = 0\)</span>.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/03/03/Integral/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/03/Integral/" class="post-title-link" itemprop="url">Integral</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-03 21:15:57" itemprop="dateCreated datePublished" datetime="2019-03-03T21:15:57+11:00">2019-03-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-03-14 18:47:35" itemprop="dateModified" datetime="2019-03-14T18:47:35+11:00">2019-03-14</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>We consider a measure space <span class="math inline">\((X, \Omega, \mu)\)</span>, where <span class="math inline">\(X\)</span> is a set of elements, <span class="math inline">\(\Omega\)</span> is a collection of measurable sets and <span class="math inline">\(\mu : \Omega \rightarrow R\)</span> a measure defined on <span class="math inline">\(\mu\)</span>. Note that by definition <span class="math inline">\(\Omega\)</span> is a <span class="math inline">\(\sigma\)</span> algebra and <span class="math inline">\(\mu\)</span> satisfies</p>
<ol type="1">
<li>(Zero element) <span class="math inline">\(\mu(\emptyset) = 0​\)</span>,<br />
</li>
<li>(Non negativity) <span class="math inline">\(\mu(E) \ge 0​\)</span> for all <span class="math inline">\(E \in \Omega\)</span>,<br />
</li>
<li>(Complete additivity) <span class="math inline">\(\mu(\cup_{i = 1}^\infty E_i) = \sum_{i = 1}^\infty \mu(E_i)\)</span> for a collection of mutually exclusive sets <span class="math inline">\(\{E_i : i \in \mathbf{N} \}\)</span>.</li>
</ol>
<h1 id="definition.-simple-function"><strong>Definition.</strong> Simple Function</h1>
<p><em>A characteristic function <span class="math inline">\([ \cdot ] \rightarrow \{0, 1\}​\)</span> is a function that takes value 1 if its argument is true and zero otherwise. A characteristic function <span class="math inline">\(\chi_E : X \rightarrow \{0, 1\}​\)</span> for a set <span class="math inline">\(E \subset X​\)</span> is denoted as <span class="math inline">\(\chi_E \doteq [x \in E]​\)</span></em>.</p>
<p><em>A simple function <span class="math inline">\(f : X \rightarrow R\)</span> is summation of finite terms:</em><br />
<span class="math display">\[
f = \sum_{i = 1}^n a_i \chi_{E_i}
\]</span></p>
<p><em>where <span class="math inline">\(\{E_1, E_2,... E_n \}\)</span> are measurable sets and constitute a partition of <span class="math inline">\(X\)</span>, i.e., <span class="math inline">\(\cup_{i = 1}^n E_i = X\)</span> and <span class="math inline">\(E_i \cap E_j = \emptyset\)</span> for <span class="math inline">\(i \neq j\)</span></em>.</p>
<h1 id="definition.-integrable-simple-function"><strong>Definition.</strong> Integrable Simple Function</h1>
<p><em>A simple function <span class="math inline">\(f=\sum_{i=1}^n a_i \chi_{E_i }\)</span> is said to be integrable if <span class="math inline">\(\mu(E_i ) &lt; \infty\)</span> for all the indices <span class="math inline">\(i\)</span> for which <span class="math inline">\(a_i \neq 0\)</span>, i.e., <span class="math inline">\(a_i \neq 0 \rightarrow \mu(E_i) &lt; \infty\)</span>.<br />
The integral of <span class="math inline">\(f\)</span> is the real number <span class="math inline">\(\sum_{i=1}^n a_i \mu(E_i)\)</span>, where we agree to take <span class="math inline">\(a_i \mu(E_i ) = 0\)</span> for all the indices <span class="math inline">\(i\)</span> for which <span class="math inline">\(a_i=0, \mu(E_i )= \infty\)</span>. We denote this sum by</em><br />
<span class="math display">\[
\int f= \sum_{i=1}^n a_i \mu(E_i )
\]</span></p>
<h1 id="theorem"><strong>Theorem</strong></h1>
<p><em>The integration is well defined and independent of the representation of <span class="math inline">\(f\)</span>.</em></p>
<p><strong>Proof:</strong> Let <span class="math inline">\(f = \sum_{i = 1}^n a_i \chi_{E_i}\)</span> and <span class="math inline">\(g = \sum_{j = 1}^m b_j \chi_{F_j}\)</span>. Suppose that <span class="math inline">\(f \equiv g\)</span>, the goal is to show that <span class="math inline">\(\int f = \int g\)</span>. Define <span class="math inline">\(S_{ij} = E_i \cap F_j\)</span>. If <span class="math inline">\(S_{ij} \neq \emptyset\)</span>, we must have <span class="math inline">\(a_i = b_j\)</span>. To see this, let <span class="math inline">\(s \in S_{i,j}\)</span>. Since <span class="math inline">\(\{E_1, E_2,... E_n \}\)</span> is a partition of <span class="math inline">\(X\)</span>,only one of the value <span class="math inline">\(\{ \chi_{E_i} (s) : i \in [1, n] \}\)</span> takes value 1 and <span class="math inline">\(f(s) = \sum_{i = 1}^n a_i \chi_{E_i}(x) = a_i \chi_{E_i}(x) = a_i\)</span>. Similarly, <span class="math inline">\(g(s) = b_j\)</span>. We have <span class="math inline">\(a_i = b_j\)</span> as <span class="math inline">\(f \equiv g\)</span>.</p>
<p>Now, let <span class="math inline">\(c_{i,j} = a_i = b_j\)</span> if <span class="math inline">\(S_{i,j} \neq \emptyset\)</span> and <span class="math inline">\(c_{i,j}= 0\)</span> otherwise. Using the fact that <span class="math inline">\(\{ F_1, ..., F_m \}\)</span> also constitutes a partition of <span class="math inline">\(X\)</span>, we have <span class="math inline">\(E_i = \cup_{j = 1}^m E_i \cap F_j\)</span> for <span class="math inline">\(i \in [1, n]\)</span>. By finite additivity of measure,<br />
<span class="math display">\[
\begin{aligned}
\int f  
&amp;= \sum_{i=1}^n a_i \mu (E_i ) \\
&amp;= \sum_{i=1}^n a_i \mu (\cup_{j=1}^m E_i \cap F_j) \\
&amp;= \sum_{i=1}^n a_i \sum_{j = 1}^m \mu (E_i \cap F_j) \\
&amp;= \sum_{i=1}^n \sum_{j=1}^m c_{i,j} \mu( S_{i,j} )
\end{aligned}
\]</span></p>
<p>By symmetry, we can show <span class="math inline">\(\int g = \sum_{i=1}^n \sum_{j=1}^m c_{i,j} \mu( S_{i,j} )\)</span>, which implies that <span class="math inline">\(\int f = \int g\)</span>, as desired.</p>
<p>NOTE: in the proof we see that <span class="math inline">\(\sum_{i=1}^n \sum_{j=1}^m c_{i,j} \mu( S_{i,j} ) = \int f &lt; \infty\)</span>. It follows that <span class="math inline">\(\mu(S_{i, j}) = \infty \rightarrow c_{i,j} = 0\)</span></p>
<p><span class="math inline">\(\blacksquare​\)</span></p>
<h1 id="theorem.-integration-on-a-measurable-set"><strong>Theorem.</strong> Integration on a measurable set</h1>
<p><em>If <span class="math inline">\(E\)</span> is any measurable set and <span class="math inline">\(f\)</span> is an integrable simple function, then <span class="math inline">\(\chi_E f \doteq \chi_{E} \sum_{i = 1}^n a_i \chi_{E_i}\)</span> is also an integrable simple function.</em></p>
<p><strong>Proof:</strong> <span class="math display">\[
\chi_E f = \chi_{E} \sum_{i = 1}^n a_i \chi_{E_i} = \sum_{i = 1}^n a_i \chi_{E_i \cap E}
\]</span> By monotonicity of measure, if <span class="math inline">\(a_i \neq 0\)</span>, then <span class="math inline">\(\mu(E_i \cap E) \le \mu(E_i) &lt; \infty\)</span>. Therefore, <span class="math inline">\(\chi_E f\)</span> is integrable.</p>
<p><span class="math inline">\(\blacksquare​\)</span></p>
<h1 id="definition"><strong>Definition</strong></h1>
<p>The integration of <span class="math inline">\(\chi_E f\)</span> is abbreviated as<br />
<span class="math display">\[
\int_E f = \int \chi_E f
\]</span></p>
<p>Now we show some basic properties of simple integration. These properties really inherit from the non-negativity and complete additivity of measure <span class="math inline">\(\mu\)</span></p>
<h1 id="basic-properties-of-simple-integrable-functions"><strong>Basic Properties of Simple Integrable Functions</strong></h1>
<p>Let <span class="math inline">\(f=\sum_{i=1}^n a_i \chi_{E_i }\)</span> and <span class="math inline">\(g=\sum_{j=1}^m b_j \chi_{F_j }\)</span> be two integrable simple functions, and <span class="math inline">\(\alpha, \beta \in R\)</span> two real values.</p>
<ol type="1">
<li><p><em>Integrable simple functions forms a vector space, i.e., <span class="math inline">\(\int \alpha f + \beta g =a \int f + \beta \int g​\)</span></em><br />
<strong>Proof:</strong><br />
Define <span class="math inline">\(S_{ij} = E_i \cap F_j​\)</span>. Now <span class="math inline">\(\{ S_{i,j} \}​\)</span> is a partition of <span class="math inline">\(X​\)</span>. Let <span class="math inline">\(c_{i,j} = a_i = b_j​\)</span> if <span class="math inline">\(S_{i,j} \neq \emptyset​\)</span> and <span class="math inline">\(c_{i,j}= 0​\)</span> otherwise. Moreover, we have <span class="math inline">\(c_{i,j} \neq 0 \rightarrow \mu(S_{i,j} ) = 0​\)</span>.<br />
<span class="math display">\[
 \begin{aligned}
 \alpha f + \beta g  
 &amp;= \alpha \sum_{i = 1}^n a_i \chi_{E_i} + \beta \sum_{j = 1}^m b_j \chi_{F_j} \\
 &amp;= \sum_{i,j} (\alpha + \beta) c_{i,j} \chi_{S_{i,j} } \\
 \int \alpha f + \beta g  
 &amp;= \sum_{i,j} (\alpha + β) c_{i,j} \mu(S_{i,j}) \\
 &amp;= \alpha \sum_{i,j} c_{i,j} \mu(S_{i,j} ) + β \sum_{i,j} c_{i,j} \mu( S_{i,j} ) \\
 &amp;= \alpha \int f + \beta \int g \qquad \qquad \qquad \qquad \qquad \blacksquare
 \end{aligned}
 \]</span></p></li>
<li><p><em>If <span class="math inline">\(f \ge 0 \ a.e.\)</span>, then <span class="math inline">\(\int f \ge 0\)</span>.</em><br />
<strong>Proof:</strong><br />
Let <span class="math inline">\(f = \sum_{i = 1}^n a_i \chi_{E_i}\)</span>. We claim that <span class="math inline">\(a_i \mu(E_i) \ge 0\)</span> for all indices <span class="math inline">\(i\)</span>.</p>
<ol type="a">
<li>If <span class="math inline">\(\mu(E_i) = \infty\)</span>, then <span class="math inline">\(a_i = 0\)</span>, since <span class="math inline">\(f\)</span> is measurable.<br />
</li>
<li>If <span class="math inline">\(\mu(E_i) &gt; 0\)</span>, then <span class="math inline">\(a_i \ge 0\)</span>. Otherwise, we have <span class="math inline">\(f &lt; 0\)</span> on a set <span class="math inline">\(E_i\)</span> with positive measure, contradicting <span class="math inline">\(f \ge 0 \ a.e.\)</span>.</li>
<li>If <span class="math inline">\(\mu(E_i) = 0\)</span>, the claim is trivially true.<br />
Therefore, <span class="math inline">\(\int f = \sum_i a_i \mu(E_i ) \ge0\)</span>.<br />
<span class="math inline">\(\blacksquare\)</span></li>
</ol></li>
<li><p><em>If <span class="math inline">\(f \ge g \ a.e\)</span>, then <span class="math inline">\(\int f \ge \int g\)</span>.</em><br />
<strong>Proof:</strong></p>
<ol type="a">
<li><span class="math inline">\(\int f-\int g=\sum_{i = 1}^n a_i \mu(E_i ) -\sum_{j = 1}^m b_j \mu(F_j ) = \sum_{i =1}^n \sum_{j =1 }^m (a_i - b_j ) \mu(E_i \cap F_j)\)</span>.<br />
</li>
<li><span class="math inline">\(a_i-b_j &lt; 0 \rightarrow \mu(E_i \cap F_j ) = 0\)</span>.</li>
</ol>
<p>NOTE: Another way to prove this is by defining <span class="math inline">\(h \doteq f - g\)</span> which if non-negative almost everywhere and use conclusion of (1).<br />
<span class="math inline">\(\blacksquare\)</span></p></li>
<li><p><em><span class="math inline">\(|f|\)</span> is an integrable simple function, and <span class="math inline">\(|\int f|\le \int |f|\)</span>.</em><br />
<strong>Proof:</strong><br />
<span class="math inline">\(|f|=\sum_i |a_i | \chi_{E_i }\)</span>. Therefore, <span class="math inline">\(|a_i| ≠ 0 \rightarrow \mu(E_i )=0\)</span>. <span class="math inline">\(|f|\)</span> is simple and integrable.<br />
<span class="math display">\[
 \int|f| =\sum_i |a_i |\mu(E_i ) \ge|\sum_i a_i \mu(E_i ) |=\left| \int f \right| \qquad \blacksquare
 \]</span></p></li>
<li><p><em><span class="math inline">\(\int|f+g | \le \int |f| + \int |g|\)</span>.</em><br />
<strong>Proof:</strong><br />
<span class="math inline">\(\int|f+g| \le \int(|f|+|g|) =\int|f| +\int|g|. \qquad \blacksquare\)</span></p></li>
<li><p><em>If <span class="math inline">\(m \le f \le \Omega \ a.e.\)</span> on a measurable set <span class="math inline">\(E\)</span> with <span class="math inline">\(\mu(E) &lt; \infty\)</span>, then <span class="math inline">\(m \mu(E) \le \int_E f \le \Omega \mu(E)\)</span>.</em><br />
<strong>Proof:</strong><br />
The condition <span class="math inline">\(\mu(E) &lt; \infty\)</span> ensures that <span class="math inline">\(m \mu(E) &lt; \infty\)</span>.</p>
<ol type="a">
<li><span class="math inline">\(\int_E f=\sum_i a_i \mu(E_i \cap E)\)</span><br />
</li>
<li><span class="math inline">\(a_i &lt; m \rightarrow \mu(E_i \cap E) = 0 ⇒ \sum_i (a_i-m) \mu(E_i \cap E) \ge0\)</span>, as desired.<br />
The other side of the inequality can be proved by symmetry.</li>
</ol>
<p>NOTE: another way is to utilize that <span class="math inline">\(\mu \chi_E\)</span> is simple, integrable <span class="math inline">\(\mu \chi_E \le f\)</span> almost everywhere.<br />
<span class="math inline">\(\blacksquare\)</span></p></li>
<li><p>If <span class="math inline">\(f \ge 0,\ a.e.\)</span>, and if <span class="math inline">\(E\)</span> and <span class="math inline">\(F\)</span> are measurable sets with <span class="math inline">\(E⊂F\)</span>, then <span class="math inline">\(\int_E f \le \int_F f\)</span>.<br />
<strong>Proof:</strong><br />
<span class="math inline">\(\int_E f = \sum_i a_i \mu(E_i \cap E) \le \sum_i a_i \mu(E_i \cap F) =\int_F f\)</span>. Then inequality holds since it is always true that <span class="math inline">\(a_i \mu(E_i \cap E) \le a_i \mu(E_i \cap E)\)</span></p>
<ol type="a">
<li>If <span class="math inline">\(\mu(E_i \cap E) \le \mu(E_i \cap F) = \infty\)</span>, then <span class="math inline">\(a_i = 0\)</span>.<br />
</li>
<li>If <span class="math inline">\(0 &lt; \mu(E_i \cap E) \le \mu(E_i \cap E) &lt; \infty\)</span>, then <span class="math inline">\(a_i \ge 0\)</span>.<br />
</li>
<li>If <span class="math inline">\(0 = \mu(E_i \cap E) = \mu(E_i \cap E)\)</span>, then it is trivially true.</li>
</ol>
<p>NOTE: another way is to utilize that <span class="math inline">\(\chi_E f \le \chi_F f\)</span> almost everywhere.<br />
<span class="math inline">\(\blacksquare​\)</span></p></li>
<li><p><em>If <span class="math inline">\(F\)</span> is a disjoint union <span class="math inline">\(\cup_{m=1}^\infty F_n\)</span> of measurable sets, then <span class="math inline">\(\int_F f=\sum_{m=1}^\infty \int_{F_m} f\)</span>.</em><br />
<strong>Proof:</strong> This is a consequence of complete additivity of measure. <span class="math display">\[
 \begin{aligned}
 \int_F f  
 &amp;= \sum_{i=1}^n a_i \mu(E_i \cap F) \\
 &amp;=\sum_{i=1}^n  a_i \mu(E_i \cap  (\cup_{m=1}^\infty F_m ))  \\
 &amp;=\sum_{i=1}^n  a_i \mu(\cup_{m=1}^\infty E_i  \cap  F_m )  \\
 &amp;=\sum_{i=1}^n  a_i \sum_{m=1}^\infty \mu(E_i  \cap  F_m) &amp; \text{ by complete additivity of measure }\\
 &amp;=\sum_{i=1}^n  a_i   \lim_{k \rightarrow \infty} ⁡\sum_{m=1}^k \mu(E_i \cap F_m) \\
 &amp;= \lim_{k \rightarrow \infty} ⁡\sum_{i=1}^n   a_i \sum_{m=1}^k  \mu(E_i \cap F_m) &amp; \text{ exchange order of limit and finite summation} \\
 &amp;= \lim_{k \rightarrow \infty} ⁡ \sum_{m=1}^k  \sum_{i=1}^n   a_i \mu(E_i \cap F_m)  \\
 &amp;= \lim_{k \rightarrow \infty} ⁡\sum_{i=1}^k \int_{F_m} f \qquad \blacksquare
 \end{aligned}
 \]</span></p></li>
<li><p><em>If <span class="math inline">\(F_1 \subset F_2 \subset F_3 \subset ...​\)</span> is a sequence of increasing measurable sets and let <span class="math inline">\(F = \cup_{n} F_n​\)</span>, then <span class="math inline">\(\lim_n \int_{F_n} f = \int_F f​\)</span>.</em><br />
<strong>Proof:</strong><br />
Let <span class="math inline">\(F_n&#39; = F_n - F_{n - 1}​\)</span>. The result follows immediately from the previous property.<br />
<span class="math inline">\(\blacksquare​\)</span></p></li>
<li><p><em>If <span class="math inline">\(F_1 \supset F_2 \supset F_3 \supset ...\)</span> is a sequence of decreasing measurable sets and let <span class="math inline">\(F = \cap_{n} F_n\)</span>, then <span class="math inline">\(\lim_n \int_{F_n} f = \int_F f\)</span>.</em><br />
<strong>Proof:</strong><br />
Let <span class="math inline">\(f = \sum_{i = 1}^N a_i \chi_{E_i}\)</span>. It follow that for <span class="math inline">\(a_i \neq 0\)</span>, we have <span class="math inline">\(\mu(E_i \cap F_1) &lt; \infty\)</span>, hence <span class="math inline">\(\lim_n \mu(E_i \cap F_n) = \mu(E_i \cap \lim_n F_n) = \mu (E_i \cap F)\)</span>, which implies that <span class="math inline">\(\lim_n \int_{F_n} f = \int_F f\)</span>.<br />
<strong>Remark:</strong><br />
We don't even require that <span class="math inline">\(\mu(F_1) &lt; \infty\)</span>.<br />
<span class="math inline">\(\blacksquare\)</span></p></li>
<li><p><em>Let <span class="math inline">\(f = \sum_{i = 1}^n a_i \chi_{E_i}\)</span> and define the support <span class="math inline">\(N(f)\)</span> of simple integrable function <span class="math inline">\(f\)</span> to be the set of elements with non-zero values <span class="math inline">\(N(f) = \{ x \in X : f(x) \neq 0 \} = \cup_{i, a_i \neq 0} E_i\)</span>, then <span class="math inline">\(\mu( N(f) ) \le \infty\)</span>.</em><br />
<strong>Proof:</strong><br />
Since <span class="math inline">\(f\)</span> is integrable, <span class="math inline">\(a_i \neq 0\)</span> implies <span class="math inline">\(\mu(E_i) &lt; \infty\)</span>. Now <span class="math display">\[
\mu( N(F) ) = \sum_{1 \le i \le n, a_i \neq 0} \mu(E_i) &lt; \infty \qquad \qquad \blacksquare
\]</span></p></li>
</ol>
<p>With simple integrable functions as building blocks, we are ready to define integration for functions in general.</p>
<p>Fist we introduce a notation of convergence we need in the following discussion.</p>
<h1 id="definition.-cauchy-in-mean"><strong>Definition.</strong> Cauchy In Mean</h1>
<p><em>A sequence <span class="math inline">\(\{ f_n \}​\)</span> of simple functions is called Cauchy in mean if</em><br />
<span class="math display">\[
\lim_{n, m} \int |f_n - f_m| = 0
\]</span></p>
<p>Cauchy in mean does not implies Cauchy almost everywhere. Consider the sequence of functions</p>
<ol type="1">
<li><span class="math inline">\(\chi_{[0, 1/2]}, \chi_{[1 / 2, 1]}\)</span>,<br />
</li>
<li><span class="math inline">\(\chi_{ [0, 1 / 4 ] }, \chi_{ [1 / 4, 1 / 2] }, \chi_{ [ 1 / 2, 3 / 4 ] }, \chi_{ [3 / 4, 1] }\)</span>,<br />
</li>
<li>...</li>
<li><span class="math inline">\(... \chi_{ [ i / 2^n, (i + 1) / 2^n ] } ...,(i \in \{0, 1, 2, ..., 2^{n} - 1 \} )\)</span></li>
</ol>
<p>They are Cauchy in mean but don's Cauchy almost everywhere. But it is Cauchy in measure.</p>
<h1 id="theorem-1"><strong>Theorem</strong></h1>
<p><em>If a sequence <span class="math inline">\(\{ f_n \}​\)</span> of simple functions is Cauchy in mean, it is Cauchy in measure.</em></p>
<p><strong>Proof:</strong><br />
Let <span class="math inline">\(h_{n, m} = |f_n - f_m| ​\)</span>. As <span class="math inline">\(f_n​\)</span> and <span class="math inline">\(f_m​\)</span> are simple and integrable, <span class="math inline">\(h_{n, m}​\)</span> is simple and integrable. Moreover, it is non-negative. We write it as <span class="math inline">\(h_{n,m} = \sum_{j =1}^k b_j \chi_{F_j}​\)</span>, where <span class="math inline">\(b_j \ge 0​\)</span>. For arbitrary positive number <span class="math inline">\(\delta &gt; 0​\)</span>, <span class="math inline">\(b_j \ge \delta &gt; 0​\)</span> implies that <span class="math inline">\(\mu(F_j) &lt; \infty​\)</span>. Now <span class="math display">\[
\delta \cdot \mu( \{ x \in X: h_{n,m}(x) \ge \delta\} ) = \sum_{1 \le j \le k, b_j \ge \delta} \delta \cdot \mu(F_j) \le  \sum_{1 \le j \le k, b_j \ge \delta} b_j \mu(F_j)  \le \int h_{n,m} = \int |f_n - f_m|
\]</span> Hence, <span class="math inline">\(\mu( \{ x \in X: h_{n,m}(x) \ge \delta\} ) \le \frac{ \int |f_n - f_m| }{ \delta }\)</span>. For any fix <span class="math inline">\(\delta\)</span>, this can be arbitrary small as <span class="math inline">\(n, m \rightarrow \infty\)</span>.<br />
<span class="math inline">\(\blacksquare\)</span>.</p>
<p>NOTE: the converse is not true.</p>
<h1 id="example"><strong>Example</strong></h1>
<p>Consider this sequence of functions:<br />
<span class="math display">\[
\{ n \cdot \chi_{[0, 1 / n] } : n \in \mathbf{N}         \}
\]</span></p>
<p>It converges in measure to <span class="math inline">\(f \equiv 0\)</span>. But <span class="math inline">\(\int n \cdot \chi_{[0, 1 / n] } = 1\)</span> for all <span class="math inline">\(n\)</span>. <span class="math inline">\(\lim_n \int n \cdot \chi_{[0, 1 / n] } \neq \int f\)</span>.</p>
<p>The implication here is that we need additional condition more than converge in mean to define the integral for a general function <span class="math inline">\(f​\)</span>. We need to connect the sequence <span class="math inline">\(\{ f_n \}​\)</span> with <span class="math inline">\(f​\)</span>, the function we want to define integral. Can we say something like <span class="math inline">\(\{ f_n \}​\)</span> converges to <span class="math inline">\(f​\)</span> in mean, i.e., <span class="math inline">\(\lim_n \int |f_n - f| = 0​\)</span>. But we have not define integral of non-simple function yet. Here is how we establish the connection.</p>
<h1 id="definition.-integrable-functions"><strong>Definition.</strong> Integrable Functions</h1>
<p><em>An extended real-valued, measurable function <span class="math inline">\(f\)</span>, on a measure space <span class="math inline">\((X, \Omega, \mu)\)</span> is said to be integrable if there exists a sequence <span class="math inline">\(\{ f_n \}\)</span> of integrable simple functions having the following properties:</em></p>
<ol type="1">
<li><span class="math inline">\(\{ f_n \}​\)</span> <em>is a Cauchy sequence in the mean.</em><br />
</li>
<li><span class="math inline">\(\lim_{n} f_n (x) = f(x) \quad a.e.​\)</span>.</li>
</ol>
<p><em>The integral of <span class="math inline">\(f​\)</span> is defined to the number <span class="math inline">\(\lim_{n} \int f_n​\)</span>, and is denoted by</em> <span class="math inline">\(\int f​\)</span>. Thus, <span class="math display">\[
\int f = \lim_{n} \int f_n
\]</span></p>
<p>There are two issues we need to answer for the definition to be well-defined. The first one is that the limit of <span class="math inline">\(\int f_n​\)</span> indeed exists. Second, we need to show that for any sequence satisfying condition (1) and (2), their integral converges to the same limit.</p>
<h1 id="theorem.-existence-of-limit"><strong>Theorem.</strong> Existence of Limit</h1>
<p><em><span class="math inline">\(\int f_n\)</span> converges as <span class="math inline">\(n \rightarrow \infty\)</span>.</em></p>
<p><strong>Proof:</strong><br />
<span class="math display">\[
\left| \int f_n - \int f_m \right| \le \int | f_n - f_m |  \rightarrow 0 \qquad as \quad n, m \rightarrow \infty
\]</span> Therefore, <span class="math inline">\(\{ \int f_n : n \in \mathbf{N} \}\)</span> (note that each element in this set is a real number) is a Cauchy sequence and its limit exists. <span class="math inline">\(\blacksquare\)</span></p>
<h1 id="theorem.-uniqueness-of-limit"><strong>Theorem.</strong> Uniqueness of Limit</h1>
<p><em>Let <span class="math inline">\(\{ f_n \}\)</span> and <span class="math inline">\(\{ g_n \}\)</span> be two Cauchy sequences in the mean of integrable simple functions, such that</em> <span class="math display">\[
\lim_n f_n = \lim_n g_n = f \qquad a.e.
\]</span> Then<br />
<span class="math display">\[
\lim_n \int f_n = \lim_n \int g_n
\]</span></p>
<p><strong>Proof:</strong><br />
Define <span class="math inline">\(h_n \doteq f_n - g_n\)</span> for <span class="math inline">\(n \in \mathbf{N}\)</span>. As <span class="math inline">\(f_n\)</span> and <span class="math inline">\(g_n\)</span> are simple and integrable, <span class="math inline">\(h_n\)</span> is simple and integrable. We claim that</p>
<ol type="1">
<li><span class="math inline">\(\{ h_n \}\)</span> is Cauchy in mean.</li>
<li><span class="math inline">\(\lim_n h_n = 0 \quad a.e.\)</span>.</li>
</ol>
<p>The first claim is due to triangle inequality and tha fact that both <span class="math inline">\(\{ f_n \}\)</span> and <span class="math inline">\(\{ g_n \}\)</span> are Cauchy in mean,<br />
<span class="math display">\[
\int |h_n - h_m| = \int | f_n - g_n - (f_m - g_m)| \le \int |f_n - f_m| + |g_n - g_m| = \int |f_n - f_m| + \int |g_n - g_m|  
\]</span></p>
<p>The second claim results from the <span class="math inline">\(\lim_n f_n = f​\)</span> and <span class="math inline">\(\lim_n g_n = f​\)</span> <span class="math inline">\(a.e.​\)</span>.</p>
<p>We are going to prove <span class="math inline">\(\lim_n \int h_n = 0​\)</span>, which then implies<br />
<span class="math display">\[
\lim_n \int (f_n - g_n) =\lim_n \left( \int f_n - \int g_n \right) = \lim_n \int f_n - \lim_n \int g_n = 0​
\]</span> , which is as desired.</p>
<p>It is left to show that <span class="math inline">\(\forall \epsilon &gt; 0\)</span>, <span class="math inline">\(\exists N &gt; 0\)</span>, s.t., <span class="math inline">\(\forall n &gt; N, | \int h_n | &lt; O(\epsilon)\)</span>. Here <span class="math inline">\(O(\epsilon)\)</span> denote <span class="math inline">\(\epsilon\)</span> times some constant number.</p>
<p>The trick here is to restrict the discussion of <span class="math inline">\(\int h\)</span> on a <span class="math inline">\(\sigma\)</span>-finite measurable set. Define the support <span class="math inline">\(N(f_n)​\)</span> of <span class="math inline">\(f_n​\)</span> to be the set with non-zero values: <span class="math inline">\(N(f_n) = \{ x \in X : f_n(x) \neq 0\}​\)</span>. As <span class="math inline">\(f_n​\)</span> is a simple integrable function, <span class="math inline">\(\mu(N(f_n)) &lt; \infty​\)</span>. Let <span class="math inline">\(E_n = \cup_{k = 1}^n N(f_k) \cup N(g_k)​\)</span> and <span class="math inline">\(E = \cup_n E_n​\)</span>. We have <span class="math inline">\(\mu(E_n) &lt; \infty​\)</span>, <span class="math inline">\(E_n \uparrow E​\)</span> and <span class="math inline">\(E​\)</span> is <span class="math inline">\(\sigma​\)</span>-finite. Further, for any <span class="math inline">\(n​\)</span>, we have<br />
<span class="math display">\[
\int h_n = \int_{E} h_n​
\]</span></p>
<p>First, as <span class="math inline">\(\{ h_n \}\)</span> is Cauchy in mean, for <span class="math inline">\(\epsilon &gt; 0\)</span>, <span class="math inline">\(\exists N_1 &gt; 0\)</span>, s.t, for <span class="math inline">\(n, k &gt; N_1\)</span>, we have <span class="math inline">\(\int |h_n - h_k| \le \epsilon\)</span> . We choose an integer <span class="math inline">\(k &gt; N_1\)</span>. As <span class="math inline">\(h_k\)</span> is a simple integrable function, and as <span class="math inline">\(E_m \uparrow E\)</span>, it holds that<br />
<span class="math display">\[
\lim_m \int_{E_m} h_k = \int_E h_k = \int h_k
\]</span></p>
<p>For fix <span class="math inline">\(k\)</span>, we choose an integer <span class="math inline">\(m\)</span>, s..t, <span class="math inline">\(\left| \int h_k - \int_{E_m} h_k \right| \le \epsilon\)</span>.</p>
<p>For a fix <span class="math inline">\(k &gt; N_1\)</span>, we claim that for any <span class="math inline">\(n &gt; N_1​\)</span>, we have <span class="math inline">\(| \int h_n - \int_{E_m} h_n | &lt; \epsilon​\)</span>,<br />
<span class="math display">\[
\begin{aligned}
\left| \int h_n  - \int_{E_m} h_n \right|  
&amp;= \left| \int h_n - \int  h_k  + \int h_k  - \int_{E_m} h_k +  \int_{E_m} h_k - \int_{E_m} h_n\right|  \\
&amp;\le \left| \int h_n - \int  h_k \right| + \left| \int h_k  - \int_{E_m} h_k \right| + \left| \int_{E_m} h_k - \int_{E_m} h_n \right| \\
&amp;\le \epsilon + \epsilon + \int_{E_m} |h_k - h_n| \\
&amp;\le 3\epsilon
\end{aligned}
\]</span></p>
<p>We have successfully restrict our discussion on a set with finite measure. The key here is that <span class="math inline">\(\int_{E_m} h_n\)</span> converges uniformly to <span class="math inline">\(\int h_n\)</span>, as <span class="math inline">\(m\)</span> increases, independent of the choice of <span class="math inline">\(n\)</span>, as long as <span class="math inline">\(\{ h_n \}\)</span> is Cauchy in mean.</p>
<p>Indeed, what we have shown here is that <span class="math inline">\(\lim_n \lim_m \int_{E_m} h_n = \lim_m \lim_n \int_{E_m} h_n\)</span></p>
<p>Second, we claim <span class="math inline">\(\int_{E_m} h_n​\)</span> could be arbitrary small if we choose large enough <span class="math inline">\(n &gt; N_1​\)</span>. So far we have not used the condition <span class="math inline">\(\lim_n h_n = 0 \ a.e.​\)</span> It is time to turn to it. Define<br />
<span class="math display">\[
S_n = \{ x  \in E_m :  |h_n(x)| &gt; \epsilon / \mu(E_m) \}
\]</span></p>
<p>Clearly <span class="math inline">\(\cup_{i = n}^\infty S_n \downarrow\)</span> with <span class="math inline">\(n\)</span> and <span class="math inline">\(\mu(\lim_n \cap_{i = n}^\infty S_n) = 0\)</span>. As <span class="math inline">\(h_k\)</span> is a simple function, it is bounded by some integer $K  a.e. $. As <span class="math inline">\(\mu(E_m) &lt; \infty\)</span>, <span class="math inline">\(\exists N_2 &gt; N_1\)</span>, s.t., for <span class="math inline">\(n &gt; N_2\)</span>, we have <span class="math inline">\(\mu(S_n) \le \mu(\cup_{i = n}^\infty S_n ) \le \epsilon / K\)</span>. Now,</p>
<p><span class="math display">\[
\begin{aligned}
\left| \int_{E_m} h_n \right|  
&amp;\le \left| \int_{S_n} h_n \right| + \left| \int_{E_m \setminus S_n} h_n \right| \\
&amp;\le \left| \int_{S_n} h_n \right| + \frac{\epsilon}{ \mu(E_m) }  \mu(E_m) \\
&amp;\le \left| \int_{S_n} h_n \right| + \epsilon  
\end{aligned}
\]</span></p>
<p>Finally, we argue that <span class="math inline">\(\left| \int_{S_n} h_n \right|​\)</span> is small enough.<br />
<span class="math display">\[
\left| \int_{S_n} h_n \right| \le \left| \int_{S_n} h_n - h_k  + h_k \right| \le \int |h_n - h_k| + \int_{S_n} |h_k| \le \epsilon + K \cdot \mu(S_n) \le 2 \epsilon
\]</span></p>
<p>Indeed, the technique demonstrated here shows that <span class="math inline">\(\{ \int_E h_n \}\)</span> is uniformly absolutely continuous with respect to <span class="math inline">\(\mu(E)\)</span>.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<h2 id="corollary-1"><strong>Corollary 1</strong></h2>
<p><em>Let <span class="math inline">\(\{ h_n \}\)</span> be a sequence of simple integrable function that are Cauchy in mean and <span class="math inline">\(E_1 \subset E_2 \subset E_3 ...\)</span> a sequence of increasing measurable sets that converge to <span class="math inline">\(E = \cup_{i = 1}^\infty E_i\)</span>. Then <span class="math inline">\(\int_{E_m} h_n \rightarrow \int_{E} h_n\)</span> uniformly, i.e., <span class="math inline">\(\forall \epsilon &gt; 0, \exists M &gt; 0\)</span>, s.t., for <span class="math inline">\(m &gt; M\)</span>, we have</em> <span class="math display">\[
\left| \int_{E_m} h_n - \int_E h_n \right| \le \epsilon
\]</span></p>
<h2 id="corollary-2"><strong>Corollary 2</strong></h2>
<p><em>Let <span class="math inline">\(\{ h_n \}\)</span> be a sequence of simple integrable function that are Cauchy in mean. <span class="math inline">\(\forall \epsilon &gt; 0, \exists \delta &gt; 0\)</span>, s.t, for any measurable set <span class="math inline">\(E\)</span> with <span class="math inline">\(\mu(E) &lt; \delta\)</span>, we have <span class="math inline">\(|\int_E h_n| &lt; \epsilon\)</span> independent of <span class="math inline">\(n\)</span></em></p>
<h1 id="definition-1"><strong>Definition</strong></h1>
<p>Let <span class="math inline">\(f\)</span> be an integrable function and <span class="math inline">\(E\)</span> be a measurable set. Then <span class="math inline">\(\chi_E f\)</span> is integrable and its integral is denoted as<br />
<span class="math display">\[
\int \chi_E f = \int_E f
\]</span></p>
<p><strong>Remark:</strong><br />
If <span class="math inline">\(f\)</span> is integrable, then there is a sequence simple, integrable function <span class="math inline">\(\{f_n \}\)</span> that are Cauchy in mean and converges to <span class="math inline">\(f\)</span> almost every. It is easy to see that <span class="math inline">\(\{ \chi_E f_n \}\)</span> is simple, integrable, Cauchy in mean and converges to <span class="math inline">\(\chi_E f\)</span> almost everywhere, therefore <span class="math inline">\(\chi_E f\)</span> is integrable. An immediately consequence is the following lemma</p>
<h1 id="lemma-1"><strong>Lemma 1</strong></h1>
<p><span class="math inline">\(\int_E f_n\)</span> converges to <span class="math inline">\(\int_E f\)</span> uniformly irrespective of <span class="math inline">\(E\)</span>.<br />
<strong>Proof:</strong> It suffices to show the sequence <span class="math inline">\(\{ \int_E f_n : n \in \mathbf{N} \}\)</span> is a uniformly Cauchy irrespectively of <span class="math inline">\(E\)</span>,<br />
<span class="math display">\[
\left| \int_E f_n - \int_E f_m \right| \le \int_E |f_n - f_m| \le \int |f_n - f_m| \rightarrow 0
\]</span> Therefore, for <span class="math inline">\(\forall E \subset \Omega\)</span>, <span class="math inline">\(\exists N &gt; 0\)</span>, for all <span class="math inline">\(n，m &gt; N\)</span>, we have<br />
<span class="math display">\[
\left| \int_E f_n - \int_E f_m \right| \le \epsilon
\]</span> Taking limit with respect to <span class="math inline">\(m\)</span>, we get <span class="math inline">\(\lim_m \int_E f_m - \epsilon \le \int_E f_n \le \lim_m \int_E f_m + \epsilon\)</span>, i.e.,<br />
<span class="math display">\[
\left| \int_E f_n - \int_E f \right| \le \epsilon
\]</span> as desired.</p>
<p>Combining Corollary 2 and Lemma 1, we have the following theorem.</p>
<h1 id="theorem.-integration-as-finite-signed-measure"><strong>Theorem.</strong> Integration as Finite Signed Measure</h1>
<p>If <span class="math inline">\(f\)</span> is integrable, then<br />
<span class="math display">\[
\lambda(E) = \int_E f
\]</span> is absolute continuous.<br />
<strong>Proof:</strong> Let <span class="math inline">\(\{ f_n \}\)</span> as defined before. For <span class="math inline">\(\forall \epsilon &gt; 0\)</span>, <span class="math inline">\(\exists N_1 &gt; 0\)</span>, for all <span class="math inline">\(n &gt; N_1\)</span>, we have <span class="math inline">\(| \int_E f - \int_E f_n | \le \epsilon\)</span>. On the other hand, For <span class="math inline">\(\forall \epsilon &gt; 0\)</span>, <span class="math inline">\(\exists \delta &gt; 0\)</span>, for all <span class="math inline">\(E\)</span> with <span class="math inline">\(\mu(E) &lt; \delta\)</span>, we have <span class="math inline">\(|\int_E f_n| &lt; \epsilon\)</span>. In combination,<br />
<span class="math display">\[
\left| \int_E f \right| \le \left| \int_E f - f_n \right| + \int_E |f_n| \le 2\epsilon  
\]</span></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<p>Next we discussion the convergence behavior of a sequence of integrable functions.</p>
<h1 id="lemma">Lemma</h1>
<p>If <span class="math inline">\(\{ f_k \}\)</span> is a sequence of simple, integrable function that are</p>
<ol type="1">
<li>Cauchy in the mean,<br />
</li>
<li>Converge to <span class="math inline">\(f\)</span> almost everywhere.</li>
</ol>
<p>Then<br />
<span class="math display">\[
\lim_k \int |f_k - f| = 0
\]</span></p>
<p><strong>Proof:</strong><br />
Note that <span class="math inline">\(|f_k - f |\)</span> may not be a simple function. To investigate the value of its integral, we need to characterize it according to the definition of integral for general functions. Here is how we do it. For a fix <span class="math inline">\(k\)</span>, the sequence <span class="math inline">\(\{ |f_k - f_n| : n \in \mathbf{N} \}\)</span> is simple, integrable, and converges to <span class="math inline">\(|f_k - f |\)</span> almost everywhere. Moreover, as <span class="math inline">\(\{ f_k \}\)</span> itself is Cauchy in mean, for <span class="math inline">\(\forall \epsilon &gt; 0\)</span>, <span class="math inline">\(\exists N &gt; 0\)</span>, s.t., <span class="math inline">\(\forall k, n, m &gt; N\)</span>,<br />
<span class="math display">\[
\int \left| |f_k - f_n| - |f_k - f_m| \right| \le \int |f_k - f_n - (f_k - f_m)| = \int |f_m - f_n| \le \epsilon
\]</span></p>
<p>As a consequence <span class="math inline">\(\{|f_k - f_n| : n \in \mathbf{N} \}\)</span> is Cauchy in the man. <span class="math inline">\(|f_k - f|\)</span> is integrable and <span class="math inline">\(\int |f_k - f| = \lim_n \int |f_k - f_n|\)</span>. But for <span class="math inline">\(k, n, m &gt; N\)</span>,<br />
<span class="math display">\[
\int |f_k - f| = \lim_m \int |f_k - f_m| \le \int |f_k - f_n| + \epsilon \le 2\epsilon
\]</span></p>
<p>As <span class="math inline">\(\epsilon\)</span> could be arbitrary small, we have <span class="math inline">\(\lim_k \int |f_k - f| = 0\)</span>.</p>
<p><span class="math inline">\(\blacksquare\)</span>.</p>
<h1 id="theorem-2"><strong>Theorem</strong></h1>
<p><em>If <span class="math inline">\({g_k}\)</span> is a sequence of integrable functions satisfying the conditions</em></p>
<ol type="1">
<li><span class="math inline">\({g_k}\)</span> is a Cauchy sequence in the mean.<br />
</li>
<li><span class="math inline">\({g_k}\)</span> converges in measure to <span class="math inline">\(f\)</span>.</li>
</ol>
<p>then <span class="math inline">\(f\)</span> is integrable and <span class="math inline">\(\int f = \lim⁡_k \int g_k\)</span>.</p>
<p><strong>Proof:</strong><br />
For each <span class="math inline">\(g_k\)</span>, there is a sequence <span class="math inline">\(\{ g_{km} : m ∈ \mathbf{N} \}\)</span> simple integrable functions,</p>
<ol type="1">
<li><p><span class="math inline">\(\{ g_{km} \}\)</span> is a Cauchy sequence in the mean.</p></li>
<li><p><span class="math inline">\(\{ g_{km} \}\)</span> converges in measure to <span class="math inline">\(g_k\)</span>.</p></li>
<li><p><span class="math inline">\(\int g_k = \lim_m ⁡\int g_{km}\)</span></p></li>
</ol>
<p>For fix <span class="math inline">\(k​\)</span>, we choose such an integer <span class="math inline">\(m​\)</span>, such that <span class="math inline">\(\int |g_k - \int g_{k m} |\le 1 / k​\)</span> and <span class="math inline">\(\mu(\{ x:|g_k (x) - g_{km} (x) | \ge 1 / k \} ) \le 1 / k​\)</span>. For convenience, denote <span class="math inline">\(g_{k m}​\)</span> as <span class="math inline">\(f_k​\)</span>. Now we claim the sequence <span class="math inline">\(\{ f_{k} \}​\)</span> of simple integrable functions satisfies</p>
<ol type="1">
<li>is a Cauchy sequence in the mean.<br />
</li>
<li>converges to <span class="math inline">\(f​\)</span> in measure.</li>
</ol>
<p>The first one result from the fact <span class="math inline">\(\{ g_k \}\)</span> is Cauchy sequence in the mean and triangle inequality<br />
<span class="math display">\[
\begin{aligned}
\int | f_{m} - f_{n} |  
&amp;\le \int | f_{m} - g_m | +| g_m - g_n |+| g_n - f_n | \\
&amp;\le \int | f_{m} - g_m | + \int | g_m - g_n | + \int | g_n - f_n | \\
&amp;\le \frac{1}{m} + \int | g_m - g_n | + \frac{1}{n} \\
&amp;\rightarrow 0 \quad \text{as } n, m \rightarrow \infty
\end{aligned}
\]</span></p>
<p>The second claim also results from triangle inequality. For any <span class="math inline">\(\delta &gt; 0\)</span>, <span class="math inline">\(\exists 1 / k \le \delta​\)</span>, s.t.,<br />
<span class="math display">\[
\begin{aligned}
\mu(\{ x \in X: |f_k - f | \ge \delta \} )  
&amp;\le \mu(\{ x \in X: |f_k - g_k | \ge \delta \} ) + \mu(\{ x \in X: |g_k - f | \ge \delta \} ) \\
&amp;\le 1/k + \mu(\{ x \in X: |g_k - f | \ge \delta \} ) \\
&amp;\rightarrow 0 \quad \text{as } k \rightarrow \infty
\end{aligned}
\]</span></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<h1 id="theorem.-lebesgues-bounded-convergence-theorem">Theorem. Lebesgue's Bounded Convergence Theorem</h1>
<p>Let <span class="math inline">\(\{ f_n \}\)</span> be a sequence of integrable functions that converges either in measure or a.e. to a measurable function <span class="math inline">\(f\)</span>. If <span class="math inline">\(|f_n(x)| \le g(x) \ a.e.\)</span> for all <span class="math inline">\(n\)</span>, where <span class="math inline">\(g\)</span> is an integrable function, then <span class="math inline">\(f\)</span> is integrable.</p>
<p>Note: compared to definition of <span class="math inline">\(f\)</span> being integrable,</p>
<ol type="1">
<li>We no longer require <span class="math inline">\(\{ f_n \}​\)</span> to be simple functions.<br />
</li>
<li>We no longer require <span class="math inline">\(\{ f_n \}\)</span> to be Cauchy in mean.</li>
</ol>
<p><strong>Proof:</strong></p>
<p>It suffices to show <span class="math inline">\(\{ f_n \}\)</span> is a Cauchy sequence in mean.</p>
<ol type="1">
<li><p>Each <span class="math inline">\(\{ f_n \}\)</span> can be approximated by a sequence of simple functions. Therefore, we can find a <span class="math inline">\(\sigma\)</span>-finite measurable set <span class="math inline">\(F_n\)</span> such that <span class="math inline">\(\int_{F_n} f_n = \int_F\)</span>. Similarly, we can find a <span class="math inline">\(\sigma\)</span> finite measurable set <span class="math inline">\(G\)</span> such that <span class="math inline">\(\int_G g = \int g\)</span>.</p></li>
<li><p>The measurable set <span class="math inline">\(E = (\cup_n F_n) \cup G\)</span> is <span class="math inline">\(\sigma\)</span> finite. There exists a sequence of increasing, finite measurable set <span class="math inline">\(E_1 \subset E_2 \subset E_3 ...\)</span> which satisfies <span class="math inline">\(E_n \uparrow E\)</span>.</p></li>
<li><p>As <span class="math inline">\(\int_E g &lt; \infty​\)</span>, and <span class="math inline">\(\lim_m \int_{E_m} g = \int_E g​\)</span>, <span class="math inline">\(\forall \epsilon &gt; 0, \exists m &gt; 0​\)</span>, s.t., <span class="math inline">\(|\int_{E \setminus E_m} g | \le \epsilon​\)</span>.</p></li>
<li><p>The integral of <span class="math inline">\(|f_n - f_m|​\)</span> outside <span class="math inline">\(E_m​\)</span> is small: <span class="math inline">\(\int_{E \setminus E_m} |f_n - f_m| \le \int_{E \setminus E_m} |f_n| + |f_m| \le 2 \int_{E \setminus E_m} g \le 2 \epsilon​\)</span>.</p></li>
<li><p>Consider the integral inside the finite set <span class="math inline">\(E_m\)</span>. Define <span class="math inline">\(S_k \doteq \{ x \in E_m : |f_i(x) - f_j(x)| \ge \epsilon / \mu(E_m) \text{ for all } i, j \ge k\}\)</span>. As <span class="math inline">\(\{ f_n \}\)</span> converges to <span class="math inline">\(f\)</span> in measure or a.e., and <span class="math inline">\(\mu(E_m) &lt; \infty\)</span>, <span class="math inline">\(\mu(S_k) \rightarrow \mu(E_m)\)</span>. We can choose an <span class="math inline">\(k\)</span>, s.t., <span class="math inline">\(\mu(E_m \setminus S_k) \le \delta\)</span>, where <span class="math inline">\(\delta\)</span> is chosen with <span class="math inline">\(\int_{E_m \setminus S_k} g &lt; \epsilon\)</span>. Such <span class="math inline">\(\delta\)</span> exists because <span class="math inline">\(g\)</span> is integrable, therefore <span class="math inline">\(\int_{E_m \setminus S_k} g\)</span> absolute continuous with respect to <span class="math inline">\(\mu(E_m \ S_k)\)</span>. Now, for <span class="math inline">\(n, m \ge k\)</span>,</p></li>
<li><p><span class="math inline">\(\int_{E_m} | f_n - f_m | = \int_{S_k} |f_n - f_m| + \int_{E_m \setminus S_k} |f_n - f_m| \le \frac{\epsilon}{\mu(E_m) }\mu(E_m) + 2 \int_{E_m \setminus S_k} g \le 3 \epsilon​\)</span></p></li>
<li><p><span class="math inline">\(\int_E |f_n - f_m| = \int_{E \setminus E_m} |f_n - f_m| + \int_{E_m} | f_n - f_m| \le 2 \epsilon + 3 \epsilon = 5 \epsilon​\)</span>.</p></li>
</ol>
<p><span class="math inline">\(\blacksquare\)</span></p>
<h1 id="theorem.-lebesgues-monotone-convergence-theorem">Theorem. Lebesgue's Monotone Convergence Theorem</h1>
<p>Let <span class="math inline">\(\{ f_n \}\)</span> be a monotone increasing sequence of non-negative integrable functions that converges almost everywhere to <span class="math inline">\(f\)</span>. Then</p>
<p><span class="math display">\[
\lim_n \int f_n = \int f
\]</span></p>
<p>Note: compared to the definition of integral of <span class="math inline">\(f\)</span></p>
<ol type="1">
<li>We no longer require <span class="math inline">\(\{ f_n \}\)</span> to be simple functions.<br />
</li>
<li><span class="math inline">\(\int f_n\)</span> might diverge to <span class="math inline">\(\infty\)</span>. In this case, <span class="math inline">\(f\)</span> is not integrable as <span class="math inline">\(\int f = \infty\)</span>. But the equation still holds.</li>
</ol>
<p><strong>Proof:</strong><br />
First consider the case <span class="math inline">\(\int f_n\)</span> is unbounded. Then <span class="math inline">\(\int f = \int_n f_n = \infty\)</span> by definition.</p>
<p>Otherwise, suppose <span class="math inline">\(\lim_n \int f_n\)</span> is bounded. Then <span class="math inline">\(\int f_n\)</span> is an increasing sequence that converges to a real number. It follows that for <span class="math inline">\(n &gt; m\)</span>, then <span class="math inline">\(f_n &gt; f_m\)</span>. Consequently<br />
<span class="math display">\[
\int |f_n - f_m| = \int f_n - f_m = \int f_n - \int f_m  \rightarrow 0 \qquad \text{ as } n, m \rightarrow \infty
\]</span></p>
<p>Thus, <span class="math inline">\(\{ f_n \}\)</span> is a Cauchy sequence in the mean. Hence, <span class="math inline">\(f\)</span> is integrable and <span class="math inline">\(\lim_n \int f_n = \int f\)</span>.</p>
<h1 id="theorem.-fatou-s-lemma">Theorem. Fatou 's Lemma</h1>
<p>Let <span class="math inline">\(\{ f_n \}\)</span> be a sequence of non-negative and integrable functions. Then<br />
<span class="math display">\[
\int \liminf_n f_n \le \liminf_n \int f_n
\]</span></p>
<p><strong>Proof:</strong> Let <span class="math inline">\(h_n = \inf_{k \ge n} f_k\)</span>. Then <span class="math inline">\(h_n\)</span> is a sequence of monotone increasing measurable functions that converges to <span class="math inline">\(\liminf_n h_n\)</span>. By monotone convergence theorem,<br />
<span class="math display">\[
\int \lim_n h_n = \lim_n \int h_n  
\]</span> On the other hand, <span class="math inline">\(h_n = \inf_{k \ge n} f_k \le f_m\)</span> for all <span class="math inline">\(m \ge n\)</span>. It follows that<br />
<span class="math display">\[
\begin{aligned}
\int h_n        &amp;\le \inf_{m \ge n} \int f_m \\
\lim_n \int h_n &amp;\le \lim_n \inf_{m \ge n} \int f_m = \liminf_n \int f_n
\end{aligned}
\]</span> Combining the two equations we obtain the Fatou 's lemma.</p>
<h1 id="basic-properties-of-integrable-functions"><strong>Basic Properties of Integrable Functions</strong></h1>
<p>Let <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> be two integrable functions, and <span class="math inline">\(\alpha, \beta \in R\)</span> two real values.</p>
<ol type="1">
<li><p><em>Integrable functions forms a vector space, i.e., <span class="math inline">\(\int \alpha f + \beta g = \alpha \int f + \beta \int g\)</span></em><br />
<strong>Proof:</strong><br />
Let <span class="math inline">\(\{ f_n \}\)</span> and <span class="math inline">\(\{ g_n \}\)</span> be two sequence of simple, integrable functions that define the integral of <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> respectively.<br />
Then <span class="math inline">\(\{ \alpha f_n + \beta g_n \}\)</span> is a sequence of simple, integrable functions that are Cauchy in the mean and converges to <span class="math inline">\(\alpha f + \beta g\)</span> almost everywhere (assuming that <span class="math inline">\(\lim_n f_n = f \ a.e.\)</span> and <span class="math inline">\(\lim_n g_n = g \ a.e.\)</span>).<br />
<span class="math display">\[
\int \alpha f + \beta g = \lim_n \int \alpha f_n + \beta g_n = \alpha \lim_n \int f_n + \beta \lim_n \int g_n = \alpha \int f + \beta \int g
\]</span> <span class="math inline">\(\blacksquare\)</span></p></li>
<li><p><em>If <span class="math inline">\(f \ge 0 \ a.e.​\)</span>, then <span class="math inline">\(\int f \ge 0​\)</span>.</em><br />
<strong>Proof:</strong><br />
Let <span class="math inline">\(\{ f_n \}​\)</span> be a sequence of simple, integrable function that are Cauchy in mean and <span class="math inline">\(\lim_n f_n = f \ a.e.​\)</span>. Then <span class="math inline">\(\lim_n \int f_n = \int f​\)</span>.<br />
As <span class="math inline">\(f \ge 0 \ a.e.​\)</span>, <span class="math inline">\(\{ |f_n| \}​\)</span> converges to <span class="math inline">\(f​\)</span> almost everywhere.<br />
Moreover, <span class="math inline">\(\{ |f_n| \}​\)</span> is simple, integrable and Cauchy in the mean.<br />
Therefore, we also have<br />
<span class="math display">\[
 \int f = \lim_n \int |f_n| \ge 0
 \]</span> <span class="math inline">\(\blacksquare\)</span></p></li>
<li><p><em>If <span class="math inline">\(f \ge g \ a.e\)</span>, then <span class="math inline">\(\int f \ge \int g\)</span>.</em><br />
<strong>Proof:</strong></p>
<p>Define <span class="math inline">\(h = f - g\)</span>, then <span class="math inline">\(h \ge 0 \ a.e.\)</span>. By property 2 and 1, we obtain<br />
<span class="math display">\[
 \int h = \int f - g = \int f - \int g \ge 0
 \]</span></p>
<p>NOTE: it is also possible to prove this from scratch. Let <span class="math inline">\(\{ f_n \}\)</span> and <span class="math inline">\(\{ g_n \}\)</span> be two sequence of simple, integrable functions that define the integral of <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> respectively. Define <span class="math inline">\(h_n = f_n - g_n\)</span> be a sequence of simple, integrable functions that are Cauchy in the mean. Moreover, we have <span class="math inline">\(\lim h_n \ge 0 \ a.e.\)</span>. We need to show that <span class="math inline">\(\int h = \lim_n \int h_n \ge 0\)</span>.</p>
<p>As before, we would like to restrict our discussion on a <span class="math inline">\(\sigma\)</span>-finite measurable set. Define <span class="math inline">\(F_m = \cup_{i = 1}^m N(f_i) \cup \cup_{i = 1}^m N(g_i)\)</span> and <span class="math inline">\(F = \cup_{m = 1}^\infty F_m\)</span>. Clearly <span class="math inline">\(F_m \uparrow F\)</span> and <span class="math inline">\(\int h = \int_{F} h\)</span>.</p>
<p>On the other hand,<br />
<span class="math display">\[
 \begin{aligned}
 \int h  
 &amp; \ge \int h_n - \left| \int h_n - \int h \right| \\
 &amp;=  \int_{F_m} h_n - \int_{F_m} h_n + \int_{F_m} h_k - \int_{F_m} h_k + \int h_k - \int h_k + \int h_n - |\int h_n - \int h|  \\
 &amp;\ge \int_{F_m} h_n - \left| \int_{F_m} h_n - \int_{F_m} h_k \right| - \left| \int_{F_m} h_k - \int h_k \right| - \left| \int h_k - \int h_n \right|  - \left| \int h_n - \int h \right| \\
 &amp;\ge \int_{F_m} h_n - \int \left| h_n - h_k \right| - \left| \int_{F_m} h_k - \int h_k \right| - \int \left|  h_k - h_n \right|  - \int \left|  h_k - h_n \right| \\
 \end{aligned}
 \]</span> Since <span class="math inline">\(\{h_n\}\)</span> is Cauchy in mean, we can take sufficient large <span class="math inline">\(N\)</span>, s.t., for <span class="math inline">\(n, k \ge N\)</span>, <span class="math inline">\(\int |h_k - h_n| \le \epsilon\)</span>. Now we choose an <span class="math inline">\(k \ge N\)</span> and fix its value. Further, as <span class="math inline">\(F_m \uparrow F\)</span>, we can choose an <span class="math inline">\(m\)</span>, s.t., <span class="math inline">\(|\int_{F_m} h_k - \int h_k| \le \epsilon\)</span>. It follow <span class="math display">\[
 \int h \ge \int_{F_m} h_n - 3 \epsilon
 \]</span> It suffice to show <span class="math inline">\(\int_{F_m} h_n\)</span> is sufficient large on a measurable set <span class="math inline">\(F_m\)</span> with finite measure for large enough <span class="math inline">\(n\)</span>. Define <span class="math inline">\(S_n \doteq \{ x \in F_m : h_i (x) \ge - \epsilon / \mu(F_m) \text{ for all } i \ge n \}\)</span>. As <span class="math inline">\(\lim_n h \ge 0 \ a.e.\)</span>, <span class="math inline">\(S_n \uparrow\)</span> and <span class="math inline">\(\exists n\)</span> s.t., <span class="math inline">\(\mu(F_m \setminus S_n) \le \delta\)</span>, where <span class="math inline">\(\delta\)</span> is chosen s.t., <span class="math inline">\(\int_{F_m \setminus S_n} |h_k| \le \epsilon\)</span>. Such <span class="math inline">\(\delta\)</span> exists since <span class="math inline">\(h_k\)</span> is simple and integrable. For such an <span class="math inline">\(n\)</span>,<br />
<span class="math display">\[
 \begin{aligned}
 \int h  
 &amp; \ge \int_{S_n} h_n + \int_{F_m \setminus S_n} h_n - 3 \epsilon \\
 &amp;\ge \frac{-\epsilon}{\mu(F_m)}\mu(F_m) + \int_{F_m \setminus S_n} h_k - \int_{F_m \setminus S_n} h_k + \int_{F_m \setminus S_n} h_n - 3 \epsilon \\
 &amp;\ge -4 \epsilon - \left| \int_{F_m \setminus S_n} h_k \right| - \int |h_k - h_n| \\
 &amp;\ge -6 \epsilon
 \end{aligned}
 \]</span> As <span class="math inline">\(\epsilon\)</span> could be arbitrary value, it must be true that <span class="math inline">\(\int h \ge 0\)</span>.</p>
<p><span class="math inline">\(\blacksquare\)</span></p></li>
<li><p><em><span class="math inline">\(|f|\)</span> is an integrable function, and <span class="math inline">\(|\int f| \le \int |f|\)</span>.</em><br />
<strong>Proof:</strong><br />
Let <span class="math inline">\(\{ f_n \}\)</span> be a sequence of simple, integrable function that are Cauchy in mean and <span class="math inline">\(\lim_n f_n = f \ a.e.\)</span> Then Let <span class="math inline">\(\{ |f_n| \}\)</span> be a sequence of simple, integrable function that are Cauchy in mean and <span class="math inline">\(\lim_n |f_n| = |f| \ a.e.​\)</span><br />
<span class="math display">\[
 \int|f| = \lim_n \int |f_n| \ge \pm \lim_n \int f_n = \pm \int f \qquad \blacksquare
 \]</span></p></li>
<li><p><em><span class="math inline">\(\int|f+g | \le \int |f| + \int |g|\)</span>.</em><br />
<strong>Proof:</strong><br />
<span class="math inline">\(\int|f+g| \le \int(|f|+|g|) =\int|f| +\int|g|. \qquad \blacksquare\)</span></p></li>
<li><p><em>If <span class="math inline">\(m \le f \le M \ a.e.\)</span> on a measurable set <span class="math inline">\(E\)</span> with <span class="math inline">\(\mu(E) &lt; \infty\)</span>, then <span class="math inline">\(m \mu(E) \le \int_E f \le M \mu(E)\)</span>.</em><br />
<strong>Proof:</strong><br />
The condition <span class="math inline">\(\mu(E) &lt; \infty\)</span> ensures that <span class="math inline">\(m \mu(E) &lt; \infty\)</span>.<br />
Then utilize that <span class="math inline">\(\mu \chi_E\)</span> is simple, integrable <span class="math inline">\(\mu \chi_E \le f\)</span> almost everywhere.<br />
<span class="math inline">\(\blacksquare\)</span></p></li>
<li><p>If <span class="math inline">\(f \ge 0,\ a.e.\)</span>, and if <span class="math inline">\(E\)</span> and <span class="math inline">\(F\)</span> are measurable sets with <span class="math inline">\(E⊂F\)</span>, then <span class="math inline">\(\int_E f \le \int_F f\)</span>.<br />
<strong>Proof:</strong><br />
Utilize that <span class="math inline">\(\chi_E f \le \chi_F f\)</span> almost everywhere.<br />
<span class="math inline">\(\blacksquare\)</span></p></li>
<li><p><em>If <span class="math inline">\(F\)</span> is a disjoint union <span class="math inline">\(\cup_{m=1}^\infty F_n\)</span> of measurable sets, then<br />
<span class="math inline">\(\int_F f=\sum_{m=1}^\infty \int_{F_m} f\)</span>.</em><br />
<strong>Proof:</strong> Let <span class="math inline">\(\{ f_n \}\)</span> be a sequence of simple, integrable function that are Cauchy in mean and <span class="math inline">\(\lim_n f_n = f \ a.e.\)</span>. What we are going to prove is<br />
<span class="math display">\[
 \lim_n \lim_k \int_{\cup_{m = 1}^k F_m} f_n = \lim_k \lim_n \int_{\cup_{m = 1}^k F_m} f_n = \lim_k \sum_{m = 1}^k \int_{F_m} f
 \]</span> The exchange order of limit is justified as <span class="math inline">\(\{f_n\}​\)</span> is a sequence that is Cauchy in mean:<br />
<span class="math display">\[
 \begin{aligned}
 \left| \int_F f \right|
 &amp;= \left| \int_F f_n \right| + \left| \int_F f_n - \int f \right| \\
 &amp;\le \left| \int_{\cup_{m=1}^k F_m} f_n \right| + \left| \int_{\cup_{m=1}^k F_m} f_n -  \int_F f_n \right| + \left| \int_F f_n - \int f \right| \\
 &amp;\le \left| \int_{\cup_{m=1}^k F_m} f \right| + \left| \int_{\cup_{m=1}^k F_m} f - \int_{\cup_{m=1}^k F_m} f_n \right| + \left| \int_{\cup_{m=1}^k F_m} f_n -  \int_F f_n \right| + \left| \int_F f_n - \int f \right| \\
 &amp;\le \left| \sum_{m=1}^k \int_{F_m} f \right| + \epsilon + \left| \int_{\cup_{m=1}^k F_m} f_n -  \int_F f_n \right| + \epsilon
 \end{aligned}
 \]</span> for large enough <span class="math inline">\(n\)</span>. The conclusion follows as <span class="math inline">\(m \rightarrow \infty\)</span>.</p>
<p><span class="math inline">\(\blacksquare\)</span>.</p></li>
<li><p><em>If <span class="math inline">\(F_1 \subset F_2 \subset F_3 \subset ...\)</span> is a sequence of increasing measurable sets and let <span class="math inline">\(F = \cup_{n} F_n\)</span>, then <span class="math inline">\(\lim_n \int_{F_n} f = \int_F f\)</span>.</em><br />
<strong>Proof:</strong><br />
Let <span class="math inline">\(F_n&#39; = F_n - F_{n - 1}\)</span>. The result follows immediately from the previous property.<br />
<span class="math inline">\(\blacksquare\)</span></p></li>
<li><p><em>If <span class="math inline">\(F_1 \supset F_2 \supset F_3 \supset ...\)</span> is a sequence of decreasing measurable sets and let <span class="math inline">\(F = \cap_{n} F_n\)</span>, then <span class="math inline">\(\lim_n \int_{F_n} f = \int_F f\)</span>.</em><br />
<strong>Proof:</strong><br />
Let <span class="math inline">\(F_n = F_{n} - F_{n + 1}\)</span> for <span class="math inline">\(n \ge 1\)</span> and <span class="math inline">\(F = \cap_n F_n\)</span>. Then <span class="math inline">\(F_1 = (\cup_{n} F_n&#39;) \cup F\)</span> <span class="math display">\[
\sum_{n = 1}^\infty \int_{F_n&#39;} f + \int_F f = \int_{F_1} f
\]</span> The fact that <span class="math inline">\(f\)</span> is integrable implies <span class="math inline">\(\int_{F_1} f &lt; \infty\)</span>. Hence <span class="math display">\[
\int_F f = \int_{F_1} f - \sum_{n = 1}^\infty \int_{F_n&#39;} f = \lim_k \left(\int_{F_1} f - \sum_{n = 1}^k \int_{F_n&#39;} f \right) = \lim_k \int_{F_{k + 1} } f
\]</span> <span class="math inline">\(\blacksquare\)</span></p></li>
<li><p>Let <span class="math inline">\(f\)</span> be an integrable function. Then for <span class="math inline">\(\forall \epsilon &gt; 0\)</span>, the set <span class="math inline">\(E = \{ x \in X : f(x) &gt; \epsilon \}\)</span> has finite measure and <span class="math inline">\(\mu(E) \le \frac{\int_E f}{\epsilon}\)</span>.<br />
<strong>Proof:</strong><br />
Clearly <span class="math inline">\(E\)</span> is measurable. Further, consider the set <span class="math inline">\(F = \{ x \in X : f(x) \neq 0 \}\)</span>, which is <span class="math inline">\(\sigma\)</span> finite. We can rewrite it as an increasing sequence of finite measurable set <span class="math inline">\(F_1 \subset F_2 \subset F_3 ...\)</span>, s.t., <span class="math inline">\(F_n \uparrow F\)</span>. As <span class="math inline">\(\mu(E \cap F_n) \le \infty\)</span>, $ _{E F_n}$ is integrable. By monotonicity of integration,<br />
<span class="math display">\[
\epsilon \mu(E \cap F_n) = \int \epsilon \chi_{E \cap F_n} \le \int f \chi_{E \cap F_n} \le \int_E f &lt; \infty
\]</span> Now we see that <span class="math inline">\(\mu(E \cap F_n) \le \frac{\int f}{\epsilon }\)</span>. Taking the limit of <span class="math inline">\(n \rightarrow \infty\)</span>, we obtain the desired result.<br />
<span class="math inline">\(\blacksquare\)</span></p></li>
</ol>
<h1 id="reference">Reference</h1>
<ol type="1">
<li>AVNER FRIEDMAN, <em>Foundations of Modern Analysis</em></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/03/02/Exchange-Order/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/02/Exchange-Order/" class="post-title-link" itemprop="url">Exchange Order</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2019-03-02 15:06:27 / Modified: 21:52:42" itemprop="dateCreated datePublished" datetime="2019-03-02T15:06:27+11:00">2019-03-02</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Consider a matrix <span class="math inline">\(A = (a_{i,j})\)</span> with countable rows and columns. Suppose for any <span class="math inline">\(m \in \mathbf{N}\)</span>, <span class="math display">\[
\sum_{i = 1}^\infty a_{i,m} = \lim_n \sum_{i = 1}^n a_{i, m} =  x_m
\]</span> exists. Moreover, <span class="math inline">\(\forall \epsilon &gt; 0\)</span>, <span class="math inline">\(\exists N \in \mathbf{N}\)</span>, s.t., for <span class="math inline">\(n &gt; N\)</span>, we have <span class="math inline">\(|\sum_{i = 1}^n \sum_{j = 1}^m a_{i,j} - \sum_{j = 1}^m x_m | \le \epsilon\)</span> for whatever choice of <span class="math inline">\(m \in \mathbf{N}\)</span>. We also know that for any <span class="math inline">\(n \in \mathbf{N}\)</span>, <span class="math display">\[
\sum_{j = 1}^\infty a_{n, j} = \lim_{m} \sum_{j = 1}^m a_{n, j} = y_n 
\]</span> exists. Suppose that <span class="math display">\[
s = \lim_{n} \sum_{i = 1}^n y_i
\]</span> then <span class="math display">\[
\lim_m \sum_{j = 1}^m x_m \ \text{exists and } \  s = \lim_m \sum_{j = 1}^m x_m
\]</span></p>
<p><em>Proof:</em> <span class="math display">\[
\begin{aligned}
|s - \sum_{j = 1}^m x_m| 
&amp;\le |s - \sum_{i = 1}^n y_i| + |\sum_{i = 1}^n y_i - \sum_{i = 1}^n \sum_{j = 1}^m a_{i,j}| + |\sum_{i = 1}^n \sum_{j = 1}^m a_{i,j} - \sum_{j = 1}^m x_m| \\
&amp;= |s - \sum_{i = 1}^n y_i| + | \sum_{i = 1}^n (y_i - \sum_{j = 1}^m a_{i,j} ) | + |\sum_{i = 1}^n \sum_{j = 1}^m a_{i,j} - \sum_{j = 1}^m x_m| 
\end{aligned}
\]</span></p>
<ol type="1">
<li>As <span class="math inline">\(\sum_{i = 1}^n y_i \rightarrow s\)</span>, <span class="math inline">\(\exists N_1 \in \mathbf{N}\)</span>, s.t., <span class="math inline">\(n &gt; N_1 \rightarrow |s - \sum_{i = 1}^n y_i| \le \epsilon / 3\)</span>,</li>
<li>For any choice of <span class="math inline">\(m\)</span>, <span class="math inline">\(\exists N_3 \in \mathbf{N}\)</span>, s.t., <span class="math inline">\(n &gt; N_3 \rightarrow |\sum_{i = 1}^n \sum_{j = 1}^m a_{i,j} - \sum_{j = 1}^m x_m| \le \epsilon / 3\)</span>,</li>
<li>Now, taking <span class="math inline">\(n &gt; \max \{ N_1, N_3 \}\)</span>, we have <span class="math display">\[
|s - \sum_{j = 1}^m x_m| \le \epsilon / 3 + |\sum_{i = 1}^n y_i - \sum_{i = 1}^n \sum_{j = 1}^m a_{i,j}| + \epsilon / 3
\]</span> If we fix <span class="math inline">\(n\)</span>, <span class="math inline">\(\exists N_2 \in \mathbf{N}\)</span>, s.t., <span class="math inline">\(m &gt; N_2 \rightarrow |\sum_{i = 1}^n y_i - \sum_{i = 1}^n \sum_{j = 1}^m a_{i,j}| &lt; \epsilon\)</span>. Therefore, we have <span class="math inline">\(|s - \sum_{j = 1}^m x_m| \le \epsilon\)</span>, as desired.</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/03/01/Measurable-Functions/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/01/Measurable-Functions/" class="post-title-link" itemprop="url">Function Convergence</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-01 18:18:08" itemprop="dateCreated datePublished" datetime="2019-03-01T18:18:08+11:00">2019-03-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-03-03 01:51:47" itemprop="dateModified" datetime="2019-03-03T01:51:47+11:00">2019-03-03</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>In this article we discuss several important convergence properties of a sequence <span class="math inline">\(\{f_n \}\)</span> of functions with defined on the measure space <span class="math inline">\((X, a, \mu)\)</span>.</p>
<h5 id="definition-pointwise-convergence">Definition (Pointwise Convergence)</h5>
<p><em><span class="math inline">\(\{ f_n \}​\)</span> converges to <span class="math inline">\(f​\)</span> almost every (a.e.) if <span class="math inline">\(\{ f_n \}\)</span> converges to <span class="math inline">\(f\)</span> except on a set of measure zero, i.e, <span class="math inline">\(\exists E \subset X​\)</span>, s.t., <span class="math inline">\(\mu(X - E) = 0​\)</span> and <span class="math inline">\(\forall x \in E, \lim_n f_n(x) = f(x)​\)</span>.</em></p>
<h5 id="definition-uniform-convergence">Definition (Uniform Convergence)</h5>
<p><span class="math inline">\(\{ f_n \}​\)</span> converges to <span class="math inline">\(f​\)</span> almost uniformly if <span class="math inline">\(\forall \epsilon &gt; 0​\)</span>. <span class="math inline">\(\exists F \subset X​\)</span>, s.t, <span class="math inline">\(\mu(X - F) \le \epsilon​\)</span> and <span class="math inline">\(\{ f_n \}​\)</span> converges uniformly to <span class="math inline">\(f​\)</span> on <span class="math inline">\(F​\)</span>.</p>
<p>The following two theorems discuss the relation between pointwise and almost uniform convergence.</p>
<h5 id="theorem-1.almost-uniform-rightarrow-pointwise">Theorem 1.[Almost Uniform <span class="math inline">\(\rightarrow\)</span> Pointwise]</h5>
<p><em>If <span class="math inline">\(\{ f_n \}\)</span> converges to <span class="math inline">\(f\)</span> almost uniformly, then <span class="math inline">\(\{ f_n \}\)</span> converge to <span class="math inline">\(f\)</span> almost everywhere</em>.</p>
<p><em>Proof:</em> By definition, <span class="math inline">\(\forall 1 / n &gt; 0, \exists F_n \subset X, s.t., \mu(X - F_n) \le 1/n\)</span> and <span class="math inline">\(\{ f_n \}\)</span> converges uniformly to <span class="math inline">\(f\)</span> on <span class="math inline">\(F_n\)</span>. But this immediately implies that <span class="math inline">\(\{ f_n \}\)</span> converges pointwise on <span class="math inline">\(F_n\)</span> and therefore it converges pointwise on <span class="math inline">\(\cup_{n = 1}^\infty F_n\)</span>.</p>
<p>We claim that <span class="math inline">\(\mu(X - \cup_{n = 1}^\infty F_n)\)</span> has measure zero and hence <span class="math inline">\(\{ f_n \}\)</span> converges to <span class="math inline">\(f\)</span> almost everywhere. Since <span class="math inline">\(\mu(X - \cup_{n = 1}^\infty F_n) = \mu( \cap_{n = 1}^\infty (X - F_n)) \le \mu(X - F_n) = 1/n\)</span> for any <span class="math inline">\(n \in \mathbf{N}\)</span>, <span class="math inline">\(\mu(X - \cup_{n = 1}^\infty F_n) = 0\)</span>, as desired.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<h5 id="theorem-2.-pointwise-rightarrow-almost-uniformegorov">Theorem 2. [Pointwise <span class="math inline">\(\rightarrow\)</span> Almost Uniform][Egorov]</h5>
<p><em>Let <span class="math inline">\(\{f_n\}\)</span> be a sequence of measurable functions that converges pointwise to <span class="math inline">\(f\)</span> almost everywhere and suppose <span class="math inline">\(\mu(X) \le \infty\)</span>, then <span class="math inline">\(\{ f_n \}\)</span> converges to <span class="math inline">\(f\)</span> almost uniformly.</em></p>
<p><em>Proof:</em> Without lost of generality, we assume that <span class="math inline">\(\{ f_n \}\)</span> converge to <span class="math inline">\(f\)</span> everywhere on <span class="math inline">\(X\)</span>.</p>
<p>Given <span class="math inline">\(\epsilon &gt; 0\)</span>, we need to find a set <span class="math inline">\(F\)</span> such that <span class="math inline">\(\{ f_n \} \rightarrow f\)</span> uniformly on <span class="math inline">\(F\)</span> and <span class="math inline">\(m(X - F) \le \epsilon\)</span>.</p>
<p>For each pair of <span class="math inline">\(k, m \in \mathbf{N}\)</span>, consider the set <span class="math inline">\(F_{k, m} = \cap_{n = m}^\infty \{ x : |f_n(x) - f(x)| \le 1 / k \}\)</span>. Now fix <span class="math inline">\(k\)</span> and note that <span class="math inline">\(F_{k, m} \subset F_{k, m+1}\)</span>.</p>
<p>Next, <span class="math inline">\(\forall x \in E\)</span>, <span class="math inline">\(\lim_n f_n(x) = f(x)\)</span>. For fix <span class="math inline">\(x\)</span> and <span class="math inline">\(k\)</span>, <span class="math inline">\(\exists m &gt; 0\)</span>, s.t., for all <span class="math inline">\(n &gt; m, |f_n(x) - f(x)| \le 1/k\)</span>. Hence <span class="math inline">\(x \in F_{k, m}\)</span>.</p>
<p>We conclude that <span class="math inline">\(F_{k, m}\)</span> is a sequence of monotone increasing sets and <span class="math inline">\(\lim_{m} F_{k,m} = X\)</span>. Thus we have <span class="math inline">\(\lim_{m} F_{k,m}) = \mu(X) &lt; \infty\)</span>. For arbitrary <span class="math inline">\(\epsilon &gt; 0\)</span>, we can find an integer <span class="math inline">\(N_k\)</span>, s.t., <span class="math inline">\(\mu(X - F_{k, N_k}) \le \epsilon / 2^k\)</span>. Now for convenience we abbreviate <span class="math inline">\(F_{k, N_k}\)</span> as <span class="math inline">\(F_k\)</span>.</p>
<p>Observe that <span class="math inline">\(\{ f_n \}\)</span> converges uniformly on <span class="math inline">\(F = \cap_{k = 1}^\infty F_k\)</span>, as for any <span class="math inline">\(\lambda &gt; 0, \exists k \in \mathbf{N}, s.t., 1 / k &lt; \lambda\)</span>, and <span class="math inline">\(x \in F\)</span> implies <span class="math inline">\(x \in F_k\)</span>. Therefore if <span class="math inline">\(n &gt; N_K\)</span>, <span class="math inline">\(|f_n(x) - f(x)| \le 1/k \le \lambda​\)</span>.</p>
<p>It remains to prove <span class="math inline">\(\mu(X - F)\)</span> is small enough. This is because of <span class="math display">\[
\begin{aligned}
\mu(E - F) 
&amp;= \mu(E - \cap_{k = 1}^\infty F_k) \\
&amp;= \mu(\cup_{k = 1}^\infty (E - F_k)) \\
&amp;\le \sum_{k = 1}^\infty \mu(E - F_k) \\
&amp;\le \sum_{k = 1}^\infty \epsilon / 2^k \\
&amp;= \epsilon
\end{aligned}
\]</span></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<p>There are another two frequently used definitions for convergence.</p>
<h5 id="definition-converges-in-measure">Definition (Converges in measure)</h5>
<p><span class="math inline">\(\{ f_n \}\)</span> converges to <span class="math inline">\(f\)</span> in measure if <span class="math inline">\(\forall \epsilon &gt; 0\)</span>, <span class="math inline">\(\forall \delta &gt; 0\)</span>, <span class="math inline">\(\exists N \in \mathbf{N}\)</span>, s.t, for <span class="math inline">\(n &gt; N\)</span>, <span class="math inline">\(\mu( \{ x : |f_n (x) - f(x)| \ge \epsilon \} ) &lt; \delta, i.e,\)</span>,<br />
<span class="math display">\[
\lim_{n} \mu( \{ x : |f_n(x) - f(x)| \ge \epsilon \}) = 0
\]</span></p>
<h5 id="definition-cauchy-in-measure">Definition (Cauchy in measure)</h5>
<p><span class="math inline">\(\{ f_n \}\)</span> is Cauchy in measure if <span class="math inline">\(\forall \epsilon &gt; 0\)</span>, <span class="math inline">\(\forall \delta &gt; 0\)</span>, <span class="math inline">\(\exists N \in \mathbf{N}\)</span>, s.t, for <span class="math inline">\(n, m &gt; N\)</span>, <span class="math inline">\(\mu( \{ x : |f_n (x) - f_m(x)| \ge \epsilon \} ) &lt; \delta, i.e,\)</span>,<br />
<span class="math display">\[
\lim_{n, m} \mu( \{ x : |f_n(x) - f_m(x)| \ge \epsilon \}) = 0
\]</span></p>
<p>It is easy to see that if <span class="math inline">\(\{ f_n \}\)</span> converge in measure, then it is Cauchy in measure. Later we will show that the converse is also true.</p>
<p>Remark: Converging in measure does not imply converge almost every where. To see this, consider a countable sequence of functions defined on <span class="math inline">\([0, 1]\)</span>.</p>
<ol type="1">
<li><span class="math inline">\(f_{1, 1} = \mathbf{1}_{[0, 1/2]}​\)</span>, <span class="math inline">\(f_{1, 2} = \mathbf{1}_{[1/2, 1]}​\)</span></li>
<li><span class="math inline">\(f_{2, 1} = \mathbf{1}_{[0, 1/4]}\)</span>, <span class="math inline">\(f_{2, 2} = \mathbf{1}_{[1/4, 1/2]}\)</span>, <span class="math inline">\(f_{2, 3} = \mathbf{1}_{[1/2, 3/4]}\)</span>, <span class="math inline">\(f_{2, 4} = \mathbf{1}_{[3/4, 1]}\)</span></li>
<li>....</li>
<li><span class="math inline">\(f_{n, 1} = \mathbf{1}_{ [0, 1/2^n] }\)</span>, ..., <span class="math inline">\(f_{n, i} = \mathbf{1}_{ [(i - 1) / 2^{n}, i /2^n] }\)</span>, ..., <span class="math inline">\(f_{n, n} = \mathbf{1}_{ [1 - 1/2^{n}, 1] }\)</span></li>
<li>...</li>
</ol>
<p>We can list the functions as <span class="math inline">\(\{ f_{1, 1}, f_{1, 2}, f_{2, 1}, ...\}\)</span> and relabel them concisely as <span class="math inline">\(\{g_1, g_2, g_3, ... \}\)</span>. Apparently, <span class="math inline">\(\{ g_n \}\)</span> converges to <span class="math inline">\(g(x) \equiv 0\)</span> in measure. But for any <span class="math inline">\(x \in [0, 1]\)</span>, there are infinite number of functions from the sequence <span class="math inline">\(\{ g_n \}\)</span> such that <span class="math inline">\(g_n(x) = 1\)</span> and so <span class="math inline">\(\{ g_n \} \nrightarrow g, a.e\)</span>.</p>
<p>However, we have the following theorem.</p>
<h5 id="theorem-3">Theorem 3</h5>
<p>If <span class="math inline">\(\{ f_n \}\)</span> is Cauchy is Cauchy in measure, then it has a sub-sequence that converges to a measurable function <span class="math inline">\(f\)</span> almost uniformly.</p>
<p>Key Observation: if we look at the previous example, <span class="math inline">\(f_{n, i}\)</span> only deviates from <span class="math inline">\(g(x) \equiv 0\)</span> by a small interval <span class="math inline">\([( i - 1) / 2^n, i / 2^n]\)</span> with length <span class="math inline">\(1 / 2^n\)</span>. However, there are <span class="math inline">\(2^n\)</span> functions with such deviation and the intervals of deviation do not overlap. This motivates filtering out a sub-sequence.</p>
<p><em>Proof:</em> Since <span class="math inline">\(\{ f_n \}\)</span> is Cauchy, <span class="math inline">\(\forall k &gt; 0\)</span>, we can find an integer <span class="math inline">\(n_k &gt; 0, s.t., \forall n, m \ge n_k, \mu( \{ x: |f_n(x) - f_m(x)| \ge 1 / 2^k \} ) \le 1/ 2^k\)</span>. We choose such a increasing sequence <span class="math inline">\((n_k)\)</span> satisfying <span class="math display">\[
n_1 &lt; n_2 &lt; n_3 &lt; ... n_k &lt; ...
\]</span> and the corresponding sub-sequence <span class="math inline">\(\{ f_{n_k} \}\)</span> of <span class="math inline">\(\{ f_n \}\)</span>.</p>
<p>Let <span class="math display">\[
\begin{aligned}
F_k &amp;= \{x : |f_n(x) - f_m(x)| \le 1 / 2^k, \forall n, m \ge n_k \} \\
E_n &amp;= \cap_{k = n}^\infty F_k
\end{aligned}
\]</span>.</p>
<p>Then <span class="math inline">\(\{ f_{n_k} \}\)</span> is uniformly Cauchy in <span class="math inline">\(E_n\)</span> and therefore converge uniformly. It follows that there is a measurable function defined on</p>
<p><span class="math display">\[
F = \cup_{n = 1}^\infty E_n
\]</span></p>
<p>such that <span class="math inline">\(\{ f_{n_k} \}\)</span> converges uniformly on each <span class="math inline">\(E_n\)</span>. We can extend the domain of <span class="math inline">\(f\)</span> to <span class="math inline">\(X\)</span> by defining <span class="math inline">\(f(x) = 0\)</span> for <span class="math inline">\(x \in X - F\)</span>. Note that <span class="math inline">\(f\)</span> is measurable on <span class="math inline">\(X\)</span>.</p>
<p>Finally, <span class="math display">\[
\mu(X - E_n) = \mu(X - \cap_{k = n}^\infty F_k) \le \sum_{k = n}^\infty \mu(x - F_k) \le 1 / 2^{n - 1}
\]</span>. It follows that <span class="math inline">\(\mu(F) = \mu(X)\)</span> and <span class="math inline">\(( f_{n_k} )\)</span> converge almost uniformly on <span class="math inline">\(F\)</span>.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<h5 id="corollary">Corollary</h5>
<p>If <span class="math inline">\(\{ f_n \}\)</span> is Cauchy is Cauchy in measure, then it converges to a measurable function <span class="math inline">\(f\)</span> in measure.</p>
<h5 id="reference">Reference</h5>
<ol type="1">
<li>Avner Friedman, <em>Foundation of Modern Analysis</em>.</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/02/28/Compact-Set/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/02/28/Compact-Set/" class="post-title-link" itemprop="url">Compact Set</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2019-02-28 19:46:25 / Modified: 23:39:22" itemprop="dateCreated datePublished" datetime="2019-02-28T19:46:25+11:00">2019-02-28</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="definition.-compact-set">Definition. Compact Set</h4>
<p>A set <span class="math inline">\(S \subset R\)</span> is compact if every sequence in <span class="math inline">\(S\)</span> has a convergent sub-sequence whose limit is in <span class="math inline">\(S\)</span>.</p>
<h5 id="theorem.-s-is-compact-if-and-only-if-it-is-closed-and-bounded.">Theorem. <span class="math inline">\(S\)</span> is compact if and only if it is closed and bounded.</h5>
<p><em>Proof:</em><br />
1. <span class="math inline">\(&quot;\Rightarrow&quot;\)</span>: Suppose <span class="math inline">\(S\)</span> is not bounded. Then there is a sequence <span class="math inline">\((a_n)\)</span> is <span class="math inline">\(S\)</span>, such that <span class="math inline">\(|a_n| \ge n\)</span>, <span class="math inline">\(\forall n \in N\)</span>. Now every sub-sequence in <span class="math inline">\((a_n)\)</span> diverges. Therefore <span class="math inline">\(S\)</span> must be bounded. Next we show that <span class="math inline">\(S\)</span> contains all its limit points. Let <span class="math inline">\(a\)</span> be a limit point of <span class="math inline">\(S\)</span>. Then there is a sequence <span class="math inline">\((a_n) \rightarrow a\)</span>. <span class="math inline">\((a_n)\)</span> is a sub-sequence of itself and so <span class="math inline">\(a \in S\)</span>. We have proved that <span class="math inline">\(S\)</span> is closed. 2. <span class="math inline">\(&quot;\Leftarrow&quot;\)</span>: Assume <span class="math inline">\(S\)</span> is closed and bounded. Consider a sequence <span class="math inline">\((a_n)\)</span> in <span class="math inline">\(S\)</span>. By Weierstrass Theorem, there is a convergent sub-sequence <span class="math inline">\(( a_{n_k} )\)</span>. But since <span class="math inline">\(S\)</span> is closed, <span class="math inline">\(\lim_k a_{n_k} \in S\)</span>.</p>
<h5 id="theorem.-s-is-compact-if-and-only-if-every-open-cover-of-s-has-a-finite-sub-cover.">Theorem. <span class="math inline">\(S\)</span> is compact if and only if every open cover of <span class="math inline">\(S\)</span> has a finite sub-cover.</h5>
<p><em>Proof:</em><br />
1. <span class="math inline">\(&quot;\Rightarrow&quot;\)</span>: If <span class="math inline">\(S\)</span> is compact, it is bounded. We can find a closed interval <span class="math inline">\(I_0\)</span> that contains <span class="math inline">\(S\)</span>. Suppose <span class="math inline">\(S\)</span> can not be covered by a finite sub-cover. We bisect <span class="math inline">\(I_0\)</span> into two closed intervals of equal length. At least one of them can not be covered with finite sets. Denote this interval <span class="math inline">\(I_1\)</span>. We continue the process, resulting in a series of intervals <span class="math inline">\(I_1 \supset I_2 \supset I_3 \supset ...\)</span>. Define <span class="math inline">\(J_n = I_n \cap S \quad \forall n \in N\)</span>. The construction of <span class="math inline">\(I_n\)</span> ensures <span class="math inline">\(J_n \neq \emptyset \quad \forall n \in N\)</span> and the length of <span class="math inline">\(I_n\)</span> approaches <span class="math inline">\(0\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span>. We claim that <span class="math inline">\(\cap_n J_n \neq \emptyset\)</span>. Indeed, there is an element <span class="math inline">\(a_n \in J_n\)</span> for <span class="math inline">\(n \in N\)</span>. It not difficult to see <span class="math inline">\((a_n)\)</span> is a Cauchy sequence since <span class="math inline">\(\forall m &gt; n \ge N\)</span>, <span class="math inline">\(a_n, a_m \in I_N\)</span> and <span class="math inline">\(|a_n - a_m| \le |I_N|\)</span>. Let <span class="math inline">\(a = \lim_n a_n\)</span>. We conclude that <span class="math inline">\(a \in J_n\)</span> for <span class="math inline">\(n \in N\)</span>. This is because <span class="math inline">\(a_{n + 1}, a_{n + 2}..., \in J_n\)</span> for all <span class="math inline">\(n \in N\)</span>. It follows that <span class="math inline">\(a \in \cap_n J_n\)</span>. Now <span class="math inline">\(a\)</span> must be covered by some open set <span class="math inline">\(O_a\)</span>. On the other hand, the construction of <span class="math inline">\(I_n\)</span> ensures that there is an integer <span class="math inline">\(N_a\)</span> such that <span class="math inline">\(I_{N_a}\)</span> is small enough such that <span class="math inline">\(I_{N_a} \subset O_a\)</span>. Contradicting the assumption that <span class="math inline">\(I_{N_a}\)</span> cannot be covered with finite sets.</p>
<ol start="2" type="1">
<li><span class="math inline">\(&quot;\Leftarrow&quot;\)</span>: Consider the collection of open balls <span class="math inline">\(\{ B(O, 1),\ B(O, 2),\ B(O, 3), ...\}\)</span> centered at <span class="math inline">\(0\)</span> with radii <span class="math inline">\(1, 2, 3, ...\)</span>. It covers <span class="math inline">\(S\)</span> and has a finite sub-cover. It follows that <span class="math inline">\(S\)</span> is bounded by the ball with largest radius in the finite sub-cover. To show <span class="math inline">\(S\)</span> is closed, it suffices to prove it complement <span class="math inline">\(S^c\)</span> is open. Let <span class="math inline">\(a \in S^c\)</span>. Take the collection of closed balls <span class="math inline">\(\{ \bar B(a, 1),\ \bar B(a, 1/2),\ \bar B(a, 1/3), ...\}\)</span> centered at <span class="math inline">\(a\)</span> with radii <span class="math inline">\(1, 1/2, 1/3, ..., 1/n, ...\)</span>. Their complements <span class="math inline">\(\{ \bar B(a, 1)^c,\ \bar B(a, 1/2)^c,\ \bar B(a, 1/3)^c, ...\}\)</span> constitute an open cover of <span class="math inline">\(S\)</span>. By assumption we can find a finite subset of them that covers <span class="math inline">\(S\)</span>. Let <span class="math inline">\(\bar B(a, \epsilon)^c\)</span> be the one with the smallest radius in the finite subset collection. We learn that <span class="math inline">\(B(a, \epsilon) \subset S^c\)</span> and therefore <span class="math inline">\(S^c\)</span> is open.</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description">你生之前悠悠千載已逝，未來還會有千年沉寂的期待</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">125</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WOW</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

</body>
</html>
