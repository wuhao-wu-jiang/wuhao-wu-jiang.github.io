<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="WOW">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>WOW</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">WOW</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">你生之前悠悠千載已逝<br>未來還會有千年沉寂的期待</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/01/12/Fourier-Transformation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/12/Fourier-Transformation/" class="post-title-link" itemprop="url">Fourier Transformation</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-12 16:21:21" itemprop="dateCreated datePublished" datetime="2021-01-12T16:21:21+11:00">2021-01-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-26 23:51:21" itemprop="dateModified" datetime="2021-01-26T23:51:21+11:00">2021-01-26</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Let <span class="math inline">\(f: [-\pi, \pi]: \rightarrow \mathbb{R}\)</span> be a real function. As <span class="math inline">\(f\)</span> itself can be complicated, we want to decompose it into a linear combination of simpler functions.</p>
<blockquote>
<p><strong>Example.</strong> A typical family of simple functions are polynomials: <span class="math display">\[
\{ 1, t, t^2, t^3, ... \}.
\]</span> Under proper condition, e.g., if <span class="math inline">\(f\)</span> is infinitely differentiable, it can be indeed decomposed into a linear combination of polynomials, such as: <span class="math display">\[
f = f(0) + f&#39;(0)  t + \frac{f&#39;&#39;(t)}{2!} t^2 + ...
\]</span></p>
</blockquote>
<h2 id="problem"><strong>Problem</strong></h2>
<p>Here we study the problem of approximating <span class="math inline">\(f\)</span> with trigonometric functions: <span class="math display">\[
    \mathfrak{T} = \{ 1, \sin t, \cos t, \sin 2t, \cos 2t, .... \}.
\]</span></p>
<p>Although <span class="math inline">\(f: [-\pi, \pi]: \rightarrow \mathbb{R}\)</span> is a function with output on <span class="math inline">\(\mathbb{R}\)</span>, we view it as a function <span class="math inline">\([-\pi, \pi]: \rightarrow \mathbb{C}\)</span> to take advantage of complex exponential. Now, we approximate <span class="math inline">\(f\)</span> with a set of sinusoids: <span class="math display">\[
   \Gamma = \{ 1, \exp(it), \exp(-it), \exp(i2t), \exp(-i2t), \exp(i3t), \exp(-i3t)... \}.
\]</span></p>
<p>Observe that <span class="math inline">\(\Gamma\)</span> generalizes <span class="math inline">\(\mathfrak{T}\)</span>, as for <span class="math inline">\(\forall k \in \mathbb{N}\)</span>, <span class="math display">\[
2 \cos kt =  \exp(ikt) + \exp(-ikt), \\
2 \sin kt =  \exp(ikt) - \exp(-ikt). 
\]</span></p>
<p>Define the span <span class="math inline">\(S(\Gamma)\)</span> as the set of all possible linear combinations of functions in <span class="math inline">\(\Gamma\)</span>: <span class="math display">\[
S(\Gamma) \doteq \left\{ \sum_{k \in \mathbb{Z} } c_k \exp(ikt) : \forall k \in \mathbb{Z}, c_k \in \mathbb{C} \right\}.
\]</span></p>
<p><strong><em>The goal is to find the closest function to <span class="math inline">\(f\)</span> in <span class="math inline">\(S(\Gamma)\)</span></em></strong>.</p>
<p>The key issues with the approximation are</p>
<ol type="1">
<li><p>How do we measure the closeness between two functions?</p></li>
<li><p>Under what condition, can <span class="math inline">\(f\)</span> be rewrite as a linear combination of functions in <span class="math inline">\(\Gamma\)</span>?</p></li>
<li><p>What is the approximation error, between <span class="math inline">\(f\)</span> and the linear combination?</p></li>
</ol>
<h2 id="norm"><strong>Norm</strong></h2>
<p>Despite the goal stated above, the closeness between <span class="math inline">\(f\)</span> and a function in <span class="math inline">\(S(\Gamma)\)</span> has not yet been defined. This raises the question of measuring the distance between two functions in <span class="math inline">\([-\pi, \pi] \rightarrow \mathcal{C}\)</span>.</p>
<p>In <span class="math inline">\(\mathbb{R}^n\)</span>, the Euclidean distance between two vectors <span class="math inline">\(u, v\)</span> is defined as <span class="math display">\[
    || u - v || = \sqrt{\sum_{i = 1}^n (u_i - v_i)^2 }.
\]</span></p>
<p>If we define <span class="math inline">\(w = u - v\)</span>, then the problem of measuring the distance between two vectors reduces to the one of measuring the length of a vector <span class="math display">\[
|| u - v || = || w || = \sqrt{\sum_{i = 1}^n w_i^2 }.
\]</span></p>
<!-- We call the function $||\cdot || : \mathbb{R}^n \rightarrow \mathbb{R}$ as norm and it satisfies the following three properties:

1. Positive-definite: $||w|| = 0 \rightarrow w = 0, \forall w \in \mathbb{R}^n$;
2. Absolutely homogeneous: $|| a w|| = |a| \cdot ||w||, \forall a \in \mathbb{R}, \forall w \in \mathbb{R}^n$; 
3. Triangle inequality: $||w + w'|| \le ||w|| + ||w'||, \forall w, w' \in \mathbb{R}^n$. -->
<p>In a similar manner, if we view a function <span class="math inline">\(h: [-\pi, \pi] \rightarrow \mathcal{C}\)</span> as an (uncountable) infinite dimension vector, it is natural to defined its length <span class="math display">\[
    || h || \doteq \sqrt{ \int_{ [-\pi, \pi] }   ||h(t) ||^2 } = \sqrt{ \int_{ [-\pi, \pi] }   \overline{h(t) } \cdot h(t)  }.
\]</span></p>
<blockquote>
<p><em>Remark:</em> 1. <em><span class="math inline">\(|| h ||^2\)</span> needs to be integrable.</em><br />
2. <em>Verify that <span class="math inline">\(|| \cdot ||\)</span> is a norm.</em></p>
</blockquote>
<p>As <span class="math inline">\(f - g\)</span> is also a function in <span class="math inline">\([-\pi, \pi] \rightarrow \mathcal{C}\)</span>, the distance between two functions <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> is given by <span class="math display">\[
\begin{aligned}
    ||f - g|| 
        &amp;= \sqrt{ \int_{ [-\pi, \pi] }   ||f(t) - g(t)||^2  } \\
        &amp;= \sqrt{ \int_{ [-\pi, \pi] }   \overline{ (f(t) - g(t) ) } \cdot (f(t) - g(t) )  } \\
        &amp;= \sqrt{ \int_{ [-\pi, \pi] }   \overline{ f(t) } \cdot f(t) + \int_{ [-\pi, \pi] }  \overline{ g(t) } \cdot g(t) - \int_{ [-\pi, \pi] }  \overline{ f(t) } \cdot g(t) - \int_{ [-\pi, \pi] }  \overline{ g(t) } \cdot f(t) \   } \\
        &amp;= \sqrt{ ||f||^2 + || g ||^2 - \int_{ [-\pi, \pi] }  \overline{ f(t) } \cdot g(t) - \int_{ [-\pi, \pi] }  \overline{ g(t) } \cdot f(t) \   }. \\
\end{aligned}
\]</span></p>
<blockquote>
<p><em>Remark:</em> 1. <span class="math inline">\(|| f - g ||^2\)</span> needs to be integrable. 2. The integration operation is required to be linear.</p>
</blockquote>
<h3 id="hermitian-product"><strong>Hermitian Product</strong></h3>
<p>To simplify the expansion of <span class="math inline">\(||f - g||\)</span>, we introduce another operation, termed Hermitian product, as follows: <span class="math display">\[
\left&lt; g, f \right&gt;_H \doteq \int_{ [-\pi, \pi] }  \overline{ g(t) } \cdot f(t).
\]</span></p>
<p>The operation is not symmetric. By definition, <span class="math display">\[
\left&lt; f, g \right&gt;_H \doteq \int_{ [-\pi, \pi] }  \overline{ f(t) } \cdot g(t).
\]</span></p>
<p><span class="math inline">\(\left&lt; g, f \right&gt;_H\)</span> is the complex conjugate of <span class="math inline">\(\left&lt; f, g \right&gt;_H\)</span>: <span class="math display">\[
\left&lt; g, f \right&gt;_H = \overline{ \left&lt; f, g \right&gt;_H }.
\]</span></p>
<p>For any <span class="math inline">\(c \in \mathbb{C}\)</span>, it holds that <span class="math display">\[
\left&lt; c \cdot g, f \right&gt;_H = \bar c \cdot \left&lt; g, f \right&gt;_H,  \\
\left&lt; g, c \cdot f \right&gt;_H = c  \cdot \left&lt; g, f \right&gt;_H. \\
\]</span></p>
<p>Now the expansion of <span class="math inline">\(||f - g||\)</span> is simplified as <span class="math display">\[
\begin{aligned}
    ||f - g|| 
        &amp;= \sqrt{ ||f||^2 + ||g||^2 - ( \overline{ \left&lt; g, f \right&gt;_H } + \left&lt; g, f \right&gt;_H ) } \\
        &amp;= \sqrt{ ||f||^2 + ||g||^2 - 2 \cdot \mathbb{Re}( \left&lt; g, f \right&gt;_H ) }. \\
\end{aligned}
\]</span></p>
<h4 id="geometric-interpretation"><strong>Geometric Interpretation</strong></h4>
<p>We have just introduced the notation of Hermitian product to simplify the expression. Its "geometric" interpretation is related to the idea of "projection". We start by reviewing the ideas of "Projection, Dot Product and Orthogonality" in <span class="math inline">\(\mathbb{R}^2\)</span>.</p>
<blockquote>
<p><strong>Projection</strong> in <span class="math inline">\(\mathbb{R}^2\)</span>. Given <span class="math inline">\(u, v \in \mathbb{R}^2\)</span>, the projection of <span class="math inline">\(u\)</span> to <span class="math inline">\(v\)</span> is the vector in the subspace <span class="math display">\[
S(v) \doteq \{ c \cdot v : c \in \mathbb{R} \}
\]</span> that is closest to <span class="math inline">\(u\)</span>.</p>
<p><strong>Dot Product</strong> in <span class="math inline">\(\mathbb{R}^2\)</span>. Given <span class="math inline">\(u, v \in \mathbb{R}^2\)</span>, their dot product is defined as <span class="math display">\[
\left&lt; u, v \right&gt; = u_1 v_1 + u_2 v_2.
\]</span> The projection of <span class="math inline">\(u\)</span> to <span class="math inline">\(v\)</span> (closest vector to <span class="math inline">\(u\)</span> in <span class="math inline">\(S(v)\)</span>) is given by <span class="math display">\[
\frac{1}{ ||v||^2 } \left&lt; u, v \right&gt; \cdot v = \frac{ \left&lt; u, v \right&gt; }{ ||v|| }  \cdot \frac{ v }{ ||v|| }.
\]</span> The first term of the final product <span class="math inline">\(\frac{ \left&lt; u, v \right&gt; }{ ||v|| } = \frac{ ||u|| \cdot ||v|| \cdot \cos \angle (u, v) }{ ||v|| } = ||u|| \cdot \cos \angle (u, v)\)</span> gives the length of <span class="math inline">\(u\)</span>'s projection to <span class="math inline">\(v\)</span>, and the second term <span class="math inline">\(\frac{ v }{ ||v|| }\)</span> is a unit vector that shares the same direction as <span class="math inline">\(v\)</span>.</p>
<p><strong>Orthogonality</strong> in <span class="math inline">\(\mathbb{R}^2\)</span>. Given <span class="math inline">\(u, v \in \mathbb{R}^2\)</span>, they are orthogonal if the projection of <span class="math inline">\(u\)</span> to <span class="math inline">\(v\)</span> is <span class="math inline">\(\vec 0\)</span>. In this case, <span class="math display">\[
\left&lt; u, v \right&gt; = 0.
\]</span></p>
</blockquote>
<p>We can extend these ideas to <span class="math inline">\([-\pi, \pi] \rightarrow \mathbb{C}\)</span>.</p>
<h4 id="projection"><strong>Projection</strong></h4>
<p>Given <span class="math inline">\(f, g:[-\pi, \pi] \rightarrow \mathcal{C}\)</span>, the projection of <span class="math inline">\(f\)</span> to <span class="math inline">\(g\)</span> is the function in the linear span of <span class="math inline">\(g\)</span> <span class="math display">\[
    S(g) \doteq \{ c \cdot g : c \in \mathbb{C} \}
\]</span> that minimize <span class="math inline">\(||f - c \cdot g||, \forall c \in \mathbb{C}\)</span>.</p>
<h4 id="hermitian-product-1"><strong>Hermitian Product</strong></h4>
<p>Hermitian product is related to projection and arises naturally when we try to solve <span class="math display">\[
    \min_{c \in \mathbb{C} }  ||f - c \cdot g||,
\]</span></p>
<p>or equivalently, <span class="math display">\[
    \min_{c \in \mathbb{C} }  ||f - c \cdot g||^2.
\]</span></p>
<p>Expanding <span class="math inline">\(||f - c \cdot g||^2\)</span> and let <span class="math inline">\(c = x + iy\)</span>, <span class="math inline">\(\left&lt; g, f \right&gt;_H = a + i b\)</span>, we get <span class="math display">\[
\begin{aligned}
    ||f - c \cdot g||^2  
        &amp;= ||f||^2 + ||c||^2 \cdot ||g||^2 -  2 \cdot \mathbb{Re}( \left&lt; c \cdot g, f \right&gt;_H )  \\
        &amp;= ||f||^2 + ||c||^2 \cdot ||g||^2 - 2 \cdot \mathbb{Re} ( \bar c \cdot \left&lt; g, f \right&gt;_H ) \\
        &amp;= ||f||^2 + (x^2 + y^2) \cdot ||g||^2 - 2 \cdot \mathbb{Re} ( ( x- i y)  \cdot (a + i b) ) \\
        &amp;= ||f||^2 + (x^2 + y^2) \cdot ||g||^2 - 2 \cdot (a x + by) \\
\end{aligned}
\]</span></p>
<blockquote>
<p><em>Remark:</em> <em>The derivation above requires the integration operation to be linear.</em></p>
</blockquote>
<p>Taking the derivate of RHS with respect to <span class="math inline">\(x\)</span>, setting it to zero and assuming that <span class="math inline">\(||g|| \neq 0\)</span>, we see <span class="math display">\[
    2x\cdot ||g||^2 - 2 a = 0 \Rightarrow x = \frac{ a }{ ||g||^2 }.
\]</span></p>
<p>Similarly, <span class="math display">\[
    2y\cdot ||g||^2 - 2 b = 0 \Rightarrow y = \frac{ b }{ ||g||^2 }.
\]</span></p>
<p>Combined, <span class="math inline">\(c\)</span> is given by <span class="math display">\[
    c = x + iy = \frac{ \left&lt; g, f \right&gt;_H  }{ ||g||^2 } = \left&lt; \frac{g }{ ||g|| }, f \right&gt;_H \cdot \frac{ 1 }{ ||g|| }.
\]</span></p>
<p>This implies that <span class="math display">\[
    c \cdot g = \frac{ \left&lt; g, f \right&gt;_H  }{ ||g||^2 } \cdot g = \left&lt; \frac{g }{ ||g|| }, f \right&gt;_H \cdot \frac{g }{ ||g|| }.
\]</span></p>
<p>Now it is clear that the Hermitian product computes the coefficient for the projection of <span class="math inline">\(f\)</span> to <span class="math inline">\(g\)</span>, scaled by a factor of <span class="math inline">\(1/ ||g||^2\)</span>. When <span class="math inline">\(|| g ||\)</span> has unit length, <span class="math display">\[  
    c \cdot g = \left&lt; g, f \right&gt;_H \cdot g.
\]</span></p>
<p>The Hermitian product <span class="math inline">\(\in \mathbb{C}\)</span> is the just the coefficient for the projection.</p>
<h4 id="orthogonality"><strong>Orthogonality</strong></h4>
<p>Given <span class="math inline">\(f, g:[-\pi, \pi] \rightarrow \mathcal{C}\)</span>, <span class="math inline">\(f\)</span> is orthogonal to <span class="math inline">\(g\)</span> if the projection of <span class="math inline">\(f\)</span> to <span class="math inline">\(g\)</span> is the zero function, i.e., the closest function (measured by <span class="math inline">\(|| \cdot ||\)</span>) to <span class="math inline">\(f\)</span> in the linear span <span class="math inline">\(S(g)\)</span> is the constant function zero. It holds that, either <span class="math inline">\(||g||^2 = 0\)</span> or <span class="math display">\[
    \arg\min_{ c \in \mathbb{C} } \left| \left|f - c \cdot g \right| \right|^2 = \frac{ \left&lt; g, f \right&gt;_H  }{ ||g||^2 } = 0.
\]</span></p>
<p>In both cases, <span class="math display">\[
    \overline{ \left&lt; g, f \right&gt;_H } = \left&lt; f, g \right&gt; = 0.
\]</span></p>
<h2 id="properties-of-gamma"><strong>Properties of <span class="math inline">\(\Gamma\)</span></strong></h2>
<p>We are now ready to discuss the properties of <span class="math inline">\(\Gamma = \{ 1, \exp(it), \exp(-it), \exp(i2t), \exp(-i2t), ... \}\)</span>. 1. For <span class="math inline">\(k \in \mathbb{Z}\)</span>, <span class="math display">\[
   || \exp(ikt) || = \sqrt{ \int_{ [-\pi, \pi] }  \overline{\exp(ikt) } \exp(ikt) \  } = \sqrt{2 \pi }.
   \]</span></p>
<ol start="2" type="1">
<li>For <span class="math inline">\(k, l \in \mathbb{Z}\)</span>, <span class="math inline">\(k \neq l\)</span>, <span class="math inline">\(\exp(ikt)\)</span> and <span class="math inline">\(\exp(ilt)\)</span> are orthogonal. <span class="math display">\[
\begin{aligned}
    \left&lt; \exp(ikt), \exp(ilt) \right&gt;_H 
     &amp;= \int_{ [ -\pi, \pi] } \exp(-ikt) \cdot \exp(ilt)  \\
     &amp;= \int_{ [ -\pi, \pi] } \exp(i (l - k) t) \\
     &amp;= \frac{1}{ i(l - k) } \exp(i (l - k) t) \mid_{- \pi}^\pi \\
     &amp;= 0.
\end{aligned}
\]</span></li>
</ol>
<p>If we normalize the function in <span class="math inline">\(\Gamma\)</span> by <span class="math inline">\(1 / \sqrt{2 \pi}\)</span>, then each function has norm 1. We call this family an orthonormal family, and rewrite it as <span class="math display">\[
\mathfrak{F} = \{ e_0,  e_1, e_2, e_3, ..., \},
\]</span></p>
<p>where <span class="math inline">\(e_0 = 1\)</span>, and for <span class="math inline">\(k \in \mathbb{N}\)</span>,</p>
<ul>
<li><p><span class="math inline">\(e_{2k + 1} = \exp(ikt) / \sqrt{2 \pi}\)</span>;</p></li>
<li><p><span class="math inline">\(e_{2k + 2} = \exp(- ikt) / \sqrt{2 \pi}\)</span>.</p></li>
</ul>
<h2 id="approximating-f-with-mathfrakf"><strong>Approximating <span class="math inline">\(f\)</span> with <span class="math inline">\(\mathfrak{F}\)</span></strong></h2>
<p>As discuss before, we have construct an orthogonal family of <span class="math inline">\(\mathfrak{F}\)</span>, such that</p>
<ol type="1">
<li><span class="math inline">\(||e_i|| = 1\)</span> for <span class="math inline">\(e_i \in \mathfrak{F}\)</span>.</li>
<li><span class="math inline">\(\left&lt; e_i, e_j \right&gt;_H = 0\)</span> for <span class="math inline">\(e_i, e_j \in \mathfrak{F}, e_i \neq e_j\)</span>.</li>
</ol>
<!-- We continue to study the following two questions. 

2. Under what condition, can $f$ be rewrite as a linear combination of functions in $\mathfrak{F}$?
   
3. What is the approximation error, between $f$ and the linear combination?

For the second question, we provide a sufficient condition as an answer:

> $f^2$ is integrable. 

Hence,  -->
<p><strong>Definition.</strong> Define <span class="math inline">\(S(\mathfrak{F}_k)\)</span> the span of the first <span class="math inline">\(k + 1\)</span> elements in <span class="math inline">\(\mathfrak{F}\)</span>: <span class="math display">\[
    S(\mathfrak{F}_k ) \doteq \left\{ \sum_{i = 0}^k c_i \cdot e_i : \forall \ 0 \le i \le k, c_i \in \mathbb{C} \right\}. 
\]</span></p>
<blockquote>
<p><strong>Theorem.</strong> The closest function to <span class="math inline">\(f\)</span> in <span class="math inline">\(S(\mathfrak{F}_k )\)</span>, denoted as <span class="math inline">\(g_k\)</span>, is given by <span class="math display">\[
    g_k \doteq \sum_{i = 0 }^k a_i \cdot e_i.
\]</span> where <span class="math inline">\(a_i \doteq \left&lt; e_i, f \right&gt;_H, 0 \le i \le k\)</span>.</p>
</blockquote>
<blockquote>
<p><em>Remark: implicitly, we assume that <span class="math inline">\(f^2\)</span>, <span class="math inline">\(\bar e_i f\)</span> is integrable.</em></p>
</blockquote>
<p><em>Proof:</em> For <span class="math inline">\(0 \le i \le k\)</span>, it holds that <span class="math display">\[
\left&lt; e_i, g_k \right&gt;_H = \sum_{j = 0 }^k \left&lt; e_i, a_j \cdot e_j \right&gt;_H =  a_i = \left&lt; e_i, f \right&gt;_H.
\]</span></p>
<p>Hence, <span class="math display">\[
\left&lt; e_i, g_k - f\right&gt;_H = \overline{ \left&lt; g_k - f, e_i \right&gt;_H  } = 0. 
\]</span></p>
<p>Let <span class="math display">\[
    f_k = \sum_{i = 0}^k c_i \cdot e_i, 
\]</span></p>
<p>be a function in <span class="math inline">\(S(\mathfrak{F}_k )\)</span>. Then, <span class="math display">\[
\begin{aligned}
    || f - f_k||^2 
        &amp;= ||f - g_k + g_k - f_k ||^2 \\
        &amp;= ||f - g_k||^2 + ||g_k - f_k||^2 + \left&lt; f - g_k, g_k - f_k\right&gt;_H + \left&lt; g_k - f_k, f - g_k \right&gt;_H. 
\end{aligned}
\]</span></p>
<p>It holds that <span class="math display">\[
\left&lt; f - g_k, g_k - f_k\right&gt;_H = \sum_{i = 0}^k (a_i - c_i) \cdot \left&lt; f - g_k,  e_i \right&gt;_H = 0.
\]</span></p>
<p>Similarly, <span class="math inline">\(\left&lt; g_k - f_k, f - g_k \right&gt;_H = 0\)</span>. So, <span class="math display">\[
\begin{aligned}
    || f - f_k||^2 
        &amp;= ||f - g_k||^2 + ||g_k - f_k||^2,  
\end{aligned}
\]</span></p>
<p>which is minimized when <span class="math inline">\(f_k = g_k\)</span>.</p>
<p><span class="math inline">\(\square\)</span></p>
<!-- $$
\begin{aligned}
    ||f - f_k||^2 
        &= \left< f - f_k, f - f_k \right>_H \\
        &= \left<  f, f\right>_H + \left<  f_k, f_k \right>_H - \left<  f, f_k \right>_H - \left<  f_k , f\right>_H \\
        &= ||f||^2 + \sum_{i = 0}^k \left( \left< c_i \cdot e_i, c_i \cdot e_i \right>_H - \left<  f, c_i \cdot e_i \right>_H - \left< c_i \cdot e_i , f \right>_H \right) \\
        &= ||f||^2 + \sum_{i = 0}^k \left( \bar c_i \cdot c_i - c_i \cdot \left<  f, e_i \right>_H - \bar c_i \cdot \left< e_i , f \right>_H + \bar a_i \cdot a_i \right) - \sum_{i = 0}^k ||a_i||^2 \\
        &= ||f||^2 + \sum_{i = 0}^k \left( \bar c_i \cdot c_i - c_i \cdot \bar a_i - \bar c_i \cdot a_i + \bar a_i \cdot a_i \right) - \sum_{i = 0}^k ||a_i||^2 \\
        &= ||f||^2 + \sum_{i = 0}^k ||c_i - a_i||^2 - \sum_{i = 0}^k ||a_i||^2. \\
\end{aligned}
$$ -->
<!-- Thus, when $c_i = a_i$, the distance between $f_k$ and $f$ is minimized.  -->
<blockquote>
<p><strong>Corollary. (Bessel Ineuqality)</strong>. <span class="math display">\[
\sum_{i = 0}^\infty ||a_i||^2 \le ||f||^2.
\]</span></p>
</blockquote>
<p><em>Proof.</em> We see that <span class="math display">\[
\begin{aligned}
    || f - g_k ||^2 
        &amp;= \left&lt; f - g_k, f \right&gt;_H - \left&lt; f - g_k, g_k \right&gt;_H \\
        &amp;= \left&lt; f , f \right&gt;_H - \left&lt;  g_k, f \right&gt;_H \\
        &amp;= ||f||^2 - \sum_{i = 0}^k ||a_i||^2 \\
        &amp;\ge 0.
\end{aligned}
\]</span></p>
<p>Therefore, <span class="math display">\[
    \sum_{i = 0}^k ||a_i||^2 \le ||f||^2.
\]</span></p>
<p>Taking the limit of <span class="math inline">\(k\)</span> we get the desired result.</p>
<p><span class="math inline">\(\square\)</span></p>
<p>The function series <span class="math inline">\(g_1, g_2, g_3, ...\)</span> is called a Cauchy series, as <span class="math inline">\(\forall \epsilon &gt; 0\)</span>, <span class="math inline">\(\exists N \ge 0\)</span>, <span class="math inline">\(\forall N \le i &lt; j\)</span>, it holds that <span class="math display">\[
    ||g_j - g_i|| = || \sum_{t = i + 1}^j a_t \cdot e_t ||
    = \sqrt{ \sum_{t = i + 1}^j ||a_t||^2 } \le \epsilon.
\]</span></p>
<p>Suppose that we are using some kind of integration and let <span class="math inline">\(I^2([-\pi, \pi])\)</span> be the set of square integrable functions. Further, assume that <span class="math inline">\(g_1, g_2, g_3, ...\)</span> are also elements in <span class="math inline">\(I^2([-\pi, \pi])\)</span>. We are interested in</p>
<blockquote>
<p>Whether a Cauchy series in <span class="math inline">\(I^2([-\pi, \pi])\)</span> converges to a function in <span class="math inline">\(I^2([-\pi, \pi])\)</span>?</p>
</blockquote>
<p>Define <span class="math display">\[
    g = \lim_{k \rightarrow \infty} g_k = \sum_{i = 0}^\infty a_i \cdot e_i.
\]</span></p>
<p>It is important that <span class="math inline">\(g \in I^2([-\pi, \pi])\)</span>, as we need the length of <span class="math inline">\(|| g ||\)</span> to be well-defined. Further, <span class="math inline">\(f - g\)</span> should also be in <span class="math inline">\(I^2([-\pi, \pi])\)</span>.</p>
<p>However, if we are using Riemann integration, the answer is no. Let <span class="math inline">\(r_1, r_2, ....\)</span> be the rational number in the interval of <span class="math inline">\([0, 1]\)</span> and define <span class="math display">\[
    h_i(x) = \begin{cases}
        \begin{aligned}
            &amp;1,  &amp;\text{if } x \in \cup_{t = 1}^i \{ r_t \} \\
            &amp;0,  &amp;\text{otherwise}
        \end{aligned}
    \end{cases}
\]</span></p>
<p>Then <span class="math inline">\(h_i \in I^2([-\pi, \pi])\)</span> but <span class="math inline">\(\lim_{i \rightarrow \infty} h_i\)</span> is not Riemann integrable, hence not in <span class="math inline">\(I^2([-\pi, \pi])\)</span>.</p>
<p>If we are using Lebesgue integration, the answer is yes.</p>
<blockquote>
<p>Fact. If we are using Lebesgue integration, then <span class="math inline">\(I^2([-\pi, \pi])\)</span> is complete, i.e., if <span class="math inline">\(g_1, g_2, ..., \in I^2([-\pi, \pi])\)</span> is Cauchy, then <span class="math inline">\(\lim_k g_k \in I^2([-\pi, \pi])\)</span>.</p>
</blockquote>
<h2 id="approximating-error"><strong>Approximating Error</strong></h2>
<p>It is left to study the error of approximating <span class="math inline">\(f\)</span> with <span class="math inline">\(g\)</span>.</p>
<blockquote>
<p><strong>Lemma. Cauchy-Schwartz Inequality.</strong> Let <span class="math inline">\(h_1, h_2 \in I^2([-\pi, \pi])\)</span>, then <span class="math display">\[
| \left&lt; h_1, h_2 \right&gt;_H | \le ||h_1|| \cdot ||h_2 ||
\]</span></p>
</blockquote>
<p><em>Proof.</em> If <span class="math inline">\(||h_2|| = 0\)</span>, then <span class="math inline">\(h_2 = 0\)</span> almost everywhere and the case is trivial. Otherwise, <span class="math inline">\(\forall c \in \mathbb{C}\)</span>, we have <span class="math display">\[
\begin{aligned}
    || h_1 - c \cdot h_2 ||^2 
        &amp;= || h_1||^2 + ||c||^2 ||h_2||^2 -  \left&lt; h_1, c \cdot h_2 \right&gt;_H -   \left&lt; c \cdot h_2, h_1 \right&gt;_H \\
        &amp;= || h_1||^2 + ||c||^2 ||h_2||^2 - c \cdot \left&lt; h_1, h_2 \right&gt;_H - \bar c \cdot \left&lt; h_2, h_1 \right&gt;_H \\
\end{aligned}
\]</span></p>
<p>Let <span class="math inline">\(c = \frac{1}{ ||h_2||^2 } \cdot \left&lt; h_2, h_1 \right&gt;_H\)</span>, then <span class="math display">\[
\begin{aligned}
    || h_1 - c \cdot h_2 ||^2 
        &amp;= || h_1||^2 - \frac{1}{ ||h_2||^2 } \cdot \left| \left&lt; h_2, h_1 \right&gt;_H \right|^2 
        &amp;\ge 0.
\end{aligned}
\]</span></p>
<!-- As  -->
<!-- $$
    || \left< h_1, h_2 \right>_H || \le ||h_1|| \cdot ||h_2 || \longleftrightarrow
    \left|\left| \left< \frac{h_1}{ ||h_1|| }, \frac{h_2}{ ||h_2 || } \right>_H \right|\right| \le  1
$$

Without lose of generality, we assume that $||h_1|| = 1$ and $||h_2|| = 1$. 

$$
\begin{aligned}
    2 \cdot \mathbb{Re} \left( \left< h_1, h_2 \right>_H \right) 
        &= \left< h_1, h_2 \right>_H  + \overline{ \left< h_2, h_1 \right>_H } \\
        &= \int_{ [ -\pi, \pi] } \bar h_1 h_2  + \bar h_2 h_1 \\
        &\le \int_{ [ -\pi, \pi] } 2 \left( ||h_1||^2 + ||h_2||^2 \right)
\end{aligned}
$$ -->
<!-- We will prove that 
$$
    || \left< h_1, h_2 \right>_H ||^2 \le 1.
$$

$$
    \begin{aligned}
        \left|\left| \int_{ [ -\pi, \pi] } \bar h_1 h_2 \right|\right|^2 
        &= \left|\left| \int_{ [ -\pi, \pi] } \mathbb{Re} (\bar h_1 h_2) + i \mathbb{Im} (\bar h_1 h_2) \right|\right|^2 \\
        &= \left( \int_{ [ -\pi, \pi] } \mathbb{Re} (\bar h_1 h_2) \right)^2 +  \left( \int_{ [ -\pi, \pi] } \mathbb{Im} (\bar h_1 h_2) \right)^2 \\
        &\le \left( \int_{ [ -\pi, \pi] } \mathbb{Re} (\bar h_1 h_2) \right)^2 +  \left( \int_{ [ -\pi, \pi] } \mathbb{Im} (\bar h_1 h_2) \right)^2
    \end{aligned}
$$ -->
<p><span class="math inline">\(\square\)</span></p>
<blockquote>
<p><strong>Lemma.</strong> <span class="math inline">\(\forall i \in \mathbb{N}\)</span>, <span class="math inline">\(\left&lt; e_i, g \right&gt;_H =a_i\)</span>.</p>
</blockquote>
<p><em>Proof.</em> By Cauchy-Schwartz inequality,</p>
<p><span class="math display">\[
\begin{aligned}
    \left|\left| \int_{ [ -\pi, \pi] } \bar e_i (g_k - g) \right|\right|^2
        &amp;\le \left( \int_{ [ -\pi, \pi] } ||e_i||^2 \right) \cdot \left( \int_{ [ -\pi, \pi] } ||g_k - g||^2 \right) \\
        &amp;= \int_{ [ -\pi, \pi] } ||g_k - g||^2 \\
        &amp;= \int_{ [ -\pi, \pi] } \lim_l ||g_k - g_l ||^2 
\end{aligned}
\]</span></p>
<p>By <strong>Fatou's lemma</strong>, <span class="math display">\[
    \int_{ [ -\pi, \pi] } \lim_l ||g_k - g_l ||^2 \le \liminf_l \int_{ [ -\pi, \pi] } ||g_k - g_l ||^2 
\]</span></p>
<p>Finally, <span class="math display">\[
    \lim_k  \left|\left|  \left&lt;  e_i, g_k - g \right&gt;_H \right|\right|^2 = \lim_k \left|\left|  \int_{ [ -\pi, \pi] } \bar e_i (g_k - g) \right|\right|^2 \le \lim_k \liminf_l \int_{ [ -\pi, \pi] } ||g_k - g_l ||^2  = 0.
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<blockquote>
<p>Remark: the above proof involves the operation of exchanging the order of two limiting operations, namely <span class="math inline">\(\lim\)</span> and <span class="math inline">\(\int\)</span>. Exchanging order like this is dangerous for Riemann integration, but we can do it safely under Lebesgue integration, under proper condition. Here we use <strong>Fatou's lemma</strong>.</p>
</blockquote>
<p>By the above lemma, the function <span class="math inline">\(g\)</span> has an important property, such that <span class="math inline">\(\forall i \in \mathbb{N}\)</span>, <span class="math display">\[
    \left&lt; e_i, f - g \right&gt;_H = 0.
\]</span></p>
<blockquote>
<p><strong>Lemma.</strong> Let <span class="math inline">\(h \in I^2([-\pi, \pi])\)</span>. If <span class="math inline">\(\forall i \in N\)</span>, <span class="math display">\[
\left&lt; e_i, h \right&gt;_H = 0,
\]</span> then <span class="math inline">\(h = 0\)</span> almost everywhere.</p>
</blockquote>
<p><em>Proof.</em> First, we assume that <span class="math inline">\(h\)</span> is a continuous function on <span class="math inline">\([-\pi, \pi]\)</span>. If <span class="math inline">\(h \not\equiv 0\)</span>, then <span class="math inline">\(|h(x)|\)</span> achieves maximum value at some point <span class="math inline">\(x^* \in [-\pi, \pi]\)</span>. Without lose of generality, we assume that <span class="math display">\[
    h(x^*) = M &gt; 0. 
\]</span></p>
<p>By continuity of <span class="math inline">\(h\)</span>, <span class="math inline">\(\exists \delta \in (0, \pi)\)</span>, such that <span class="math inline">\(h(x) &gt; M / 2\)</span> in the interval <span class="math display">\[
    I \doteq (x^* - \delta, x^* + \delta) \cap [-\pi, \pi].
\]</span></p>
<p>We will capture the maximum value of <span class="math inline">\(f\)</span>, by taking Hermitian product of <span class="math inline">\(f\)</span> with a signal function that</p>
<ol type="1">
<li>is a linear combination of functions in <span class="math inline">\(\mathfrak{F}\)</span>;</li>
<li>is <span class="math inline">\(\ge 1\)</span> in <span class="math inline">\(I\)</span>;</li>
<li>is <span class="math inline">\(&lt; 1\)</span> in <span class="math inline">\([-\pi, \pi] \setminus I\)</span>.</li>
</ol>
<p>The signal function is given by <span class="math display">\[
    s(x) = 1 + \cos \left( \frac{1}{2} \cdot (x - x^*) \right) - \cos \frac{\delta}{2}.
\]</span></p>
<p>Observe that <span class="math inline">\(s\)</span></p>
<ol type="1">
<li>achieves maximum value <span class="math inline">\(s(x^*) = 2 - \cos \frac{\delta}{2}\)</span>;</li>
<li>is <span class="math inline">\(\ge 1\)</span> for <span class="math inline">\(x \in I\)</span>;</li>
<li>has period <span class="math inline">\(4 \pi\)</span>.</li>
</ol>
<p>Hence, it increases on the interval <span class="math inline">\([x^* - 2\pi, x^*]\)</span> and decreases on <span class="math inline">\([x^*, x^* + 2\pi]\)</span>. So</p>
<ol start="4" type="1">
<li><span class="math inline">\(s(x) &lt; 1\)</span> for <span class="math inline">\(x \in [-\pi, \pi] \setminus I\)</span>.</li>
</ol>
<p>For <span class="math inline">\(n \ge 1\)</span>, <span class="math inline">\(s^n(x)\)</span> is also a linear combination of functions in <span class="math inline">\(\mathfrak{F}\)</span>. It always holds that <span class="math inline">\(\left&lt; s^n(x), f \right&gt;_H \in \mathbb{R}\)</span> and by assumption on <span class="math inline">\(f\)</span>, it holds that <span class="math display">\[
    \left&lt; s^n(x), f \right&gt;_H = 0.
\]</span></p>
<p>But this is impossible. By monotonicity of integration, <span class="math display">\[
\int_{ [-\pi, \pi] \setminus I } f(x) s^n(x) \ dx \ge \int_{ [-\pi, \pi] \setminus I } (-M) \cdot 1 \ dx = - 2 \cdot \pi \cdot M.
\]</span></p>
<p>Define <span class="math display">\[
    I&#39; \doteq (x^* - \delta / 2, x^* + \delta / 2) \cap [-\pi, \pi].
\]</span></p>
<p>Then <span class="math inline">\(|I&#39;| \ge \delta / 2\)</span> and <span class="math inline">\(m \doteq \min_{x \in I&#39;} s(x) &gt; 1\)</span>. <span class="math display">\[
    \int_{ I } f(x) s^n(x) \ dx \ge \int_{ I&#39; } \frac{M}{2} \cdot m^n \ dx \ge \frac{M \cdot m^n \cdot \delta }{ 4 }.
\]</span></p>
<p>This implies as <span class="math inline">\(n \rightarrow \infty\)</span>, <span class="math display">\[
    \left&lt; s^n(x), f \right&gt;_H \ge - 2 \cdot \pi \cdot M + \frac{M \cdot m^n \cdot \delta }{ 4 } \rightarrow \infty, 
\]</span></p>
<p>which is a contradiction.</p>
<p>Next, we consider the general case of <span class="math inline">\(h \in I^2([-\pi, \pi])\)</span>. Define <span class="math display">\[
    w(x) = \int_{-\pi}^x h(t) \ dt.
\]</span></p>
<p>The function is absolutely continuous on <span class="math inline">\([-\pi, \pi]\)</span>. Moreover, <span class="math inline">\(w(0) = 0\)</span> and by assumption, <span class="math inline">\(w(\pi) = \left&lt; e_0, h \right&gt;_H = 0\)</span>. For <span class="math inline">\(k \in \mathbb{N}\)</span>, integrating by part gives <span class="math display">\[
    \begin{aligned}
        \sqrt{2 \cdot \pi} \cdot \left&lt; e_{2k + 1}, w \right&gt;_H 
            &amp;= \int_{ [-\pi, \pi] } \exp(-ikx) w(x) \ dx \\
            &amp;= \frac{1}{ik} \exp(-ikx) w(x) \mid_{-\pi}^\pi - \frac{1}{ik}  \int_{ [-\pi, \pi] } \exp(-ikx) w&#39;(x) \ dx \\
            &amp;=  - \frac{1}{ik}  \int_{ [-\pi, \pi] } \exp(-ikx) h(x) \ dx \\
            &amp;=  - \frac{1}{ik}  \left&lt; e_{2k + 1}, h\right&gt;_H \\
            &amp;= 0.
    \end{aligned}
\]</span></p>
<p>Similarly, we can prove that <span class="math inline">\(\left&lt; e_{2k + 2}, w \right&gt;_H = 0\)</span>.</p>
<p>Hence, <span class="math inline">\(\forall k \ge 1\)</span>, <span class="math inline">\(\left&lt; e_k, w \right&gt;_H = 0\)</span>. But it is not guaranteed that <span class="math inline">\(\left&lt; e_0, w \right&gt;_H = 0\)</span>. To fix this, we construct another function <span class="math display">\[
    W(x) \doteq w(x) - B.
\]</span></p>
<p>where <span class="math inline">\(B = \left&lt; e_0, w \right&gt;_H\)</span> is a constant. It holds that</p>
<ol type="1">
<li><span class="math inline">\(\forall k \ge 1\)</span>, <span class="math inline">\(\left&lt; e_k, W \right&gt;_H = \left&lt; e_k, w \right&gt;_H - \left&lt; e_k, B \right&gt;_H = - B \cdot \left&lt; e_k, e_0 \right&gt;_H = 0\)</span>.<br />
</li>
<li><span class="math inline">\(\left&lt; e_0, W \right&gt;_H = \left&lt; e_0, w \right&gt;_H + \left&lt; e_0, B \right&gt;_H = B - B \cdot \left&lt; e_0, e_0 \right&gt;_H = 0\)</span>.</li>
</ol>
<p>By previous result, <span class="math inline">\(W(x) \equiv 0\)</span> and <span class="math inline">\(w(x) \equiv B\)</span>. This implies <span class="math display">\[
w&#39;(x) = h(x) = 0, \quad a.e.
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/12/24/Gamma-Function/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/12/24/Gamma-Function/" class="post-title-link" itemprop="url">Gamma Function</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-12-24 21:32:57 / Modified: 21:47:33" itemprop="dateCreated datePublished" datetime="2020-12-24T21:32:57+11:00">2020-12-24</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Consider the integral <span class="math display">\[
    \int_0^\infty e^{- st} \ dt = \frac{1}{s} e^{- st} \mid_0^\infty  = \frac{1}{s}.
\]</span></p>
<p>Taking derivative with respect to <span class="math inline">\(s\)</span> of both side, we get <span class="math display">\[
    \int_0^\infty t e^{- t s} \ dt = \frac{1}{s^2}.
\]</span></p>
<p>Repeating this process one more step, <span class="math display">\[
    \int_0^\infty t^2 e^{- st} \ dt = \frac{2}{s^3}.
\]</span></p>
<p>By induction on <span class="math inline">\(k \in \mathbb{N}^+\)</span>, we obtain <span class="math display">\[
    \int_0^\infty t^k e^{- st} \ dt = \frac{k!}{s^{k + 1} }.
\]</span></p>
<p>Setting <span class="math inline">\(s = 1\)</span>, we have <span class="math display">\[
    k! = \int_0^\infty t^k e^{ -t } \ dt.
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/12/19/Hermitian-Inner-Products/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/12/19/Hermitian-Inner-Products/" class="post-title-link" itemprop="url">Hermitian Inner Products</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-12-19 23:17:13" itemprop="dateCreated datePublished" datetime="2020-12-19T23:17:13+11:00">2020-12-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-12-23 00:41:33" itemprop="dateModified" datetime="2020-12-23T00:41:33+11:00">2020-12-23</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>The inner product of two complex vectors <span class="math inline">\(\vec u, \vec v \in \mathbb{C}^n\)</span> is defined as <span class="math display">\[
    \vec u^H \vec v = [ \bar u_1, \bar u_2, ..., \bar u_n ] \begin{bmatrix} v_1 \\ v_2 \\ . \\ . \\ . \\ v_n \end{bmatrix} = \bar u_1 v_1 + \bar u_2 v_2 ... + \bar u_n v_n. 
\]</span></p>
<p>It is tempting to think the inner product should be <span class="math inline">\(\vec u^T \vec v\)</span>, as the one for real vectors. Why do we take the conjugate of <span class="math inline">\(\vec u\)</span>? To answer this, we need to study the geometric meaning of inner product. We begin from the inner product in <span class="math inline">\(\mathbb{R}^n\)</span>.</p>
<h1 id="inner-product-in-mathbbrn">Inner Product in <span class="math inline">\(\mathbb{R}^n\)</span></h1>
<p>The inner product is closely related to the concept of "length". Generally, we express the length of a vector in term of inner product. Here we take a reverse approach. We consider the length of a vector as a more fundamental concept. Once the length of a vector is defined, it leads naturally the definition of inner product.</p>
<p>For a vector <span class="math inline">\(\vec u \in \mathbb{R}^n\)</span>, we define its length as <span class="math display">\[
||\vec u || = \sqrt{ \sum_{i \in [n] } u_i^2 }. 
\]</span></p>
<p>Given two vector <span class="math inline">\(\vec u, \vec v \in \mathbb{R}^n\)</span>, the definition of the inner product of <span class="math inline">\(\vec u^T \vec v\)</span> stems from the following problem:</p>
<blockquote>
<p>Find a vector in the subspace generated by <span class="math inline">\(\vec u\)</span>, such that it distance to <span class="math inline">\(\vec v\)</span> is minimized.</p>
</blockquote>
<p>The subspace generated by <span class="math inline">\(\vec u\)</span> is the line that passes through <span class="math inline">\(\vec u\)</span> and can be represented as <span class="math display">\[
\{ t \vec u : t \in \mathbb{R} \}. 
\]</span></p>
<p>The problem gives rise to the optimization problem: <span class="math display">\[
\min_{ t \in \mathbb{R} } ||\vec v - t \vec u||^2. 
\]</span></p>
<p>Define <span class="math display">\[
y \doteq || \vec v - t \vec u||^2 = || \vec u ||^2 t^2 - 2 ( \vec v^T \vec u) t + || \vec  v||^2. 
\]</span></p>
<p>By differentiating and setting the derivative equal to zero, we get <span class="math display">\[
y&#39; = 2 || \vec u ||^2 t - 2 (\vec  v^T  \vec  u) = 0 \implies t = \frac{ \vec  v^T \vec u }{ || \vec u ||^2 }. 
\]</span></p>
<p>The inner product appears exactly in the numerator. Its meaning is clear now: it is related to the magnitude of the closest vector in the subspace spanned by <span class="math inline">\(\vec u\)</span>. In case that <span class="math inline">\(\vec u\)</span> is a unit vector, <span class="math inline">\(t = \vec v^T \vec u\)</span> is exactly the length of this closest vector.</p>
<p>This also sheds light on the meaning of orthogonality:</p>
<blockquote>
<p>If <span class="math inline">\(\vec u\)</span> is orthogonal to <span class="math inline">\(\vec v\)</span>, then the best approximation (measured by <span class="math inline">\(|| \cdot ||\)</span>) of <span class="math inline">\(\vec v\)</span> in the subspace spanned by <span class="math inline">\(\vec u\)</span> is the zero vector.</p>
</blockquote>
<h1 id="inner-product-in-mathbbcn">Inner Product in <span class="math inline">\(\mathbb{C}^n\)</span></h1>
<p>To get the desired expression of inner product <span class="math inline">\(\mathbb{C}^n\)</span>, we first extend the definition of length in <span class="math inline">\(\mathbb{R}^n\)</span> to <span class="math inline">\(\mathbb{C}^n\)</span>. For <span class="math inline">\(\vec u \in \mathbb{C}^n\)</span>, define <span class="math display">\[
|| \vec u || = \sqrt{ \sum_{i \in [n]}  |u_i|^2 }.
\]</span></p>
<p>Given <span class="math inline">\(\vec u, \vec v \in \mathbb{C}^n\)</span>, we consider the similar problem:</p>
<blockquote>
<p>Find a vector in the subspace generated by <span class="math inline">\(\vec u\)</span>, such that it distance to <span class="math inline">\(\vec v\)</span> is minimized.</p>
</blockquote>
<p>However, this time the subspace generated by <span class="math inline">\(\vec u\)</span> is given by <span class="math display">\[
\{ (t^r + i t^i ) \vec u: t^r, t^i \in \mathbb{R} \}. 
\]</span></p>
<p>Let <span class="math inline">\(\vec u^r \in \mathbb{R}^n\)</span> be the real part of <span class="math inline">\(\vec u\)</span> and <span class="math inline">\(\vec u^i \in \mathbb{R}^n\)</span> be its imaginary part. Then <span class="math inline">\(\vec u = \vec u^r + i \vec u^i\)</span>. Similarly, we can decompose <span class="math inline">\(\vec v\)</span> into <span class="math inline">\(\vec v = \vec v^r + i \vec v^i\)</span>.</p>
<p>We want to minimize <span class="math display">\[
\begin{aligned}
    y   &amp;\doteq ||(t^r + i t^i ) \vec u - \vec v||^2 \\
        &amp;=      ||(t^r + i t^i ) (\vec u^r + i \vec u^i) - \vec v^r - i \vec v^i ||^2 \\
        &amp;=      || t^r \vec u^r - t^i \vec u^i - \vec v^r + i ( t^i \vec u^r + t^r \vec u^i - \vec v^i ) ||^2 \\
        &amp;=      || t^r \vec u^r - t^i \vec u^i - \vec v^r ||^2 + || t^i \vec u^r + t^r \vec u^i - \vec v^i ||^2 \\
\end{aligned}
\]</span></p>
<p>Taking the derivative with respect to <span class="math inline">\(t^r\)</span>, we get <span class="math display">\[
    \frac{\partial y}{ \partial t^r } = 2 ||\vec u^r||^2 t^r - 2 ( \vec u^r \cdot \vec u^i) t^i - 2 ( \vec u^r \cdot \vec v^r) + 2 ||\vec u^i||^2 t^r + 2 (\vec u^r \cdot \vec u^i ) t^i - 2 ( \vec u^i \cdot \vec v^i )
\]</span></p>
<p>where <span class="math inline">\(\vec u^r \cdot \vec u^i\)</span> denotes their dot product. Setting the derivative to zero, we have <span class="math display">\[
    t^r = \frac{ \vec u^r \cdot \vec v^r + \vec u^i \cdot \vec v^i }{ ||\vec u^r||^2 + ||\vec u^i||^2 } = \frac{ \vec u^r \cdot \vec v^r + \vec u^i \cdot \vec v^i }{ ||\vec u||^2  }.
\]</span></p>
<p>Also, <span class="math display">\[
    \frac{\partial y}{ \partial t^i } = 2 ||\vec u^i||^2 t^i - 2 ( \vec u^r \cdot \vec u^i) t^r + 2 ( \vec u^i \cdot \vec v^r) + 2 ||\vec u^r||^2 t^i + 2 (\vec u^r \cdot \vec u^i ) t^r - 2 ( \vec u^r \cdot \vec v^i ).
\]</span></p>
<p>Setting the derivative to zero, we obtain <span class="math display">\[
    t^i = \frac{ -\vec u^i \cdot \vec v^r + \vec u^r \cdot \vec v^i }{ ||\vec u^r||^2 + ||\vec u^i||^2 } = \frac{ -\vec u^i \cdot \vec v^r + \vec u^r \cdot \vec v^i }{ ||\vec u||^2  }.
\]</span></p>
<p>On the other hand, the Hermitian inner product is <span class="math display">\[
    \overline{(\vec u^r + i \vec u^i)}  \cdot (\vec v^r + i \vec v^i ) = (\vec u^r \cdot \vec v^r + \vec u^i \cdot \vec v^i) + i ( -\vec u^i \cdot \vec v^r + \vec u^r \cdot \vec v^i ).
\]</span></p>
<p>Therefore, <span class="math display">\[
    t^r + i t^i = \frac{1}{||\vec u||^2} \vec u^H \vec v.
\]</span></p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/HermitainProduct.png?raw=true" /></p>
<p><span class="math inline">\(\square\)</span></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/12/18/Complex-Numbers/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/12/18/Complex-Numbers/" class="post-title-link" itemprop="url">Complex Numbers</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-12-18 11:06:31" itemprop="dateCreated datePublished" datetime="2020-12-18T11:06:31+11:00">2020-12-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-12-21 00:43:06" itemprop="dateModified" datetime="2020-12-21T00:43:06+11:00">2020-12-21</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>I feel uncomfortable with complex numbers for a long time, partially because of the way they are introduced in the textbooks. They are considered necessary for solving equations such as <span class="math display">\[
x^2 + 1= 0. 
\]</span></p>
<p>Somehow magically, a symbol <span class="math inline">\(i\)</span> is introduced, and its square <span class="math inline">\(i^2\)</span> is manually defined as <span class="math inline">\(-1\)</span>. Following this, typically a set of operations defined on complex numbers as well as their properties are listed by the textbooks, leaving the question of why we can have such "magical symbol" unsolved.</p>
<p>In this blog, I am trying to introduce complex numbers in a more natural manner, by studying <em>rotations</em>, <em>dilations</em> and <em>additions</em> of points in <span class="math inline">\(\mathbb{R}^2\)</span>. I will show that these operations satisfy some properties, such that we can manipulate points in <span class="math inline">\(\mathbb{R}^2\)</span> in a similar way as real numbers (by addition and multiplication).</p>
<p>We first reflect on the real numbers <span class="math inline">\(\mathbb{R}\)</span>. They are concrete, since they can be represented by points on the real axis. We can perform addition (<span class="math inline">\(+\)</span>) and multiplication (<span class="math inline">\(\cdot\)</span>) on them, that satisfy the following properties (referred to as <strong>field axioms</strong>). Let <span class="math inline">\(a, b, c \in \mathbb{R}\)</span>,</p>
<ol type="1">
<li><em>Associativity of addition:</em> <span class="math inline">\(a + (b + c) = (a + b) + c\)</span>.</li>
<li><em>Commutativity of addition:</em> <span class="math inline">\(a + b = b + a\)</span>.</li>
<li><em>Additive identity:</em> there exists a 'zero' element <span class="math inline">\(0\)</span> such that <span class="math inline">\(a + 0 = a\)</span>.<br />
</li>
<li><em>Additive inverse:</em> there is an element, denoted as <span class="math inline">\(-a\)</span>, such that <span class="math inline">\(a + (-a) = 0\)</span>.<br />
</li>
<li><em>Associativity of multiplication:</em> <span class="math inline">\(a \cdot (b \cdot c) = (a \cdot b) \cdot c\)</span>.</li>
<li><em>Commutativity of addition:</em> <span class="math inline">\(a \cdot b = b \cdot a\)</span>.</li>
<li><em>Multiplicative identity:</em> there exists a 'one' element <span class="math inline">\(1\)</span> such that <span class="math inline">\(a \cdot 1 = a\)</span>.</li>
<li><em>Multiplicative inverse:</em> there exists a element <span class="math inline">\(a^{-1}\)</span> for <span class="math inline">\(a \neq 0\)</span> such that <span class="math inline">\(a \cdot a^{-1} = 1\)</span>.<br />
</li>
<li><em>Distributivity:</em> <span class="math inline">\(a \cdot (b + c) = a \cdot b + a \cdot c\)</span>.</li>
</ol>
<p>Any set with two operations that satisfy similar properties as above is called a field. In the remainder of the blog, we show how to construct a field from <span class="math inline">\(\mathbb{R}^2\)</span>.</p>
<p>We can view <span class="math inline">\(\mathbb{R}^2\)</span> as the set of vectors that originates from the origin. Hence, each element in <span class="math inline">\(\mathbb{R}^2\)</span> is considered as both a point and a vector. We will define addition and multiplication for <span class="math inline">\(\mathbb{R}^2\)</span>. For the moment, we will use <span class="math inline">\(\oplus\)</span> and <span class="math inline">\(\odot\)</span> to denote addition and multiplications in <span class="math inline">\(\mathbb{R}^2\)</span>, to distinguish the operations <span class="math inline">\(+\)</span> and <span class="math inline">\(\cdot\)</span> for <span class="math inline">\(\mathbb{R}\)</span>. Lastly, we show that the set system <span class="math inline">\((\mathbb{R}^2, \oplus, \odot)\)</span> constitutes a field.</p>
<p>In the remainder of the blog, when we refer to a vector, we refer to the one that originate from the origin.</p>
<h1 id="addition-oplus">Addition <span class="math inline">\(\oplus\)</span></h1>
<p>Addition in <span class="math inline">\(\mathbb{R}^2\)</span> is defined the same way as vector addition. When points are specified by Cartesian coordinates, it is easy to get a closed form expression of addition. Let <span class="math inline">\(a = (a_1, a_2), b = (b_1, b_2) \in \mathbb{R}^2\)</span>, then <span class="math display">\[
a \oplus b = (a_1 + b_1, a_2 + b_2). 
\]</span></p>
<!-- The figure below shows that addition is commutative.  -->
<div style="text-align:center">
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/ComplexNumber/addition.png?raw=true" width="400" height="340" /></p>
</div>
<h1 id="multiplication-odot">Multiplication <span class="math inline">\(\odot\)</span></h1>
<p>When multiplying two vectors, their lengths multiply and their angles add. It is an operation that involves both dilation and rotation.</p>
<p>We investigate multiplication in the polar coordinates. For <span class="math inline">\(a \in \mathbb{R}^2\)</span>, let <span class="math inline">\(|a| \in \mathbb{R}\)</span> be its length and <span class="math inline">\(\theta_a\)</span> be its angle with respect to the <span class="math inline">\(x\)</span>-axis. We can write <span class="math inline">\(a\)</span> as: <span class="math display">\[
a = |a| \angle \theta_a.
\]</span></p>
<p>For <span class="math inline">\(a, b \in \mathbb{R}^2\)</span>, <span class="math display">\[
a \odot b \doteq (|a| \cdot |b|) \angle (\theta_{v_1} + \theta_{v_2} )
\]</span></p>
<p>The result is a vector (from the origin) with length <span class="math inline">\(|a| \cdot |b|\)</span> and angle <span class="math inline">\(\theta_a + \theta_b\)</span>.</p>
<div style="text-align:center">
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/ComplexNumber/multiplication.png?raw=true" width="400" height="340" /></p>
</div>
<p><em>Remark: we have use different coordinate systems to get closed form formulas for addition and multiplication separately. This is immaterial. We need only to make sure both addition and multiplication are functions in <span class="math inline">\(\mathbb{R}^2 \times \mathbb{R}^2 \rightarrow \mathbb{R}^2\)</span>. Writing the closed form of a function in a coordinate system is just a specific way to describe it. For a specific function <span class="math inline">\(f\)</span> in <span class="math inline">\(\mathbb{R}^2 \times \mathbb{R}^2 \rightarrow \mathbb{R}^2\)</span>, it maps each pair of <span class="math inline">\(a, b \in \mathbb{R}^2 \times \mathbb{R}^2\)</span> to a unique point <span class="math inline">\(f(a, b) \in \mathbb{R}^2\)</span>, whether this function is described in Cartesian or polar coordinates. If we want, we can even describe it by language. For example, the sentence "<span class="math inline">\(f\)</span> takes every pair of <span class="math inline">\(\forall a, b \in \mathbb{R}^2\)</span> to the origin." defines a constant function.</em></p>
<h1 id="field-verification">Field Verification</h1>
<p>We need to verify that the set system <span class="math inline">\((\mathbb{R}^2, \oplus, \odot)\)</span> is a field.</p>
<h2 id="associativity-of-addition-a-oplus-b-oplus-c-a-oplus-b-oplus-c">1. <em>Associativity of addition:</em> <span class="math inline">\(a \oplus (b \oplus c) = (a \oplus b) \oplus c\)</span></h2>
<p>The figure below shows that addition is associative.</p>
<div style="text-align:center">
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/ComplexNumber/addition-associativity.png?raw=true" width="400" height="340" /></p>
</div>
<p>Associativity is also easy to verify in Cartesian coordinates. Let <span class="math inline">\(a = (a_1, a_2), b = (b_1, b_2), c = (c_1, c_2)\)</span>, we get <span class="math display">\[
a \oplus ( b \oplus c) = (a_1 + b_1 + c_1, a_2 + b_2 + c_2) = (a \oplus b) \oplus c.
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h2 id="commutativity-of-addition-a-oplus-b-b-oplus-a">2. <em>Commutativity of addition:</em> <span class="math inline">\(a \oplus b = b \oplus a\)</span></h2>
<p>This is verified when we define addition or we can check it easily in Cartesian coordinate system.</p>
<p><span class="math inline">\(\square\)</span></p>
<h2 id="additive-identity-exists-vec-0-s.t.-a-oplus-vec-0-a">3. <em>Additive identity:</em> <span class="math inline">\(\exists\)</span> <span class="math inline">\(\vec 0\)</span>, s.t. <span class="math inline">\(a \oplus \vec 0 = a\)</span></h2>
<p><span class="math inline">\((0, 0) \in \mathbb{R}^2\)</span> serves as the zero element.</p>
<p><span class="math inline">\(\square\)</span></p>
<h2 id="additive-inverse-exists--a-in-mathbbr2-s.t.-a-oplus--a-vec-0">4. <em>Additive inverse:</em> <span class="math inline">\(\exists (-a) \in \mathbb{R}^2\)</span>, s.t. <span class="math inline">\(a \oplus (-a) = \vec 0\)</span></h2>
<p>Let <span class="math inline">\((-a)\)</span> be the vector that is symmetric to <span class="math inline">\(a\)</span> with respect to the origin. Then <span class="math inline">\(a \oplus (-a) = 0\)</span>. Indeed, if <span class="math inline">\(a = (a_1, a_2)\)</span>, <span class="math display">\[
(-a) = (-a_1, -a_2).
\]</span></p>
<div style="text-align:center">
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/ComplexNumber/inverse.png?raw=true" width="400" height="340" /></p>
</div>
<p><span class="math inline">\(\square\)</span></p>
<h2 id="associativity-of-multiplication-a-odot-b-odot-c-a-odot-b-odot-c">5. <em>Associativity of multiplication:</em> <span class="math inline">\(a \odot (b \odot c) = (a \odot b) \odot c\)</span></h2>
<p>It is more convenient to check the properties involved multiplication via polar coordinates.</p>
<p><span class="math display">\[
a \odot b \odot c = ( |a| \cdot |b| \cdot |c| ) \angle (\theta_a + \theta_b + \theta_c ) = a\odot (b \odot c).
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h2 id="commutativity-of-addition-a-odot-b-b-odot-a">6. <em>Commutativity of addition:</em> <span class="math inline">\(a \odot b = b \odot a\)</span></h2>
<p>Similarly, <span class="math display">\[
a \odot b = (|a| \cdot |b|) \angle (\theta_a + \theta_b ) = (|b| \cdot |a|) \angle (\theta_a + \theta_b ) = b \odot a. 
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h2 id="multiplicative-identity-exists-vec-1-s.t.-a-odot-vec-1-a">7. <em>Multiplicative identity:</em> <span class="math inline">\(\exists \vec 1\)</span> s.t. <span class="math inline">\(a \odot \vec 1 = a\)</span></h2>
<p><span class="math inline">\((1, 0) = |1|\angle 0\)</span> is the 'one' vector.</p>
<p><span class="math inline">\(\square\)</span></p>
<h2 id="multiplicative-inverse-if-a-neq-vec-0-exists-a-1-s.t.-a-odot-a-1-vec-1">8. <em>Multiplicative inverse:</em> If <span class="math inline">\(a \neq \vec 0\)</span>, <span class="math inline">\(\exists a^{-1}\)</span>, s.t. <span class="math inline">\(a \odot a^{-1} = \vec 1\)</span></h2>
<p>The multiplicative inverse is given by <span class="math display">\[
a^{-1} = \frac{1}{|a|} \angle (-\theta_a).
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h2 id="distributivity-a-odot-b-oplus-c-a-odot-b-oplus-a-odot-c">9. <em>Distributivity:</em> <span class="math inline">\(a \odot (b \oplus c) = a \odot b \oplus a \odot c\)</span></h2>
<p>Distributivity involves both addition and multiplication. We prove it geometrically.</p>
<p>Let <span class="math inline">\(w = b \oplus c\)</span>.</p>
<p>First suppose <span class="math inline">\(|a| = 1\)</span>. In such case, <span class="math inline">\(a = |1| \angle \theta_a\)</span> and <span class="math display">\[
w \odot a = |w| \angle (\theta_w + \theta_a)
\]</span></p>
<p>Multiplying <span class="math inline">\(w\)</span> by <span class="math inline">\(a\)</span> is equivalent to rotating it by an angle of <span class="math inline">\(\theta_a\)</span>. Let <span class="math inline">\(w&#39;, b&#39;, c&#39;\)</span> be the vectors obtained by rotating <span class="math inline">\(b, c, w\)</span> by angle <span class="math inline">\(\theta_a\)</span>. Then <span class="math display">\[
w&#39; = a \odot w, \quad b&#39; = a \odot b, \quad c&#39; = a \odot c.
\]</span></p>
<p>The figure belows show that <span class="math display">\[
w&#39; = b&#39; \oplus c&#39; \implies a \odot w = a \odot b \oplus a \odot c.
\]</span></p>
<p>In case <span class="math inline">\(|a| &gt; 1\)</span>, <span class="math inline">\(|w&#39;|\)</span>, <span class="math inline">\(|b&#39;|\)</span> and <span class="math inline">\(|c&#39;|\)</span> are magnified by a factor of <span class="math inline">\(|a|\)</span> and the same conclusion apply.</p>
<div style="text-align:center">
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/ComplexNumber/distributivity.png?raw=true" width="600" height="340" /></p>
</div>
<p><span class="math inline">\(\square\)</span></p>
<h1 id="conclusion">Conclusion</h1>
<p>We have shown that <span class="math inline">\((\mathbb{R}^2, \oplus, \odot)\)</span> is indeed a field. For convenience, we use <span class="math inline">\(\mathbb{C}\)</span> to denote this set system. If we define <span class="math display">\[
\vec j = (1, 0), \qquad \vec i = (0, 1),
\]</span></p>
<p>Hence, <span class="math inline">\(\vec j = \vec 1\)</span> and</p>
<ol type="1">
<li><span class="math inline">\(\vec j \odot \vec j = \vec 1\)</span>,</li>
<li><span class="math inline">\(\vec i \odot \vec j = \vec j \odot \vec i = \vec i\)</span>,</li>
<li><span class="math inline">\(\vec i \odot \vec i = |1| \angle ( \pi / 2 + \pi / 2) = (-1, 0) = -\vec j\)</span>.</li>
</ol>
<p>For <span class="math inline">\(a = (a_1, a_2), b = (b_1, b_2) \in \mathbb{R}^2\)</span>, we can write <span class="math display">\[
a = a_1 \vec j \oplus a_2 \vec i, \qquad b = b_1 \vec j \oplus b_2 \vec i, 
\]</span></p>
<p>and <span class="math display">\[
    a \oplus b = (a_1 + b_1) \vec j \oplus (a_2 + b_2) \vec i.
\]</span></p>
<p>To derive a formula for multiplication, we use the <em>distributivity</em> property of the two operations <span class="math display">\[
\begin{aligned}
    a \odot b 
        &amp;= a \odot ( b_1 \vec j \oplus b_2 \vec i ) \\
        &amp;= a \odot (b_1 \vec j) \oplus a \odot (b_2 \vec i) \\
        &amp;= (a_1 \vec j \oplus a_2 \vec i) \odot (b_1 \vec j) \oplus (a_1 \vec j \oplus a_2 \vec i) \odot (b_2 \vec i) \\
        &amp;=  (a_1 \cdot b_1) (\vec j \odot \vec j)  \oplus (a_2 \cdot b_1) (\vec i \odot \vec j) \oplus (a_1 \cdot b_2) (\vec j \odot \vec i) \oplus (a_2 \cdot b_2)  (\vec i \odot \vec i) \\
        &amp;=  (a_1 \cdot b_1) \vec j  \oplus (a_2 \cdot b_1) \vec i \oplus (a_1 \cdot b_2) \vec i \oplus (a_2 \cdot b_2)  ( - \vec j ) \\
        &amp;=  (a_1 \cdot b_1 - a_2 \cdot b_2) \vec j  \oplus (a_2 \cdot b_1 + a_1 \cdot b_2) \vec i.  \\
\end{aligned}
\]</span></p>
<p>We are almost done. We now further simplify the notations. As <span class="math inline">\(\vec j\)</span> plays the role of <span class="math inline">\(\vec 1\)</span>, we can omit it. For <span class="math inline">\(a = (a_1, a_2)\)</span>, we use only <span class="math inline">\(\vec i\)</span> to distinguish its <span class="math inline">\(y\)</span>-coordinate from the <span class="math inline">\(x\)</span>-coordinate: <span class="math display">\[
a = a_1 \oplus a_2 \vec i. 
\]</span></p>
<p>Addition and multiplication can be performed correctly in this representation:</p>
<ol type="1">
<li><span class="math inline">\(a \oplus b = a_1 \oplus a_2 \vec i \oplus b_1 \oplus b_2 \vec i = (a_1 + b_1) \oplus (a_2 + b_2) \vec i\)</span>.<br />
</li>
<li><span class="math display">\[
\begin{aligned}
    a \odot b 
        &amp;= a \odot ( b_1  \oplus b_2 \vec i ) \\
        &amp;= a \odot b_1 \oplus a \odot (b_2 \vec i) \\
        &amp;= (a_1  \oplus a_2 \vec i) \odot b_1 \oplus (a_1  \oplus a_2 \vec i) \odot (b_2 \vec i) \\
        &amp;=  (a_1 \cdot b_1) \oplus (a_2 \cdot b_1) \vec i \oplus (a_1 \cdot b_2) \vec i \oplus (a_2 \cdot b_2)  (\vec i \odot \vec i) \\
        &amp;=  (a_1 \cdot b_1)   \oplus (a_2 \cdot b_1) \vec i \oplus (a_1 \cdot b_2) \vec i \oplus (- a_2 \cdot b_2) \\
        &amp;=  (a_1 \cdot b_1 - a_2 \cdot b_2)   \oplus (a_2 \cdot b_1 + a_1 \cdot b_2) \vec i.  \\
\end{aligned}
  \]</span></li>
</ol>
<p>Finally, observe that if we restrict <span class="math inline">\(\oplus\)</span> and <span class="math inline">\(\odot\)</span> to the points on the <span class="math inline">\(x\)</span>-axis, they perform similarly as <span class="math inline">\(+\)</span> and <span class="math inline">\(\cdot\)</span> do for <span class="math inline">\(\mathbb{R}\)</span>. If we do not distinguish a number <span class="math inline">\((a_1, 0) \in \mathbb{R}^2\)</span> and <span class="math inline">\(a_1 \in \mathbb{R}\)</span>, replace <span class="math inline">\(\oplus\)</span> and <span class="math inline">\(\odot\)</span> with <span class="math inline">\(+\)</span> and <span class="math inline">\(\cdot\)</span>, we get exactly the same formula for standard complex number addition and multiplication: <span class="math inline">\(\forall a, b \in \mathbb{R}^2\)</span>,</p>
<ol type="1">
<li><span class="math inline">\(a + b = (a_1 + b_1) + (a_2 + b_2) \vec i\)</span>,</li>
<li><span class="math inline">\(a \cdot b = (a_1 + a_2 \vec i) \cdot (b_1 + b_2 \vec i) = (a_1 \cdot b_1 - a_2 \cdot b_2) + (a_1 \cdot b_2 + a_2 \cdot b_1) \vec i\)</span>.</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/12/10/Stirling-s-Approximation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/12/10/Stirling-s-Approximation/" class="post-title-link" itemprop="url">Stirling's Approximation</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-12-10 10:22:35" itemprop="dateCreated datePublished" datetime="2020-12-10T10:22:35+11:00">2020-12-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-01 12:40:39" itemprop="dateModified" datetime="2021-01-01T12:40:39+11:00">2021-01-01</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>The Stirling's approximation [1] states that <span class="math inline">\(\forall n \in \mathbb{N}^+\)</span>, <span class="math display">\[
\sqrt{2 \pi} \sqrt{n} \left( \frac{n}{e} \right)^n e^{ \frac{1}{ 12n + 1 } } \le n! \le \sqrt{2 \pi} \sqrt{n} \left( \frac{n}{e} \right)^n e^{ \frac{1}{ 12n } }. 
\]</span></p>
<p>As <span class="math inline">\(\forall x \in R, e^x \ge 1 + x\)</span>, and for <span class="math inline">\(0 &lt; x &lt; 0.5\)</span>, <span class="math inline">\(e^x \le 1 + 2 x\)</span>, we get <span class="math inline">\(\forall n \in \mathbb{N}^+\)</span>, <span class="math display">\[
\sqrt{2 \pi} \sqrt{n} \left( \frac{n}{e} \right)^n \left( 1 +  \frac{1}{ 12n + 1 } \right) \le n! \le \sqrt{2 \pi} \sqrt{n} \left( \frac{n}{e} \right)^n \left( 1 +  \frac{1}{ 6n } \right).
\]</span></p>
<p>Asymptotically, <span class="math display">\[
n! = \sqrt{2 \pi} \sqrt{n} \left( \frac{n}{e} \right)^n \left( 1 +  \Theta \left( \frac{1}{n} \right) \right). 
\]</span></p>
<p>In the remainder of the blog, we try to approach this estimation incrementally. First we have two trivial facts.</p>
<h3 id="n-le-nn.">1. <span class="math inline">\(n! \le n^n\)</span>.</h3>
<h3 id="n-ge-n-2n-2.">2. <span class="math inline">\(n! \ge (n / 2)^{n / 2}\)</span>.</h3>
<p><em>Proof:</em> Clearly this holds for even numbers. When <span class="math inline">\(n\)</span> is odd, <span class="math inline">\(\lceil n / 2 \rceil = (n + 1) / 2\)</span>. There are <span class="math inline">\((n + 1) / 2\)</span> numbers in <span class="math inline">\([n]\)</span> that are <span class="math inline">\(\ge (n + 1) / 2\)</span>. <span class="math display">\[
   n! \ge \prod_{i = (n + 1) / 2)}^n i \ge \big( (n + 1) / 2) \big)^{ (n + 1) / 2) } \ge (n / 2)^{n / 2}
   \]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<p>Somewhat unexpectedly, we can combine inequality (1) and (2) to obtain the asymptotical trend of <span class="math inline">\(\log n!\)</span> up to some constant: <span class="math display">\[
(n / 2) \log_2 n - (n / 2) \le \log_2 n! \le n \log_2 n.
\]</span></p>
<p>This implies that <span class="math display">\[
\log_2 n! = \Theta( n \log n).
\]</span></p>
<p>We proceed to get even sharper bounds.</p>
<h3 id="n-ge-fracnn-expn-n-en.">3. <span class="math inline">\(n! \ge \frac{n^n}{ \exp(n) } = (n / e)^n\)</span>.</h3>
<p><em>Proof:</em> Using the Taylor expansion for <span class="math inline">\(\exp(x)\)</span> for <span class="math inline">\(\forall x \in \mathbb{R}\)</span>, we get <span class="math display">\[
    \exp(x) = 1 + x + \frac{x^2}{2!} + ... + \frac{x^n}{n!} + ... 
\]</span></p>
<p>Keeping only the <span class="math inline">\(n\)</span>-th term of the expansion, we have <span class="math display">\[
    n! \ge \frac{x^n}{\exp(x) }. 
\]</span></p>
<p>Taking <span class="math inline">\(x = n\)</span> maximizes the RHS.</p>
<p><span class="math inline">\(\square\)</span></p>
<h3 id="n-ge-e-n-en.">4. <span class="math inline">\(n! \ge e ( n / e)^n\)</span>.</h3>
<p><em>Proof:</em> Using the Taylor expansion for <span class="math inline">\(\exp(x)\)</span> for <span class="math inline">\(\forall x \in \mathbb{R}\)</span>, we get <span class="math display">\[
    \exp(x) = 1 + x + \frac{x^2}{2!} + ... + \frac{x^n}{n!} + ... 
\]</span></p>
<p>Setting <span class="math inline">\(x = n\)</span>, we get <span class="math display">\[
\exp(n) \ge \frac{n^{n - 1} }{ (n - 1)!} + \frac{ n^n }{n !} = 2 \frac{ n^n }{n !},
\]</span> which finishes our proof.</p>
<p><span class="math inline">\(\square\)</span></p>
<p>Next we resort to calculus to get finer estimation.</p>
<h3 id="n-ge-e-n-en.-1">5. <span class="math inline">\(n! \ge e ( n / e)^n\)</span>.</h3>
<p><em>Proof:</em> As the figure below shows, <span class="math inline">\(\sum_{i \in [n] } \ln i\)</span> is the sum of areas of a set of rectangles and it upper bounds the area under the curve <span class="math inline">\(y = \log t\)</span>: <span class="math display">\[
\sum_{i \in [n]} \ln i \ge \int_1^n \ln t \ dt = t \ln t \mid_1^n - \int_1^n 1 \ dt = n \ln n - n + 1. 
\]</span></p>
<p>Hence, <span class="math inline">\(n! \ge e (n / e)^n\)</span>. <img src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/StirlingApproximation/LowerBound.png?raw=true" /></p>
<p><span class="math inline">\(\square\)</span></p>
<h3 id="n-le-e-sqrtn-n-en.">6. <span class="math inline">\(n! \le e \sqrt{n} (n / e)^n\)</span>.</h3>
<p><em>Proof:</em> For a rectangle, its area can be decomposed into the curvilinear area under <span class="math inline">\(y = \ln t\)</span> and a curvy triangle. To obtain an upper bound for <span class="math inline">\(\sum_{i \in [n] } \ln i\)</span>, we want to upper bound the areas of the curvy triangles.</p>
<p>How are we going to do that? Image that we put a wall at <span class="math inline">\(t = 1\)</span>, and line the curvy triangles up against the wall. By the figure, they take up at most half the area of the rectangle with width <span class="math inline">\(1\)</span> and height <span class="math inline">\(\ln n\)</span>. Then</p>
<p><span class="math display">\[
\sum_{i \in [n]} \ln i \le \int_1^n \ln t \ dt + \frac{1}{2} \ln n = n \ln n - n + 1 + \frac{1}{2} \ln n. 
\]</span></p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/StirlingApproximation/UpperBound1.png?raw=true" /></p>
<p><span class="math inline">\(\square\)</span></p>
<p>By inequality (4) and (5), we get <span class="math display">\[
e ( n / e)^n \le n! \le e \sqrt{n} (n / e)^n.
\]</span></p>
<p>So <span class="math display">\[
n! = \Theta ( (n / e)^n ). 
\]</span></p>
<p>Indeed the approximation of <span class="math inline">\(e \sqrt n (n / e)^n\)</span> is quite sharp. If we compute its ratio with the near accurate estimation <span class="math inline">\(\sqrt{2 \pi} \sqrt n (n / e)^n\)</span>, we see that the ratio is very close to 1: <span class="math display">\[
\frac{ e \sqrt n (n / e)^n  }{ \sqrt{2 \pi} \sqrt n (n / e)^n } = \frac{e }{\sqrt{ 2 \pi} } \approx 1.084.
\]</span></p>
<p>Therefore, when <span class="math inline">\(n\)</span> is large, <span class="math inline">\(e \sqrt n (n / e)^n\)</span> is within <span class="math inline">\(10\%\)</span> of the real value of <span class="math inline">\(n!\)</span>.</p>
<h3 id="n-le-e-sqrtn-n-en.-1">7. <span class="math inline">\(n! \le e \sqrt{n} (n / e)^n\)</span>.</h3>
<p>The same inequality can be obtained in the following manner.</p>
<p><em>Proof:</em> We lower bound the integral by the areas of trapezoids. The trapezoid between <span class="math inline">\(t\)</span> and <span class="math inline">\(t + 1\)</span> has base heights <span class="math inline">\(\ln t\)</span> and <span class="math inline">\(\ln (t + 1)\)</span>, and area <span class="math inline">\(\frac{1}{2} (\ln t + \ln (t + 1) )\)</span>. Hence,</p>
<p><span class="math display">\[
\begin{aligned}
    \sum_{i = 1}^n \ln i &amp;= \frac{1}{2} \sum_{t = 1}^{n - 1} (\ln t + \ln (t + 1) ) + \frac{1}{2} \ln n \\
    &amp;\le \int_1^n \ln t \ dt + \frac{1}{2} \ln n \\
    &amp;= n \ln n - n + 1 + \frac{1}{2} \ln n 
\end{aligned}
\]</span> <img src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/StirlingApproximation/UpperBound0.png?raw=true" /></p>
<p><span class="math inline">\(\square\)</span></p>
<h3 id="n-in-e11-12-sqrtn-left-fracne-rightn-e-1-12n-1-e12-13-sqrtn-left-fracne-rightn-e1-12-n">8. <span class="math inline">\(n! \in [e^{11 / 12} \sqrt{n} \left( \frac{n}{e} \right)^n e^{ 1 / (12n + 1)}, e^{12 / 13} \sqrt{n} \left( \frac{n}{e} \right)^n e^{1 / (12 n) }]\)</span></h3>
<p><em>Proof:</em> Let <span class="math display">\[
\begin{aligned}
    U_k &amp;= \int_k^{k + 1} \ln t \ dt, \\
    L_k &amp;= \frac{1}{2} \left(\ln k + \ln (k + 1) \right).
\end{aligned}
\]</span></p>
<p>The estimation error in the previous section is determined by the gap between <span class="math inline">\(U_k\)</span> and <span class="math inline">\(L_k\)</span>, for <span class="math inline">\(k \in [n - 1]\)</span>. To investigate it carefully, define <span class="math inline">\(\forall k \in [n - 1]\)</span>, <span class="math display">\[
    \epsilon_k \doteq U_k - L_k .
\]</span></p>
<p>Denote <span class="math inline">\(S = \sum_{i \in [n] } \ln i\)</span> and <span class="math inline">\(\hat S = n \ln n - n + 1 + \frac{1}{2} \ln n\)</span>. The derivation in the previous section shows <span class="math display">\[
\hat S - S = \sum_{i = 1}^{n - 1} \epsilon_k.  
\]</span></p>
<p>For a fixed <span class="math inline">\(k\)</span>, we can compute <span class="math inline">\(\epsilon_k\)</span> in closed form: <span class="math display">\[
\begin{aligned}
    \epsilon_k 
        &amp;= t \ln t \mid_k^{k + 1} - t \mid_k^{k + 1} - \frac{1}{2} \left( \ln k + \ln (k + 1) \right) \\
        &amp;= \ln \frac{ (k + 1)^{k + 1} }{ k^k } \cdot \frac{1}{ k^{\frac{1}{2} } (k + 1)^{\frac{1}{2} } } - 1 \\
        &amp;= \ln \left( \frac{k + 1}{k } \right)^{ k + \frac{1}{2} } - 1 \\
        &amp;= \left(  \frac{2k + 1}{2} \right) \cdot \ln \left( \frac{k + 1}{k } \right)- 1 \\
\end{aligned}
\]</span></p>
<p>Let <span class="math inline">\(x = \frac{1}{2k + 1}\)</span>. As <span class="math inline">\(k + 1 = \frac{1}{2}( (2k + 1) + 1)\)</span>, and <span class="math inline">\(k = \frac{1}{2}( (2k + 1) - 1)\)</span>, we can write <span class="math display">\[
    \epsilon_k = \left(  \frac{2k + 1}{2} \right) \cdot \ln \left( \frac{1 + k }{k } \right)- 1 = \frac{1}{2 x} \ln \frac{1 + x}{1 - x} - 1. 
\]</span></p>
<p>Using the Taylor's expansions for <span class="math inline">\(y = \ln(1 -x)\)</span> and <span class="math inline">\(y = \ln(1 + x)\)</span>, we have <span class="math display">\[
\ln(1 - x) = -(x + \frac{x^2}{2} + \frac{x^3}{3} + ...) \\
\ln(1 + x) = -(-x + \frac{x^2}{2} - \frac{x^3}{3} + ...) \\
\]</span></p>
<p>and <span class="math display">\[
\ln \frac{1 + x}{1 - x} = 2 (x + \frac{x^3}{3} + \frac{x^5}{5} + \frac{x^7}{7} + ... ). 
\]</span></p>
<p>It follows that <span class="math display">\[
\epsilon_k = \frac{x^2}{3} + \frac{x^4}{5} + \frac{x^6}{7} + ... 
\]</span></p>
<p>We can upper bound <span class="math inline">\(\epsilon_k\)</span> by <span class="math display">\[
\begin{aligned}
    \epsilon_k 
        &amp;\le \frac{x^2}{3} ( 1 + x^2 +x^4 + ... ) \\
        &amp;= \frac{x^2}{3} \frac{1}{1 - x^2} \\
        &amp;= \frac{1}{3} \frac{1}{ (2k + 1)^2 - 1} \\
        &amp;= \frac{1}{12} \left(\frac{1}{k } - \frac{1}{k + 1} \right).
\end{aligned}
\]</span></p>
<p>Also, we can lower bound <span class="math inline">\(\epsilon_k\)</span> by <span class="math display">\[
\begin{aligned}
    \epsilon_k 
        &amp;\ge \frac{x^2}{3} ( 1 + x^2 / 3 +x^4 / 3^2 + ... ) \\
        &amp;= \frac{x^2}{3} \frac{1}{1 - x^2 / 3} \\
        &amp;= \frac{1}{ 3(2k + 1)^2 - 1} \\
        &amp;= \frac{1}{ 12(k^2 + k + \frac{2}{12} ) } \\
        &amp;\ge \frac{1}{ 12(k + 1 + \frac{1}{12}) ( k + \frac{1}{12} ) } \\
        &amp;= \frac{1}{12} \left(\frac{1}{k + \frac{1}{12} } - \frac{1}{k + 1 + \frac{1}{12} } \right). 
\end{aligned}
\]</span></p>
<p>Let <span class="math inline">\(A = \sum_{k = 1}^\infty \epsilon_k\)</span> and <span class="math inline">\(R = \sum_{k = n}^\infty \epsilon_k\)</span>. Then <span class="math display">\[
\begin{aligned}
    \hat S - S &amp;= A - R \\
    \implies S &amp;= \hat S - A + R \\
    \implies S &amp;= n \ln n - n + 1 + \frac{1}{2} \ln n - A + R \\
    \implies n! &amp;= e^{1 - A} \sqrt{n} \left( \frac{n}{e} \right)^n e^R.
\end{aligned}
\]</span></p>
<p>By previous inequalities, we know <span class="math display">\[
    \begin{aligned}
        A &amp;\ge \frac{1}{12} \sum_{k = 1}^\infty \left( \frac{1}{k + \frac{1}{12} } - \frac{1}{k + 1 + \frac{1}{12} } \right) = \frac{1}{12} \frac{1}{1 + \frac{1}{12} } = \frac{1}{13} \\
        A &amp;\le \frac{1}{12} \sum_{k = 1}^\infty \left(\frac{1}{k } - \frac{1}{k + 1} \right) = \frac{1}{12}.
    \end{aligned}
\]</span></p>
<p>Similarly, we can get <span class="math inline">\(\frac{1}{12n + 1 } = \frac{1}{12} \frac{1}{n + \frac{1}{12} } \le R \le \frac{1}{12n}\)</span>. To finish our proof, we have <span class="math display">\[
n! \in [e^{11 / 12} \sqrt{n} \left( \frac{n}{e} \right)^n e^{ 1 / (12n + 1)}, e^{12 / 13} \sqrt{n} \left( \frac{n}{e} \right)^n e^{1 / (12 n) }]
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h3 id="reference">Reference</h3>
<p>[1] H. Robbins, “A Remark on Stirling’s Formula,” The American Mathematical Monthly, vol. 62, no. 1, pp. 26–29, 1955</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/25/">25</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">125</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WOW</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
