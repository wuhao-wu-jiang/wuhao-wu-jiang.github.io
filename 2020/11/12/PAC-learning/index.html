<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="We discuss a toy model of probably approximately correct (PAC) learning [1]. The setting focuses on a $d$-dimension Boolean hypercube ${0, 1}^d$ and a set of functions $\mathcal{H} &#x3D; { h : {0, 1}^d \r">
<meta property="og:type" content="article">
<meta property="og:title" content="PAC Learning Basic">
<meta property="og:url" content="http://example.com/2020/11/12/PAC-learning/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:description" content="We discuss a toy model of probably approximately correct (PAC) learning [1]. The setting focuses on a $d$-dimension Boolean hypercube ${0, 1}^d$ and a set of functions $\mathcal{H} &#x3D; { h : {0, 1}^d \r">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/PAC-Learning.png?raw=true">
<meta property="article:published_time" content="2020-11-12T05:06:55.000Z">
<meta property="article:modified_time" content="2020-11-19T04:16:12.249Z">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/PAC-Learning.png?raw=true">

<link rel="canonical" href="http://example.com/2020/11/12/PAC-learning/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>PAC Learning Basic | WOW</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">WOW</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/11/12/PAC-learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          PAC Learning Basic
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-12 16:06:55" itemprop="dateCreated datePublished" datetime="2020-11-12T16:06:55+11:00">2020-11-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-11-19 15:16:12" itemprop="dateModified" datetime="2020-11-19T15:16:12+11:00">2020-11-19</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>We discuss a toy model of probably approximately correct (PAC) learning [1]. The setting focuses on a $d$-dimension Boolean hypercube ${0, 1}^d$ and a set of functions $\mathcal{H} = { h : {0, 1}^d \rightarrow {0, 1 } }$. A function $h \in \mathcal{H}$ is called a hypothesis or a concept, which assigns each vertex in the hypercube a label 0 or 1. </p>
<p>The goal of PAC learning is to learn an unknown hypothesis, denoted as $h^* \in \mathcal{H}$, from a dataset, which consists of $n$ points $X_1, X_2, …, X_n \in {0, 1}^n$ sampled independently from an unknown distribution $D$ (over the hypercube), as well as their labels $Y_1 = h^*(X_1), Y_2 = h^*(X_2), …, Y_n = h^*(X_n)$.  </p>
<p>We can state the algorithm for PAC learning in just one sentence. </p>
<blockquote>
<p>Output any hypothesis $h’ \in \mathcal{H}$ that is consistent with the sampled dataset, i.e.,<br>$$<br>    h’(X_i) = Y_i, \qquad \forall i \in [n]<br>$$</p>
</blockquote>
<p>Such an hypothesis always exists, as $h^*$ satisfies this constraint. We have the classic PAC learning theorem. </p>
<blockquote>
<p><strong><em>Theorem.</em></strong> Let $X \in {0, 1}^n$ be a random point sampled from the unknown distribution, then for a given $\delta \in (0, 1)$,<br>$$<br>        \Pr[ h’(X) \neq h^*(X)] \ge \sqrt{ \log |\mathcal{H}| + \log \frac{ 1 }{ \delta } \over 2n}<br>$$<br>with probability at most $\delta$. </p>
</blockquote>
<p>The PAC learning theorem states that the probability that $h’$ mislabels a point is bounded by $\sqrt{ \log |\mathcal{H}| + \log \frac{ 1 }{ \delta } \over 2n}$. </p>
<p><em>Proof.</em> Consider some fixed $h \in \mathcal{H}$. For convenience, we rewrite<br>$$<br>\Pr[ h(X) \neq h^*(X)] = \mu_h.<br>$$</p>
<p>Denote $Z_i$ the indicator variable of whether $h$ mislabels $X_i$, i.e.,<br>$$<br>Z_i = \begin{cases}<br>    0, \qquad \text{ if } h(X_i) = Y_i \<br>    1, \qquad \text{ if } h(X_i) \neq Y_i<br>\end{cases}<br>$$</p>
<p>By definition, $\mathbb{E}[Z_i]$ is an unbiased estimator of $\mu_h$. Further, denote $\hat \mu_h$ the empirical mean of $Z_i$’s<br>$$<br>\hat \mu_h \doteq \frac{1}{n} \sum_{i \in [n] } Z_i<br>$$</p>
<p>Note that for the outputted $h’$, $\hat \mu_{h’} = 0$. </p>
<p>By Hoeffding inequality, for any $\delta’ &gt; 0$,<br>$$<br>\Pr[ \hat \mu_h \le \mu_h - \sqrt{ \frac{ \log \frac{1}{\delta’} }{2n} } ] \le \delta’.<br>$$</p>
<p>By union bound, the probability that<br>$$<br>\exists h \in \mathcal{H}, \hat \mu_h \ge \mu_h - \sqrt{ \frac{ \log \frac{1}{\delta’} }{2n} }<br>$$</p>
<p>is bounded by $| \mathcal{H} | \delta’$. By setting $\delta’ = \frac{\delta}{ | \mathcal{H} | }$, it is guaranteed that<br>$$<br>0 = \hat \mu_{h’ } \le \mu_{h’} -  \sqrt{ \log |\mathcal{H}| + \log \frac{ 1 }{ \delta } \over 2n}<br>$$</p>
<p>with probability at most $\delta$.</p>
<p>$\blacksquare$</p>
<p>The previous theorem can be improved with the $\sqrt{ \cdot }$ removed. The key here is that the selected $h’$ is error-free on the samples. </p>
<blockquote>
<p><strong><em>Theorem.</em></strong> Let $X \in {0, 1}^n$ be a random point sampled from the unknown distribution, then for a given $\delta \in (0, 1)$,<br>$$<br>        \Pr[ h’(X) \neq h^*(X)] \ge { \log |\mathcal{H}| + \log \frac{ 1 }{ \delta } \over n}<br>$$<br>with probability at most $\delta$. </p>
</blockquote>
<p><em>Proof.</em> Consider some fixed $h \in \mathcal{H}$. For convenience, we rewrite<br>$$<br>\Pr[ h(X) \neq h^*(X)] = \mu_h.<br>$$</p>
<p>We will prove that if $\mu_h \ge { \log |\mathcal{H}| + \log \frac{ 1 }{ \delta } \over n}$, then $h$’s probability of being selected is very low. </p>
<p>Denote $Z_i$ the indicator variable of whether $h$ mislabels $X_i$, i.e.,<br>$$<br>Z_i = \begin{cases}<br>    0, \qquad \text{ if } h(X_i) = Y_i \<br>    1, \qquad \text{ if } h(X_i) \neq Y_i<br>\end{cases}<br>$$</p>
<p>By definition, $\Pr[Z_i = 1] = \mu_h$. Therefore,<br>$$<br>    \begin{aligned}<br>        \Pr[ Z_1 = 0 \wedge Z_2 = 0 \wedge … \wedge Z_n = 0] = (1 - \mu_h)^n \le \exp(- \mu_h n) = \frac{\delta}{ |\mathcal{H} | }<br>    \end{aligned}<br>$$</p>
<p>Taking union bound over all possible $h$ gives the desired result. </p>
<p>$\blacksquare$</p>
<p><strong><em>Caveat.</em></strong> <em>In both theorem, we see a $\log \mathcal{H}$ term in the failure probability, which is due to the use of union bound and can be roughly considered as the complexity of the hypothesis family. It is tempting to think that this could be avoid as follows.</em> </p>
<blockquote>
<p>For the outputted $h’$, $Z_1, …, Z_n$ are i.i.d samples. Therefore, the probability of all of them being $0$ is give by<br>  $$<br>        (1 - \mu_{h’} )^n \le \exp( - \mu_{h’} n).<br>  $$<br>Bounding this probability by $\delta$ gives $\mu_{h’} \le \frac{ \log \frac{1}{\delta} } {n}$. </p>
</blockquote>
<p><em>The argument is wrong. For the outputted $h’$, the $Z_1, …, Z_n$ are not i.i.d samples, as $h’$ is selected according to $Z_1, …, Z_n$ and depends on them.</em> </p>
<p><em>To make it more concrete, suppose that there is an $h$, such that $\mu_h = \frac{ \log \frac{1}{\delta} } {n}$. Consider the following experiment</em></p>
<blockquote>
<ol>
<li>Sample $n$ points independently the distribution $D$.  </li>
<li>Pick an $h’$ that makes no prediction error on the samples. </li>
</ol>
</blockquote>
<p><em>If we repeat the experiment $N$ times for some positive integer $N$, then the fixed $h$ makes no mistake in roughly $(1 - \delta) N$ of the experiments and constitutes an candidate of $h’$. However, on the other roughly $\delta N$ experiments, where $h$ makes prediction error, it is no longer considered as the candidate of $h’$. The selection procedure of $h’$ ignores bad event of $h$ automatically.</em></p>
<p><em>We could also investigate the following example. Let $h^</em> = h_0$. There are also other two hypothesis $h_1$ and $h_2$. Let $S$ be the sample space. It holds that*<br>$$<br>|h_1(x) - h^*(x) | = \begin{cases}<br>    2 \epsilon, \forall x \in S \setminus S_{h_1} \<br>    0,\ \       \forall x \in S_{h_1}<br>\end{cases}<br>$$<br>$$<br>|h_2(x) - h^*(x) | = \begin{cases}<br>    2 \epsilon, \forall x \in S \setminus S_{h_2} \<br>    0,\ \       \forall x \in S_{h_2}<br>\end{cases}<br>$$<br><em>Moreover, $\Pr[S_{h_1}] = \Pr[S_{h_2} ] = \delta$. How, if we get a sample in $S_{h_1}$, then we can output $h’$ as $h_0$ or $h_1$, since both of them make no error when $x \in S_{h_1}$. Similarly, if $x \in S_{h_2}$, we can output either $h_0$ or $h_2$. We call $S_{h_1}$ and $S_{h_2}$ the bad areas. When $x$ is in the bad area of any hypothesis, we can’t distinguish this hypothesis from the true hypothesis. That is why we need to use union bound to bound the total probabilities of these bad areas.</em> </p>
<div style="text-align:center">
<img src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/PAC-Learning.png?raw=true" width="400" height="340" />
</div>


<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] Leslie G. Valiant. A theory of the learnable. Communications of the ACM, 27(11):1134-1142, 1984. 6</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/11/06/Gaussian-Mechanism/" rel="prev" title="Gaussian Mechanism">
      <i class="fa fa-chevron-left"></i> Gaussian Mechanism
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/11/13/Advanced-Composition/" rel="next" title="Advanced Composition">
      Advanced Composition <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Reference"><span class="nav-number">1.</span> <span class="nav-text">Reference</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description">你生之前悠悠千載已逝，未來還會有千年沉寂的期待</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">125</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WOW</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
