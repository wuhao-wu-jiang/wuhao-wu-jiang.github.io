<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
<meta property="og:type" content="website">
<meta property="og:title" content="WOW">
<meta property="og:url" content="http://example.com/page/5/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/5/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>WOW</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">WOW</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/02/27/Some-basic-theorems-for-real-numbers/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/02/27/Some-basic-theorems-for-real-numbers/" class="post-title-link" itemprop="url">Reading Notes-Some basic theorems for real numbers</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-02-27 19:55:27" itemprop="dateCreated datePublished" datetime="2019-02-27T19:55:27+11:00">2019-02-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-03-01 02:00:58" itemprop="dateModified" datetime="2019-03-01T02:00:58+11:00">2019-03-01</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="Axiom-of-completeness"><a href="#Axiom-of-completeness" class="headerlink" title="Axiom of completeness"></a>Axiom of completeness</h3><p><em>Any nonempty set of real numbers that is bounded above has an least upper bound.</em></p>
<h4 id="Monotone-Convergence-Theorem"><a href="#Monotone-Convergence-Theorem" class="headerlink" title="Monotone Convergence Theorem"></a>Monotone Convergence Theorem</h4><p><em>Let $(a_n)$ be an increasing sequence that is bounded above, then it converges.</em></p>
<p><em>Proof:</em>   </p>
<p>Consider the set of point ${ a_n : n \in N }$. By assumption, it is bounded. By Axiom of Completeness, the set ${ a_n }$ has an least upper bound, denoted as $a = \sup { a_n : n \in N }$. Because $a$ is a least upper bound, $\forall \epsilon &gt; 0$, there is an element $a_N$, such that $a_N \ge a - \epsilon$. But $(a_n)$ is an increasing sequence. Therefore, for any $n \ge N$, we have $a \ge a_n \ge a_N \ge a - \epsilon$, which implies that $(a_n) \rightarrow a$. </p>
<h5 id="Corollary"><a href="#Corollary" class="headerlink" title="Corollary:"></a>Corollary:</h5><p><em>Let $(b_n)​$ be a decreasing sequence that is bounded below, then it converges.</em></p>
<h4 id="Nested-Interval-Property"><a href="#Nested-Interval-Property" class="headerlink" title="Nested Interval Property"></a>Nested Interval Property</h4><p>Let $I_1 \supset I_2 \supset I_3 …$ be a collection of closed intervals. Then $\cap_{n} I_n \neq \emptyset$. </p>
<p><em>Proof 1 (By Axiom of Completeness):</em>   </p>
<p>Denote $I_n = [a_n, b_n]= { x \in R : a_n \le x \le b_n }$. By definition, we have<br>$$<br>a_1 \le a_2 \le a_3 \le … a_n \le … \le b_n \le … \le b_3 \le b_2 \le b_1<br>$$<br>We are going to use Axiom of Completeness to produce a single real number $a \in \cap_n  I_n$. The set we consider is<br>$$<br>A \doteq { a_1, a_2, … }<br>$$<br> It is bounded above by any $b_n​$ for $n \ge 1​$. Therefore we are justified in the setting $a = \sup A​$. Because $a​$ is an upper bound, we have $a_n \le a​$. The fact $b_n​$ is an upper bound and that $a​$ is the least upper bound implies $a \le b_n​$. Putting together, $a \in I_n​$ for $n \ge 1​$. Hence, $a \in \cap_n I_n​$. </p>
<p><em>Proof 2 (By Monotone Convergence Theorem):</em>   </p>
<p>$(a_n)$ is a monotone increasing sequence and bounded above. By Monotone Convergence Theorem, there exists a real number $a = \lim_n a_n$. Moreover, it holds that $b_m \ge a_n$ for any integer $m$ and $n$, which implies that $b_m \ge \lim_n a_n = a$, as desired. </p>
<h5 id="Remark"><a href="#Remark" class="headerlink" title="Remark:"></a>Remark:</h5><p>We may not necessarily choose Axiom of Completeness as our starting point. For example, if we assume that <em>Nested Interval Property</em> is true and $\lim 1/2^n \rightarrow 0$, it can be used to prove Axiom of Completeness.</p>
<p><em>Proof:</em> Let $A$ be an nonempty set that is bounded above, let $b_1$ be an upper bound and $a_1$ be an element in $A$. Necessarily, $a_1 &lt; b_1$ and we can define the closed interval $I_1 = [a_1, b_1]$. </p>
<p>The idea is to construct a sequence of closed intervals and use Nested Interval Property. Now we bisect $I_1$ into two closed intervals of equal length let $c_1$ be the midpoint. If $c_1$ is an upper bound for $A$, we define $I_2 = [a_1, c_1]$. Otherwise, let $I_2 = [c_1, b_1]$. In general, we construct $I_n = [a_n, b_n]$ by taking the half from $I_{n - 1}$ such that, $a_n$ is no greater than any upper bound of $A$ and $b_n$ is no less than any element of $A$. </p>
<p>By Nested Interval Property, there exists $a \in \cap_n I_n$. Also we notice that the length of $I_n \rightarrow 0$, which implies $\lim a_n = \lim b_n = s$. </p>
<p>Because for all $n \in N$, and any element $a \in A$, we have $a \le b_n$. Taking limit of the right hand side, we obtain $a \le s$, which shows $s$ is an upper bound for $A$. </p>
<p>Moreover, for any upper bound $l$ for $A$, we have $a_n \le l$. Again taking limit of the left hand side, we conclude $s \le l$, which shows that $s$ is the least upper bound. </p>
<h4 id="Bolzano-Weierstrass-Theorem"><a href="#Bolzano-Weierstrass-Theorem" class="headerlink" title="Bolzano-Weierstrass Theorem"></a>Bolzano-Weierstrass Theorem</h4><p>Let $(a_n)$ be a bounded sequence,  then it has a convergent sub-sequence. </p>
<p><em>Proof:</em><br>Since $(a_n)$ is bounded there exists $M &gt; 0$ such that $|a_n| \le M$ for all $n \in N$ . Define $I_0 = [-M, M]$. Then at least one of the intervals $[-M, 0]$ and $[0, M]$ contains infinite number of terms from the sequence $(a_n)$. Select such half interval and label it $I_1$. Let $a_{n_1}$ be some term from $(a_n)$ belonging to $I_1$. </p>
<p>Next, we continue to bisect $I_1$ into two closed intervals of equal length. Choose the half that contains infinite number of terms from $(a_n)$ and label it as $I_2$. We can select an element $a_{n_2} \in I_2$ from $(a_n)$ with $n_2 \ge n_1$. In general, we construct $I_k$ by taking the half from $I_{k - 1}$ that contains infinite number of terms of $(a_n)$ and then choose $a_{n_k} \in I_k$ so that $n_k &gt; n_{k - 1} &gt;  … &gt; n_2 &gt; n_1$. The sets ${ I_n : n \in N }$ forms a sequence of nested closed intervals<br>$$<br>I_1 \supset I_2 \supset I_3 …<br>$$<br>By Nested Interval Property, there is at least on point $a \in \cap_n I_n$. On the other hand, the lengths of the intervals shrink to $0$, which implies that $a_{n_k} \rightarrow a$, as desired. </p>
<h4 id="Cauchy-Criterion"><a href="#Cauchy-Criterion" class="headerlink" title="Cauchy Criterion"></a>Cauchy Criterion</h4><p>Let $(a_n)​$ be a sequence which satisfies<br>$$<br>\forall \epsilon &gt; 0, \exists N \in \mathbf{N}, s.t., \forall n \ge m \ge N \rightarrow |a_n - a_m| \le \epsilon<br>$$<br>Then $(a_n)​$ converges. </p>
<p><em>Proof:</em></p>
<p>Step 1: $(a_n)$ is bounded. To see this, let $N_1$ be the integer that for $n \ge N$, we have $|a_n - a_{N_1} | \le 1$ and so $|a_n| \le |a_{N_1} | + 1$. It can be verified $\max { |a_1|, |a_2|, …, |a_{N_1 - 1} |, |a_{N_1} | + 1 }$ is an upper bound for the sequence $( a_n )​$.  </p>
<p>Step 2: Now, by Bolzano-Weierstrass Theorem, $(a_n)$ has an convergent sub-sequence $( a_{n_k} ) \rightarrow a$. We show that $(a_n)$ converges to the same limit. Let $\epsilon &gt; 0$, because $(a_n)$ is Cauchy,<br>$$<br>\exists N &gt; 0,s.t., \forall n \ge m \ge N \rightarrow |a_n - a_m| \le \epsilon / 2<br>$$<br>We also know $(a_{n_k}) \rightarrow a$, so choose a term $a_{n_k}$, with $n_k &gt; N$ and<br>$$<br>|a_{n_k} - a| \le \epsilon / 2<br>$$<br>Putting together,<br>$$<br>\forall n &gt; N, |a_n - a| \le |a_n - a_{n_k} | + |a_{n_k} - a| \le \epsilon<br>$$<br>as desired. </p>
<h5 id="Remark-1"><a href="#Remark-1" class="headerlink" title="Remark:"></a>Remark:</h5><p><em>Cauchy Criterion</em> can be used to prove <em>Bolzano-Weierstrass</em> Theorem. The key is to construct a sequence of nested  closed intervals $I_1 \supset I_2 \supset I_3 …$ as before and obtain a sub-sequence $(a_{n_k})$. Then, instead of using Nested Interval Property, we observe that $(a_{n_k})$ is Cauchy as the length of $I_k$ shrinks to zero. We know $(a_{n_k})$ converges by Cauchy Criterion. </p>
<p><strong>Reference:</strong> Stephen Abbott, <em>Understanding Analysis</em></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/02/27/Convergence-Tests/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/02/27/Convergence-Tests/" class="post-title-link" itemprop="url">Convergence Tests</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2019-02-27 16:20:18 / Modified: 22:44:25" itemprop="dateCreated datePublished" datetime="2019-02-27T16:20:18+11:00">2019-02-27</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="Ration-Test"><a href="#Ration-Test" class="headerlink" title="Ration Test"></a>Ration Test</h3><p>Given a series $s_n = \sum_{k = 1}^n a_n$ with $a_n \neq 0$, the Ratio Test states that if $(a_n)$ satisfies<br>$$<br>\lim \left| \frac{a_{n + 1} }{ a_n } \right| = r \le 1<br>$$</p>
<p>then $(s_n)$ converges absolutely. </p>
<p><em>Proof</em>: The condition implies that<br>$$<br>\exists N &gt; 0, s.t., \exists r \le r’ &lt; 1, \forall n \ge N, a_{n + 1} \le r’ a_n<br>$$</p>
<p>It follows that for $n &gt; m \ge N$,<br>$$<br>\begin{aligned}<br>|s_n - s_m|<br>&amp;= | a_{m + 1} + a_{m + 1} + … + a_n| \<br>&amp;\le |a_N| \sum_{k = 0}^{n - m - 1} (r’)^{m - N + k} \<br>&amp;\le |a_N| \sum_{k = 0}^{ \infty } (r’)^{m - N + k} \<br>&amp;\le \frac{|a_N| }{1 - (r’) } (r’)^{m - N}<br>\end{aligned}<br>$$</p>
<p>If $m$ is sufficient large, then $|s_n - s_m|$ is arbitrary small. It concludes that $(s_n)$ is Cauchy sequence. </p>
<h3 id="Abel’s-Test"><a href="#Abel’s-Test" class="headerlink" title="Abel’s Test"></a>Abel’s Test</h3><p>If the series $s_n = \sum_{k = 1}^n a_n$ converges and if $(b_n)$ is a sequence satisfying<br>$$<br>b_1 \ge b_2 \ge b_3 \ge … \ge 0<br>$$<br>then the series $\sum_{k = 1}^\infty a_k b_k$ converges. </p>
<h5 id="Lemma-Partial-Sum"><a href="#Lemma-Partial-Sum" class="headerlink" title="Lemma: Partial Sum"></a>Lemma: Partial Sum</h5><p>Define $s_0 = 0$, then<br>$$<br>\sum_{k = 1}^n x_k y_k<br>= \sum_{k = 1}^n (s_k - s_{k - 1}) b_k<br>= \sum_{k = 1}^n s_k b_k - \sum_{k = 1}^{n - 1} s_k b_{k + 1}<br>= s_n b_n + \sum_{k = 1}^{n - 1} s_k (b_k - b_{k + 1})<br>$$</p>
<p><em>Proof:</em><br>$(b_n)$ is monotone and bounded, therefore $(b_n)$ converges. Since both $(s_n)$ and $(b_n)$ converges, $(s_n b_n)$ converges. </p>
<p>It remains to prove $\sum_{k = 1}^{n - 1} s_k (b_k - b_{k + 1})$ converges. We show it is a Cauchy sequence. We know the convergent sequence $(s_n)$ is bounded. Let $| s_n | \le M$. Thus, for $n &gt; m$,<br>$$<br>|\sum_{k = m}^{n - 1} s_k (b_k - b_{k + 1})| \le M \sum_{k = m}^{n - 1} (b_k - b_{k + 1} ) = M (b_m - b_n)<br>$$</p>
<p>The fact $(b_n)$ converges implies that $b_m - b_n \rightarrow 0$ for large $m$ and so, $|\sum_{k = m}^{n - 1} s_k (b_k - b_{k + 1})| \rightarrow 0$. </p>
<h3 id="Dirichlet’s-Test"><a href="#Dirichlet’s-Test" class="headerlink" title="Dirichlet’s Test"></a>Dirichlet’s Test</h3><p>If the series $s_n = \sum_{k = 1}^n a_n$ is bounded (but not necessary convergent), and if $(b_k)$ is a sequence satisfying<br>$$<br>\begin{cases}<br>b_1 \ge b_2 \ge b_3 \ge … \ge 0 \quad and \<br>\lim b_k = 0<br>\end{cases}<br>$$<br>then the series $\sum_{k = 1}^\infty a_k b_k$ converges.</p>
<p><em>Proof:</em><br>Let $|s_n| \le M$. As $(b_n) \rightarrow 0$, $(s_n b_n) \rightarrow 0$. The proof for the convergence of $\sum_{k = 1}^{n - 1} s_k (b_k - b_{k + 1})$ is exactly the same as that of Abel’s test. </p>
<p><strong>Reference</strong>: Stephen Abbott, <em>Understanding Analysis, Second Edition.</em></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/02/21/Hahn-s-Lemma/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/02/21/Hahn-s-Lemma/" class="post-title-link" itemprop="url">Hahn's Lemma</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2019-02-21 15:26:50 / Modified: 23:51:39" itemprop="dateCreated datePublished" datetime="2019-02-21T15:26:50+11:00">2019-02-21</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><em>Hahn’s Lemma.</em> Let $\mu​$ be a signed measure on the measurable space $(X, M)​$ and $E​$ a measurable set for which $0 &lt; \mu(E) &lt; \infty​$. Then there is a measurable subset $A​$ of $E​$ that is positive and of positive measure. </p>
<p><em>Proof</em>.  The high level idea is to iteratively take the measurable subset in $E$ with most negative measure and remove it from $E$. If all measurable subsets are of non-negative measure, then the proof is complete. The technical hurdle is that we may not be able to find the subset with most negative measure. We relax the condition by finding a subset with “almost” most negative measure. </p>
<p>If $E$ itself is positive, then the proof is trivial. Otherwise, $E$ contains sets of negative measure. Now, consider the perfect case that we can find a set $E_1$ such that $\lambda_1 = \mu(E_1) = \inf { \mu(S) \mid S \subset E \wedge S \in M } &lt; 0$. Let $n$ be a natural number for which $\lambda_1, …, \lambda_n$ and measurable sets $E_1, …, E_n$ have been chosen such that, for $1 \le k \le n$, $\lambda_k = \inf { \mu(S) \mid S \subset E - \cup_{i=1}^{k - 1} E_i \wedge S \in M } &lt; 0$ and $E_k$ is a subset for which $\mu(E_k) = \lambda_k​$ (we consider the perfect case first). </p>
<p>If the selection process terminates for some positive number $n$, then $A = E - \cup_{k = 1}^n E_i$ is exactly what we want. Otherwise, define<br>$$<br>A = E - \cup_{k = 1}^\infty E_i<br>$$</p>
<p>Therefore, $A \cup E_1 \cup E_2 \cup …$ is a partition of $E$. By countable additivity of $\mu$, </p>
<p>$$<br>\mu(E) = \mu(A) + \mu(\cup_{k = 1}^\infty E_k)<br>$$</p>
<p>Since $|\mu(E)| &lt; \infty$,<br>$$<br>-\infty &lt; \mu(\cup_{k = 1}^\infty E_k) = \sum_{k = 1}^\infty \mu(E_k) = \sum_{k = 1}^\infty \lambda_k &lt; 0<br>$$</p>
<p>Thus $\lim_{k \rightarrow \infty} \lambda_k = 0$ and $\mu(A) = \mu(E) - \mu(\cup_{k = 1}^\infty E_k) &gt; 0$. It remains to show that $A$ is a positive set. Indeed, if $B \subset A \wedge B \in M$, then for each $k$, </p>
<p>$$<br>B \subset A \subset E - \cup_{i = 1}^k E_k<br>$$</p>
<p>and so, by the definition of $\lambda_k$, $\mu(B) \ge \lambda_k$. As $k \rightarrow \infty$, $\lambda_k \rightarrow 0$, we have $\mu(B) \ge 0$. Thus $A$ is positive set. </p>
<p><em>Remark:</em> For a given $\lambda_k = \inf { \mu(S) \mid S \subset E - \cup_{i=1}^{k - 1} E_i \wedge S \in M } &lt; 0$ as defined in the proof, we may not always be able to find a set $E_k$ such that $\mu(E_k) = \lambda_k$. There are two possible cases. </p>
<ol>
<li><p>In the first case, $0&gt; \lambda_k &gt; -\infty$ for all $k = 1, 2, …$. By definition of $\lambda_k$, we can always find a set $E_k$ such that $\lambda_k’ = \mu(E_k) &lt; \lambda_k / 2$.  </p>
</li>
<li><p>It is more tricky if $\lambda_k = -\infty$ for some $k$ (is this case possible?). In this case we just take an $E_k$ such that $\lambda_k’ = \mu(E_k) \le - 1$.</p>
</li>
</ol>
<p>In a similar manner we have $-\infty &lt; \mu(\cup_{k = 1}^\infty E_k) = \sum_{k = 1}^\infty \mu(E_k) = \sum_{k = 1}^\infty \lambda_k’ &lt; 0$ and $\lambda_k’ \rightarrow 0$. For large enough $k$, $-1 &lt; \lambda_k’ &lt; 0$. By the definition of $\lambda_k$ and the choice of $\lambda_k’$, for any $B \subset A \wedge B \in M$, we have $B \subset A \subset E - \cup_{i = 1}^k E_k$ and $\mu(B) \ge \lambda_k \ge 2 \mu(E_k) \ge 2 \lambda_k’$.  Therefore, $\mu(B) \ge \lim_{k \rightarrow \infty} 2\lambda_k’ = 0$.</p>
<p><em>Reference</em>：H. Royden, P. Fitzpatrick Real Analysis</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/01/19/Strong-Duality/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/01/19/Strong-Duality/" class="post-title-link" itemprop="url">Strong Duality</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-01-19 23:22:08" itemprop="dateCreated datePublished" datetime="2019-01-19T23:22:08+11:00">2019-01-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-01-28 11:51:36" itemprop="dateModified" datetime="2020-01-28T11:51:36+11:00">2020-01-28</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>We prove strong duality of linear program by Farkas Lemma. Let the primal be </p>
<p>$$<br>\begin{aligned}<br>&amp;\max &amp;c^T x &amp; \<br>&amp;s.t., &amp;Ax &amp; = b \<br>&amp;&amp;x &amp; \ge 0<br>\end{aligned}<br>$$</p>
<p>where $A \in R^{m \times n}, c, b, x \in R^n$. The dual is given by</p>
<p>$$<br>\begin{aligned}<br>&amp;\min &amp;y^T b&amp; \<br>&amp;s.t., &amp;y^T A&amp; \ge c^T \<br>\end{aligned}<br>$$<br>where $y \in R^m$. </p>
<p><strong><em>Theorem</em></strong>. If both primal and dual are feasible, then $\max = \min$.  </p>
<p>Note that by weak duality, we have<br>$$<br>c^T x \le (y^T A) x = y^T (A x) = y^T b<br>$$</p>
<p>It suffices to prove the first inequality holds as equality.</p>
<p><em>Proof</em>.  Assume that the dual is feasible and $\min = \alpha$. By weak duality, $\max \le \alpha$. It suffices to prove $\max \ge \alpha$. We are searching for an $x$ satisfying</p>
<p>$$<br>\begin{aligned}<br>Ax &amp; = b \<br>c^T x &amp; \ge \alpha \<br> x&amp; \ge 0<br>\end{aligned}<br>$$</p>
<p>Consider the convex and closed set $P = {(z_1, z_2) \in R^{m + 1} : z_1 = Ax, z_2 \le  c^T x,  x \in R^n  \wedge x \ge 0}$. If $(b, \alpha) \notin P$, the $\exists z = (z’_1, z’_2)$ that minimizes the distance from $(b, \alpha)$ to points in $P$. Define $\bar y^T =  (y, s) = (z’_1, z’_2) - (b, \alpha)$, and the separation plane $\bar y^T (z - z’) = 0$. As $0 \in P$ and $2 z’ \in P$, we have $\bar y^T (-z’) \ge 0$ and $\bar y^T (z’) \ge 0$, which implies that $\bar y^T z’  = 0$. Hence $\bar y^T z \ge 0$ for all $z \in P$. But </p>
<p><em>Lemma</em>: $\bar y^T z \ge 0 \forall z \in P$ if and only if<br>$$<br>\begin{aligned}<br>\bar y^T \left[ \begin{matrix} A \ c^T \end{matrix} \right] = y^T A + sc^T \ge 0<br>\end{aligned}<br>$$</p>
<p>Moreover, we have $\bar y^T (b, \alpha) &lt; 0$, hence $y^T b + s \alpha &lt; 0$. Finally, we claim that $s &lt; 0$. To see, this, note that for any $k &gt; 0$, $(0, -k) \in P$, as $0 = A 0, -k \le c^T 0$. Now $\bar y^T (0, -k) = -k s &gt; 0$, taking $k = 1$ proves the result. </p>
<p>An alternative way to see this is by converting the primal into an equivalent one:<br>$$<br>\begin{aligned}<br>Ax &amp; = b \<br>c^T x  - z &amp;= \alpha \<br> x,z &amp; \ge 0<br>\end{aligned}<br>$$</p>
<p>or more concisely,<br>$$<br>\begin{aligned}<br>\bar A \bar x &amp;= \bar b\<br>\bar x &amp; \ge 0<br>\end{aligned}<br>$$</p>
<p>where<br>$$<br>\begin{aligned}<br>\bar A =<br>\left[ \begin{matrix}<br>    A,   &amp; 0 \<br>    c^T, &amp; -1<br>\end{matrix} \right],<br>\bar x = \left[\begin{matrix} x \ z \end{matrix} \right],<br>\bar b = \left[\begin{matrix} b \ \alpha \end{matrix} \right]<br>\end{aligned}<br>$$</p>
<p>No feasible solution implies that $(b, \alpha)$ lies outside the conic combination of columns of $\bar A$. Therefore, $\exists \bar y$, such that $\bar y^T \bar A \ge 0$. In particular, $\bar y^T \bar A[:, -1] &gt; 0$, which implies the last dimension of $\bar y$ is non-negative. </p>
<p>See the following example in 2 dimensions. </p>
<p><img src="https://pic2.zhimg.com/80/v2-8d0e896dbf81dfc276c356ec0074866d_hd.jpg"></p>
<p>In this example, $A[:, 1] = (-2, 1)$, $A[:, 2] = (-1, 2)$, $c = (1, 1)$, $\bar A [:, 1] = (-2, 1, 1), \bar A[:, 2] = (-1, 2, 1)$. ${ Ax = b, x \ge 0 }$ is feasible implies that $b$ is inside the cone spanned by $A[:, 1], A[:, 2]$. ${ \bar A \bar x = \bar b, x \ge 0 }$ implies that $\bar b = (b, \alpha)$ is outside the cone formed by $\bar A[:, 1], \bar A[:, 2], [0, 0, -1]$. The $z$-dimension of vector $y$ must be negative. </p>
<p>Rigorously, we can use Farkas’ lemma to derive: $\exists y, s$, s.t,<br>$$<br>\begin{aligned}<br>A^T y - s c &amp;\ge 0\<br>s &amp; \ge 0 \<br>b^T y - s \alpha &amp;&lt; 0 \<br>\end{aligned}<br>$$</p>
<!-- y, s, & \ge 0 -->

<p>If $s = 0$, then ${ y^T A \ge 0, b^T y &lt; 0 }$ implies that dual is unbounded and hence ${ Ax = b, x \ge 0 }$ is infeasible, a contradiction. If $s &gt; 0$, then scaling $s$ to $1$ gives ${ A^T y \ge c, b^T y &lt; \alpha }$, contradicting $\min = \alpha$. </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2019/01/17/Farkas-Lemma/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/01/17/Farkas-Lemma/" class="post-title-link" itemprop="url">Farkas' Lemma</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-01-17 22:42:53" itemprop="dateCreated datePublished" datetime="2019-01-17T22:42:53+11:00">2019-01-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-01-31 17:31:04" itemprop="dateModified" datetime="2020-01-31T17:31:04+11:00">2020-01-31</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Given $A \in R^{m \times n}$ and $b \in R^n$, the Farkas Lemma states that exactly one of the following holds:</p>
<ol>
<li>$\exists x \in R^n​ : Ax  = b$, $x \ge 0$,</li>
<li>$\exists y \in R^m : y^T A \le  0$, $y^T b &gt; 0$.</li>
</ol>
<p>Geometrically, the first statements says that $b$ is a non-negative linear combination of columns of $A$. Denote the conic combination of columns of $A$ as $P = { Ax: \forall x \ge 0} \subset R^m$. Note that it is a subset of the columns space of $A$. </p>
<p>If $b \notin P$, the second statement is equivalent to that </p>
<ol start="3">
<li>$\exists y \in R^m$, such that $y^T b &gt; 0$ and $\forall z \in P$, we have $y^T z \le 0$. </li>
</ol>
<p>When (3) holds, clearly (2) holds, as columns of $A$ belong to $P$. On the other hand, every element in $P$ is conic combination of columns of $A$, then $\forall z = Ax \in P$, then $y^T z = y^T (A x) = (y^T A) x \le 0$ by the fact that $y^T A \le 0 \wedge x \ge 0$. </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/Farkas'%20Lemma.jpg?raw=true" alt="Geometry Interpretation"></p>
<p>The existence of $y$ is justified as follows: as $P$ is convex and closed, the <a target="_blank" rel="noopener" href="https://wuhao-wu-jiang.github.io/2018/12/01/Separation-Plane-Theorem/">Separation Theorem</a> states that we can find a point $z^* = A x^*$ in $P$ that satisfies </p>
<p>$$<br>(b - z^*)^T(z - z^*) \le 0​<br>$$</p>
<p>Let $y = (b - z^*) \in R^m$. Note that $y &gt; 0$ as $b \notin P$ and $P$ is closed. Consider the plane $y^T (x - z^*) = 0$. It has the following properties:</p>
<ol>
<li>Points in $P$ lies on the negative side of the plane, that is $z \in P$, we have $y^T (z - z^*) \le 0$. </li>
<li>$b$ is on the positive side of the plane. As $y^T (b - z^*) = y^T y &gt; 0$. </li>
<li>It holds that $y^T z^* = 0$, which implies that either $z^* = 0$ or $y$ is normal to $z^*$. To verify this, we move along the line that pass through the vector $z^*$ and note that for any $k \ge 0$, we have $kz^* \in P$, hence $y^T (kz^* - z^*) \le 0$. Replace $k$ with $0$ and $2$ respectively, we have the desired result. </li>
<li>It concludes that $z \in P$, $y^T z \le 0$ and $y^T b &gt; 0$.  </li>
</ol>
<p>An equivalent form states that </p>
<ol>
<li>$\exists x \in R^n : Ax \le b$</li>
<li>$\exists y \in R^m : y^T A = 0$, $y^T b &gt; 0$, $y \le 0$. </li>
</ol>
<p>We can prove this by converting statement (2) into an equivalent one: </p>
<ol start="3">
<li><p>$\exists y \in R^m : y^T A = 0$, $y^T b = 1$, $y \le 0$. </p>
<p>and hence </p>
</li>
<li><p>$\exists y \in R^m : (-y)^T [A, b] = [0, -1]$, $-y \ge 0$. </p>
</li>
</ol>
<p>If this doesn’t hold, by previous result, we have $\exists (x, \lambda) \in R^{n + 1}$, s,t., $[A, b] (x, \lambda) = Ax + \lambda b \le 0$ and $[0, 1](x, -\lambda) = -\lambda &gt; 0$, which implies that$A \frac{x}{-\lambda} \le b$.</p>
<p>But this can also be verified via their geometrical meanings. We are not going to give all details here, just an example in $R^2$: </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/blob/master/Farkas'%20Lemma%202.jpg?raw=true" alt="Geometry Interpretation 2"></p>
<p>Another equivalent form of Farkas Lemma is written as</p>
<ol>
<li>$\exists x \in R^n : Ax \le b$, $x \ge 0$.</li>
<li>$\exists y \in R^m : y^T A \le 0$, $y^T b &gt; 0$, $y \le 0$. </li>
</ol>
<p>Define $P = { z \mid \exists x \in R^n : z \ge Ax, x \ge 0} \subset R^m$. </p>
<ol>
<li><p>Statement 1 says $b \in Z$. </p>
</li>
<li><p>Otherwise, as $P$ is convex and closed </p>
<ul>
<li><p>$z_1, z_2 \in P \rightarrow \exists x_1, x_2 \ge 0, z_1 \ge Ax_1, z_2 \ge Ax_2$, then $\mu_1 z_1 + \mu_2 z_2 \ge A(\mu_1 x_1 + \mu_2 x_2), \forall \mu_1, \mu_2 \ge 0, \mu_1 + \mu_2 = 1$, </p>
</li>
<li><p>Closeness follows from $\ge$ in the definition of $P$.<br>There is a unique point $z^*$ that minimize $||z - b||$ for $z \in Z$. Let $y = (b - z^*) \neq 0$. Then it holds $y^T (b - z^*) = y^T y &gt; 0$ and $y^T(z - z^*) \le 0$ for any $z \in Z$. </p>
</li>
<li><p>Similarly, $z^* \in P \rightarrow \exists x \ge 0, z^* \ge Ax \rightarrow k \ge 0, k z^* \ge A (kx) \rightarrow kz \in P$. Then $0 \in P$ and $2z^* \in P$, which implies $- y^T z^* \le 0$ and $y^T z^* \le 0$. Hence $y^T z^* = 0$ and $y^T b = y^T y + y^T z^* &gt; 0$. </p>
</li>
<li><p>Further, the fact $z^* + e_i \in Z$ gives $y^T e_i \le 0$ for arbitrary $i$. Therefore $y \le 0$. The  $y^T b &lt; 0$ and $y^T A \le 0$ follow from the same proof given above. </p>
</li>
</ul>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/12/13/Complex-Integration/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/12/13/Complex-Integration/" class="post-title-link" itemprop="url">Complex Integral</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-12-13 22:26:11" itemprop="dateCreated datePublished" datetime="2018-12-13T22:26:11+11:00">2018-12-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-13 16:24:32" itemprop="dateModified" datetime="2019-12-13T16:24:32+11:00">2019-12-13</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>In this article are going to walk through complex integral and establish it step by step. First, we review the classical Riemann integral and see how this motivates complex integral.  </p>
<h1 id="Riemann-Sums"><a href="#Riemann-Sums" class="headerlink" title="Riemann Sums"></a>Riemann Sums</h1><p>Intuitively, given a interval $[a, b]$ and a function $f$ defined on that, the Riemann integral is obtained by dividing $[a, b]$ into many small intervals and summing over the product of the length of each interval and function value at a arbitrary chosen point on the interval. Such a sum is well-defined if it converges to some fixed value when the partition chosen is “refined” enough. </p>
<p><em>DEFINITION.</em><br>Let $f(x)$ be a function defined on a closed interval $[a, b]$. We say a number $J$ is the definite integral of $f$ over $[a, b]$ and that $J$ is the limit of the Riemann sums $\sum_{k = 1}^n f(c_k) \Delta_{k}$ if the following condition is satisfied:  </p>
<p>Given any number $\epsilon &gt; 0$, there is a corresponding number $\delta &gt; 0$ such that for every partition $P = {x_0, x_1, …, x_n }$ of $[a, b]$ with $||P|| &lt; \delta$ （where $||P|| \doteq \max_{1 \le i \le n} \Delta_i$ and $\Delta_i \doteq x_i - x_{i - 1}$) and any choice of $c_k$ in $[x_{k - 1}, x_k]$, we have<br>$$<br>\left| \sum_{k = 1}^n f(c_k) \Delta_k - J \right| &lt; \epsilon<br>$$<br>When the limit exists we write it as the definite integral<br>$$<br>J = \lim_{||P|| \rightarrow 0} \sum_{k = 1}^n f(c_k) \Delta_{k}<br>$$<br>There is a specified notation for this limit of Riemann sums<br>$$<br>\int_a^b f(x) dx = \lim_{||P|| \rightarrow 0} \sum_{k = 1}^n f(c_k) \Delta_{k}<br>$$</p>
<h1 id="Complex-Integral"><a href="#Complex-Integral" class="headerlink" title="Complex Integral"></a>Complex Integral</h1><h2 id="Real-to-complex-function"><a href="#Real-to-complex-function" class="headerlink" title="Real to complex function"></a>Real to complex function</h2><p>How do we extend integral in real line to complex plane. The most simplest extension is of a real to complex function $\gamma(t) = x(t) + i y(t)$, whose integral on a interval is obtained by integrating its real part and imaginary part respectively.  </p>
<p><em>DEFINITION</em> If $\gamma : D \rightarrow C$ is simply a function on a real interval $D = [a, b]$, then the integral $\int_a^b \gamma(t) dt$ is defined as<br>$$<br>\int_a^b \gamma(t) dt = \int_a^b x(t) dt + i\int_a^b y(t) dt,<br>$$<br>where $\gamma(t) = x(t) + i y(t)$.  </p>
<h2 id="Complex-to-complex-function"><a href="#Complex-to-complex-function" class="headerlink" title="Complex to complex function"></a>Complex to complex function</h2><p>Another natural idea is to consider a smooth path $C$ with endpoints $a$ and $b$ on the complex plane and a complex function $f$ whose domain contains the path. </p>
<p>Note we do not even require $a \neq b$; but in case $a = b$, we must specify an orientation for the closed path $C$.  </p>
<p>Next, we repeat the partition and product idea: let $P = {z_0, z_1, …, z_n}$ be a partition of the curve such that $z_0 = a$ and $z_n = b$. A Riemann sum associated with $P$ is just what it is in the real case: $J$ is the limit of the $\sum_{k = 1}^n f(z_k) \Delta_{k}$ (where $\Delta \doteq |z_k - z_{k - 1}| = \sqrt{Re(z_k - z_{k - 1})^2 + Im(z_k - z_{k - 1})^2}$) if the following condition is satisfied </p>
<p>Given any number $\epsilon &gt; 0$, there is a corresponding number $\delta &gt; 0$ such that for every partition $P = {z_0, z_1, …, z_n}$ of $[a, b]$ with $||P|| &lt; \delta$ and any choice of $d_k$ in $[z_{k - 1}, z_k]$, we have<br>$$<br>|\sum_{k = 1}^n f(d_k) \Delta_{k} - J| &lt; \epsilon<br>$$<br>When the limit exists we write it as the definite integral<br>$$<br>J = \lim_{||P|| \rightarrow 0} \sum_{k = 1}^n f(d_k) \Delta_{k}<br>$$<br>There is a specified notation for this limit of Riemann sums<br>$$<br>\int_C f(x) dx = \lim_{||P|| \rightarrow 0} \sum_{k = 1}^n f(d_k) \Delta_{k}<br>$$</p>
<h2 id="Rules-satisfied-by-the-integrals"><a href="#Rules-satisfied-by-the-integrals" class="headerlink" title="Rules satisfied by the integrals"></a>Rules satisfied by the integrals</h2><ol>
<li>Constant Multiple: $\int_C k f(x) dx = k \int_C f(x) dx$. </li>
<li>Sum: $\int_C f(x) + g(x) dx = \int_C f(x) dx + \int_C g(x) dx$</li>
</ol>
<p><em>Proof:</em> For any partition $P$ of $C$ and for every choice of the points $z_k$,<br>$$<br>\sum_{j = 1}^n kf(z_j) \Delta_{z_j} = k \sum_{j = 1}^n f(z_j) \Delta_{z_j} \<br>\sum_{j = 1}^n (f(z_j) + g(z_j))\Delta_{z_j} = \sum_{j = 1}^n f(z_j) \Delta_{z_j} + \sum_{j = 1}^n g(z_j) \Delta_{z_j}<br>$$<br>Taking limit of both side, we get the desired answer. Remark: given two sequence ${ a_1, a_2, …, }$ and ${b_1, b_2, …, }$, if $a_i = b_i$ for arbitrary $i \ge 0$ and $\lim_i b_i = S$, then $\lim_i a_i$ exits and $\lim_i a_i = S$.</p>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><p>To evaluate such integral, we can choose a description $\gamma(t) = x(t) + i y(t) : [a, b] \rightarrow C$ of curve $C$. We partition $C$ by partitioning the interval $[a, b]$ in usual way $P_t = { a = t_0 &lt; t_1&lt;  … &lt; t_n = b }$. Then $\gamma(P_t) \doteq { \gamma(t_0), \gamma(t_1), …, \gamma(t_n) }$ is a partition of $C$.  </p>
<p>If $\gamma$ is continuous, it is uniformly continuous on $[a, b]$. Therefore, as $||P_t|| \rightarrow 0$, $||\gamma(P_t)|| \rightarrow 0$. If $\int_C f(z) dz$ exists, then</p>
<p>$$<br>\int_C f(z) dz = \lim_{||P_t|| \rightarrow 0} \sum_{j = 1}^n f(\gamma(e_j)) \big(\gamma(t_j) - \gamma(t_{j - 1}) \big)<br>$$</p>
<p>for arbitrary choice $e_j \in [t_{j - 1}, t_j]$.</p>
<p>When the derivative of $\gamma$ exists and is continuous, it is uniformly continuous on the closed bounded interval $[a, b]$. We now can rewrite the Riemann sum as  </p>
<p>$$<br>\sum_{j = 1}^n f(\gamma(e_j)) \frac{\gamma(t_j) - \gamma(t_{j - 1})}{t_j - t_{j - 1} }(t_j - t_{j - 1})<br>= \sum_{j = 1}^n f(\gamma(e_j)) \frac{x(t_j) - x(t_{j - 1})+ i (y(t_j) - y_(t_{j - 1}))}{t_j - t_{j - 1} }(t_j - t_{j - 1})<br>$$</p>
<p>By intermediate value theorem, as $x’(t)$ and $y’(t)$ exist, there are some $e_j’ \in [t_{j - 1}, t_j]$ and $e_j’’ \in [t_{j - 1}, t_j]$, such that  </p>
<p>$$<br>\frac{x(t_j) - x(t_{j - 1})}{t_j - t_{j - 1} } = x’(e_j’) \quad \wedge \frac{y(t_j) - y(t_{j - 1})}{t_j - t_{j - 1} } = x’(e_j’’)<br>$$</p>
<p> On the other hand, as $x’(t)$ and $y’(t)$ are uniformly continuous, for arbitrary $\epsilon &gt; 0$, there is a $\delta$ such that if $||P_t|| &lt; \delta$, $|x’(e_j’) - x’(e_j)| &lt; \epsilon$ and $|y’(e_j’’) - y’(e_j)| &lt; \epsilon$. It follows that  </p>
<p>$$<br> \frac{x(t_j) - x(t_{j - 1})+ i (y(t_j) - y_(t_{j - 1}))}{t_j - t_{j - 1} } = x’(e_j) + i y’(e_j) \pm \epsilon(1 + i)\<br> \sum_{j = 1}^n f(\gamma(e_j)) \frac{\gamma(t_j) - \gamma(t_{j - 1})}{t_j - t_{j - 1} }(t_j - t_{j - 1})<br> = \sum_{j = 1}^n f(\gamma(e_j)) \gamma’(e_j) (t_j - t_{j - 1}) \pm \epsilon (1 + i)|C|<br>$$</p>
<p>where $|C|$ is the length of the path $C$.  </p>
<p>Taking the limit of $||P_t|| \rightarrow 0$, we get<br>$$<br>\int_C f(z) dz = \int_a^b f(\gamma(t))\gamma’(t) dt<br>$$</p>
<p><strong>Remark 1:</strong> <em>Can we relax the condition that $\gamma’(t)$ is continuous and that $[a, b]$ is a closed interval?</em>  </p>
<p><strong>Remark 2:</strong> <em>We have also showed that the integration is independent of the choice of $\gamma$, i.e., any representation of $C$ that is continuously differentiable gives the same integration value</em>.  </p>
<h2 id="Anti-derivative"><a href="#Anti-derivative" class="headerlink" title="Anti-derivative"></a>Anti-derivative</h2><p>Now suppose that $F(z) = u(x, y) + i v(x, y)$ and $F’(z) = f(z)$. We claim that $\int_C f(z) dz = F(b) - F(a)$.  </p>
<p>First, $F’(\gamma(t)) = \frac{\partial u}{\partial x} \frac{\partial x}{\partial t} + \frac{\partial u}{\partial y} \frac{\partial y}{\partial t} + i (  \frac{\partial v}{\partial x} \frac{\partial x}{\partial t} + \frac{\partial v}{\partial y} \frac{\partial y}{\partial t}  )$. Therefore,<br>$$<br>\int_C f(z) dz = \int_a^b (\frac{\partial u}{\partial x} \frac{\partial x}{\partial t} + \frac{\partial u}{\partial y} \frac{\partial y}{\partial t}) dt + i \int_a^b (  \frac{\partial v}{\partial x} \frac{\partial x}{\partial t} + \frac{\partial v}{\partial y} \frac{\partial y}{\partial t}  ) dt<br>$$</p>
<p>But<br>$$<br>\begin{aligned}<br>u(x(b), y(b)) - u(x(a), y(a))<br>&amp;= \sum_{j = 1}^n [u(x(t_j), y(t_j)) - u(x(t_{j - 1}), y(t_{j - 1}))] \<br>&amp;= \sum_{j = 1}^n [u(x(t_j), y(t_j)) - u(x(t_j), y(t_{j - 1})) + u(x(t_j), y(t_{j - 1})) - u(x(t_{j - 1}), y(t_{j - 1}))] \<br>&amp;= \sum_{j = 1}^n \frac{u(x(t_j), y(t_j) ) - u(x(t_j), y(t_{j - 1} ) ) }{y(t_j) - y(t_{j - 1} ) } \frac{y(t_j) - y(t_{j - 1} )}{ t_j - t_{j - 1} }(t_j - t_{j - 1})\<br>&amp;\quad +\sum_{j = 1}^n \frac{u(x(t_j), y(t_{j - 1})) - u(x(t_{j - 1}), y(t_{j - 1}))}{x(t_j) - x(t_{j - 1})} \frac{x(t_j) - x(t_{j - 1}) }{t_j - t_{j - 1} } (t_j - t_{j - 1}) \<br>&amp;= \sum_{j = 1}^n [u_y’ (x(t_j), y^<em>_j) y’(e_j’) + u_x’ (x^</em><em>j, y(t</em>{j - 1})) x’(e_j’’)] (t_j - t_{j - 1})\<br>\end{aligned}<br>$$</p>
<p>where $y^<em><em>j \in [ y( t</em>{j - 1} ), y( t_j ) ]$, $x^</em><em>j \in [ x( t</em>{j - 1} ), x( t_j ) ]$, $e_j’, e_j’’ \in [ t_{j - 1}, t_j ]$. If $u’<em>x, u’_y, x’(t), y’(t)$ are continuous, then as $||P_t|| \rightarrow 0$, $\sum</em>{j = 1}^n [u_y’ ( x( t_j ), y( t_j ) ) y’( t_j ) + u_x’ ( x( t_j ), y( t_j ) ) x’( t_j ) ] ( t_j - t_{j - 1} ) = \sum_{j = 1}^n \frac{\partial u}{\partial t} ( t_j - t_{j - 1} ) \rightarrow u(x(b), y(b) ) - u(x(a), y(a) )$.  An immediately consequence is that  </p>
<p>$$<br>F(\gamma(b)) - F(\gamma(a)) = \int_C F’(\gamma(t)) dt<br>$$</p>
<p>On the other hand, since $F(z)$ is differential, $\lim_{h \rightarrow 0} \frac{F(z + h) - F(z) }{h} = \frac{\partial u}{\partial x}  + i \frac{\partial v}{\partial x} = \lim_{ih \rightarrow 0} \frac{F(z + ih) - F(z) }{ih} = -i \frac{\partial u}{\partial y}  + \frac{\partial v}{\partial y}$. It holds that $\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y}$ and $\frac{\partial v}{\partial x}  = -\frac{\partial u}{\partial y}$. Therefore,<br>$$<br>F’(\gamma(t)) = \frac{\partial u}{\partial x} \frac{\partial x}{\partial t} - \frac{\partial v}{\partial x} \frac{\partial y}{\partial t} + i (  \frac{\partial v}{\partial x} \frac{\partial x}{\partial t} + \frac{\partial u}{\partial x} \frac{\partial y}{\partial t}  ) = (\frac{\partial u}{\partial x} + i \frac{\partial v}{\partial x}) ( \frac{\partial x}{\partial t} + i \frac{\partial y}{\partial t} ) = F’(\gamma(t)) \gamma’(t) = f(\gamma(t)) \gamma’(t)<br>$$<br>and<br>$$<br>F(\gamma(b)) - F(\gamma(a)) = \int_C f(\gamma(t)) \gamma’(t) dt<br>$$</p>
<p>Remark: That $u_x’, u_y’$ are continuous is a strong condition. What we need in the proof is just that *</p>
<p>$$<br>\begin{aligned}<br>u(x(t_j), y(t_j))<br>&amp;= u(x(t_{j - 1}), y(t_{j - 1})) \<br>&amp;+ u_x’(x(t_{j - 1}), y(t_{j - 1})) (x(t_j) -  x(t_{j - 1})) \<br>&amp;+ u_y’(x(t_{j - 1}), y(t_{j - 1})) (y(t_j) -  y(t_{j - 1})) \<br>&amp;+ o(x(t_j) -  x(t_{j - 1}), y(t_j) -  y(t_{j - 1}))<br>\end{aligned}<br>$$</p>
<p>or</p>
<p>$$<br>\begin{aligned}<br>u(x(t_{j - 1}) + \delta_x, y(t_{j - 1}) + \delta_y)<br>&amp;= u(x(t_{j - 1}), y(t_{j - 1})) \<br>&amp;+ u_x’(x(t_{j - 1}), y(t_{j - 1})) \delta_x \<br>&amp;+ u_y’(x(t_{j - 1}), y(t_{j - 1})) \delta_y \<br>&amp;+ o(\delta_x, \delta_y)<br>\end{aligned}<br>$$</p>
<p><em>i.e., $u$ is differentiable at every point in the domain.</em>  </p>
<p>Question: Is is possible that $u$ is differentiable but its partial derivatives are not continuous? The answer is NO. First we consider an one dimension counter example:<br>$$<br>f(x) =<br>\begin{cases}<br>x^2 \sin \frac{1}{x} \quad \forall x \neq 0, \<br>0, \quad if \quad x = 0<br>\end{cases}<br>$$<br>To show $f(x)$ is differential at $0$, we use the definition of derivative:<br>$$<br>f’(0) = \lim_{h \rightarrow } \frac{f(h) - f(0)}{h - 0} = \lim_{h \rightarrow 0} h \sin \frac{1}{h} = 0<br>$$<br>On the other hand, $f(x)$ is always differentiable from $0$:<br>$$<br>f’(x) = 2x \sin \frac{1}{x} + x^2 ( -1 / x^2) cos \frac{1}{x} = 2x \sin \frac{1}{x} -cos \frac{1}{x}<br>$$<br>Hence, $f(x)$ is differentiable everywhere, but $f’(x)$ is not continuous at $0$.  </p>
<p>The above example can be easily extended to two dimension case:<br>$$<br>f(x, y) =<br>\begin{cases}<br>(x^2 + y^2) \sin \frac{1}{ \sqrt{x^2 + y^2} } \quad \forall (x, y) \neq (0, 0) \<br>0 \qquad \qquad \qquad \qquad \quad if \quad  (x, y) = (0, 0)<br>\end{cases}<br>$$<br>By definition, $f(x, y)$ is differential at $(0, 0)$,<br>$$<br>\lim_{||(x, y)|| \rightarrow 0} \frac{||f(x, y) - f(0) - (0,0) \cdot (x, y)||}{||(x, y)||} \le \lim_{||(x, y)|| \rightarrow 0} \frac{||x^2 + y^2||}{||(x, y)||} = \lim_{||(x, y)|| \rightarrow 0} ||(x, y)||= 0<br>$$<br>However, it partial derivative from $(0, 0)$<br>$$<br>\frac{\partial f}{\partial x} = 2x \sin \frac{1}{ \sqrt{x^2 + y^2} } + (x^2 + y^2) (-\frac{ 2x }{ \sqrt{ x^2 + y^2 }^{3} }) \cos \frac{1}{ \sqrt{x + y} } = 2x \sin \frac{1}{ \sqrt{x^2 + y^2} } - \frac{ 2x }{ \sqrt{ x^2 + y^2 } } \cos \frac{1}{ \sqrt{x^2 + y^2 } }<br>$$<br>and<br>$$<br>\frac{\partial f}{\partial x}(0, 0) = \lim_{h \rightarrow} \frac{h^2 \sin \frac{1}{|h|} }{h} = 0<br>$$<br>Therefore, $\partial f / \partial x$ is not continuous.  </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/12/01/Separation-Plane-Theorem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/12/01/Separation-Plane-Theorem/" class="post-title-link" itemprop="url">Separation Plane Theorem</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-12-01 20:17:53" itemprop="dateCreated datePublished" datetime="2018-12-01T20:17:53+11:00">2018-12-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-14 11:02:01" itemprop="dateModified" datetime="2019-12-14T11:02:01+11:00">2019-12-14</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Given a convex and closed set $S$ and a point $p$, if $p$ does not belongs to $S$, then the <em>Separation Theorem</em> states that there is a separation plane between $S$ and $p$. </p>
<p>To prove it, define $\delta = \min { ||s - p|| \mid s \in S }$, where $||\cdot ||$ is the $l_2$ norm. </p>
<p><em>Lemma</em>: There is indeed a point $s^* \in S$ that achieves $||s^* - p || = \delta$.</p>
<p><em>Proof</em>: </p>
<ol>
<li>Pick arbitrary point $s \in S$. Denote $r = ||s - p||$. Define $S’ = S \cap {||x - p|| \le r }$. By definition $S’$ is nonempty, bounded, and closed. </li>
<li>Define a function $f: S’ \rightarrow R$ by $f(s) = ||s - p||$. $f$ is a continuous function. Combining with the fact $S’$ is bounded and closed, there exists a point $s^*$ that minimizes $f(s)$. </li>
<li>We claim that $f(s^*) = \delta$. Otherwise, there is a point $s’’ \in S$, s.t., $f(s^*) &gt; ||s’’ - p|| &gt; \delta$. But this implies $s’’ \in S’$, a contradicting $s^* = \min_{s \in S’} f(s)$. </li>
</ol>
<p><em>Lemma:</em> $s^*$ is unique. </p>
<p><em>Proof:</em> The uniqueness results from the convexity of $S$. If not, let $s’’$ be another optimal point. Now $||q - s’|| = \delta$ and $||q - s’’|| = \delta$. The middle point between $s’$ and $s’’$ is clearly closer to $p$ than both $s’$ and $s’’$, as<br>$$<br>||p - (s’ + s’’) / 2|| = || (p - s’) / 2 + (p - s’’) / 2|| \le 1/2 ||p - s’|| + 1/2 ||p - s’’|| = \delta<br>$$<br>The inequality is tight if $s’ \neq s’’$. Therefore, we use $s^*$ to indicate the unique point. </p>
<!---
To see this, let $s_i$ be  a sequence such that $\lim_i ||s_i - p|| = \delta$.  Let $N$ be a number such that $\forall i, j \ge N$, $||s_i - p|| \le \delta + \epsilon$ and $||s_j - p|| \le \delta + \epsilon$. This implies that $s_i$ and $s_j$ are located between the ball $B(p, \delta)$ and $B(p, \delta + \epsilon)$. Does this necessarily means that $s_i$ and $s_j$ are close? Without the condition of $S$ being convex, the answer is no. $s_i$ and $s_j$ can lie on a line that passes through $p$ and their distance can be as far as $2\delta + 2\epsilon$. Is $S$ is convex, things become completely different. The line segment that connects $s_i$ and $s_j$ can not intersect with $B(p, \delta)$, otherwise the distance between $p$ and $S$ is smaller. This imposes restriction on the possible locations of $s_i$ and $s_j$. Given $s_i$, what is the longest distance between $s_j$ and $s_i$, conditioning on that $\delta \le ||p - s_j|| \le \delta + \epsilon$ and $S$ being convex? This is given by 
$$
||s_i - s_j|| \le 2\sqrt{(\delta + \epsilon)^2 - \delta^2}=2\sqrt{2\delta\epsilon + \epsilon^2}
$$

It follows that $\{s_i\}$ is a *[Cauchy sequence](https://en.wikipedia.org/wiki/Cauchy_sequence)* there is a limit $s' = \lim_i s_i$. As $S$ is a closed set, $s' \in S$. 




Moreover, $s'$ is unique. If not, let $s''$ be another optimal point. Now $||q - s'|| = \delta$ and $||q - s''|| = \delta$. The middle point between $s'$ and $s''$ is clearly closer to $p$ than both $s'$ and $s''$, as  
$$
||p - (s' + s'') / 2|| = || (p - s') / 2 + (p - s'') / 2|| \le 1/2 ||p - s'|| + 1/2 ||p - s''|| = \delta
$$
The inequality is tight if $s' \neq s''$. Therefore, we use $s^*$ to indicate the unique point. 
-->

<p><em>Theorem</em>: $(p - s^*)^T(x - s^*) = 0$ is a separation plane between $S$ and $p$. </p>
<p><em>Proof</em>. </p>
<ol>
<li><p>$(p - s^*)^T(p - s^*) = \delta^2 &gt; 0$ since $p \notin S$ and $S$ is closed. </p>
</li>
<li><p>We claim that $\forall s \in S​$, $(p - s^*)^T(s - s^*) \le 0​$. Consider any real number $t \in (0, 1)​$, by convexity, $s^* + t(s - s^*) \in S​$. By the definition of $s^<em>​$,<br>$$<br>||t(s - s^</em>) + s^* - p||^2 = ||p - s||^2 - 2t(p - s^*)^T(s - s^*) + t^2||s - s^*||^2 \ge ||p - s^*||^2<br>$$<br>Therefore, $\frac{t}{2}||s - s^*||^2 \ge (p - s^*)^T(s - s^*)$. As $t\rightarrow 0$,  we obtained the desired result. </p>
</li>
</ol>
<!---

Otherwise, suppose that there is another point $s^+ \in S$  such that $\gamma \doteq (p  - s^*)^T (s^+ - s^*) > 0$, then $s^*$ is not the closest point from $S$ to $p$. To see why, consider the points in the line segment spanned by $s^*$ and $s^+$. Such a point must belong to the convex set $S$ and can be expressed as $s^* + t (s^+ - s^*) $ for $t \in (0, 1)$, whose distance to $p$ is given by 
$$
\begin{aligned}
&(s^* + t(s^+ - s^*) - p)^T(s^* + t(s^+ - s^*) - p) \\
=& (s^* - p)^T(s^* - p) + 2t(s^+ - s^*)(s^* - p) + t^2(s^+ - s^*)^T(s^+ - s^*) \\
=& \delta^2 -2\gamma t + ||s^+ - s^*||^2 t^2
\end{aligned}
$$
As a function of $t$, the distance has value $\delta^2$ and negative derivative when $t = 0$. Therefore, there must be a point whose distance is close to $p$ in $S$, a contradiction. 

-->

<!---

The separation plane is given by $(p - s^*)^T(x - s^*) \ge 0$. We claim that the points in $S$ lie on the where $(p - s^*)^T(x - s^*) \le 0$ while $p$ is on the side with $(p - s^*)^T(p - s^*) > 0$. The second part is easy to prove: as $(p - s^*)^T(p - s^*) \ge 0$ and $p \notin S$, it must be the case $(p - s^*)^T(p - s^*) > 0$. For the first part, suppose that there is another point $s^+ \in S$  such that $\gamma \doteq (p  - s^*)^T (s^+ - s^*) > 0$, then $s^*$ is not the closest point from $S$ to $p$. To see why, consider the points in the line segment spanned by $s^*$ and $s^+$. Such a point must belong to the convex set $S$ and can be expressed as $s^* + t (s^+ - s^*) $ for $t \in (0, 1)$, whose distance to $p$ is given by 
$$
\begin{aligned}
&(s^* + t(s^+ - s^*) - p)^T(s^* + t(s^+ - s^*) - p) \\
=& (s^* - p)^T(s^* - p) + 2t(s^+ - s^*)(s^* - p) + t^2(s^+ - s^*)^T(s^+ - s^*) \\
=& \delta^2 -2\gamma t + ||s^+ - s^*||^2 t^2
\end{aligned}
$$
As a function of $t​$, the distance has value $\delta^2​$ and negative derivative when $t = 0​$. Therefore, there must be a point whose distance is close to $p​$ in $S​$, a contradiction. 

-->
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/11/21/RSA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/11/21/RSA/" class="post-title-link" itemprop="url">RSA</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-11-21 21:52:18" itemprop="dateCreated datePublished" datetime="2018-11-21T21:52:18+11:00">2018-11-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-04 20:52:46" itemprop="dateModified" datetime="2019-12-04T20:52:46+11:00">2019-12-04</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>We discuss the problem of sending a message secretly over the internet. Suppose the original message is a sequence $x$, the encrypt message is $y$. </p>
<p>One solution is to perform XOR operation. Suppose there is a key $(k)_2$ that is known both to the sender the receiver. Then the sender encrypt the message by<br>$$<br>(y)_2 = (x)_2 \oplus k<br>$$<br>The receiver can decrypt the message by<br>$$<br>(x)_2 = (y)_2 \oplus k<br>$$<br>Given $x$ with length $n$, if $k$ is chosen uniformly at random from ${0, 1}^n$, then $(y)_2$ is a sequence uniformly at random from ${0, 1}^n$. If the message is sent only one time, the eavesdropper can’t get more information about $x$ after seeing $y$. </p>
<p>Two drawbacks exists. First, how can the sender exchange the key $k$ with the receiver without meeting each other. Second, if the many messages are sent, there are frequency pattern associated with $y$, making it breakable. </p>
<p>RSA encryption algorithm overcomes the first issue by generating two keys for the receiver: the secrete key and the public key. The public key is distributed across the internet. The sender encrypts the message $x$ with the public key. Only the receiver who has the secret key can decrypt the message. The mathematics behind is explained as follows. </p>
<p>Question to ponder: can we attack RSA by the frequency pattern?</p>
<p>First generate two prime number $p, q$ and let $N = pq$. Further, we find a integer $e$, such that </p>
<ol>
<li>$e$ is coprime to $(p - 1)(q - 1)$, i.e., $\exists d$, such that $ed \equiv 1 \mod (p - 1)(q - 1)$. </li>
<li>$e \neq p$, $e \neq q$. </li>
</ol>
<p>Question to ponder: does such $e$ exists? </p>
<p>Answer: YES. There are $O(\frac{(p - 1)(q - 1) }{ \log (p - 1)(q - 1) } -  \frac{ \sqrt{ (p - 1)(q - 1) } }{ \log \sqrt { (p - 1)(q - 1) } } )$ prime numbers in $(\sqrt{(p - 1)(q - 1)}, (p - 1)(q - 1))$, which can not be prime factors of $(q - 1)(p -  1)$. </p>
<p>Then we give out the pair as <em>public key</em>:<br>$$<br>(n, e)<br>$$</p>
<p>And keep in secrete the triple as <em>private key</em>:<br>$$<br>(p, q, d)<br>$$</p>
<p>The algorithm for encryption and decryption is as follows:</p>
<p>Encryption:<br>$$<br>y = f(x) = x^e \pmod N<br>$$</p>
<p>Decryption:<br>$$<br>g(y) = y^d \pmod N<br>$$</p>
<p>The key theorem states:</p>
<p><em>Theorem</em>:<br>$$<br>g(y) = x<br>$$</p>
<p><em>Proof 1:</em> the first proof relies on a result derived from the Chinese Reminder Theorem, which i that for any integer $a &lt; b$, we have<br>$$<br>a \equiv b \mod p \vee a \equiv b \mod q<br>$$<br>Then, $p | (b - a)$ and $q | (b - a)$. If follows that $N | (b - a)$, since $p$ and $q$ are primes and $N$ is their least common multiple. </p>
<p>Now define $m = x^{ed} = x^{k(p - 1)(q - 1) + 1}$. By Fermat’s Little Theorem,<br>$$<br>m \equiv x  \mod p \wedge m \equiv x \mod q<br>$$</p>
<p>Hence $N | (m - x)$ and $m \equiv x \mod N$. </p>
<p><em>Proof 2:</em><br>$$<br>y^d = x^{ed} = x^{k(p - 1)(q - 1) + 1} \pmod N<br>$$</p>
<p>Case 1: this is the easy case in which $x$ is coprime to $N$. Then by Fermat-Euler theorem, $x^{\varphi(N)} = 1 \pmod N$. It follows immediately that $x^{ed} = x \pmod N$. </p>
<p>Case 2: otherwise, $x = lp$ for some $1 \le l \le q$ or $x = lq$ for some $1\le l \le p$. WLOG, we just consider the former case. Now $y^d = (lp)^{k(p - 1)(q - 1) + 1} \pmod N$.  On the other hand, as $(lp)^{k(p - 1)}$ is relative prime to $q$, we conclude that $((lp)^{k(p-1)})^{q- 1} = mq + 1$ for some integer $m$, by Fermat’s little theorem. Therefore, $y^d = (mq + 1) x = (mq + 1) (lp) = mlpq + lp = lp = x \pmod N$ , which finishes our proof. </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/11/20/Fermat-s-Little-Theorem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/11/20/Fermat-s-Little-Theorem/" class="post-title-link" itemprop="url">Fermat's Little Theorem</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-11-20 22:55:39" itemprop="dateCreated datePublished" datetime="2018-11-20T22:55:39+11:00">2018-11-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2018-11-28 02:39:47" itemprop="dateModified" datetime="2018-11-28T02:39:47+11:00">2018-11-28</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Fermat’s Little Theorem is of fundamental importance in cryptography. It states that given arbitrary prime number $p$ and any positive integer $a \in N^+$, we have<br>$$<br>a^{p - 1} = 1 \quad \pmod p<br>$$<br>Indeed, it suffices to show the theorem holds for any number that belongs to $[p]^+ \doteq { 1, 2, …, p - 1}$. There are several proofs for this fundamental theorem. </p>
<h5 id="Proof-One"><a href="#Proof-One" class="headerlink" title="Proof One"></a>Proof One</h5><p>Consider the function $f : [p]^+ \rightarrow [p]^+$ such that $f(x) = ax \mod p$. Note for any $x, x’ \in [p]^+$, $ax = ax’ \mod p$ implies that $x = x’$, since $p$ is a prime. It immediately follows that $f$ is a bijection. Therefore, the set of numbers ${f(1), f(2), …, f(p - 1)}$ is exactly the same as $[p]^+$ (might be in different order). Now we take product of all number in  $[p]^+$,<br>$$<br>(p - 1)! = \prod_{i = 1}^{p - 1} (ai) = a^{p - 1} (p - 1)! \pmod p<br>$$<br>As $p$ is a prime, every non-zero integer has a multiplicative inverse mod $p$. Therefore we can cancel out $(p - 1)!$ from both side by multiplying its inverse and get $1 = a^{p - 1} \pmod p$, which finishes the proof. </p>
<p>Remark: an extension of the above proof gives Fermat-Euler theorem which relaxes the condition that $p$ is prime to p being any positive integer and states for any positive integer $a \in N^+$ such that $gcd(a, p) = 1$ (i.e., $a$ and $p$ are coprime) , it holds that<br>$$<br>a^{\varphi(p)} = 1 \pmod p<br>$$<br>where $\varphi(p)$ is the number of elements that are coprime to $p$ between ${1, 2, .., p - 1}$. When $p$ is prime, $\varphi(p)  = p - 1$. Clearly, Fermat-Euler is a generation of Fermat’s Little Theorem. The proof is similar to the previous by observing that: let $S \subset [p]^+$ be the set of elements that are coprime to  $p$, then $f: S \rightarrow S$ given by $f(x) = ax \pmod p$ is a bijection. Therefore, $\prod_{x \in S} x = a^{\varphi(p)} \prod_{x \in S} x \pmod p$. Cancelling out the factor $\prod_{x \in S} x$ gives the desired result. </p>
<h5 id="Proof-Two"><a href="#Proof-Two" class="headerlink" title="Proof Two"></a>Proof Two</h5><p>This proof uses the binomial expansion as follows:<br>$$<br>\begin{aligned}<br>(a + 1)^p<br>&amp;= a^p + \binom{p}{1} a^{p - 1} + … + \binom{p}{p - 1} a + 1  &amp;\pmod p \<br>&amp;= a^{p} + 1 &amp;\pmod p \<br>&amp;= (a - 1)^{p} + 1 + 1 &amp;\pmod p \<br>&amp;= … \<br>&amp;= \begin{matrix} \underbrace{1 + 1 + … + 1} \ a + 1 \end{matrix} &amp;\pmod p  \<br>&amp;= a + 1 &amp;\pmod p<br>\end{aligned}<br>$$<br>The second equality holds since for $1 \le i \le p - 1$, the coefficient $\binom{p}{i} = \frac{p (p - 1) … (p - i + 1)}{i !}$ divides $p$, as $p$ is relative prime to all integers $1, 2, …, i$. The third equality follows from respectively applying the previous expansion. Finally, we get Fermat’s Little Theorem by multiplying both sides of $(a + 1)^p = (a + 1) \pmod p$ by the inverse of $a + 1$ module $p$. </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/11/08/Some-elementary-results-of-number-theory/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/11/08/Some-elementary-results-of-number-theory/" class="post-title-link" itemprop="url">Some elementary results of number theory</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-11-08 20:08:51" itemprop="dateCreated datePublished" datetime="2018-11-08T20:08:51+11:00">2018-11-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2018-11-11 02:11:57" itemprop="dateModified" datetime="2018-11-11T02:11:57+11:00">2018-11-11</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="Multiplicative-Inverse"><a href="#Multiplicative-Inverse" class="headerlink" title="Multiplicative Inverse"></a>Multiplicative Inverse</h4><p>Given positive integers $x$ and $y$, $z$ is called the multiplicative inverse of $x$ module $y$ if $xz \equiv 1 \mod y$. </p>
<p><strong>Theorem</strong>.<br>$x$ has a multiplicative inverse module $y$ iff $gcd(x, y) = 1$.<br><em>Proof.</em><br>Consider the set $S = { ax + by \mid a, b \in Z}$. Let $s^* = a^* x + b^* y$ be the smallest positive integer in $S$. Our proof relies on the following lemma.</p>
<p><em>Lemma</em>: $gcd(x,y) = s^*$.<br>First notice that every element is $S$ is a linear combination of both $x$ and $y$, therefore a multiple of $gcd(x, y)$.  We have $gcd(x, y) | s^*$ and $gcd(x, y) \le s^*$. Now we claim that $s^* | x$ and $s^* | y$.  </p>
<p>To verify the above claim, suppose $s^* \nmid x$. Then $x$ can be decomposed into $x = k s^* + l$ for some positive integers $k$ and $l \in [1, s^*)$.  It follows that $l = x - k s^* = (1 - a^*) x + (-b^*) y \in S$, contradicting $s^*$ being the smallest positive element in $S$. Similarly argument holds for $s^* | y$. </p>
<p>Therefore, $s^*$ is a common divisor of both $x$ and $y$ and $s^* \le gcd(x, y)$. </p>
<p>It concludes that $s^*$ equals to $gcd(x, y)$. </p>
<p>The proof of the above theorem immediately follows from the lemma. </p>
<ol>
<li><p>$gcd(x, y) = 1 \rightarrow x$ has a multiplicative inverse.<br>In this case, $s^* = a^* x + b^* y = 1$. $a^*$ is th multiplicative inverse of $x$ module $y$. </p>
</li>
<li><p>$x$ has a multiplicative inverse $\rightarrow gcd(x, y) = 1$.<br>If $x$ has a multiplicative inverse, there exists some $z$ and $l$, such that $zx = ly + 1$. </p>
</li>
</ol>
<p><strong>Theorem</strong>.<br>If $x$ has a multiplicative inverse module $y$, it must be unique (module $y$).<br><em>Proof.</em><br>Let $a$ and $b$ both be the multiplicative inverse of $x$ module $y$, i.e., $a x \equiv 1 \mod y$ and $bx \equiv 1 \mod y$. It turns out that $a \equiv a \cdot 1 \equiv a (xb) \equiv (ax) b \equiv b \mod y$.</p>
<h4 id="Euclid’s-Algorithm"><a href="#Euclid’s-Algorithm" class="headerlink" title="Euclid’s Algorithm"></a>Euclid’s Algorithm</h4><p>Euclid’s algorithm computes $gcd(x, y)$ as follows: </p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int gcd(int x, int y) &#123;</span><br><span class="line">    if(y &#x3D;&#x3D; 0) return x;</span><br><span class="line">    return gcd(y, x mod y);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> When $y == 0$, clearly $gcd(x, y) = x$. If $x &lt; y$, $x mod y = x$. The algorithm exchanges the value of $x$ and $y$ after the first recursion. It suffices to consider only the case where $x \ge y &gt; 0$. </p>
<p> <em>Lemma</em>: if $x \ge y &gt; 0$, then $gcd(x, y) = gcd(y, x \mod y)$.<br> We show that any common divisor $d$ of $x$ and $y$ is a common divisor of $y$ and $x \mod y$. Suppose $x = k d$ and $y = l d$, then $x - y = (k - l) d$. It follows from induction $d$ divides $x \mod y$, since $x \mod y = x - y - … - y$. The other direction follows in a similar manner. </p>
<p>We can modify the Euclid’s algorithm to return explicitly values of $a^*, b^*$ s.t. $gcd(x, y) = s^* = a^* x + b^* y$. </p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[] gcd(int x, int y) &#123;</span><br><span class="line">    if(y &#x3D;&#x3D; 0) return (x, 1, 0);</span><br><span class="line">    (s, a&#39;, b&#39;) &#x3D; gcd(y, x mod y);</span><br><span class="line">    return (s, b&#39;, a&#39; - b&#39;(x &#x2F; y));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>To verify the correctness of the algorithm, suppose $s = a’ y + b’ (x \mod y)$. Then $s = a’ y + b’(x - \lfloor x / y \rfloor y) =b’ x + (a’ - b’ \lfloor x / y \rfloor) y$. This is why the algorithm work. </p>
<p><em>Example:</em><br>$$<br>\begin{aligned}<br>&amp; gcd(9, 6) = (3, 1, -1)  \quad [-1 = 0 - 1 * 9 / 6] \<br>&amp; \rightarrow gcd(6, 3) = (3, 0, 1) \quad [1 = 1 - 0 * 6 / 3]\<br>&amp; \quad \rightarrow gcd(3, 0) = (3, 1, 0) \<br>\end{aligned}<br>$$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/10/26/Bellman-Ford/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/10/26/Bellman-Ford/" class="post-title-link" itemprop="url">Bellman Ford</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-10-26 22:13:41" itemprop="dateCreated datePublished" datetime="2018-10-26T22:13:41+11:00">2018-10-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2018-10-27 02:06:16" itemprop="dateModified" datetime="2018-10-27T02:06:16+11:00">2018-10-27</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Here we discuss the Bellman Ford algorithm for computing shortest path or negative cycle in an undirected weighted graph $G = (V, E, W)$ that contains negative edges. </p>
<p>Recall the Dijkstra algorithm bases on the induction of the number of vertices. The Bellman Ford algorithm, on the other hand, bases on the induction of the number of edges of the shortest path. </p>
<p>Let $P_k = (s, v_1, v_2, .., v_k, t)$ be the shortest path between $s$ and $t$. If we finds the shortest $P_{k - 1} = (s, v_1, v_2, …, v_{k - 1})$, then we can easily find the path $P_k$. To this end, we define dist[v] the distance from source node $s$ to vertex $v$. </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">std::vector&lt;int&gt; dist(n, INT_MAX); </span><br><span class="line">std::vector&lt;int&gt; pred(n, 0);</span><br><span class="line">dist[s] &#x3D; 0;</span><br><span class="line">for(int i &#x3D; 0; i &lt; n - 1; ++i) &#123;</span><br><span class="line">    for each edge (u, v) &#123;</span><br><span class="line">        if(dist[u] + w(u, v) &lt; dist[v]) &#123;</span><br><span class="line">            dist[v] &#x3D; dist[u] + w(u, v);</span><br><span class="line">            pred[v] &#x3D; u;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>If the graph does not contain a negative cycle, the above code compute the shortest path correctly. On the other hand, to check the existence of a negative, we could execute an additional iteration after the above code</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">bool check_negative_cycle() &#123;</span><br><span class="line">     for each edge (u, v) &#123;</span><br><span class="line">        if(dist[u] + w(u, v) &lt; dist[v]) &#123;</span><br><span class="line">            dist[v] &#x3D; dist[u] + w(u, v);</span><br><span class="line">            pred[v] &#x3D; u;</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;    </span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>The correctness can be verified as follows: if the graph does not contain negative cycle, the any shortest path contains at most $(n - 1)$-th edges. The value of $dist[v]$ should not change in this $n$-th iteration. </p>
<p>To return a negative cycle, when we find an edge $(u, v)$ such that $dist[u] + w(u, v) &lt; dist[v]$ (in this $n$-th iteration), we can trace the predecessor of $v$ until we encounter a cycle. Notice that this cycle may not necessarily contains $v$. But we claim that this cycle must be negative. </p>
<h4 id="Theorem"><a href="#Theorem" class="headerlink" title="Theorem"></a>Theorem</h4><p>Let $C = (v_1, v_2, …, v_j)$ be the cycle we found, such that $pred[v_i] = pred[v_{i - 1}], \forall 2 \le i \le j$ and $pred[v_1] = v_j$. WLOG, let $v_1$ be the vertex whose value $pred[v_1]$ is updated latest among $pred[v_1], pred[v_2], …, pred[v_j]$. It holds that </p>
<p>$$<br>\begin{aligned}<br>dist[v_2] &gt; dist[v_1] + w(v_1, v_2) \<br>\text{this holds with strict inequality since we update } pred[v_1] \text{ lastly }\<br>dist[v_3] \ge dist[v_2] + w(v_1, v_2) \<br>… \<br>dist[v_1] = dist[v_j] + w(v_1, v_2) \<br>\end{aligned}<br>$$</p>
<p>It follows that $\sum_{i = 1}^j dist[v_i] &gt; \sum_{i = 1}^j dist[v_i] dist[v_i] + \sum_{i = 2}^j w(v_{i - 1}, v_i) + w(v_j, v_1)$, which implies that $\sum_{i = 2}^j w(v_{i - 1}, v_i) + w(v_j, v_1) &lt; 0$. </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/10/18/Fully-Binary-Tree/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/10/18/Fully-Binary-Tree/" class="post-title-link" itemprop="url">Fully Binary Tree</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-10-18 23:23:51" itemprop="dateCreated datePublished" datetime="2018-10-18T23:23:51+11:00">2018-10-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2018-10-19 02:30:30" itemprop="dateModified" datetime="2018-10-19T02:30:30+11:00">2018-10-19</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>A binary tree is called a fully binary tree if each non-leaf node has two children. Suppose there are $n$ leaf nodes. Then the number of non-leaf nodes is $n - 1$. To see this, we remove a pair of leaves that shares the same parent repeatedly until there are 3 nodes left. Each time we remove such a pair of nodes, both the number of leaf nodes and the number of non-leaf nodes decreases by one. Therefore the difference between the number of leaf and non-leaf node remains. By induction we see that the difference is exactly one. </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/09/16/Max-Cut/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/09/16/Max-Cut/" class="post-title-link" itemprop="url">Max Cut</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2018-09-16 17:10:22 / Modified: 23:01:31" itemprop="dateCreated datePublished" datetime="2018-09-16T17:10:22+10:00">2018-09-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Given an undirected graph $G = (V, E)$, the maximum cut problem asks for a subset $S \subset V$ that maximizes the number of edges which cross $S$, i.e., $S = \arg \max_{S’ \subset S} \delta(S)$, where $\delta(S) = |{ \ (i, j) \ \mid \ (i, j) \in E \wedge i \in S, j \notin S}|$. </p>
<h5 id="Programming-Formulation"><a href="#Programming-Formulation" class="headerlink" title="Programming Formulation"></a>Programming Formulation</h5><p>To solve the problem, we can assign each vertex $i \in V$ a binary variable $x_i \in {-1, 1}$, which serves as an indicator of whether $i$ belongs to $S$. WLOG, we can specify here that $i \in S$ if $x_i = 1$. Now the value of $\delta(S)$ can be expressed as </p>
<p>$$<br>\delta(S) = \sum_{(i,j) \in E} \frac{1 - x_i x_j}{2}<br>$$</p>
<p>The correctness of the expression can be verified as follows: (1) if $i, j \in V$ belongs to the same partition, i.e, $i, j \in S$ or $i, j \in V - S$, then $x_i x_j = 1$ and $\frac{1 - x_i x_j}{2} = 0$. (2) Otherwise, $x_i x_j = -1$ and $\frac{1 - x_i x_j}{2} = 1$. </p>
<h5 id="Convex-Relaxation"><a href="#Convex-Relaxation" class="headerlink" title="Convex Relaxation"></a>Convex Relaxation</h5><p>We consider a relaxation of the above programming:<br>$$<br>\begin{aligned}<br>&amp;&amp;\max &amp;&amp;\sum_{(i,j) \in E} \frac{1 - x_i^T x_j}{2} \<br>&amp;&amp;s.t., &amp;&amp; x_i^T x_i = 1 &amp;&amp;\forall i \in V \<br>&amp;&amp;      &amp;&amp; x_i \in R^n   &amp;&amp;\forall i \in V<br>\end{aligned}<br>$$</p>
<p>Note that this can be transformed into a convex optimization:<br>$$<br>\begin{aligned}<br>&amp;&amp;\max &amp;&amp;\sum_{(i,j) \in E} \frac{1 - y_{i,j}}{2} &amp;&amp;\<br>&amp;&amp;s.t., &amp;&amp; y_{i,i} = 1 &amp;&amp;\forall i \in V \<br>&amp;&amp;      &amp;&amp; y_{i,j} = y_{j,i} &amp;&amp;\forall i, j \in V \<br>&amp;&amp;      &amp;&amp; Y = (y_{i,j}) \succcurlyeq 0<br>\end{aligned}<br>$$</p>
<p>The above problem can be solved within $\epsilon$ additive error in polynomial time in terms of input size and $\log 1/\epsilon$. </p>
<h5 id="Rounding"><a href="#Rounding" class="headerlink" title="Rounding"></a>Rounding</h5><p>To round the fractional solution to integral solution, we take a random unit vector $v$ from $R^n$. For each vertex $i$, if $v^T x_i \ge 0$ we set $x_i’ = 1$ otherwise we set $x_i’ = 0$. For any pair $i, j \in V$, denote the angle between $x_i$ and $x_j$ as $\theta_{i,j} = \arccos x_i^T x_j$. Notice that $\sum_{(i,j) \in E} \frac{1 - x_i x_j}{2} = \sum_{(i,j) \in E} \frac{1 - \cos \theta_{i,j}}{2}$. Furthermore, the probability that $x_i’$ and $x_j’$ are assigned different values is given by $\theta_{i,j} / \pi$. By linearity of expectation, the expected cut value is </p>
<p>$$<br>E[\sum_{(i,j) \in E} \frac{1 - x_i’ x_j’}{2}] = \sum_{(i,j) \in E} \frac{\theta_{i,j}}{\pi}<br>$$</p>
<p>As $\max_{0 \le \theta \le \pi} \frac{\pi}{\theta}\frac{1 - \cos \theta}{2} \approx 1.138$, $E[\sum_{(i,j) \in E} \frac{1 - x_i’ x_j’}{2}]$ is greater approximately $1/1.138 = 0.878$ $\sum_{(i,j) \in E} \frac{1 - x_i x_j}{2}$. </p>
<!-- 
<p align="center">
  <img https://imglf6.nosdn0.126.net/img/Y1FUYmVJRmJqaTNNVk15SFhyTUZHalJjMStjRE4wYXV4aEtMazNHMHJieFdDdDM4L29PcTl3PT0.png?imageView&thumbnail=500x0&quality=96&stripmeta=0%7Cwatermark&type=2&text=wqkgbHdwaGlsZSAvIGx3cGhpbGUubG9mdGVyLmNvbQ==&font=bXN5aA==&gravity=southwest&dissolve=30&fontsize=240&dx=8&dy=10&stripmeta=0>
</p> -->

<p><img src="http://imglf6.nosdn0.126.net/img/Y1FUYmVJRmJqaTNNVk15SFhyTUZHalJjMStjRE4wYXV4aEtMazNHMHJieFdDdDM4L29PcTl3PT0.png?imageView&thumbnail=500x0&quality=96&stripmeta=0%7Cwatermark&type=2&text=wqkgbHdwaGlsZSAvIGx3cGhpbGUubG9mdGVyLmNvbQ==&font=bXN5aA==&gravity=southwest&dissolve=30&fontsize=240&dx=8&dy=10&stripmeta=0" alt="$\max_{0 \le \theta \le \pi} \frac{\pi}{\theta}\frac{1 - \cos \theta}{2} \approx 1.138$"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/09/14/Facility-Location-Problem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/09/14/Facility-Location-Problem/" class="post-title-link" itemprop="url">Facility Location Problem</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-09-14 10:58:58" itemprop="dateCreated datePublished" datetime="2018-09-14T10:58:58+10:00">2018-09-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-13 16:58:50" itemprop="dateModified" datetime="2020-05-13T16:58:50+10:00">2020-05-13</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p> <strong><em>Update on May/7th/2020.</em></strong></p>
<p>Suppose we have a set of facilities $F$ and a set of clients $C$. We would like to open some facilities from $F $ to serve the clients. The cost consists of two parts: 1) the one for opening the selected facilities; 2) the one for connecting each client to its closest facility. </p>
<p>Formally, denote $f_i$ the cost of facility $i \in F$ and $c_{i,j}$ the distance from a client $j \in C$ to a facility $i \in F$. Let $S \subset F$ be a subset of facilities, and let $\mu : C \rightarrow S$ be the corresponding function that assigns each client $j \in C$ to a facility in $S$, i.e.,<br>$$<br>\mu(j) \doteq \arg\min_{i \in S} c_{i,j}<br>$$</p>
<p>The cost of $S$ is given by<br>$$<br>\sum_{i \in S} f_i + \sum_{j \in C} c_{\mu(j), j}<br>$$</p>
<p>The problem is to find a set $S$ that minimizes this cost. </p>
<h2 id="LP-Formulation"><a href="#LP-Formulation" class="headerlink" title="LP Formulation"></a><strong><em>LP Formulation</em></strong></h2><p>It can be formulated as linear program and then relaxed as as a linear one:</p>
<p>$$<br>\begin{array}{lrllr}<br>\text{Primal:}<br>    &amp;&amp;\min  &amp; \sum_{i \in F, j \in C} c_{i, j} x_{i, j} + \sum_{i \in F} f_i y_i &amp; &amp;  \<br>    &amp;&amp;s.t., &amp; \sum_{i \in F} x_{i j} \ge 1  &amp; \forall j \in C  &amp; (1) \<br>    &amp;&amp;      &amp; y_i - x_{i,j} \ge 0           &amp; \forall i \in F, j \in C &amp; (2)<br>\end{array}<br>$$</p>
<p>The first constraint says that each client is assigned to at least one facility. The second one can be interpreted as that a facility must be open if there is a client assigned to it. </p>
<p>To obtain the dual, let $\alpha_j$ be the dual variable associated with constraint (1) and $\beta_{i,j}$ be the one with constraint (2). We need to ensure that weak duality holds. </p>
<h3 id="Weak-Duality"><a href="#Weak-Duality" class="headerlink" title="Weak Duality"></a><em>Weak Duality</em></h3><p>$$<br>\begin{array}{rl}<br>    \sum_{j \in C} \alpha_j<br>        &amp;= \sum_{j \in C} \alpha_j \cdot 1 + \sum_{i \in F, j \in C} \beta_{i,j} \cdot 0 \<br>        &amp;\le \sum_{j \in C} \alpha_j \cdot (\sum_{i \in F} x_{i,j} ) + \sum_{i \in F, j \in C} \beta_{i,j} \cdot (y_i - x_{i,j}) \<br>        &amp;= \sum_{i \in F, j \in C} (\alpha_j - \beta_{i,j}) \cdot x_{i,j}  + \sum_{i \in F} \left( \left( \sum_{j \in C} \beta_{i,j} \right) \cdot y_i \right) \<br>        &amp;\le \sum_{i \in F, j \in C} c_{i, j} x_{i, j} + \sum_{i \in F} f_i y_i<br>\end{array}<br>$$<br>The dual can be formulated such that the above inequalities hold.</p>
<h3 id="Dual-Program"><a href="#Dual-Program" class="headerlink" title="Dual Program"></a><em>Dual Program</em></h3><p>$$<br>\begin{array}{lllr}<br>    \text{Dual:} \qquad<br>    &amp;\max &amp; \sum_{j \in C} \alpha_j \<br>    &amp;s.t.,&amp; \alpha_j - \beta_{i,j} \le c_{i,j} &amp; \forall i \in F, \forall j \in C\<br>    &amp;     &amp; \sum_{j \in C} \beta_{i,j} \le f_i  &amp; \forall i \in F\<br>\end{array}<br>$$</p>
<p>Here we give a more intuitive way of deriving the dual. First, we notice that $\sum_{j \in C} \min_{i \in F} c_{i,j}$ is a trivial lower bound of the primal programming. In this case, each client is assigned to its nearest facility. However we ignore facility cost entirely. </p>
<p>To incorporate the facility cost, for each facility $i$ we divide its cost $f_i$ among the clients, such that client $j$ needs to pay $\beta_{i, j}$ if it is assigned facility $i$. Note that $\beta_{i, j}$ can be arbitrary non-negative number as long as it satisfies that $\sum_{j \in C} \beta_{i,j} = f_i$ for all $i \in F$. </p>
<p><strong><em>Theorem.</em></strong> For any solution $S$ and $\mu$, it holds that<br>$$<br>\begin{aligned}<br>    \sum_{j \in C} (c_{\mu(j), j} + \beta_{\mu(j), j} )<br>        &amp;\le \sum_{i \in S} f_i + \sum_{j \in C} c_{\mu(j) , j}<br>\end{aligned}<br>$$</p>
<p><em>Proof.</em><br>$$<br>\begin{aligned}<br>    \sum_{j \in C} (c_{\mu(j), j} + \beta_{\mu(j), j} )<br>        &amp;=  \sum_{i \in F} \sum_{j \in \mu^{-1}(i) } ( \beta_{ i, j} ) + \sum_{j \in C} c_{\mu(j) , j} \<br>        &amp;\le  \sum_{i \in F} \sum_{j \in C } ( \beta_{ i, j} ) + \sum_{j \in C} c_{\mu(j) , j} \<br>        &amp;= \sum_{i \in S} f_i + \sum_{j \in C} c_{\mu(j) , j}<br>\end{aligned}<br>$$<br>$\blacksquare$</p>
<p>If we define<br>$$<br>\alpha_j = \min_{i \in F} (c_{i,j} + \beta_{i, j})<br>$$</p>
<p>Then $\sum_{j \in F} \alpha_j$ constitutes a lower bound for the cost of any solution. In particular, it is a lower bound of the cost of the optimal integral solution $F^*$ (its corresponding assignment function is denoted as $\mu^*$):</p>
<p>$$<br>\begin{aligned}<br>&amp; \sum_{j \in C} \alpha_j<br>    \le \sum_{i \in F^*} f_i + \sum_{j \in C} c_{\mu^* (j), j} \<br>\end{aligned}<br>$$</p>
<p>The idea of determining a set of $\beta_{i,j}$’s that maximizes the lower bound $\sum_{j \in C} \alpha_j$ gives the dual program.</p>
<h3 id="Complementary-Slackness"><a href="#Complementary-Slackness" class="headerlink" title="Complementary Slackness"></a><em>Complementary Slackness</em></h3><p>Let $x^*, y^*$ and $\alpha^*, \beta^*$ be the optimal primal and dual solution respectively. For these set of variables, weak duality holds with equalities. By complementary slackness, it holds that </p>
<ol>
<li>$\alpha^<em><em>j = 0$ or $\sum</em>{i \in F} x^</em>_{i,j} = 1$</li>
<li>$\beta^<em>_{i,j} = 0$ or $y^</em><em>i - x^*</em>{i,j} = 0$</li>
</ol>
<p>and </p>
<ol start="3">
<li>$\alpha^<em>_j - \beta^</em><em>{i,j} = c</em>{i,j}$ or $x^*_{i,j} = 0$</li>
<li>$\sum_{j \in C} \beta^<em>_{i,j} = f_i$ or $y^</em>_i = 0$</li>
</ol>
<h2 id="LP-Rounding"><a href="#LP-Rounding" class="headerlink" title="LP Rounding"></a><strong><em>LP Rounding</em></strong></h2><p>We show how to construct a integral solution $x$ from the optimal solution $x^*, y^*$, $\alpha^*$ and $\beta^*$ to the primal and dual LP. First we construct a derived graph $G = (V, E)$ from primal LP. </p>
<p><strong><em>Definition.</em></strong> A derived graph from the optimal LP consists of the follows:</p>
<ol>
<li> The vertex set $V = F \cup C$;</li>
<li> The edge set $E = { (i, j) : x^<em>_{i,j} &gt; 0, \forall i \in F, j \in C}$. That is, the edge set $E$ contains all facility-client pairs $(i, j)$ such that $x^</em>_{i,j} &gt; 0$.</li>
</ol>
<p>In the graph $G$, the neighbors a client $j$ can only be facilities.</p>
<p><strong><em>Definition.</em></strong> <em>For a client $j \in C$, denote $N(j)$ the set of facilities that are adjacent to $j$ in $G$.</em></p>
<p>Similarly, we define two hop neighbor of a client $j$, as the client who connects to $j$ via a intermediate facility.</p>
<p><strong><em>Definition.</em></strong> <em>For a client $j \in C$, its two hop neighbors are the set of client whose distance to $j$ is 2 in $G$:<br>$$<br>N^2(j) ={ j’ \in C: \exists i \in F, s.t., x^</em><em>{i,j’} &gt;0 \wedge   x^*</em>{i,j} &gt; 0 }<br>$$</p>
<p>Below is an example. The cycles represent clients and the squares are for facilities. Associated each client and each facility are the $\alpha_j^*$ value and opening cost respectively.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm1.1.png"></p>
<p>An important property of this graph is that </p>
<blockquote>
<p>If $(i,j) \in E$, then $x^<em>_{i,j} &gt;0$, which implies that $\alpha^</em><em>j =c</em>{i,j} + \beta^<em>_{i,j}$ by complementary slackness. It concludes that $\alpha^</em><em>j \ge c</em>{i,j}$ if there is an edge $(i,j)$ in $G$.</p>
</blockquote>
<h3 id="Deterministic-Rounding-1"><a href="#Deterministic-Rounding-1" class="headerlink" title="Deterministic Rounding [1]"></a><strong><em>Deterministic Rounding [1]</em></strong></h3><p>As a warm up, we introduce the first constant factor approximation algorithm for the un-capacitated facility location problem, proposed in 1997 [1]. It is a deterministic rounding algorithm.</p>
<blockquote>
<p>Algorithm 1:     </p>
<ol>
<li>$S \leftarrow \emptyset$.  </li>
<li>$D \leftarrow \emptyset$.  </li>
<li>While there exists some client not assigned to any facility  </li>
<li>$\quad$ Let $j$ be the unassigned one with smallest $\alpha^*_j$, add it to $D$.     </li>
<li>$\quad$ Open the cheapest facility $i$ in $N(j)$, add it to $S$.   </li>
<li>$\quad$ Assign $j$ to $i$:  $\mu(j) \leftarrow i$    </li>
<li>$\quad$ For each un-assigned client $j’ \in N^2(j)$ do  </li>
<li>$\quad$ $\quad$ $\quad$ Assign $j’$ to $i$: $\mu(j’)   \leftarrow i$</li>
</ol>
</blockquote>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm1.2.png"></p>
<p>The example above shows one iteration of the algorithm. The vertex with minimum value of $\alpha^*_j$ (i.e. 1) is opened, highlighted by the red cycle. There are two facilities connected to it, the cheap opening cost of which is 1. Then all un-assigned clients neighboring these two facilities are assigned to the cost 1 facility, as shown by the purple dashed arrows. </p>
<p>Intuitively, each iteration of the algorithm creates a clusters, which contains three kinds of vertices: </p>
<ol>
<li>The selected un-assigned client $j$ with minimum $\alpha^*_j$. </li>
<li>All $j$’s neighboring facilities.  </li>
<li>All un-assigned clients neighboring to these facilities.</li>
</ol>
<p>It is left to analyze the cost of the solution returned. </p>
<h4 id="Facility-Cost"><a href="#Facility-Cost" class="headerlink" title="Facility Cost"></a>Facility Cost</h4><p>At each iteration, a client $j$ is selected. In the primal LP, constraint (1) requires that<br>$$<br>\sum_{i \in F} x^*_{i,j} \ge 1<br>$$</p>
<p>Note that although $j$ can assigned to a client fractionally, the total amount of assignment must be at least 1. Further, although a facility can be fractionally open in primal LP,  the constraint (2)<br>$$<br>y^<em>_i \ge x^</em><em>{i, j}<br>$$<br>implies that the open amount must be at least the amount a client assign to it. By the selection of $\mu(j)$, we conclude that<br>$$<br>\begin{array}{llr}<br>    f( \mu_S(j) )<br>        &amp;\le f( \mu(j) ) \cdot \sum_{i \in N(j)} x^*</em>{i, j} \<br>        &amp;\le \sum_{i \in N(j)} x^<em>_{i, j} f_i \<br>        &amp;\le \sum_{i’ \in N(j)} y^</em><em>{i} f</em>{i}<br>\end{array}<br>$$</p>
<p>The neighbor sets $N(j)$’s of the selected clients $j \in D$ are dis-joint. </p>
<p>Therefore, summing over $j \in D$, the total facility cost is bounded by </p>
<p>$$<br>\sum_{j \in D} \sum_{i \in N(j)} y^<em><em>{i} f</em>{i} \le \sum_{i \in F} y^</em>_i f_i \le OPT<br>$$</p>
<h4 id="Connection-Cost"><a href="#Connection-Cost" class="headerlink" title="Connection Cost"></a>Connection Cost</h4><p>Now we analyze the assignment cost. When a client $j$ with smallest $\alpha^*_j$ is selected and assigned to the cheapest facility $i$ in $N(j)$. Unassigned clients $j’ \in N^2(j)$ are also assigned to $i$. There are two possible cases: </p>
<ol>
<li><p>There is an edge $(i, j’)$ in $G$, i.e., $j’ \in N(i)$. Then the assign cost is $c_{i, j’} \le \beta^*_{j’}$.</p>
</li>
<li><p>There is no edge between $i$ and $j’$ in $G$. In this case, there exists some other facility $i’ \in N(j)$, such that $(i’,j’) \in E$. By triangle inequality, we have<br> $$<br> c_{i , j’} \le c_{i, j} + c_{i’, j} + c_{i’, j’} \le \alpha^<em>_{j} + \alpha^</em><em>j + \alpha^*</em>{j’} \le 3\alpha^*_{j’}<br> $$</p>
<p> The last inequality holds since $\alpha^<em>_{j’} \le \alpha^</em>_j$.</p>
</li>
</ol>
<p>Combing assignment cost and facility cost, algorithm 1 is 4-approximation. </p>
<p>How happy are we with the 4-approximation algorithm? Probably not. In the previous example, when a facility is opened, only one client contributes to its opening cost. However, in the primal solution, many other clients assigned to it do not contribute to the opening cost, which implies that the current analysis may not be tight. </p>
<h3 id="Randomized-Rounding-3"><a href="#Randomized-Rounding-3" class="headerlink" title="Randomized Rounding [3]"></a><strong><em>Randomized Rounding</em></strong> [3]</h3><h4 id="3-Approximation-Rounding"><a href="#3-Approximation-Rounding" class="headerlink" title="3-Approximation Rounding"></a><strong><em>3-Approximation Rounding</em></strong></h4><p>In the section, we improve the approximation ratio of 4 to an expected value of 3. In the previous rounding, we bound the opening cost as<br>$$<br>\sum_{j \in D} \min_{i \in N(j) } f_i \le OPT<br>$$</p>
<p>which is not tight. Define the assignment cost for client $j$ in the optimal primal LP solution as $A_j = \sum_{i \in F} x^<em><em>{i,j} c</em>{i,j}$. Indeed, it is affordable to bound<br>$$<br>\sum_{j \in D} \sum_{i \in N(j) } x^</em>_{i,j} f_i +  \sum_{j \in C} A_j \le OPT<br>$$</p>
<p>It is possible to devise a randomized rounding algorithm that incorporates this cost and improve the approximation ratio to 3. The only differences compared to the first rounding algorithm are   </p>
<ol>
<li>We pick a client that minimize $\alpha^*_j + A_j$;</li>
<li>We pick a facility with probability $x^*_{i,j}$.</li>
</ol>
<p>Below is the algorithm. </p>
<blockquote>
<p>Algorithm 2:     </p>
<ol>
<li>$S \leftarrow \emptyset$.  </li>
<li>$D \leftarrow \emptyset$.  </li>
<li>While there exists un-assigned client   </li>
<li>$\quad$ Let $j$ be the unassigned one with smallest $\alpha^*_j + A_j$, add $j$ to $D$.      </li>
<li>$\quad$ Sample a facility $i$ in $N(j)$ with probability $x^*_{i,j}$, add it to $S$.    </li>
<li>$\quad$ Assign $j$ to $i$:  $\mu(j) \leftarrow i$    </li>
<li>$\quad$ For each un-assigned client $j’ \in N^2(j)$ do  </li>
<li>$\quad$ $\quad$ $\quad$ Assign $j’$ to $i$: $\mu(j’)   \leftarrow i$</li>
</ol>
</blockquote>
<h5 id="Facility-Cost-1"><a href="#Facility-Cost-1" class="headerlink" title="Facility Cost"></a>Facility Cost</h5><p>The analysis of expected facility cost is almost the same as before. It is guaranteed that the $N(j)$’s for selected clients $j \in D$ are disjoint. Therefore, the expected opening cost is bounded by<br>$$<br>\sum_{j \in D} \sum_{i \in N(j) } x^<em><em>{i,j} f_i \le \sum_{j \in D} \sum</em>{i \in N(j) } y^</em>_i f_i<br>$$</p>
<h5 id="Connection-Cost-1"><a href="#Connection-Cost-1" class="headerlink" title="Connection Cost"></a>Connection Cost</h5><p>Now we analyze the assignment cost. When a client $j$ and a facility $i$ in $N(j)$ is sampled, unassigned clients $j’ \in N^2(j)$ are assigned to $i$. As $j’ \in N^2(j)$, there exists some other facility $i’ \in N(j)$, such that $(i’,j’) \in E$. By triangle inequality, the expected connection cost is at most<br>$$<br>\begin{aligned}<br>c_{i, j’}<br>&amp;\le \sum_{i \in N(j)} x^<em><em>{i,j} c</em>{i, j} + c_{i’, j} + c_{i’, j} \<br>&amp;\le A_j + \alpha^</em><em>{j} + \alpha^<em><em>j \<br>&amp;\le A</em>{j’} + 2\alpha^</em></em>{j’}<br>\end{aligned}<br>$$</p>
<p>Summing over all clients, the cost is at most<br>$$<br>\sum_{j \in D} \sum_{i \in N(j) } x^<em><em>{i,j} f_i + \sum_{i \in F, j \in C} c</em>{i, j} x^</em><em>{i, j} + 2\sum</em>{j \in C} \alpha^*_j \le 3 \cdot OPT<br>$$</p>
<p><strong><em>Remark</em></strong>: there is still room for improvement. When a client $j$ is selected and a facility $i$ is sampled, $j’ \in N^2(j)$ is assigned to $i$. On the other hand, $j’$ itself may contributes to the opening cost of some other facility not open. To make the expected opening cost tight, we may consider opening facilities directly with respect to probability $y^*_i$.  </p>
<h4 id="1-3-e-Approximation-Rounding-3"><a href="#1-3-e-Approximation-Rounding-3" class="headerlink" title="$(1 + 3/e)$-Approximation Rounding [3]"></a><strong><em>$(1 + 3/e)$-Approximation Rounding</em></strong> [3]</h4><!-- To have an intuition of the rounding technique, we illustrate a wrong but instructive rounding technique. Here we assume that $x^*_{i,j} = y^*_i$ for all $i \in F, j \in C$. If we select each facility $i$ independently with probability $y^*_i$, then for a client $j$, the probability that none of its neighbor is selected is 
$$
\prod_{i \in N(j) } (1 - y^*_i) \le e^{-\sum_{i \in N(j) } y^*_i} \le e^{ - \sum_{i \in N(j) } x^*_{i,j} } = e^{-1}
$$

The problem here is that, if none of $j$'s neighbors is sampled, the connection cost of $j$ might be unacceptable large. We need some backup mechanism. For example, if we can somehow combine Algorithm 1 and bound the connection cost to $3 v^*_j$ for this bas case. Let $Z$ be the random variable that represents connection cost for $j$ and $Y_i$ ($i \in N(j)$) indicator random variable of whether $i$ is sampled.
$$
Z \le Z' \doteq \min_{i \in N(j), Y_i = 1} \{ c_{i,j} Y_i \} + 3 v^*_j \cdot \mathbb{1}_{[ Y_i = 0, \forall i \in N(j)] }
$$


Therefore, 
$$
\begin{aligned}
    E[Z] 
    &\le E[Z'] \\
    &\le E \left[ \sum_{i \in N(j)}  c_{i,j} Y_i  + 3 v^*_j \cdot \mathbb{1}_{[ Y_i = 0, \forall i \in N(j)] } \right] \\
    &= \sum_{i \in N(j)}  c_{i,j} E[Y_i]  + 3 v^*_j \cdot E\left[ \mathbb{1}_{[ Y_i = 0, \forall i \in N(j)] } \right] \\
    &\le \sum_{i \in N(j) } c_{i,j} x^*_{i,j} + \frac{3}{e} v^*_j
\end{aligned}
$$

The third equality does not even require that $Y_i$'s are independent. Then the total cost is bounded by 
$$
\begin{aligned}
    &\sum_{i \in F} y^*_i f_i + \sum_{j \in C}  x^*_{i,j} c_{i,j} + \frac{3}{e} \sum_{j \in C} v^*_j \\
    =& (1 + \frac{3}{e} ) \cdot  OPT
\end{aligned}
$$


Below we show the actual algorithm that achieves this expected approximation ratio. The facilities are no longer sampled independently. However, we will see that, for facility $i$, it is still selected with probability $y^*_i$. Therefore, the expected cost of opening the facilities is still $\sum_{i \in F} y^*_i f_i$.  -->

<!-- 
> Algorithm 3:     
> 1. $S \leftarrow \emptyset$.  
> 2. $D \leftarrow \emptyset$.  
> 3. $T \leftarrow F$.   
> 2. While there exists un-assigned client   
> 3. $\quad$ Let $j$ be the unassigned one with smallest $\alpha^*_j$, add $j$ to $D$.      
> 5. $\quad$ Sample a facility $i$ in $N(j)$ with probability $x^*_{i,j}$, add it to $S$.    
> 6. $\quad$ $T \leftarrow T \setminus N(j)$.
> 6. $\quad$ Assign $j$ to $i$:  $\mu(j) \leftarrow i$  
> 6. $\quad$ For each un-assigned client $j' \in N^2(j)$ do  
> 8. $\quad$ $\quad$ $\quad$ Assign $j'$ to $i$: $\mu(j')   \leftarrow i$
> 9. Sample each facility $i \in T$ independently with probability $y^*_i$. 
-->

<p>In the previous analysis, we see that a facility may be under-sampled. There are two reasons for this:   </p>
<ol>
<li>For a facility $i$, $\exists j \in N(i)$ such that $j \in D$. When $j$ is selected, facility $i$ is sampled with probability $x^<em>_{i,j}$, which might be smaller than $y^</em>_i$.   </li>
<li>For a facility $i$, none of its clients $j \in N(i)$ is selected, therefore $i$ is never sampled. </li>
</ol>
<p>To fix theses issues and based on algorithm 1, we have the following algorithm. The algorithm presented here is a modified version of the one proposed in [3] but guided the same philosophy. </p>
<blockquote>
<p>Algorithm 3:     </p>
<ol>
<li>$T \leftarrow F$  </li>
<li>$k \leftarrow 0$  </li>
<li>$S_1, S_2, S_3 \leftarrow \emptyset$  </li>
<li>While there exists un-assigned client   </li>
<li>$\quad$ $k \leftarrow k + 1$    </li>
<li>$\quad$ Let $j_k$ be the unassigned one with smallest $\alpha^*_j$  </li>
<li>$\quad$ Open exactly one facility $i_k \in N( j_k )$ with probability $x^*_{i,j}$      </li>
<li>$\quad$ $S_1 \leftarrow S_1 \cup { i_k }$  </li>
<li>$\quad$ For each $i \in N(j_k) - { i_k }$ </li>
<li>$\qquad$ Open $i$ with probability $(y^<em>_{i} - x^</em><em>{i,j } ) / ( 1- x^*</em>{i,j} )$      </li>
<li> $\qquad \quad$ $S_2 \leftarrow S_2 \cup { i }$ </li>
<li>$\quad$ $T \leftarrow T - N(j_k)$  </li>
<li>$\quad$ Assign $j$ to $i_k$, for $\forall j \in  { j_k } \cup N^2( j_k )$  </li>
<li>For each facility $i \in T$ </li>
<li>$\quad$ Open $i$ with probability $y^*_i$    </li>
<li>$\qquad$ $S_3 \leftarrow S_3 \cup { i }$</li>
<li>Re-assign each $j \in C$ to its nearest open facility.</li>
</ol>
</blockquote>
<p>When the algorithm stops, denote $S = S_1 \cup S_2 \cup S_3$ the set of open facilities and $D = {j_1, j_2, …, j_{|D| } }$ the set of selected facilities by line 5. The following lemma shows that Algorithm 3 fully samples each facility and therefore never loses to Algorithm 1.</p>
<h5 id="Facility-Cost-2"><a href="#Facility-Cost-2" class="headerlink" title="Facility Cost"></a>Facility Cost</h5><p><strong><em>Lemma 1.</em></strong> For each $i \in F$, it is  opened with probability $y^<em>_i$.<br><em>Proof.</em> Note the facilities are not open independently. The claim is trivially true if a facility is is sampled in line 10. Otherwise, $\exists j \in D$, s.t., $i \in N(j)$. The probability of $i$ being open is<br>$$<br>x^</em><em>{i,j} + (1 - x^*</em>{i,j} ) \frac{y^<em>_{i} - x^</em><em>{i,j} }{ 1- x^*</em>{i,j} } = y^*_i<br>$$<br>$\blacksquare$</p>
<p><strong><em>Corollary.</em></strong> By linearity of expectation, the expected facility opening cost is $\sum_{i \in F} y^*_i f_i$.</p>
<h5 id="Connection-Cost-2"><a href="#Connection-Cost-2" class="headerlink" title="Connection Cost"></a>Connection Cost</h5><p>What is not trivial is the analysis of the assignment cost. Given $S$, assigning $j \in C$ to its nearest facility in $S$ minimizes the assignment cost. To bound this cost, we investigate a sub-optimal assignment based on $S$. For each $j \in C$ we select a subset $S(j) \subset S$ and assign it to a closest facility in $S(j)$. This leads to a possibly increase in the expected assignment cost. </p>
<p>Let $Z$ be the random variable of the assignment cost for client $j$ and $X_i$ ($i \in N(j)$) be the indicator random variable of $i$ being in $S(j)$. As when none of the facility in $N(j)$ is selected into $S(j)$, then assignment cost is bounded by $3 \cdot v^<em><em>j$, the value of $Z$ is therefore at most<br>$$<br>Z \le \min</em>{i \in N(j), X_i = 1} { c_{i,j} X_i } + 3 v^</em><em>j \cdot \mathbb{1}</em>{[ Y_i = 0, \forall i \in N(j)] }<br>$$</p>
<p>The goal is to provide a method for generating $S(j)$, such that </p>
<ol>
<li>$\Pr[X_i = 1] = x^*_{i,j}$, for $\forall i \in N(j)$; </li>
<li>$\Pr[\mathbb{1}_{[ Y_i = 0, \forall i \in N(j)]} = 1 ] \le 1/e$.</li>
</ol>
<p>Any such generation method satisfies to bound the assignment cost of client $j$:<br>$$<br>\begin{aligned}<br>    E[Z]<br>    &amp;\le E \left[ \sum_{i \in N(j)}  c_{i,j} X_i  + 3 v^<em><em>j \cdot \mathbb{1}</em>{[ X_i = 0, \forall i \in N(j)] } \right] \<br>    &amp;= \sum_{i \in N(j)}  c_{i,j} E[X_i]  + 3 v^</em><em>j \cdot E\left[ \mathbb{1}</em>{[ X_i = 0, \forall i \in N(j)] } \right] \<br>    &amp;\le \sum_{i \in N(j) } c_{i,j} x^<em>_{i,j} + \frac{3}{e} v^</em>_j<br>\end{aligned}<br>$$</p>
<p>Note that the inequality here may not be tight, as we replace the $\min$ operation into $\sum$. But it suffices to prove the expected approximation ratio. When combined with the expected facility opening cost, we know that total expected cost is bounded by<br>$$<br>\sum_{i \in F} y^<em><em>i f_i + \sum_{j \in C} \sum</em>{i \in N(j) } c_{i,j} x^</em>_{i,j} + \frac{3}{e} v^*_j = \left( 1 + \frac{3}{e} \right) \cdot OPT<br>$$</p>
<p>The $S(j)$ is generated as follows. If $j \in D$, then we let $S(j) = S$. Otherwise, we initialize $S(j)$ with $S - N(j)$, and for facility $i \in N(j) \cap S$, we perform some carefully designed operations to ensure that $\Pr[i \in S(j) ]= x^*_{i,j}$. </p>
<ol>
<li><p>If $i \in S_3$, we keep it in $S(j)$ with probability $\frac{x^<em>_{i,j} } {y^</em><em>i}$. Therefore,<br> $$<br> \Pr[i \in S(j)] = \Pr[i \in S(j) \mid i \in S] \cdot \Pr[i \in S] = x^*</em>{i,j}<br> $$</p>
</li>
<li><p>Otherwise, $\exists j_k \in D$, such that $i \in N(j_k)$. There are two possible cases</p>
<ol>
<li><p>Case 1: $x^<em>_{i,j_k} \ge x^</em>_{i,j}$, the probability of selecting $i$ is defined as follows:<br> $$<br> \Pr[i \in S(j) \mid i \in S] =<br> \begin{cases}</p>
<pre><code> \begin&#123;array&#125;&#123;lr&#125;
     &#123;x^*_&#123;i,j&#125; &#125; / &#123; x^*_&#123;i,j_k&#125; &#125;,   &amp;i \in S_1 \\
     0,                                 &amp;
     i \in S_2
 \end&#123;array&#125;
</code></pre>
<p> \end{cases}<br> $$<br> Therefore,<br> $$<br> \begin{array}{ll}</p>
<pre><code> \Pr[i \in S(j)] 
     &amp;= \Pr[i \in S(j) |i \in S_1 ] \cdot \Pr[ i \in S_1 ] + \Pr[i \in S(j) |i \in S_2 ] \cdot \Pr[ i \in S_2 ] \\
     &amp;= x^*_&#123;i,j&#125;  /  x^*_&#123;i,j_k&#125;  \cdot  x^*_&#123;i,j_k&#125;  \\
     &amp;= x^*_&#123;i,j&#125; 
</code></pre>
<p> \end{array}<br> $$</p>
</li>
<li><p>Case 2: $x^<em>_{i,j_k} &lt; x^</em>_{i,j}$, the probability of selecting $i$ is defined as follows:<br> $$<br> \Pr[i \in S(j) \mid i \in S] =<br> \begin{cases}</p>
<pre><code> \begin&#123;array&#125;&#123;lr&#125;
     1,   &amp;i \in S_1 \\
     (x^*_&#123;i,j&#125; - x^*_&#123;i, j_k&#125;  ) \cdot ( 1 - x^*_&#123;i,j_k &#125; ) / (y^*_&#123;i&#125; - x^*_&#123;i,j_k &#125; ),                                 &amp; i \in S_2
 \end&#123;array&#125;
</code></pre>
<p> \end{cases}<br> $$</p>
<p> The probability is well defined as $y^<em>_i \ge x^</em>_{i,j}$. It follows</p>
<p> $$<br> \begin{array}{ll}</p>
<pre><code> \Pr[i \in S(j)] 
     &amp;= \Pr[i \in S(j) |i \in S_1 ] \cdot \Pr[ i \in S_1 ]  + \Pr[i \in S(j) |i \in S_2 ] \cdot \Pr[ i \in S_2  ] \\
     &amp;=  x^*_&#123;i,j_k&#125;  +  (x^*_&#123;i,j&#125; - x^*_&#123;i, j_k&#125;  ) \cdot ( 1 - x^*_&#123;i,j_k &#125; ) / (y^*_&#123;i&#125; - x^*_&#123;i,j_k &#125; ) \cdot (y^*_&#123;i&#125; - x^*_&#123;i,j_k &#125; ) / (x^*_&#123;i,j&#125; - x^*_&#123;i, j_k&#125;  )\\
     &amp;= x^*_&#123;i,j&#125; 
</code></pre>
<p> \end{array}<br> $$</p>
</li>
</ol>
</li>
</ol>
<p>It is left to show that $\Pr[\mathbb{1}_{[ Y_i = 0, \forall i \in N(j)]} = 1 ] \le 1/e$. For $j \in D$, this holds trivially. If not, we prove the following lemma. </p>
<p><strong><em>Lemma 2.</em></strong> For any client $j \in C \setminus D$, the probability that none of facility in $N(j)$ belongs to $S(j)$ is bounded by $1/ e$. </p>
<p><strong><em>Proof.</em></strong> </p>
<p>Observe that<br>$$<br>N(j_1) \cup N(j_2) \cup … \cup N(j_{|D| } ) \cup T = F<br>$$</p>
<p>constitutes a partition of $F$. For any client $j$, define $R_k = N(j_k) \cap N(j)$, where $1 \le k \le |D|$. Further, let $R_{|D| + 1} = T \cap N(j)$. Then ${ R_k }_{k  \in [|D| + 1]}$ is a partition of $N(j)$. </p>
<p>Consider facilities in $N(j_k)$ ($k \in [|D|]$). The probability of none of them being in $S(j)$ is<br>$$<br>\begin{aligned}<br>    &amp;\left( 1 - \sum_{i \in R_k \wedge x^<em>_{i, j_k} &lt; x^</em><em>{i,j} } x^*</em>{i, j_k}   - \sum_{i \in R_k \wedge x^<em>_{i, j_k} \ge x^</em><em>{i,j} } x^*</em>{i, j_k} \cdot \frac{x^<em>_{i,j} }{ x^</em><em>{i, j_k} }     \right)<br>     \cdot \prod_{i \in R_k \wedge x^<em>_{i, j_k} &lt; x^</em>_{i,j} } \left(1 - \frac{y^*</em>{i} - x^<em>_{i,j } }{ 1- x^</em><em>{i,j}}<br>    \frac{ 1- x^*</em>{i,j}}{y^<em>_{i} - x^</em><em>{i,j } } (x^*</em>{i,j} - x^<em>_{i, j_k}  )<br>    \right) \<br>    &amp;\le \exp \left( - \sum_{i \in R_k \wedge x^</em><em>{i, j_k} &lt; x^<em>_{i,j} } x^</em></em>{i, j_k}  - \sum_{i \in R_k \wedge x^<em>_{i, j_k} \ge x^</em><em>{i,j} } x^*</em>{i,j}\right)<br>    \cdot \prod_{i \in R_k \wedge x^<em>_{i, j_k} &lt; x^</em><em>{i,j} } \left(1 -  (x^*</em>{i,j} - x^<em>_{i, j_k}  )<br>    \right) \<br>    &amp;\le \exp \left( - \sum_{i \in R_k \wedge x^</em><em>{i, j_k} &lt; x^<em>_{i,j} } x^</em></em>{i, j_k}  - \sum_{i \in R_k \wedge x^<em>_{i, j_k} \ge x^</em><em>{i,j} } x^*</em>{i,j}\right)<br>    \cdot \exp \left( -\sum_{i \in R_k \wedge x^<em>_{i, j_k} &lt; x^</em><em>{i,j} } (x^*</em>{i,j} - x^<em>_{i, j_k}  )<br>    \right) \<br>    &amp;= \exp \left( { - \sum_{i \in R_k} x^</em>_{i, j} } \right)<br>\end{aligned}<br>$$</p>
<p>The relation holds even if $R_k = \emptyset$, in which $\sum_{i \in R_k} x^*_{i, j} = 0$.</p>
<p>For $k = |D| + 1$, the probability that none of the facility in $R_k$ is sampled is given by<br>$$<br>\prod_{i \in R_{k + 1} } \left( 1 - y^<em>_i \frac{x^</em><em>{i,j} } {y^*<em>i}  \right) \le e^{- \sum</em>{i \in R</em>{k + 1} } x^*_{i,j} }<br>$$</p>
<p>Therefore, taking product over all the events, we know that<br>$$<br>\begin{aligned}<br>    \prod_{k \in [|D| + 1] } e^{- \sum_{i \in R_k } x^<em><em>{i,j} }<br>        &amp;= e^{ - \sum</em>{i \in N(j) } x^</em>_{i,j} } \<br>        &amp;= \frac{1}{e}<br>\end{aligned}<br>$$<br>$\blacksquare$</p>
<!-- #### ***$(1 + 2/e)$-Approximation Rounding***

> Algorithm 4:     
> 1. $S \leftarrow \emptyset$.  
> 2. $D \leftarrow \emptyset$.  
> 3. $T \leftarrow F$.   
> 2. While there exists un-assigned client   
> 3. $\quad$ Let $j$ be the unassigned one with smallest $\alpha^*_j + A_j$, add $j$ to $D$.        
> 5. $\quad$ Sample a facility $i$ in $N(j)$ with probability $x^*_{i,j}$, add it to $S$.    
> 6. $\quad$ $T \leftarrow T \setminus N(j)$.
> 6. $\quad$ Assign $j$ to $i$:  $\mu(j) \leftarrow i$  
> 6. $\quad$ For each un-assigned client $j' \in N^2(j)$ do  
> 8. $\quad$ $\quad$ $\quad$ Assign $j'$ to $i$: $\mu(j')   \leftarrow i$
> 9. Sample each facility $i \in T$ independently with probability $y^*_i$.

***Theorem.*** For any client $j$, the expected assignment cost is give by $(1 - p_j) A_j + p_j (2v^*_j + A_j)$.

***Proof*** -->

<h2 id="Primal-Dual-Algorithm-2"><a href="#Primal-Dual-Algorithm-2" class="headerlink" title="Primal-Dual Algorithm [2]"></a><strong><em>Primal-Dual Algorithm</em></strong> [2]</h2><p>In this section we show a primal-dual algorithm that is purely combinatorial. </p>
<ol>
<li>Initially we have a set of dual variables $\alpha_j$’s and $\beta_{i,j}$’s that are set to 0. Note that they are feasible.  </li>
<li>Then we try to optimize this set of variables by increasing all $\alpha_j$’s in parallel until some $\alpha_j$’s are blocked. </li>
</ol>
<p>Why are they blocked? Because the dual constraint<br>$$<br>\alpha_j \le c_{i,j} + \beta_{i,j}<br>$$</p>
<p>becomes tight for some facilities $i \in F$. If we increase $\alpha_j$ further, the variables are no longer dual feasible. However,  we can modify our strategy by increasing these $\beta_{i,j}$ simultaneously with $\alpha_j$ until facility $i$ is <em>blocked</em>, i.e.,<br>$$<br>\sum_{j \in C} \beta_{i,j} = f_i<br>$$</p>
<p>Before we proceed, for a given facility $i$, we define its neighbors $N(i)$ as to be the clients such that $\alpha_j \ge c_{i,j}$. </p>
<blockquote>
<p>Algorithm: Dual Variable Increment.   </p>
<ol>
<li>$U \leftarrow C$: the set of un-blocked clients.    </li>
<li>$B \leftarrow \emptyset$: the set of blocked facilities.   </li>
<li><em>while</em> $U \neq \emptyset$ <em>do</em>   </li>
<li>   $\quad$ <em>For</em> $\forall j \in U$  </li>
<li>   $\qquad$ Increase all $\alpha_j$ (if necessary, $\beta_{i,j}$ for some $i$ ) simultaneously  </li>
<li>   $\quad$  <em>Until</em> either  </li>
<li>   $\qquad$ * some facility $i \notin B$ is blocked:  </li>
<li>   $\qquad\quad$  $B \leftarrow B \cup {i }$  </li>
<li>   $\qquad\quad$  $U \leftarrow U \setminus N(i)$  </li>
<li>   $\qquad$ * some client $j$ neighbors a blocked facility $i \in B$:  </li>
<li>   $\qquad\quad$  $U \leftarrow U \setminus { j }$  </li>
</ol>
</blockquote>
<p><em>Question to ponder</em>: what is the running time for the <em>Dual Variable Increment</em> algorithm: </p>
<p>After running the algorithm above, we get a set of maximal variable which we can’t simultaneously increase any more. It has the following property</p>
<blockquote>
<p><em>Property.</em> Each client $j \in C$ neighbors at least one block facility. </p>
</blockquote>
<p>If not, the algorithm will increase the $\alpha_j$ further. </p>
<p>We show how to construct an approximate solution from the maximal dual variables. First we construct a derived graph $G = (V, E)$ from primal LP. </p>
<ol>
<li> The vertex set $V = B \cup C$. </li>
<li> The edge set $E = { (i, j) : \beta_j \ge c_{i,j}, \forall i \in B, j \in C}$. </li>
</ol>
<p>Moreover, if $\beta_{i,j} &gt; 0$ for some $i \in F$, $j \in C$, we say that $j$ contributes to $i$. Given a facility $i$, we are particular interested in the set of clients that contributes to it, denoted as $N_+(i)$.</p>
<blockquote>
<p>Algorithm: Facility Selection and Client Assignment       </p>
<ol>
<li>$S \leftarrow \emptyset$.</li>
<li><em>while</em> $B \neq \emptyset$ <em>do</em>   </li>
<li>   $\quad$ Let $i \in B$ be the earliest blocked facility.  </li>
<li>   $\quad$ $S \leftarrow S \cup { i }$  </li>
<li>   $\quad$ $B \leftarrow B \setminus { i }$  </li>
<li>   $\quad$ // Assign all $j \in C$ that contributes to both $i$. </li>
<li>   $\quad$ $\mu_S(j) \leftarrow i$ for all $j \in N_+(i)$. </li>
<li>   $\quad$ // Remove all facilities $i’$ if $\exists j \in C$ that contributes to both $i$ and $i’$. </li>
<li>   $\quad$ $B \leftarrow B \setminus { i’ \in B : N_+(i) \cap N_+(i’) \neq \emptyset }$.</li>
<li>Assign each unassigned client to its closest facility in $S$.</li>
</ol>
</blockquote>
<p>The figure below shows an example of dual variable increment algorithm.<br><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm2.2.png"></p>
<p>The figure below shows the corresponding derived graph.<br><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm2.3.png"></p>
<p>The figure below shows an example of facility selection. The selected facilities are marked with dark green. The clients contributing to theses facilities are connected to them red lines.<br><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm2.4.png"></p>
<h4 id="Facility-Cost-3"><a href="#Facility-Cost-3" class="headerlink" title="Facility Cost"></a>Facility Cost</h4><p>We can show by induction that when a blocked facility is selected, its opening cost is fully covered by all clients contributing to this facility. Note that if any other blocked facility is connected to any of these clients, it is removed from the candidate set. Therefore, when a new blocked facility $i$ is selected, the clients in $N_+(i)$ can contribute to any previous selected facility.</p>
<p>The cost of open facilities in $S$, plus the cost of connecting clients in $N_+(i)$ for $i \in S$,  is given by<br>$$<br>\sum_{i \in S} (f_i + \sum_{j \in N_+(i)} c_{ij}) = \sum_{i \in S} (\sum_{j \in N_+(i)} \beta_{ij} + \sum_{j \in N_+(i)} c_{ij}) = \sum_{i \in S} \sum_{j \in N_+(i)} \alpha_j<br>$$</p>
<h4 id="Connection-Cost-3"><a href="#Connection-Cost-3" class="headerlink" title="Connection Cost"></a>Connection Cost</h4><p>It is left to analyze the connection of other clients. If a client $j \in C$ is in $N(i)$ for some $i \in S$, then the connection cost if<br>$$<br>c_{ij} \le \alpha_j<br>$$<br>Otherwise, by the property of the algorithm, <strong><em>we know that there exists a facility $i$ that stops $\alpha_j$ from increasing</em></strong>. The reason that $i$ is not selected is  that when some other facility $i’$ is selected into $S$, $i$ is removed from the candidate set $B$ because $N_+(i) \cap N_+(i’) \neq \emptyset$ . Let $j’ \in N_+(i) \cap N_+(i’) \neq \emptyset$. We claim </p>
<blockquote>
<p>$\alpha_{j’} \le \alpha_{j}$</p>
</blockquote>
<p>To see this, when $i$ stops $\alpha_j$, we know that either $\alpha_{j’}$ has stopped from increasing or $\alpha_j$ stops simultaneously with $j$, as $j’$ contributes to $i$. </p>
<p>Therefore, the cost of assigning $j$ to $i’$ is at most<br>$$<br>c_{i’j} \le c_{i’j’} + c_{ij’} + c_{ij} \le 2 \alpha_{j’} + \alpha_j \le 3 \alpha_j<br>$$<br><em>Question to ponder</em>: what is the running time of the algorithm?</p>
<p>Finally we show another example where the edge weight between (b,y) is changed to 1.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm2.5.png"></p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm2.6.png"></p>
<p>Note that compared to the previous example, only facility $x$ is selected (marked by dark green), because we can use $b$ to contribute only one facility. Now facility $y$ is the one that stops $\alpha_c$ and $\alpha_d$ from increasing. </p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm2.7.png"></p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference."></a>Reference.</h3><p>[1] Shmoys DB, Tardos É, Aardal K. Approximation algorithms for facility location problems. InProceedings of the twenty-ninth annual ACM symposium on Theory of computing 1997 May 4 (pp. 265-274).</p>
<p>[2] Jain K, Vazirani VV. Primal-dual approximation algorithms for metric facility location and k-median problems. In 40th annual symposium on foundations of computer science (Cat. No. 99CB37039) 1999 Oct 17 (pp. 2-13). IEEE.</p>
<p>[3] Chudak FA, Shmoys DB. Improved approximation algorithms for the uncapacitated facility location problem. SIAM Journal on Computing. 2003;33(1):1-25.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/09/11/Confidence-Interval-of-Berstein-Inequality/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/09/11/Confidence-Interval-of-Berstein-Inequality/" class="post-title-link" itemprop="url">Confidence Interval of Berstein Inequality</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-09-11 21:07:20" itemprop="dateCreated datePublished" datetime="2018-09-11T21:07:20+10:00">2018-09-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-02 19:57:23" itemprop="dateModified" datetime="2019-12-02T19:57:23+11:00">2019-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>(Berstein inequality).<br>Let $X_1, …, X_n$ be random variables with range $[0, 1]$ and<br>$$<br>\sum_{t = 1}^n Var[X_t \mid X_{t - 1}, …, X_1] = \sigma^2<br>$$</p>
<p>Let $S_n = X_1 + … + X_n$. Then for all $a \ge 0$<br>$$<br>\Pr[S_n \ge E[S_n] + an] \le \exp\left(- \frac{n^2 a^2 / 2}{\sigma^2 + n a / 2} \right)<br>$$</p>
<p>Suppose we would like to calculate the confidence interval with probability $\delta$, then we need to solve the following equation:<br>$$<br>\exp\left( -\frac{n^2 a^2 / 2}{\sigma^2 + n a / 2} \right) = \delta<br>$$</p>
<p>After transformation, we get<br>$$<br>n^2 a^2 - n a \ln \frac{1}{\delta} - 2 \sigma^2 \ln \frac{1}{\delta} = 0<br>$$</p>
<p>Therefore,<br>$$<br>a = \frac{n \ln \frac{1}{\delta} + \sqrt{n^2 \ln^2 \frac{1}{\delta} + 8 \sigma^2 n^2 \ln \frac{1}{\delta}} }{2n^2 } = \frac{\ln \frac{1}{\delta} + \sqrt{\ln^2 \frac{1}{\delta} + 8 \sigma^2 \ln \frac{1}{\delta}} }{2n }<br>$$</p>
<p>But<br>$$<br>\sqrt{\ln^2 \frac{1}{\delta} + 8 \sigma^2 \ln \frac{1}{\delta}} \le \sqrt{\ln^2 \frac{1}{\delta}}  + \sqrt{8\sigma^2 \ln \frac{1}{\delta}} = \ln \frac{1}{\delta} + 2\sigma \sqrt{2 \ln \frac{1}{\delta}}<br>$$</p>
<p>It follows that<br>$$<br>a = \frac{\ln \frac{1}{\delta} }{n} + \frac{\sigma \sqrt{2\ln \frac{1}{\delta} } }{n}<br>$$</p>
<p><strong>Corollary:</strong> If $X_1, …, X_n$ are i.i.d. random variables and<br>$$<br>\sum_{t = 1}^n Var[X_t \mid X_{t - 1}, …, X_1] = n Var[X_1]<br>$$<br>Then<br>$$<br>a = \frac{\ln \frac{1}{\delta}}{n} + \sqrt{\frac{2 Var[X_1] \ln \frac{1}{\delta}}{n}}<br>$$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/09/02/Interval-Estimate/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/09/02/Interval-Estimate/" class="post-title-link" itemprop="url">Interval Estimate</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-09-02 19:23:25" itemprop="dateCreated datePublished" datetime="2018-09-02T19:23:25+10:00">2018-09-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2018-09-16 19:52:14" itemprop="dateModified" datetime="2018-09-16T19:52:14+10:00">2018-09-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Let $X$ be a Bernoulli random variable with unknown probability<br>$$<br>\begin{aligned}<br>P[X = 1] &amp;= \mu. \<br>P[X = 0] &amp;= 1 - \mu<br>\end{aligned}<br>$$</p>
<p>where $\frac{1}{n} \le \mu \le 1$ for some integer $n &gt; 0$. The goal is to estimate $\mu$ (denoted by $\tilde \mu$) via sampling. </p>
<p>By law of large number, $\tilde \mu$ converges to $\mu$ when we sample enough numbers of $X$. The convergence behavior is captured by Chernoff inequality and $O(\frac{1}{\delta^2 \mu}\log{1 \over p_{fail} })$ samples are needed to get an estimation $\tilde \mu$ such that $P [ \tilde \mu \in (1 \pm \delta) \mu] \ge 1 - p_{fail}$ (See Exercise 1). Such an $\tilde \mu$ is called an $(\delta, p_{fail})$-estimation of $\mu$. </p>
<p>As $\mu \ge \frac{1}{n}$, $O(\frac{n}{\delta^2}\log{1 \over p_{fail} })$ samples are enough. The problem is, if $\mu$ is much larger than $1/n$, we waste a lot of samples. E.g., when $n = 1000$ and $\mu = \frac{1}{2}$,  $\frac{1}{\delta^2 \mu}\log{1 \over p_{fail} }$ gives us $\frac{2}{\delta^2}\log{1 \over p_{fail} }$ while $\frac{n}{\delta^2}\log{1 \over p_{fail} }$ equals to $\frac{1000}{\delta^2}\log{1 \over p_{fail} }$.  </p>
<p>Can we obtain an $(\delta, p_{fail})$-estimation $\tilde \mu$ with just $O(\frac{1}{\delta^2 \mu}\log{1 \over p_{fail} })$ samples, even though $\mu$ itself is unknown?  </p>
<p>Yes we can (with the lost of a factor $\log \log n$, which is almost negligible). First we relax the goal a little bit – finding a $\tilde \mu \in [\mu/2, 2 \mu]$ instead of a $\tilde \mu \in (1 \pm \delta) \mu$. We show how to achieve this with $O(\frac{1}{\mu}\log{\log n \over p_{fail} })$ samples. </p>
<p>The high level idea is to divide $[\frac{1}{n}, 1]$ into a set of intervals<br>$$<br>{ [\frac{1}{n}, \frac{1}{2^{ \log n  -1} }], …, [\frac{1}{2^{i} }, \frac{1}{2^{i - 1} }], …,, [\frac{1}{4}, \frac{1}{2}],   [\frac{1}{2}, 1]}<br>$$<br>Let $[\frac{1}{2^{j} }, \frac{1}{2^{j - 1} }]$ $(j \in N)$ be the interval that $u$ belongs to. </p>
<p><img src="http://imglf6.nosdn.127.net/img/Y1FUYmVJRmJqaTNrbC9RWmRCdlpzYVQyNS9OR00wSUwzdGgwRU9rZGV0anhzUlpaMVhBWVB3PT0.jpg?imageView&thumbnail=1969y285&type=jpg&quality=96&stripmeta=0&type=jpg" alt="Figure"></p>
<p>Given an integer $i$, such that $i \le j - 2$ or $i \ge j + 1$, we can determine whether $\mu \ge \frac{1}{2^i}$ with high probability. We generate $O(2^i \log \frac{\log n}{p_{fail} })$ samples and test whether their average (i.e., $\tilde \mu$) is greater than $\frac{1}{2^i}$. If $\tilde \mu &gt; \frac{1}{2^i}$, by Chernoff inequality, $\mu &gt; \frac{1}{2^i}$ with high probability and the test returns true. </p>
<p>To search for the interval $[\frac{1}{2^{j} }, \frac{1}{2^{j - 1} }]$ that $\mu$ belongs to, we perform the test for increasing values of $i = 1, 2, …$ until we find the first $i$, such that the test for $\mu \ge \frac{1}{2^i}$ returns true. We claim that with high probability, $i$ takes one of the following values: ${j - 1, j, j + 1 }$. The reason is that the test returns false (with high probability) when $i  \le j - 2$. The results for $i = j - 1$ and $j$ are undetermined. Even if the test fails to return true for both $i = j - 1$ and $j$, it returns true for $i = j + 1$ with high probability. </p>
<p>Finally, after we find an $i \in {j - 1, j, j + 1 }$, we know that $\mu \ge \frac{1}{2 \cdot 2^i}$. Therefore, $O(2^i \log \frac{\log n}{p_{fail} })$ samples gives an $(\delta, p_{fail})$-estimate of $\mu$. </p>
<p>Then the total number of samples we generate is at most:<br>$$<br>\sum_{k = 1}^{j+1}O(2^k\log \frac{\log n}{p_{fail} }) = O(2^{j+2}\log \frac{\log n}{p_{fail} }) = O(\frac{1}{\mu}\log \frac{\log n}{p_{fail} })<br>$$</p>
<p>The procedure code is shown by Algorithm 1. </p>
<blockquote>
<p><strong>Algorithm 1</strong> </p>
<ol>
<li><strong>for</strong> $i \leftarrow 1$ to $\log n - 1$ <strong>do</strong></li>
<li>$\quad$        Let $\theta = 6 \cdot 2^i \log \frac{\log n}{p_{fail} }$.</li>
<li>$\quad$        Let $Y = 0$</li>
<li>$\quad$        <strong>for</strong> $j \leftarrow 1$ to $\theta$ <strong>do</strong> </li>
<li>$\quad$$\quad$                Generate a sample of $X$, denoted by $X_j$.</li>
<li>$\quad$$\quad$                $Y = Y + X_j$.</li>
<li>$\quad$        <strong>if</strong> $\frac{Y}{\theta} &gt; \frac{1}{2^i}$ <strong>then</strong> </li>
<li>$\quad$ $\quad$               <strong>return</strong> $\frac{Y}{\theta}$</li>
<li><strong>return</strong> $\frac{1}{n}$</li>
</ol>
</blockquote>
<p>To analyse Algorithm 1, we use the following Chernoff Bounds.</p>
<p><strong>Chernoff Bound</strong></p>
<blockquote>
<p>Let $X_1, X_2, …, X_\theta$ be $i.i.d.$ Bernoulli random variables with mean $\mu$ and $Y = \frac{1}{\theta} \sum_{k =1}^\theta X_k$. Then </p>
<ol>
<li>$P[Y \ge (1 + \delta) \mu] \le \exp(- \frac{\delta^2}{\delta + 2} \theta \mu)$.</li>
<li>$P[Y \le (1 - \delta) \mu] \le \exp(- \frac{\delta^2}{2} \theta \mu)$</li>
</ol>
</blockquote>
<p>Corollary</p>
<blockquote>
<p>For an integer $k \ge 1$, </p>
<ol>
<li>$P[Y \ge 2^k \mu] \le \exp (- \frac{(2^k -1)^2}{2^k + 1} \theta \mu) \le \exp(- \frac{2^{2k - 2} }{2^k + 1}  \theta \mu) = \exp(-\frac{2^k}{4(1+ {1} / {2^k})}  \theta \mu) \le \exp(-\frac{2^k}{6} \theta \mu)$</li>
<li>$P[Y \le \frac{1}{2^k}\mu] \le \exp(-\frac{(1-\frac{1}{2^k})^2}{2}  \theta \mu) \le \exp(-\frac{1}{8}\theta \mu)$</li>
</ol>
</blockquote>
<p><strong>Theorem</strong></p>
<blockquote>
<p>Let $X_1, X_2, …, X_\theta$ be $i.i.d.$ Bernoulli random variables with mean $\mu \in [\frac{1}{2^j}, \frac{1}{2^{j - 1} }]$ and $Y = \frac{1}{\theta} \sum_{k =1}^\theta X_k$. Suppose $\theta = 6 \cdot 2^i \log \frac{\log n}{p_{fail} }$ for some $i$, then </p>
<ol>
<li>$P[Y \ge \frac{1}{2^i}] \le \frac{p_{fail} }{\log n}$,  if $i \le j - 2$,</li>
<li>$P[Y \le \frac{1}{2^i}] \le \frac{p_{fail} }{2^{i - j - 1} \log n}$,  if $i \ge j + 1$.</li>
</ol>
</blockquote>
<p>Proof: First consider $i \le j - 2$. Then  $\frac{1}{2^i} \ge 2^{j - 1 - i} \mu$ , $2^{j - 1} \mu \ge 1$ and<br>$$<br>\begin{aligned}<br>P[Y \ge \frac{1}{2^i}]<br>&amp;\le P[Y \ge 2^{j - 1 - i} \mu] \<br>&amp;\le \exp(-\frac{2^{j- 1 - i} }{6}\theta \mu) \<br>&amp;= \exp(-\frac{2^{j - 1} \mu \cdot 2^{-i}\theta}{6}) \<br>&amp;\le\exp(-\frac{2^{-i}\theta}{6}) \<br>&amp;\le \frac{p_{fail} }{\log n}<br>\end{aligned}<br>$$</p>
<p>For $i \ge j + 1$, we have $\frac{1}{2^{i} } \le \frac{1}{2^{i - j} } \mu$ , $i - j \ge 1$ and<br>$$<br>\begin{aligned}<br>P[ Y \le \frac{1}{2^{i} }] &amp;\le P [Y \le \frac{1}{2^{i - j} } \mu] \<br>&amp;\le \exp(-\frac{\mu \theta}{8}) \<br>&amp;\le \exp(-\frac{2^{-j}\theta }{8}) \<br>&amp;\le \frac{p_{fail} }{2^{i - j -1}\log n}<br>\end{aligned}<br>$$</p>
<p>It follows that by union bound the test fails for all $i = 1, 2, …, j - 2, j + 1$ is at most $\frac{p_{fail} }{\log n} \cdot (j - 1) \le p_{fail}$.</p>
<h5 id="Exercise"><a href="#Exercise" class="headerlink" title="Exercise"></a>Exercise</h5><ol>
<li>Given a Bernoulli random variable $X$ with mean $\mu$, prove that (with Chernoff bound) if we generate $\Omega(\frac{1}{\delta^2 \mu}\log{1 \over p_{fail} })$ independent samples, we get an estimate of $X$ with relative error $\delta$ with probability $1 - p_{fail}$. </li>
</ol>
<h5 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h5><ol>
<li>Tang Youze, Xiaokui Xiao, and Yanchen Shi. “Influence maximization: Near-optimal time complexity meets practical efficiency.” <em>Proceedings of the 2014 ACM SIGMOD international conference on Management of data</em>. ACM, 2014. </li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/09/01/Vertex-Cover/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/09/01/Vertex-Cover/" class="post-title-link" itemprop="url">Vertex Cover</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-09-01 08:59:27" itemprop="dateCreated datePublished" datetime="2018-09-01T08:59:27+10:00">2018-09-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2018-09-04 01:32:44" itemprop="dateModified" datetime="2018-09-04T01:32:44+10:00">2018-09-04</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Given an undirected graph $G = &lt;V, E&gt;$ in which each vertex $i$ is associated with a weight $w_i$, vertex cover asks for the subset of vertices with minimum weight such that every each in $G$ is incident to at least one vertex in the set. The problem can be formulate as integer program and relaxed as linear program: let $x_i \in [0, 1]$ be a variable associated with the $i$ vertex, $n$ be the number of vertices and $m$ the number of edges, </p>
<p>$$<br>\begin{aligned}<br>&amp;\min  &amp; \sum_{i = 1}^n w_i x_i &amp;  &amp;\<br>&amp;s.t., &amp; x_i + x_j \ge 1 &amp; &amp; \forall e = (i,j) \in E \<br>&amp;      &amp; x_i \ge 0       &amp; &amp; \forall i \in [n]<br>\end{aligned}<br>$$</p>
<p>Its dual is given by </p>
<p>$$<br>\begin{aligned}<br>&amp;\max  &amp; \sum_{e \in E} y_e &amp;  &amp;\<br>&amp;s.t., &amp; \sum_{(i, j) \in E} y_{i, j} \le w_i &amp; &amp; \forall i \in [n] \<br>&amp;      &amp; y_{i, j} \ge 0       &amp; &amp; \forall e = (i, j) \in e<br>\end{aligned}<br>$$</p>
<p>By weak duality,<br>$$<br>\sum_{(i, j) \in E} y_{i, j} \le \sum_{(i,j) \in E} (x_i + x_j ) y_{i, j} = \sum_{i = 1}^n \left( \sum_{(i, j) \in E} y_{i, j}\right) x_i \le \sum_{i = 1}^n w_i x_i<br>$$</p>
<p>Let $x^*$ and $y^*$ denotes the primal and dual optimal solutions respectively. By strong duality, the complementary slackness states that<br>$$<br>\begin{aligned}<br>&amp; x_i + x_j = 1 &amp;\vee &amp;&amp; y_{i, j} = 0 &amp;&amp; (1)\<br>&amp; \sum_{(i, j) \in E} y^<em>_{i, j} = w_i &amp;\vee &amp;&amp; x^</em> = 0 &amp;&amp; (2)<br>\end{aligned}<br>$$</p>
<p>Now we show how to use this condition to construct an approximate primal solution. We begin with an initial values of $x = (0, 0, …, 0)$ and $y = (0, 0, …, 0)$. Note that $y$ is a dual feasible solution and condition $(2)$ holds. However $x$ is not a primal feasible solution. In the following we give an algorithm that maintains the feasibility of $y$ and condition $(2)$ while restores the feasibility of $x$. </p>
<blockquote>
<p>Algorithm 1  – an 2 approximation algorithm<br>while $\exists (i, j) \in E, s.t., x_i + x_j &lt; 1$<br>$\quad$ increase $y_{i, j}$ as much as possible until either </p>
<blockquote>
<p>$1. \quad \sum_{(i, k) \in E} y_{i, k} = w_i$, then set $x_i = 1$<br>$2. \quad \sum_{(j, k) \in E} y_{j, k} = w_j$, then set $x_j = 1$  </p>
</blockquote>
</blockquote>
<p>Note that in the inner loop, if two conditions hold simultaneously, we need only set one of $x_i$ and $x_j$ to 1. </p>
<p>Now we analyze the algorithm. It is apparent that $\sum_{(i, j) \in E} y_{i,j} \le w_i \forall i \in [i]$ holds throughout the algorithm. Moreover, for $i \in [i]$, $x_i = 0$ or $x_i = 1$. In the latter case, we must have $\sum_{(i, k) \in E} y_{i, k} = w_i$. We conclude that when the algorithm terminates, </p>
<p>$$<br>\sum_{(i, j) \in E} y_{i, j} \le \sum_{i = 1}^n w_i x_i =  \sum_{i = 1}^n \left( \sum_{(i, j) \in E} y_{i, j}\right) x_i  = \sum_{(i,j) \in E} (x_i + x_j ) y_{i, j}<br>$$</p>
<p>But $x_i + x_j$ is at most $2$, therefore $\sum_{(i, j) \in E} y_{i, j} \le \sum_{i = 1}^n w_i x_i \le 2\sum_{(i, j) \in E} y_{i, j}$. </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/08/28/Heavy-Hitter/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/08/28/Heavy-Hitter/" class="post-title-link" itemprop="url">Heavy Hitter</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-08-28 14:03:26" itemprop="dateCreated datePublished" datetime="2018-08-28T14:03:26+10:00">2018-08-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-06-05 00:38:04" itemprop="dateModified" datetime="2019-06-05T00:38:04+10:00">2019-06-05</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Given a sequence of numbers $S = { x_1, x_2, …, x_n }$ where each element comes from a finite domain $U$, the heavy hitter problem asks for the element that appears at least $\frac{n}{k + 1} + 1$ times in the sequence. Note that there could be at most $k$ such elements.</p>
<h2 id="Deterministic"><a href="#Deterministic" class="headerlink" title="Deterministic"></a>Deterministic</h2><p>If false positive is allowed, we have a deterministic algorithm that has $O(k)$ space overhead.  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">L = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> S:</span><br><span class="line">    <span class="keyword">if</span> x <span class="keyword">in</span> L:</span><br><span class="line">        L[x] = L[x] + <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">len</span>(L) &lt; k:</span><br><span class="line">        L[x] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        decrement the value of every elements <span class="keyword">in</span> L by <span class="number">1</span></span><br><span class="line">        delete elements <span class="keyword">in</span> L <span class="keyword">with</span> value = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>To see the correctness of the algorithm, we give each element in $S$ a token. There are $n$ tokens in total. If a element is not added to the list $L$, $k + 1$ token are throw away. If an elements appears more than $\frac{n}{k + 1}$ times, it must appears in $L$ when the algorithm terminates.  </p>
<p>Another way to prove this is that, each time an element is thrown away, it is not in the counter and the sum of counter decremented is $k$. Let $f_x$ be the frequency of an element $x$. Then the maximum number of times $x$ is thrown away is bounded by $k f_x \le n - f_x$, which implies that $f_x \le \frac{n}{k + 1}$.</p>
<h2 id="Randomized"><a href="#Randomized" class="headerlink" title="Randomized"></a>Randomized</h2><p>An alternate approach is randomized algorithm. In high level, we would like to maintain a set of $m$ bins and assign each element in $U$ uniformly at random one of the bins. Then we put each number in $S$ into the $m$ bins according which bin it is assigned to. In expectation, each bin will receive $\frac{n}{m}$ elements. To estimate the number of time an element $x$ appears in $S$, we just return the number of elements of the bin $x$ is assigned. Note that we might overestimate $x$’s frequency, whose expectation is at most $\frac{n}{m}$. We might repeat this several time to reduce variance.  </p>
<p>The tools to achieve the idea are $t$ hash functions $h_1, h_2, …, h_t : S \rightarrow [m]$. Initially, we have $l$ list (denoted as $L_1, L_2, .., L_t$) where each list has size $m$. Then we go through elements in $S$. For each element $x$, we increment the $L_i[h_i(x)]$ by 1 for all $i \in [t]$. Finally for an element $x$, we use the minimum value $\min_i { L_i[h_i(x)] }$ as its frequency estimation. </p>
<p>$$<br>\begin{aligned}<br>E[L_i[h_i(x)]]<br>&amp;= f_x + \sum_{y \in S, y \neq x} P [h_i (y) \<br>&amp;= f_x + \frac{(n - f_x)}{m} \<br>&amp;\le f_x + \frac{n}{m}<br>\end{aligned}<br>$$</p>
<p>By Markov inequality,<br>$$<br>P[ L_i[h_i(x)] -  f_x &gt;  2 \frac{n}{m}] \le \frac{E[L_i[h_i(x)] - f_x]}{ 2 \frac{n}{m} }  \le \frac{ \frac{n}{m} }{ 2 \frac{n}{m} }  \le \frac{1}{2}<br>$$</p>
<p>Therefore,<br>$$<br>P[ \min_i { L_i[h_i(x)] } - f_x &gt; 2 \frac{n}{m}] \le \frac{1}{2^t}<br>$$</p>
<p>which decreases exponentially with respect to the size of $t$. If we would like the failure probability to be $\delta$, we need to set $t = O(\log \frac{1}{\delta})$.</p>
<p>In conclusion, we can return the estimation of frequency of elements, such that $\forall x \in U$,  $\tilde{f_x} \le f_x + 2\frac{n}{m}$, with probability at least $1 - \delta$ and space overhead $O(m \log \frac{1}{\delta})$.</p>
<p>Reference:  </p>
<ol>
<li>MIT 6.854/18.415: Advanced Algorithms, Spring 2016, Lecture 4</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/08/27/Consistent-Hashing/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/08/27/Consistent-Hashing/" class="post-title-link" itemprop="url">Consistent Hashing</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2018-08-27 19:55:06 / Modified: 22:25:55" itemprop="dateCreated datePublished" datetime="2018-08-27T19:55:06+10:00">2018-08-27</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Suppose that we would like to implement a distributed file system. There are $m$ files and $n$ servers to store the file. We want to spread the work load to the servers so that each one keeps approximate $\frac{m}{n}$ files. One way to achieve this is by hashing. Let $p \gg m$ be a prime number. Then<br>$$<br>h(x) = ax + b \mod p \mod n<br>$$<br>gives us the desired property if $a \in {1, 2, …, p -1}$ and $b \in {0, 1, 2, …, p - 1}$ are selected uniformly at random. </p>
<p>The problem is that what if $n$ changes constantly? </p>
<p>Consider mapping the $n$ servers uniformly and independently to real numbers in $[0, 1]$. Let’s divide $[0, 1]$ into $n$ equally sized intervals $[0, 1/n]$, $[1/n, 2/n]$, …, $[(n - 1)/n, 1]$. Now, for an interval that a particular server belongs, the probability that no server maps to the $2 \log n$ intervals to the left of this interval is given by </p>
<p>$$<br>(1 - \frac{2 log n}{n})^{n - 1} \le e^{-\frac{2 log n}{n} (n - 1)} = \frac{1}{n^2} e^{\frac{2 log n}{n}} \le \frac{e}{n^2}<br>$$</p>
<p>By union bound, this happens to some server is bounded by $\frac{e}{n}$. </p>
<p>What is the probability that the interval between some pair of servers is $O(1 / n^2)$. If we divide $[0, 1]$ into $\Theta(n^2)$ equally size intervals, by Birthday’s Paradox, there is high probability that some interval contains two servers. </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/08/26/Birthday-Paradox/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="你生之前悠悠千載已逝，未來還會有千年沉寂的期待">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/08/26/Birthday-Paradox/" class="post-title-link" itemprop="url">Birthday Paradox</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-08-26 11:29:30" itemprop="dateCreated datePublished" datetime="2018-08-26T11:29:30+10:00">2018-08-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-12-09 18:34:28" itemprop="dateModified" datetime="2020-12-09T18:34:28+11:00">2020-12-09</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Suppose that we throw $m$ balls into $n$ bins uniformly at random, where $n$ is a fixed number. What is the probability that some pair of balls are placed in the same bin? </p>
<p>Define $X_{i, j}$ be the indicator variable that the $i$-th ball and the $j$-th ball go to the same bin. Its expectation is given by </p>
<p>$$<br>E[X_{i,j}] = 1\cdot P[ X_{i,j} = 1] + 0 \cdot P[X_{i,j} = 0] = \frac{1}{n}.<br>$$</p>
<p>By linearity of expectation, we have<br>$$<br>E[\sum_{1 \le i &lt; j \le m} X_{i,j}] = \sum_{1 \le i &lt; j \le m} E[X_{i,j}] = \frac{m (m - 1)}{2n}.<br>$$</p>
<p>When $m \approx \sqrt{2n}$, in expectation, there is a pair of ball going to the same bin. However, this estimate is too loose. </p>
<p>Define $p(m, n)$ the exact probability that no ball goes to the same bin. Then </p>
<p>$$<br>p(m, n) = \prod_{i = 0}^m \frac{n - i}{n} = \prod_{i = 0}^m (1 - \frac{i}{n}).<br>$$</p>
<p>By inequality $1 - \frac{i}{n} \le e^{- \frac{i}{n} }$, we have a upper bound for the above probability:<br>$$<br>p(m, n) \le  e^{- \frac{m (m - 1)}{2n} }.<br>$$</p>
<p>Therefore, the probability that there is at least one collision is lower bounded by<br>$$<br>1 - e^{- \frac{m (m - 1)}{2n} }.<br>$$</p>
<p>If $m = \sqrt n$, we get $e^{- \frac{m (m - 1)}{2n} }  \approx e^{-\frac{1}{2} }  \approx 0.6$. If $m = 2 \sqrt n$, we get $e^{- \frac{m (m - 1)}{2n} }  \approx e^{-2} \approx 0.14$.</p>
<p>In the case $n = 365$, we say that if there are $\sqrt n \approx 19$ people, $40%$ of times some pair of them share the same birthday. If there are $36$ people, the probability is over $80%$.  </p>
<p><em>Remark:</em> let’s play some math to bound $p(m, n)$ asymptotically. First, when $x \le 1 / 2$, we have<br>$$<br>e^x = \sum_{i = 0}^\infty x^i / i! \le 1 + x + \frac{x^2}{2} \left( \sum_{i = 0}^\infty ( \frac{1}{2})^i \right) \le 1 + 2 x.<br>$$</p>
<p>Hence,<br>$$<br>p(m, n) \le  e^{- \frac{m (m - 1)}{2n} } \le \exp( -\frac{m^2}{2n} ) \cdot (1 + \frac{m}{n} ).<br>$$</p>
<p>On the other hand, for $k \in \mathbb{N}^+$,<br>$$<br>(1 - x) ( \sum_{i = 0}^k  x^k) = 1 - x^{k + 1}.<br>$$</p>
<p>when $|x| &lt; 1$,<br>$$<br>(1 - x) ( \sum_{i = 0}^\infty  x^i) = \lim_{k \rightarrow \infty} (1 - x^{k + 1} ) = 1.<br>$$</p>
<p>Therefore, when $|x| &lt; 1$,<br>$$<br>\frac{1}{1 - x} = \sum_{i = 0}^\infty x^i.<br>$$</p>
<p>Replacing $x$ with $-x$, we get<br>$$<br>\frac{1}{1 + x} = \sum_{i = 0}^\infty (-1)^i x^i = 1 - x + x^2 - x^3 + …<br>$$</p>
<p>By $(\ln (1 + x) )’ = \frac{1}{1 + x}$, we get<br>$$<br>\ln (1 + x) = x - \frac{x^2}{2} + \frac{x^3}{3} - …<br>$$</p>
<p>and<br>$$<br>\ln (1 - x) = - x - \frac{x^2}{2} - \frac{x^3}{3} - …<br>$$</p>
<p>When $x \le 1 / 2$, we get<br>$$<br>\ln (1 - x) \ge - x - \frac{x^2}{2}( \sum_{i = 0}^\infty (\frac{1}{2})^i ) = -x - x^2.<br>$$</p>
<p>So, when $m &lt; n / 2$,<br>$$<br>\begin{aligned}<br>    p(m, n)<br>        &amp;= \prod_{i = 0}^m (1 - \frac{i}{n}) \<br>        &amp;\ge \exp( - \sum_{i = 0}^m \frac{i}{n} - \sum_{i = 0}^m \frac{i^2}{n^2}) \<br>        &amp;\ge \exp( - \frac{m (m - 1)}{2n} ) ( 1 - \sum_{i = 0}^m \frac{i^2}{n^2}) \<br>        &amp;\ge \exp( - \frac{m^2}{2n} ) ( 1 - O( \frac{m^3}{n^2} ) ).<br>\end{aligned}<br>$$</p>
<p>Combined, we get<br>$$<br>\exp( - \frac{m^2}{2n} ) ( 1 - O( \frac{m^3}{n^2} ) ) \le p(m, n) \le \exp( - \frac{m^2}{2n} ) ( 1 - m / n ).<br>$$</p>
<p>If $m &lt; \sqrt n$, then $m^3 / n^2 &lt; m / n$. In this case,<br>$$<br>p(m, n) = \Theta \left( \exp( - \frac{m^2}{2n} ) ( 1 - m / n ) \right).<br>$$</p>
<p>Replacing $m = \sqrt{2 n\ln 2}$, then<br>$$<br>p(m, n) = \frac{1}{2} + \Theta( \frac{1}{\sqrt n}).<br>$$</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference."></a>Reference.</h3><p>[1]. Ryan O’Donnell, Lecture 3, CS Theory Toolkit, CARNEGIE MELLON UNIVERSITY</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/4/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/6/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description">你生之前悠悠千載已逝，未來還會有千年沉寂的期待</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">125</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WOW</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
