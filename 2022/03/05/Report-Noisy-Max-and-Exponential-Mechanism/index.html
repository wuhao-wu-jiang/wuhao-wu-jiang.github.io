<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Let \(d \in \mathbb{N}^+\) be a positive integer, and \(\vec{u} \in \mathbb{N}^d\) be a vector.  Definition. Two vectors \(\vec{u}, \vec{v} \in \mathbb{N}^d\) are neighboring, denoted as \(\vec{u">
<meta property="og:type" content="article">
<meta property="og:title" content="Report Noisy Max and Exponential Mechanism">
<meta property="og:url" content="http://example.com/2022/03/05/Report-Noisy-Max-and-Exponential-Mechanism/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:description" content="Let \(d \in \mathbb{N}^+\) be a positive integer, and \(\vec{u} \in \mathbb{N}^d\) be a vector.  Definition. Two vectors \(\vec{u}, \vec{v} \in \mathbb{N}^d\) are neighboring, denoted as \(\vec{u">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-03-06T00:12:45.000Z">
<meta property="article:modified_time" content="2022-10-18T02:29:00.892Z">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2022/03/05/Report-Noisy-Max-and-Exponential-Mechanism/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Report Noisy Max and Exponential Mechanism | WOW</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">WOW</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">你生之前悠悠千載已逝<br>未來還會有千年沉寂的期待</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/03/05/Report-Noisy-Max-and-Exponential-Mechanism/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Report Noisy Max and Exponential Mechanism
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-03-05 19:12:45" itemprop="dateCreated datePublished" datetime="2022-03-05T19:12:45-05:00">2022-03-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-10-17 22:29:00" itemprop="dateModified" datetime="2022-10-17T22:29:00-04:00">2022-10-17</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Let <span class="math inline">\(d \in \mathbb{N}^+\)</span> be a
positive integer, and <span class="math inline">\(\vec{u} \in
\mathbb{N}^d\)</span> be a vector.</p>
<blockquote>
<p><strong>Definition.</strong> Two vectors <span
class="math inline">\(\vec{u}, \vec{v} \in \mathbb{N}^d\)</span> are
neighboring, denoted as <span class="math inline">\(\vec{u} \sim
\vec{v}\)</span>, if <span class="math inline">\(\Vert \vec{u} - \vec{v}
\Vert_\infty = 1\)</span>.</p>
</blockquote>
<p>We are interested in the following research problem.</p>
<blockquote>
<p><strong>Problem.</strong> Design an <span
class="math inline">\(\epsilon\)</span>-differentially private algorithm
to report <span class="math display">\[
\underset{i \in [d]}{\arg\max} \, u_i.
\]</span></p>
</blockquote>
<h1 id="laplacian-mechanism">Laplacian Mechanism</h1>
<p>Since <span class="math inline">\(\Vert \vec{u} - \vec{v}
\Vert_\infty = 1\)</span>, it is possible that <span
class="math inline">\(\Vert \vec{u} - \vec{v} \Vert_1 = d\)</span>. A
naive approach would be adding independent Laplacian noise <span
class="math inline">\(X_i \sim \mathcal{Lap}( \epsilon / d)\)</span> to
each coordinate of <span class="math inline">\(\vec{u}\)</span>, and
then return <span class="math display">\[
    \mathcal{M}(\vec{u}) \doteq \underset{ i \in [d] }{\arg \max} \big(
u_i + X_i \big).
\]</span></p>
<blockquote>
<p><strong>Theorem (Privacy Guarantee).</strong> The algorithm is <span
class="math inline">\(\epsilon\)</span>-differentially private.</p>
</blockquote>
<p><strong>Proof.</strong></p>
<p>This follows directly from Laplacian mechanism.</p>
<p><span class="math inline">\(\square\)</span></p>
<blockquote>
<p><strong>Theorem (Utility Guarantee).</strong> With probability at
least <span class="math inline">\(1 - \beta\)</span>, it holds that
<span class="math display">\[
u_{ \mathcal{M}(\vec{u}) } \ge \left( \max_{i \in [d] } u_i \right) -
\frac{d}{\epsilon} \ln \frac{d}{\beta}.
\]</span> <strong>Proof.</strong> For each <span class="math inline">\(i
\in [d]\)</span>, <span class="math display">\[
\Pr \left[ |X_i| \ge \frac{d}{\epsilon} \ln \frac{d}{\beta} \right] \le
\frac{\beta}{d}.
\]</span> Via union bound, <span class="math display">\[
\Pr \left[ \exists i \in [d] : |X_i| \ge \frac{d}{\epsilon} \ln
\frac{d}{\beta} \right] \le \beta.
\]</span> <span class="math inline">\(\square\)</span></p>
</blockquote>
<h1 id="report-noisy-max">Report Noisy Max</h1>
<h2 id="laplacian-noise">Laplacian Noise</h2>
<p>It is possible to add Laplacian noise <span class="math inline">\(X_i
\sim \mathcal{Lap}(2 / \epsilon)\)</span> to each coordinate of <span
class="math inline">\(\vec{u}\)</span>, and then return <span
class="math display">\[
    \mathcal{M}(\vec{u}) \doteq \underset{ i \in [d] }{\arg \max} \big(
u_i + X_i \big).
\]</span></p>
<blockquote>
<p><strong>Theorem (Privacy Guarantee).</strong> The algorithm is <span
class="math inline">\(\epsilon\)</span>-differentially private.</p>
</blockquote>
<p><strong>Proof.</strong> We prove that for each <span
class="math inline">\(k \in [d]\)</span>, and each <span
class="math inline">\(\vec{u}, \vec{v} \in \mathbb{N}^d\)</span> s.t.,
<span class="math inline">\(\vec{v} \sim \vec{u}\)</span>, it holds that
<span class="math display">\[
    e^{-\epsilon} \cdot \Pr[ \mathcal{M}(\vec{v}) = k] \le
    \Pr[ \mathcal{M}(\vec{u}) = i ]
    \le
    e^\epsilon \cdot \Pr[ \mathcal{M}(\vec{v}) = k].
\]</span> By symmetry, we prove the claim for just <span
class="math inline">\(k = n\)</span>.</p>
<p>For each <span class="math inline">\(\vec{u} \in
\mathbb{N}^d\)</span> and each sequence <span
class="math inline">\(\vec{s} = (s_1, \ldots, s_{n - 1} ) \in
\mathbb{R}^{n - 1}\)</span>, define <span class="math display">\[
    z (\vec{u}, \vec s) = \max_{j \in [n - 1] } \big(  u_j + s_j \big).
\]</span></p>
<p>Let <span class="math inline">\(X_j \sim \mathcal{Lap}(\epsilon / 2),
j \in [n]\)</span>, and denote <span class="math inline">\(\vec X_{n -
1} \doteq (X_1, \ldots, X_{n - 1})\)</span>. The event <span
class="math inline">\(\mathcal{M}(\vec{u}) = n\)</span> happens if and
only if<br />
<span class="math display">\[
    z( \vec{u} , \vec X_{n - 1} ) &lt; u_n + X_n.
\]</span></p>
<p>Fix a sequence <span class="math inline">\(\vec s = (s_1, \ldots,
s_{n - 1} ) \in \mathbb{R}^{n - 1}\)</span>: <span
class="math display">\[
    \begin{aligned}
        \Pr\big[ \mathcal{M}(\vec{u}) = n \Vert \vec X_{n - 1} = \vec s
\big]
            &amp;= \Pr \big[ X_n &gt; z( \vec{u} , \vec{s} ) - u_n \big]
\\
            &amp;= \begin{cases}
                    \begin{aligned}
                        \frac{1}{2} \exp \left( -\frac{\epsilon}{2}
\cdot | z( \vec{u} , \vec{s} ) - u_n| \right),
                    \end{aligned}    
                    &amp;\text{ if } z( \vec{u} , \vec{s} ) - u_n &gt;
0, \\
                    \begin{aligned}
                        1 - \frac{1}{2} \exp \left( -\frac{\epsilon}{2}
\cdot | z( \vec{u} , \vec{s} ) - u_n| \right),
                    \end{aligned}    
                    &amp;\text{ if } z( \vec{u} , \vec{s} ) - u_n \le 0.
            \end{cases}
    \end{aligned}
\]</span></p>
<p>Similarly, <span class="math display">\[
    \begin{aligned}
        \Pr\big[ \mathcal{M}(\vec{v}) = n \Vert \vec X_{n - 1} = \vec s
\big]
            &amp;= \Pr \big[ X_n &gt; z( \vec{v} , \vec{s} ) - v_n \big]
\\
            &amp;= \begin{cases}
                    \begin{aligned}
                        \frac{1}{2} \exp \left( -\frac{\epsilon}{2}
\cdot | z( \vec{v} , \vec{s} ) - v_n | \right),
                    \end{aligned}    
                    &amp;\text{ if } z( \vec{v} , \vec{s} ) - v_n &gt;
0, \\
                    \begin{aligned}
                        1 - \frac{1}{2} \exp \left( -\frac{\epsilon}{2}
\cdot | z( \vec{v} , \vec{s} ) - v_n| \right),
                    \end{aligned}    
                    &amp;\text{ if } z( \vec{v} , \vec{s} ) - v_n \le 0.
            \end{cases}
    \end{aligned}
\]</span></p>
<p>Let <span class="math inline">\(\Delta \doteq z( \vec{u} , \vec{s} )
- u_n - (z( \vec{v} , \vec{s} ) - v_n)\)</span>. The assumption <span
class="math inline">\(\Vert \vec{u} - \vec{v} \Vert_\infty = 1\)</span>
implies that <span class="math inline">\(|\Delta| \le 2\)</span>. WLOG,
assume that <span class="math inline">\(z( \vec{u} , \vec{s} ) - u_n \le
z( \vec{v} , \vec{s} ) - v_n\)</span>. Then <span
class="math display">\[
    \Pr \big[ X_n &gt; z( \vec{v} , \vec{s} ) - v_n \big]
        = \Pr \big[ X_n + \Delta &gt; z( \vec{u} , \vec{s} ) - u_n
\big].
\]</span></p>
<p>Define <span class="math inline">\(Y_n \doteq X_n + \Delta\)</span>,
which is also a Laplacian random variable with distribution <span
class="math inline">\(\mathcal{L}ap (\Delta, 2 / \epsilon)\)</span>. It
follows that <span class="math inline">\(Y_n\)</span> is <span
class="math inline">\((\epsilon, 0)\)</span>-close to <span
class="math inline">\(X_n\)</span>, and <span class="math display">\[
    \begin{aligned}
        \frac{
            \Pr\big[ \mathcal{M}(\vec{u}) = n \Vert \vec X_{n - 1} =
\vec s \big]
        }{
            \Pr \big[ \mathcal{M}(\vec{v}) = n \Vert \vec X_{n - 1} =
\vec s \big]
        }
            =
            \frac{
                \Pr \big[ X_n &gt; z( \vec{u} , \vec{s} ) - u_n \big]
            }{
                \Pr \big[ Y_n &gt; z( \vec{u} , \vec{s} ) - u_n \big]
            }
            \le e^\epsilon.
    \end{aligned}
\]</span></p>
<p><strong>Remark 1.</strong> We can also verifies this via the close
form expressions.</p>
<p>If <span class="math inline">\(0 \le z( \vec{u} , \vec{s} ) -
u_n\)</span>, clearly we have <span class="math display">\[
    \begin{aligned}
        \frac{\Pr\big[ \mathcal{M}(\vec{u}) = n \Vert \vec X_{n - 1} =
\vec s \big] }{ \Pr \big[ \mathcal{M}(\vec{v}) = n \Vert \vec X_{n - 1}
= \vec s \big] }
            \le \exp(\epsilon).
    \end{aligned}
\]</span></p>
<p>Consider <span class="math inline">\(z( \vec{v} , \vec{s} ) - v_n \le
0\)</span>. Let <span class="math inline">\(a \doteq |z( \vec{u} ,
\vec{s} ) - u_n|\)</span>, <span class="math inline">\(|b \doteq z(
\vec{v} , \vec{s} ) - v_n|\)</span>, and <span class="math inline">\(c =
1 / 2 \cdot \exp \left( - {\epsilon} / {2} \cdot b \right) \in [0, 1 /
2]\)</span>. Then <span class="math inline">\(a, b \ge 0\)</span>, <span
class="math inline">\(a - b \le 2\)</span>, and <span
class="math display">\[
    \begin{aligned}
        \frac{\Pr\big[ \mathcal{M}(\vec{u}) = n \Vert \vec X_{n - 1} =
\vec s \big] }{ \Pr \big[ \mathcal{M}(\vec{v}) = n \Vert \vec X_{n - 1}
= \vec s \big] }
            &amp;=        
            \frac{
                1 - \frac{1}{2} \exp \left( -\frac{\epsilon}{2} \cdot a
\right)
            }{
                1 - \frac{1}{2} \exp \left( -\frac{\epsilon}{2} \cdot b
\right)       
            } \\
            &amp;=       
            \frac{
                1 - c \cdot \exp \left( -\frac{\epsilon}{2} \cdot (a -
b) \right)
            }{
                1 - c       
            } \\
            &amp;\le       
            \frac{
                1 - c \cdot \exp \left( -\epsilon \right)
            }{
                1 - c       
            } \\                           
            &amp;=       
            \frac{1}{e^\epsilon}
            \frac{
                e^\epsilon - 1 + 1 - c
            }{
                1 - c       
            } \\
            &amp;=       
            \frac{1}{e^\epsilon}
            \left(
                \frac{
                    e^\epsilon - 1
                }{
                    1 - c       
                }  
                + 1
            \right) \\
            &amp;\le       
            \frac{1}{e^\epsilon}
            \left(
                \frac{
                    e^\epsilon - 1
                }{
                    1 - 1 / 2       
                }  
                + 1
            \right) \\                                 
            &amp;=       
            \frac{1}{e^\epsilon}
            \left(
                    2 e^\epsilon - 1
            \right) \\                   
            &amp;\le \exp(\epsilon).
    \end{aligned}
\]</span></p>
<p>Finally, consider <span class="math inline">\(z( \vec{u} , \vec{s} )
- u_n &lt; 0, z( \vec{v} , \vec{s} ) - v_n &gt; 0\)</span>. Let <span
class="math inline">\(a \doteq |z( \vec{u} , \vec{s} ) - u_n|\)</span>,
<span class="math inline">\(|b \doteq z( \vec{v} , \vec{s} ) -
v_n|\)</span>, and <span class="math inline">\(c = 1 / 2 \cdot \exp
\left( - {\epsilon} / {2} \cdot b \right) \in [0, 1 / 2]\)</span>. Then
<span class="math inline">\(a, b \ge 0\)</span>, <span
class="math inline">\(a + b \le 2\)</span>, and <span
class="math display">\[
    \begin{aligned}
        \frac{\Pr\big[ \mathcal{M}(\vec{u}) = n \Vert \vec X_{n - 1} =
\vec s \big] }{ \Pr \big[ \mathcal{M}(\vec{v}) = n \Vert \vec X_{n - 1}
= \vec s \big] }
            &amp;=        
            \frac{
                1 - \frac{1}{2} \exp \left( -\frac{\epsilon}{2} \cdot a
\right)
            }{
                \frac{1}{2} \exp \left( -\frac{\epsilon}{2} \cdot b
\right)       
            } \\
            &amp;=       
            \frac{
                1 - c \cdot \exp \left( -\frac{\epsilon}{2} \cdot (a -
b) \right)
            }{
                c       
            } \\
            &amp;\le       
            \frac{
                1 - c \cdot \exp \left( -\epsilon \right)
            }{
                c       
            } \\                           
            &amp;=       
            \frac{1}{c} -
            \frac{
                1
            }{
                e^\epsilon       
            } \\
            &amp;\le       
            2 - \exp(-\epsilon) \\
            &amp;\le \exp(\epsilon).
    \end{aligned}
\]</span></p>
<p>Integrating over <span class="math inline">\(\vec X_{n - 1} = \vec
s\)</span> for all possible <span class="math inline">\(\vec s\)</span>
finishes the proof.</p>
<p><span class="math inline">\(\square\)</span></p>
<blockquote>
<p><strong>Theorem (Utility Guarantee).</strong> With probability at
least <span class="math inline">\(1 - \beta\)</span>, it holds that
<span class="math display">\[
u_{ \mathcal{M}(\vec{u}) } \ge \left( \max_{i \in [d] } u_i \right) -
\frac{1}{\epsilon} \ln \frac{d}{\beta}.
\]</span> <strong>Proof.</strong> For each <span class="math inline">\(i
\in [d]\)</span>, <span class="math display">\[
\Pr \left[ |X_i| \ge \frac{1}{\epsilon} \ln \frac{d}{\beta} \right] \le
\frac{\beta}{d}.
\]</span> Via union bound, <span class="math display">\[
\Pr \left[ \exists i \in [d] : |X_i| \ge \frac{1}{\epsilon} \ln
\frac{d}{\beta} \right] \le \beta.
\]</span> <span class="math inline">\(\square\)</span></p>
</blockquote>
<h2 id="exponential-noise">Exponential Noise</h2>
<p>It is possible to add Exponential noise <span
class="math inline">\(X_i \sim \mathcal{Exp}(2 / \epsilon)\)</span> to
each coordinate of <span class="math inline">\(\vec{u}\)</span>, and
then return <span class="math display">\[
    \mathcal{M}(\vec{u}) \doteq \underset{ i \in [d] }{\arg \max} \big(
u_i + X_i \big).
\]</span></p>
<p>Following the same vein, we have <span class="math display">\[
    \begin{aligned}
        \Pr\big[ \mathcal{M}(\vec{u}) = n \Vert \vec X_{n - 1} = \vec s
\big]
            &amp;= \Pr \big[ X_n &gt; z( \vec{u} , \vec{s} ) - u_n \big]
\\
            &amp;= \begin{cases}
                    \begin{aligned}
                        \exp \left( -\frac{\epsilon}{2} \cdot | z(
\vec{u} , \vec{s} ) - u_n| \right),
                    \end{aligned}    
                    &amp;\text{ if } z( \vec{u} , \vec{s} ) - u_n &gt;
0, \\
                    \begin{aligned}
                        1 ,
                    \end{aligned}    
                    &amp;\text{ if } z( \vec{u} , \vec{s} ) - u_n \le 0.
            \end{cases}
    \end{aligned}
\]</span></p>
<p>And <span class="math display">\[
    \begin{aligned}
        \Pr\big[ \mathcal{M}(\vec{v}) = n \Vert \vec X_{n - 1} = \vec s
\big]
            &amp;= \Pr \big[ X_n &gt; z( \vec{v} , \vec{s} ) - v_n \big]
\\
            &amp;= \begin{cases}
                    \begin{aligned}
                        \exp \left( -\frac{\epsilon}{2} \cdot | z(
\vec{v} , \vec{s} ) - v_n | \right),
                    \end{aligned}    
                    &amp;\text{ if } z( \vec{v} , \vec{s} ) - v_n &gt;
0, \\
                    \begin{aligned}
                        1 ,
                    \end{aligned}    
                    &amp;\text{ if } z( \vec{v} , \vec{s} ) - v_n \le 0.
            \end{cases}
    \end{aligned}
\]</span></p>
<p>It is straightforward to check that <span class="math display">\[
    \begin{aligned}
        \frac{\Pr\big[ \mathcal{M}(\vec{u}) = n \Vert \vec X_{n - 1} =
\vec s \big] }{ \Pr \big[ \mathcal{M}(\vec{v}) = n \Vert \vec X_{n - 1}
= \vec s \big] }
            \le \exp(\epsilon).
    \end{aligned}
\]</span></p>
<h1 id="exponential-mechanism">Exponential Mechanism</h1>
<p>The exponential mechanism is defined by its output
distribution:<br />
<span class="math display">\[
    \Pr[\mathcal{M}(\vec{u}) = i] \propto \exp \left( \epsilon
\cdot   u_i  / 2 \right), \quad \forall i \in [d].
\]</span></p>
<p>Normalizing these probabilities give <span class="math display">\[
    \Pr[\mathcal{M}(\vec{u}) = i]
        = \frac{
            \exp \left( \epsilon \cdot u_i / 2 \right)
        }{
            \sum_{j \in [d] } \exp \left( \epsilon \cdot u_j / 2 \right)
        },
        \quad \forall i \in [d].
\]</span></p>
<blockquote>
<p><strong>Theorem (Privacy Guarantee).</strong> The algorithm is <span
class="math inline">\(\epsilon\)</span>-differentially private.</p>
</blockquote>
<p><strong>Proof.</strong> Fix a <span class="math inline">\(\vec{u} \in
\mathbb{N}^d\)</span>. We prove that for each <span
class="math inline">\(i \in [d]\)</span>, and each <span
class="math inline">\(\vec{v} \sim \vec{u}\)</span>, it holds that <span
class="math display">\[
    e^{-\epsilon} \cdot \Pr[ \mathcal{M}(\vec{v}) = i] \le \Pr[
\mathcal{M}(\vec{u}) = i ] \le e^\epsilon \cdot \Pr[
\mathcal{M}(\vec{v}) = i].
\]</span> By symmetry, we prove the claim for just <span
class="math inline">\(i = n\)</span>.</p>
<p><span class="math display">\[
    \begin{aligned}
        \frac{\Pr[ \mathcal{M}(\vec{u}) = n] }{\Pr[ \mathcal{M}(\vec{v})
= n] }
        &amp;= \frac{
            \exp \left( \epsilon \cdot u_n / 2 \right)
        }{
            \exp \left( \epsilon \cdot v_n / 2 \right)
        }
        \cdot \frac{
            \sum_{j \in [d] } \exp \left( \epsilon \cdot  v_j / 2
\right)
        }{
            \sum_{j \in [d] } \exp \left( \epsilon \cdot u_j / 2 \right)
        } \\
        &amp;\le
        \exp( \epsilon / 2 )
        \cdot \exp( \epsilon / 2 ) \\
        &amp;= \exp( \epsilon ).
    \end{aligned}
\]</span></p>
<p>The inequality follows since <span class="math display">\[
    \begin{aligned}
        u_i - v_i \le \Vert \vec{u} - \vec{v} \Vert_\infty \le 1,
        \implies \exp( \epsilon (u_i - v_i) / 2) \le \exp( \epsilon  /
2), \, \forall i \in [d].
    \end{aligned}
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<blockquote>
<p><strong>Theorem (Utility Guarantee).</strong> With probability at
least <span class="math inline">\(1 - \beta\)</span>, it holds that
<span class="math display">\[
u_{ \mathcal{M}(\vec{u}) } \ge \left( \max_{i \in [d] } u_i \right) -
\frac{2}{\epsilon} \cdot \ln \frac{|S|}{|S_{OPT}| \cdot \beta}.
\]</span> <strong>Proof.</strong> For each <span class="math inline">\(t
\in \mathbb{R}\)</span>, the un-normalized probability mass assigned to
the set <span class="math inline">\(S \doteq \{ i \in [d] : u_i \le t
\}\)</span> is at most <span class="math inline">\(|S| \cdot \exp \left(
\epsilon \cdot t / 2\right)\)</span>.</p>
</blockquote>
<p>On the other hand, the un-normalized probability mass assigned to the
set <span class="math inline">\(S_{OPT} \subseteq [d]\)</span>
consisting of optimal solutions is <span class="math inline">\(|S_{OPT}|
\cdot \exp \left( \epsilon \cdot \left( \max_{i \in [d] } u_i \right) /
2\right)\)</span>.</p>
<p><span class="math display">\[
    \begin{aligned}
        \Pr \left[ u_{ \mathcal{M}(\vec{u}) } \le t \right]
        &amp;\le
        \frac{
            |S| \cdot \exp \left( \epsilon \cdot t / 2\right)
        }
        {
            |S_{OPT}| \cdot \exp \left( \epsilon \cdot \left( \max_{i
\in [d] } u_i \right) / 2 \right)
        } \\
        &amp;\le \frac{|S|}{|S_{OPT}|} \exp \left( \epsilon \left( t -
\max_{i \in [d] } u_i \right) / 2 \right).
    \end{aligned}
\]</span></p>
<p>To bound the last term by <span class="math inline">\(\beta\)</span>,
we can set <span class="math display">\[
    t = \left( \max_{i \in [d] } u_i \right) - \frac{2}{\epsilon} \cdot
\ln \frac{|S|}{|S_{OPT}| \cdot \beta}.
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h2 id="gumbel-noise">Gumbel Noise</h2>
<p>A random variable <span class="math inline">\(X\)</span> follows the
Gumbel distribution <span class="math inline">\(\mathcal{Gumbel}(\mu,
b)\)</span> if its density is given by <span class="math display">\[
    p(x)
        \doteq \frac{1}{b} \cdot \exp \left( - (x - \mu) / b - e^{- (x -
\mu) / b}  \right)
        = \frac{1}{b} \cdot e^{ - (x - \mu) / b } \cdot \exp \left(-
e^{- (x - \mu) / b} \right), \forall x \in \mathbb{R}.
\]</span> It follows that the cumulative distribution of <span
class="math inline">\(X\)</span> is <span class="math display">\[
    \begin{aligned}
        \Pr[ X \le t ]
            &amp;= \int_{-\infty}^t \frac{1}{b} \cdot e^{ - (x - \mu) /
b } \cdot \exp \left(- e^{- (x - \mu) / b} \right) \, d x \\
            &amp;= - \int_{-\infty}^t \exp \left(- e^{- (x - \mu) / b}
\right) \, d e^{ -  (x - \mu) / b } \\
            &amp;= \int^{\infty}_{\exp(- (t - \mu) / b)} \exp \left(- y
\right) \, d y \\
            &amp;= \exp \left(- e^{ - (t - \mu) / b } \right).
    \end{aligned}
\]</span></p>
<blockquote>
<p><strong>Theorem.</strong> If we add Gumbel noise <span
class="math inline">\(X_i \sim \mathcal{Gumbel}(0, 2 /
\epsilon)\)</span> to each coordinate of <span
class="math inline">\(\vec{u}\)</span>, and then return <span
class="math display">\[
\mathcal{M}(\vec{u}) \doteq \underset{ i \in [d] }{\arg \max} \big( u_i
+ X_i \big),  
\]</span> the output has the same distribution as the one of exponential
mechanism.</p>
</blockquote>
<p><strong>Proof.</strong> Let <span class="math inline">\(b = 2 /
\epsilon\)</span>, and <span class="math inline">\(Z_i \doteq u_i +
X_i\)</span>. Then <span class="math inline">\(Z_i \sim
\mathcal{Gumbel}(u_i, b)\)</span>, and <span class="math display">\[
    \begin{aligned}
        \Pr[ \mathcal{M}(\vec{u}) = n]
            &amp;= \int_{-\infty}^\infty \left( p(z_n) \cdot \prod_{i
\in [n - 1]} \Pr[ Z_i \le z_n ] \right) \, d z_n \\
            &amp;= \int_{-\infty}^\infty \left(
                    \frac{1}{b} \cdot e^{ - (z_n - u_n) / b } \cdot \exp
\left(- e^{- (z_n - u_n) / b} \right)
                    \cdot
                    \prod_{i \in [n - 1]} \exp \left(- e^{- (z_n - u_i)
/ b } \right)
                \right) \, d z_n  \\
            &amp;= e^{ u_n / b } \cdot \int_{-\infty}^\infty \left(
                    \frac{1}{b} \cdot e^{ - z_n / b } \cdot \exp \left(-
e^{- z_n / b} \cdot \sum_{i \in [n ]}  e^{ u_i / b } \right)
                \right) \, d z_n  \\
            &amp;= - e^{ u_n / b } \cdot \int_{\infty}^0
                    \exp \left( - y \cdot \sum_{i \in [n ]}  e^{ u_i / b
} \right)
                \, d y
            &amp; (y \doteq e^{-z_n/b} ) \\
            &amp;= \frac{ \exp \left( u_n / b \right) }{
                \sum_{i \in [n]} \exp \left( u_i / b \right)
            }.
    \end{aligned}
\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<h1 id="reference">Reference</h1>
<p>[1] <em>C. Dwork and A. Roth, “The Algorithmic Foundations of
Differential Privacy,”</em></p>
<p>[2] <a
target="_blank" rel="noopener" href="https://lips.cs.princeton.edu/the-gumbel-max-trick-for-discrete-distributions/"><em>The
Gumbel-Max Trick for Discrete Distributions</em></a></p>
<p>[3] <em>D. Durfee and R. M. Rogers, “Practical Differentially Private
Top-k Selection with Pay-what-you-get Composition,” in Advances in
Neural Information Processing Systems, 2019, vol. 32. Accessed: Sep. 13,
2022.</em></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/02/11/Approximate-Densest-Subgraph/" rel="prev" title="Approximate Densest Subgraph">
      <i class="fa fa-chevron-left"></i> Approximate Densest Subgraph
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/03/18/van-Emde-Boas-Trees/" rel="next" title="van Emde Boas Tree">
      van Emde Boas Tree <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#laplacian-mechanism"><span class="nav-number">1.</span> <span class="nav-text">Laplacian Mechanism</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#report-noisy-max"><span class="nav-number">2.</span> <span class="nav-text">Report Noisy Max</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#laplacian-noise"><span class="nav-number">2.1.</span> <span class="nav-text">Laplacian Noise</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#exponential-noise"><span class="nav-number">2.2.</span> <span class="nav-text">Exponential Noise</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#exponential-mechanism"><span class="nav-number">3.</span> <span class="nav-text">Exponential Mechanism</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#gumbel-noise"><span class="nav-number">3.1.</span> <span class="nav-text">Gumbel Noise</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#reference"><span class="nav-number">4.</span> <span class="nav-text">Reference</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">196</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WOW</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
