<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="WOW">
<meta property="og:url" content="http://example.com/page/34/index.html">
<meta property="og:site_name" content="WOW">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="WOW">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/34/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>WOW</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">WOW</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">你生之前悠悠千載已逝<br>未來還會有千年沉寂的期待</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/09/14/Facility-Location-Problem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/09/14/Facility-Location-Problem/" class="post-title-link" itemprop="url">Facility Location Problem</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-09-14 10:58:58" itemprop="dateCreated datePublished" datetime="2018-09-14T10:58:58+10:00">2018-09-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-13 16:58:50" itemprop="dateModified" datetime="2020-05-13T16:58:50+10:00">2020-05-13</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong><em>Update on May/7th/2020.</em></strong></p>
<p>Suppose we have a set of facilities <span class="math inline">\(F\)</span> and a set of clients <span class="math inline">\(C\)</span>. We would like to open some facilities from $F $ to serve the clients. The cost consists of two parts: 1) the one for opening the selected facilities; 2) the one for connecting each client to its closest facility.</p>
<p>Formally, denote <span class="math inline">\(f_i\)</span> the cost of facility <span class="math inline">\(i \in F\)</span> and <span class="math inline">\(c_{i,j}\)</span> the distance from a client <span class="math inline">\(j \in C\)</span> to a facility <span class="math inline">\(i \in F\)</span>. Let <span class="math inline">\(S \subset F\)</span> be a subset of facilities, and let <span class="math inline">\(\mu : C \rightarrow S\)</span> be the corresponding function that assigns each client <span class="math inline">\(j \in C\)</span> to a facility in <span class="math inline">\(S\)</span>, i.e., <span class="math display">\[
\mu(j) \doteq \arg\min_{i \in S} c_{i,j}
\]</span></p>
<p>The cost of <span class="math inline">\(S\)</span> is given by <span class="math display">\[
\sum_{i \in S} f_i + \sum_{j \in C} c_{\mu(j), j}
\]</span></p>
<p>The problem is to find a set <span class="math inline">\(S\)</span> that minimizes this cost.</p>
<h2 id="lp-formulation"><strong><em>LP Formulation</em></strong></h2>
<p>It can be formulated as linear program and then relaxed as as a linear one:</p>
<p><span class="math display">\[
\begin{array}{lrllr}
\text{Primal:}
    &amp;&amp;\min  &amp; \sum_{i \in F, j \in C} c_{i, j} x_{i, j} + \sum_{i \in F} f_i y_i &amp; &amp;  \\
    &amp;&amp;s.t., &amp; \sum_{i \in F} x_{i j} \ge 1  &amp; \forall j \in C  &amp; (1) \\
    &amp;&amp;      &amp; y_i - x_{i,j} \ge 0           &amp; \forall i \in F, j \in C &amp; (2)
\end{array}
\]</span></p>
<p>The first constraint says that each client is assigned to at least one facility. The second one can be interpreted as that a facility must be open if there is a client assigned to it.</p>
<p>To obtain the dual, let <span class="math inline">\(\alpha_j\)</span> be the dual variable associated with constraint (1) and <span class="math inline">\(\beta_{i,j}\)</span> be the one with constraint (2). We need to ensure that weak duality holds.</p>
<h3 id="weak-duality"><em>Weak Duality</em></h3>
<p><span class="math display">\[
\begin{array}{rl}
    \sum_{j \in C} \alpha_j 
        &amp;= \sum_{j \in C} \alpha_j \cdot 1 + \sum_{i \in F, j \in C} \beta_{i,j} \cdot 0 \\
        &amp;\le \sum_{j \in C} \alpha_j \cdot (\sum_{i \in F} x_{i,j} ) + \sum_{i \in F, j \in C} \beta_{i,j} \cdot (y_i - x_{i,j}) \\
        &amp;= \sum_{i \in F, j \in C} (\alpha_j - \beta_{i,j}) \cdot x_{i,j}  + \sum_{i \in F} \left( \left( \sum_{j \in C} \beta_{i,j} \right) \cdot y_i \right) \\
        &amp;\le \sum_{i \in F, j \in C} c_{i, j} x_{i, j} + \sum_{i \in F} f_i y_i
\end{array}
\]</span> The dual can be formulated such that the above inequalities hold.</p>
<h3 id="dual-program"><em>Dual Program</em></h3>
<p><span class="math display">\[
\begin{array}{lllr}    
    \text{Dual:} \qquad
    &amp;\max &amp; \sum_{j \in C} \alpha_j \\
    &amp;s.t.,&amp; \alpha_j - \beta_{i,j} \le c_{i,j} &amp; \forall i \in F, \forall j \in C\\
    &amp;     &amp; \sum_{j \in C} \beta_{i,j} \le f_i  &amp; \forall i \in F\\
\end{array}
\]</span></p>
<p>Here we give a more intuitive way of deriving the dual. First, we notice that <span class="math inline">\(\sum_{j \in C} \min_{i \in F} c_{i,j}\)</span> is a trivial lower bound of the primal programming. In this case, each client is assigned to its nearest facility. However we ignore facility cost entirely.</p>
<p>To incorporate the facility cost, for each facility <span class="math inline">\(i\)</span> we divide its cost <span class="math inline">\(f_i\)</span> among the clients, such that client <span class="math inline">\(j\)</span> needs to pay <span class="math inline">\(\beta_{i, j}\)</span> if it is assigned facility <span class="math inline">\(i\)</span>. Note that <span class="math inline">\(\beta_{i, j}\)</span> can be arbitrary non-negative number as long as it satisfies that <span class="math inline">\(\sum_{j \in C} \beta_{i,j} = f_i\)</span> for all <span class="math inline">\(i \in F\)</span>.</p>
<p><strong><em>Theorem.</em></strong> For any solution <span class="math inline">\(S\)</span> and <span class="math inline">\(\mu\)</span>, it holds that <span class="math display">\[
\begin{aligned}
    \sum_{j \in C} (c_{\mu(j), j} + \beta_{\mu(j), j} ) 
        &amp;\le \sum_{i \in S} f_i + \sum_{j \in C} c_{\mu(j) , j}
\end{aligned}
\]</span></p>
<p><em>Proof.</em> <span class="math display">\[
\begin{aligned}
    \sum_{j \in C} (c_{\mu(j), j} + \beta_{\mu(j), j} ) 
        &amp;=  \sum_{i \in F} \sum_{j \in \mu^{-1}(i) } ( \beta_{ i, j} ) + \sum_{j \in C} c_{\mu(j) , j} \\ 
        &amp;\le  \sum_{i \in F} \sum_{j \in C } ( \beta_{ i, j} ) + \sum_{j \in C} c_{\mu(j) , j} \\ 
        &amp;= \sum_{i \in S} f_i + \sum_{j \in C} c_{\mu(j) , j}
\end{aligned}
\]</span> <span class="math inline">\(\blacksquare\)</span></p>
<p>If we define <span class="math display">\[
\alpha_j = \min_{i \in F} (c_{i,j} + \beta_{i, j})
\]</span></p>
<p>Then <span class="math inline">\(\sum_{j \in F} \alpha_j\)</span> constitutes a lower bound for the cost of any solution. In particular, it is a lower bound of the cost of the optimal integral solution <span class="math inline">\(F^*\)</span> (its corresponding assignment function is denoted as <span class="math inline">\(\mu^*\)</span>):</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \sum_{j \in C} \alpha_j 
    \le \sum_{i \in F^*} f_i + \sum_{j \in C} c_{\mu^* (j), j} \\
\end{aligned}
\]</span></p>
<p>The idea of determining a set of <span class="math inline">\(\beta_{i,j}\)</span>'s that maximizes the lower bound <span class="math inline">\(\sum_{j \in C} \alpha_j\)</span> gives the dual program.</p>
<h3 id="complementary-slackness"><em>Complementary Slackness</em></h3>
<p>Let <span class="math inline">\(x^*, y^*\)</span> and <span class="math inline">\(\alpha^*, \beta^*\)</span> be the optimal primal and dual solution respectively. For these set of variables, weak duality holds with equalities. By complementary slackness, it holds that</p>
<ol type="1">
<li><span class="math inline">\(\alpha^*_j = 0\)</span> or <span class="math inline">\(\sum_{i \in F} x^*_{i,j} = 1\)</span></li>
<li><span class="math inline">\(\beta^*_{i,j} = 0\)</span> or <span class="math inline">\(y^*_i - x^*_{i,j} = 0\)</span></li>
</ol>
<p>and</p>
<ol start="3" type="1">
<li><span class="math inline">\(\alpha^*_j - \beta^*_{i,j} = c_{i,j}\)</span> or <span class="math inline">\(x^*_{i,j} = 0\)</span></li>
<li><span class="math inline">\(\sum_{j \in C} \beta^*_{i,j} = f_i\)</span> or <span class="math inline">\(y^*_i = 0\)</span></li>
</ol>
<h2 id="lp-rounding"><strong><em>LP Rounding</em></strong></h2>
<p>We show how to construct a integral solution <span class="math inline">\(x\)</span> from the optimal solution <span class="math inline">\(x^*, y^*\)</span>, <span class="math inline">\(\alpha^*\)</span> and <span class="math inline">\(\beta^*\)</span> to the primal and dual LP. First we construct a derived graph <span class="math inline">\(G = (V, E)\)</span> from primal LP.</p>
<p><strong><em>Definition.</em></strong> A derived graph from the optimal LP consists of the follows:</p>
<ol type="1">
<li>The vertex set <span class="math inline">\(V = F \cup C\)</span>;</li>
<li>The edge set <span class="math inline">\(E = \{ (i, j) : x^*_{i,j} &gt; 0, \forall i \in F, j \in C\}\)</span>. That is, the edge set <span class="math inline">\(E\)</span> contains all facility-client pairs <span class="math inline">\((i, j)\)</span> such that <span class="math inline">\(x^*_{i,j} &gt; 0\)</span>.</li>
</ol>
<p>In the graph <span class="math inline">\(G\)</span>, the neighbors a client <span class="math inline">\(j\)</span> can only be facilities.</p>
<p><strong><em>Definition.</em></strong> <em>For a client <span class="math inline">\(j \in C\)</span>, denote <span class="math inline">\(N(j)\)</span> the set of facilities that are adjacent to <span class="math inline">\(j\)</span> in <span class="math inline">\(G\)</span>.</em></p>
<p>Similarly, we define two hop neighbor of a client <span class="math inline">\(j\)</span>, as the client who connects to <span class="math inline">\(j\)</span> via a intermediate facility.</p>
<p><strong><em>Definition.</em></strong> *For a client <span class="math inline">\(j \in C\)</span>, its two hop neighbors are the set of client whose distance to <span class="math inline">\(j\)</span> is 2 in <span class="math inline">\(G\)</span>: <span class="math display">\[
N^2(j) =\{ j&#39; \in C: \exists i \in F, s.t., x^*_{i,j&#39;} &gt;0 \wedge   x^*_{i,j} &gt; 0 \}
\]</span></p>
<p>Below is an example. The cycles represent clients and the squares are for facilities. Associated each client and each facility are the <span class="math inline">\(\alpha_j^*\)</span> value and opening cost respectively.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm1.1.png" /></p>
<p>An important property of this graph is that</p>
<blockquote>
<p>If <span class="math inline">\((i,j) \in E\)</span>, then <span class="math inline">\(x^*_{i,j} &gt;0\)</span>, which implies that <span class="math inline">\(\alpha^*_j =c_{i,j} + \beta^*_{i,j}\)</span> by complementary slackness. It concludes that <span class="math inline">\(\alpha^*_j \ge c_{i,j}\)</span> if there is an edge <span class="math inline">\((i,j)\)</span> in <span class="math inline">\(G\)</span>.</p>
</blockquote>
<h3 id="deterministic-rounding-1"><strong><em>Deterministic Rounding [1]</em></strong></h3>
<p>As a warm up, we introduce the first constant factor approximation algorithm for the un-capacitated facility location problem, proposed in 1997 [1]. It is a deterministic rounding algorithm.</p>
<blockquote>
<p>Algorithm 1:<br />
1. <span class="math inline">\(S \leftarrow \emptyset\)</span>.<br />
2. <span class="math inline">\(D \leftarrow \emptyset\)</span>.<br />
2. While there exists some client not assigned to any facility<br />
3. <span class="math inline">\(\quad\)</span> Let <span class="math inline">\(j\)</span> be the unassigned one with smallest <span class="math inline">\(\alpha^*_j\)</span>, add it to <span class="math inline">\(D\)</span>.<br />
5. <span class="math inline">\(\quad\)</span> Open the cheapest facility <span class="math inline">\(i\)</span> in <span class="math inline">\(N(j)\)</span>, add it to <span class="math inline">\(S\)</span>.<br />
6. <span class="math inline">\(\quad\)</span> Assign <span class="math inline">\(j\)</span> to <span class="math inline">\(i\)</span>: <span class="math inline">\(\mu(j) \leftarrow i\)</span><br />
6. <span class="math inline">\(\quad\)</span> For each un-assigned client <span class="math inline">\(j&#39; \in N^2(j)\)</span> do<br />
8. <span class="math inline">\(\quad\)</span> <span class="math inline">\(\quad\)</span> <span class="math inline">\(\quad\)</span> Assign <span class="math inline">\(j&#39;\)</span> to <span class="math inline">\(i\)</span>: <span class="math inline">\(\mu(j&#39;) \leftarrow i\)</span></p>
</blockquote>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm1.2.png" /></p>
<p>The example above shows one iteration of the algorithm. The vertex with minimum value of <span class="math inline">\(\alpha^*_j\)</span> (i.e. 1) is opened, highlighted by the red cycle. There are two facilities connected to it, the cheap opening cost of which is 1. Then all un-assigned clients neighboring these two facilities are assigned to the cost 1 facility, as shown by the purple dashed arrows.</p>
<p>Intuitively, each iteration of the algorithm creates a clusters, which contains three kinds of vertices:</p>
<ol type="1">
<li>The selected un-assigned client <span class="math inline">\(j\)</span> with minimum <span class="math inline">\(\alpha^*_j\)</span>.</li>
<li>All <span class="math inline">\(j\)</span>'s neighboring facilities.<br />
</li>
<li>All un-assigned clients neighboring to these facilities.</li>
</ol>
<p>It is left to analyze the cost of the solution returned.</p>
<h4 id="facility-cost">Facility Cost</h4>
<p>At each iteration, a client <span class="math inline">\(j\)</span> is selected. In the primal LP, constraint (1) requires that <span class="math display">\[
\sum_{i \in F} x^*_{i,j} \ge 1
\]</span></p>
<p>Note that although <span class="math inline">\(j\)</span> can assigned to a client fractionally, the total amount of assignment must be at least 1. Further, although a facility can be fractionally open in primal LP, the constraint (2) <span class="math display">\[
y^*_i \ge x^*_{i, j}
\]</span> implies that the open amount must be at least the amount a client assign to it. By the selection of <span class="math inline">\(\mu(j)\)</span>, we conclude that <span class="math display">\[
\begin{array}{llr}
    f( \mu_S(j) ) 
        &amp;\le f( \mu(j) ) \cdot \sum_{i \in N(j)} x^*_{i, j} \\
        &amp;\le \sum_{i \in N(j)} x^*_{i, j} f_i \\
        &amp;\le \sum_{i&#39; \in N(j)} y^*_{i} f_{i}
\end{array}
\]</span></p>
<p>The neighbor sets <span class="math inline">\(N(j)\)</span>'s of the selected clients <span class="math inline">\(j \in D\)</span> are dis-joint.</p>
<p>Therefore, summing over <span class="math inline">\(j \in D\)</span>, the total facility cost is bounded by</p>
<p><span class="math display">\[
\sum_{j \in D} \sum_{i \in N(j)} y^*_{i} f_{i} \le \sum_{i \in F} y^*_i f_i \le OPT
\]</span></p>
<h4 id="connection-cost">Connection Cost</h4>
<p>Now we analyze the assignment cost. When a client <span class="math inline">\(j\)</span> with smallest <span class="math inline">\(\alpha^*_j\)</span> is selected and assigned to the cheapest facility <span class="math inline">\(i\)</span> in <span class="math inline">\(N(j)\)</span>. Unassigned clients <span class="math inline">\(j&#39; \in N^2(j)\)</span> are also assigned to <span class="math inline">\(i\)</span>. There are two possible cases:</p>
<ol type="1">
<li><p>There is an edge <span class="math inline">\((i, j&#39;)\)</span> in <span class="math inline">\(G\)</span>, i.e., <span class="math inline">\(j&#39; \in N(i)\)</span>. Then the assign cost is <span class="math inline">\(c_{i, j&#39;} \le \beta^*_{j&#39;}\)</span>.</p></li>
<li><p>There is no edge between <span class="math inline">\(i\)</span> and <span class="math inline">\(j&#39;\)</span> in <span class="math inline">\(G\)</span>. In this case, there exists some other facility <span class="math inline">\(i&#39; \in N(j)\)</span>, such that <span class="math inline">\((i&#39;,j&#39;) \in E\)</span>. By triangle inequality, we have <span class="math display">\[
 c_{i , j&#39;} \le c_{i, j} + c_{i&#39;, j} + c_{i&#39;, j&#39;} \le \alpha^*_{j} + \alpha^*_j + \alpha^*_{j&#39;} \le 3\alpha^*_{j&#39;}
 \]</span></p>
<p>The last inequality holds since <span class="math inline">\(\alpha^*_{j&#39;} \le \alpha^*_j\)</span>.</p></li>
</ol>
<p>Combing assignment cost and facility cost, algorithm 1 is 4-approximation.</p>
<p>How happy are we with the 4-approximation algorithm? Probably not. In the previous example, when a facility is opened, only one client contributes to its opening cost. However, in the primal solution, many other clients assigned to it do not contribute to the opening cost, which implies that the current analysis may not be tight.</p>
<h3 id="randomized-rounding-3"><strong><em>Randomized Rounding</em></strong> [3]</h3>
<h4 id="approximation-rounding"><strong><em>3-Approximation Rounding</em></strong></h4>
<p>In the section, we improve the approximation ratio of 4 to an expected value of 3. In the previous rounding, we bound the opening cost as <span class="math display">\[
\sum_{j \in D} \min_{i \in N(j) } f_i \le OPT
\]</span></p>
<p>which is not tight. Define the assignment cost for client <span class="math inline">\(j\)</span> in the optimal primal LP solution as <span class="math inline">\(A_j = \sum_{i \in F} x^*_{i,j} c_{i,j}\)</span>. Indeed, it is affordable to bound <span class="math display">\[
\sum_{j \in D} \sum_{i \in N(j) } x^*_{i,j} f_i +  \sum_{j \in C} A_j \le OPT
\]</span></p>
<p>It is possible to devise a randomized rounding algorithm that incorporates this cost and improve the approximation ratio to 3. The only differences compared to the first rounding algorithm are</p>
<ol type="1">
<li>We pick a client that minimize <span class="math inline">\(\alpha^*_j + A_j\)</span>;</li>
<li>We pick a facility with probability <span class="math inline">\(x^*_{i,j}\)</span>.</li>
</ol>
<p>Below is the algorithm.</p>
<blockquote>
<p>Algorithm 2:<br />
1. <span class="math inline">\(S \leftarrow \emptyset\)</span>.<br />
2. <span class="math inline">\(D \leftarrow \emptyset\)</span>.<br />
2. While there exists un-assigned client<br />
3. <span class="math inline">\(\quad\)</span> Let <span class="math inline">\(j\)</span> be the unassigned one with smallest <span class="math inline">\(\alpha^*_j + A_j\)</span>, add <span class="math inline">\(j\)</span> to <span class="math inline">\(D\)</span>.<br />
5. <span class="math inline">\(\quad\)</span> Sample a facility <span class="math inline">\(i\)</span> in <span class="math inline">\(N(j)\)</span> with probability <span class="math inline">\(x^*_{i,j}\)</span>, add it to <span class="math inline">\(S\)</span>.<br />
6. <span class="math inline">\(\quad\)</span> Assign <span class="math inline">\(j\)</span> to <span class="math inline">\(i\)</span>: <span class="math inline">\(\mu(j) \leftarrow i\)</span><br />
6. <span class="math inline">\(\quad\)</span> For each un-assigned client <span class="math inline">\(j&#39; \in N^2(j)\)</span> do<br />
8. <span class="math inline">\(\quad\)</span> <span class="math inline">\(\quad\)</span> <span class="math inline">\(\quad\)</span> Assign <span class="math inline">\(j&#39;\)</span> to <span class="math inline">\(i\)</span>: <span class="math inline">\(\mu(j&#39;) \leftarrow i\)</span></p>
</blockquote>
<h5 id="facility-cost-1">Facility Cost</h5>
<p>The analysis of expected facility cost is almost the same as before. It is guaranteed that the <span class="math inline">\(N(j)\)</span>'s for selected clients <span class="math inline">\(j \in D\)</span> are disjoint. Therefore, the expected opening cost is bounded by<br />
<span class="math display">\[
\sum_{j \in D} \sum_{i \in N(j) } x^*_{i,j} f_i \le \sum_{j \in D} \sum_{i \in N(j) } y^*_i f_i 
\]</span></p>
<h5 id="connection-cost-1">Connection Cost</h5>
<p>Now we analyze the assignment cost. When a client <span class="math inline">\(j\)</span> and a facility <span class="math inline">\(i\)</span> in <span class="math inline">\(N(j)\)</span> is sampled, unassigned clients <span class="math inline">\(j&#39; \in N^2(j)\)</span> are assigned to <span class="math inline">\(i\)</span>. As <span class="math inline">\(j&#39; \in N^2(j)\)</span>, there exists some other facility <span class="math inline">\(i&#39; \in N(j)\)</span>, such that <span class="math inline">\((i&#39;,j&#39;) \in E\)</span>. By triangle inequality, the expected connection cost is at most <span class="math display">\[
\begin{aligned}
c_{i, j&#39;} 
&amp;\le \sum_{i \in N(j)} x^*_{i,j} c_{i, j} + c_{i&#39;, j} + c_{i&#39;, j} \\
&amp;\le A_j + \alpha^*_{j} + \alpha^*_j \\
&amp;\le A_{j&#39;} + 2\alpha^*_{j&#39;}
\end{aligned}
\]</span></p>
<p>Summing over all clients, the cost is at most <span class="math display">\[
\sum_{j \in D} \sum_{i \in N(j) } x^*_{i,j} f_i + \sum_{i \in F, j \in C} c_{i, j} x^*_{i, j} + 2\sum_{j \in C} \alpha^*_j \le 3 \cdot OPT
\]</span></p>
<p><strong><em>Remark</em></strong>: there is still room for improvement. When a client <span class="math inline">\(j\)</span> is selected and a facility <span class="math inline">\(i\)</span> is sampled, <span class="math inline">\(j&#39; \in N^2(j)\)</span> is assigned to <span class="math inline">\(i\)</span>. On the other hand, <span class="math inline">\(j&#39;\)</span> itself may contributes to the opening cost of some other facility not open. To make the expected opening cost tight, we may consider opening facilities directly with respect to probability <span class="math inline">\(y^*_i\)</span>.</p>
<h4 id="e-approximation-rounding-3"><strong><em><span class="math inline">\((1 + 3/e)\)</span>-Approximation Rounding</em></strong> [3]</h4>
<!-- To have an intuition of the rounding technique, we illustrate a wrong but instructive rounding technique. Here we assume that $x^*_{i,j} = y^*_i$ for all $i \in F, j \in C$. If we select each facility $i$ independently with probability $y^*_i$, then for a client $j$, the probability that none of its neighbor is selected is 
$$
\prod_{i \in N(j) } (1 - y^*_i) \le e^{-\sum_{i \in N(j) } y^*_i} \le e^{ - \sum_{i \in N(j) } x^*_{i,j} } = e^{-1}
$$

The problem here is that, if none of $j$'s neighbors is sampled, the connection cost of $j$ might be unacceptable large. We need some backup mechanism. For example, if we can somehow combine Algorithm 1 and bound the connection cost to $3 v^*_j$ for this bas case. Let $Z$ be the random variable that represents connection cost for $j$ and $Y_i$ ($i \in N(j)$) indicator random variable of whether $i$ is sampled.
$$
Z \le Z' \doteq \min_{i \in N(j), Y_i = 1} \{ c_{i,j} Y_i \} + 3 v^*_j \cdot \mathbb{1}_{[ Y_i = 0, \forall i \in N(j)] }
$$


Therefore, 
$$
\begin{aligned}
    E[Z] 
    &\le E[Z'] \\
    &\le E \left[ \sum_{i \in N(j)}  c_{i,j} Y_i  + 3 v^*_j \cdot \mathbb{1}_{[ Y_i = 0, \forall i \in N(j)] } \right] \\
    &= \sum_{i \in N(j)}  c_{i,j} E[Y_i]  + 3 v^*_j \cdot E\left[ \mathbb{1}_{[ Y_i = 0, \forall i \in N(j)] } \right] \\
    &\le \sum_{i \in N(j) } c_{i,j} x^*_{i,j} + \frac{3}{e} v^*_j
\end{aligned}
$$

The third equality does not even require that $Y_i$'s are independent. Then the total cost is bounded by 
$$
\begin{aligned}
    &\sum_{i \in F} y^*_i f_i + \sum_{j \in C}  x^*_{i,j} c_{i,j} + \frac{3}{e} \sum_{j \in C} v^*_j \\
    =& (1 + \frac{3}{e} ) \cdot  OPT
\end{aligned}
$$


Below we show the actual algorithm that achieves this expected approximation ratio. The facilities are no longer sampled independently. However, we will see that, for facility $i$, it is still selected with probability $y^*_i$. Therefore, the expected cost of opening the facilities is still $\sum_{i \in F} y^*_i f_i$.  -->
<!-- 
> Algorithm 3:     
> 1. $S \leftarrow \emptyset$.  
> 2. $D \leftarrow \emptyset$.  
> 3. $T \leftarrow F$.   
> 2. While there exists un-assigned client   
> 3. $\quad$ Let $j$ be the unassigned one with smallest $\alpha^*_j$, add $j$ to $D$.      
> 5. $\quad$ Sample a facility $i$ in $N(j)$ with probability $x^*_{i,j}$, add it to $S$.    
> 6. $\quad$ $T \leftarrow T \setminus N(j)$.
> 6. $\quad$ Assign $j$ to $i$:  $\mu(j) \leftarrow i$  
> 6. $\quad$ For each un-assigned client $j' \in N^2(j)$ do  
> 8. $\quad$ $\quad$ $\quad$ Assign $j'$ to $i$: $\mu(j')   \leftarrow i$
> 9. Sample each facility $i \in T$ independently with probability $y^*_i$. 
-->
<p>In the previous analysis, we see that a facility may be under-sampled. There are two reasons for this:<br />
1. For a facility <span class="math inline">\(i\)</span>, <span class="math inline">\(\exists j \in N(i)\)</span> such that <span class="math inline">\(j \in D\)</span>. When <span class="math inline">\(j\)</span> is selected, facility <span class="math inline">\(i\)</span> is sampled with probability <span class="math inline">\(x^*_{i,j}\)</span>, which might be smaller than <span class="math inline">\(y^*_i\)</span>.<br />
2. For a facility <span class="math inline">\(i\)</span>, none of its clients <span class="math inline">\(j \in N(i)\)</span> is selected, therefore <span class="math inline">\(i\)</span> is never sampled.</p>
<p>To fix theses issues and based on algorithm 1, we have the following algorithm. The algorithm presented here is a modified version of the one proposed in [3] but guided the same philosophy.</p>
<blockquote>
<p>Algorithm 3:<br />
1. <span class="math inline">\(T \leftarrow F\)</span><br />
2. <span class="math inline">\(k \leftarrow 0\)</span><br />
3. <span class="math inline">\(S_1, S_2, S_3 \leftarrow \emptyset\)</span><br />
2. While there exists un-assigned client<br />
4. <span class="math inline">\(\quad\)</span> <span class="math inline">\(k \leftarrow k + 1\)</span><br />
3. <span class="math inline">\(\quad\)</span> Let <span class="math inline">\(j_k\)</span> be the unassigned one with smallest <span class="math inline">\(\alpha^*_j\)</span><br />
5. <span class="math inline">\(\quad\)</span> Open exactly one facility <span class="math inline">\(i_k \in N( j_k )\)</span> with probability <span class="math inline">\(x^*_{i,j}\)</span><br />
6. <span class="math inline">\(\quad\)</span> <span class="math inline">\(S_1 \leftarrow S_1 \cup \{ i_k \}\)</span><br />
6. <span class="math inline">\(\quad\)</span> For each <span class="math inline">\(i \in N(j_k) - \{ i_k \}\)</span> 7. <span class="math inline">\(\qquad\)</span> Open <span class="math inline">\(i\)</span> with probability <span class="math inline">\((y^*_{i} - x^*_{i,j } ) / ( 1- x^*_{i,j} )\)</span><br />
8. <span class="math inline">\(\qquad \quad\)</span> <span class="math inline">\(S_2 \leftarrow S_2 \cup \{ i \}\)</span> 6. <span class="math inline">\(\quad\)</span> <span class="math inline">\(T \leftarrow T - N(j_k)\)</span><br />
6. <span class="math inline">\(\quad\)</span> Assign <span class="math inline">\(j\)</span> to <span class="math inline">\(i_k\)</span>, for <span class="math inline">\(\forall j \in \{ j_k \} \cup N^2( j_k )\)</span><br />
9. For each facility <span class="math inline">\(i \in T\)</span> 10. <span class="math inline">\(\quad\)</span> Open <span class="math inline">\(i\)</span> with probability <span class="math inline">\(y^*_i\)</span><br />
10. <span class="math inline">\(\qquad\)</span> <span class="math inline">\(S_3 \leftarrow S_3 \cup \{ i \}\)</span> 10. Re-assign each <span class="math inline">\(j \in C\)</span> to its nearest open facility.</p>
</blockquote>
<p>When the algorithm stops, denote <span class="math inline">\(S = S_1 \cup S_2 \cup S_3\)</span> the set of open facilities and <span class="math inline">\(D = \{j_1, j_2, ..., j_{|D| } \}\)</span> the set of selected facilities by line 5. The following lemma shows that Algorithm 3 fully samples each facility and therefore never loses to Algorithm 1.</p>
<h5 id="facility-cost-2">Facility Cost</h5>
<p><strong><em>Lemma 1.</em></strong> For each <span class="math inline">\(i \in F\)</span>, it is opened with probability <span class="math inline">\(y^*_i\)</span>.<br />
<em>Proof.</em> Note the facilities are not open independently. The claim is trivially true if a facility is is sampled in line 10. Otherwise, <span class="math inline">\(\exists j \in D\)</span>, s.t., <span class="math inline">\(i \in N(j)\)</span>. The probability of <span class="math inline">\(i\)</span> being open is <span class="math display">\[
x^*_{i,j} + (1 - x^*_{i,j} ) \frac{y^*_{i} - x^*_{i,j} }{ 1- x^*_{i,j} } = y^*_i
\]</span> <span class="math inline">\(\blacksquare\)</span></p>
<p><strong><em>Corollary.</em></strong> By linearity of expectation, the expected facility opening cost is <span class="math inline">\(\sum_{i \in F} y^*_i f_i\)</span>.</p>
<h5 id="connection-cost-2">Connection Cost</h5>
<p>What is not trivial is the analysis of the assignment cost. Given <span class="math inline">\(S\)</span>, assigning <span class="math inline">\(j \in C\)</span> to its nearest facility in <span class="math inline">\(S\)</span> minimizes the assignment cost. To bound this cost, we investigate a sub-optimal assignment based on <span class="math inline">\(S\)</span>. For each <span class="math inline">\(j \in C\)</span> we select a subset <span class="math inline">\(S(j) \subset S\)</span> and assign it to a closest facility in <span class="math inline">\(S(j)\)</span>. This leads to a possibly increase in the expected assignment cost.</p>
<p>Let <span class="math inline">\(Z\)</span> be the random variable of the assignment cost for client <span class="math inline">\(j\)</span> and <span class="math inline">\(X_i\)</span> (<span class="math inline">\(i \in N(j)\)</span>) be the indicator random variable of <span class="math inline">\(i\)</span> being in <span class="math inline">\(S(j)\)</span>. As when none of the facility in <span class="math inline">\(N(j)\)</span> is selected into <span class="math inline">\(S(j)\)</span>, then assignment cost is bounded by <span class="math inline">\(3 \cdot v^*_j\)</span>, the value of <span class="math inline">\(Z\)</span> is therefore at most <span class="math display">\[
Z \le \min_{i \in N(j), X_i = 1} \{ c_{i,j} X_i \} + 3 v^*_j \cdot \mathbb{1}_{[ Y_i = 0, \forall i \in N(j)] }
\]</span></p>
<p>The goal is to provide a method for generating <span class="math inline">\(S(j)\)</span>, such that</p>
<ol type="1">
<li><span class="math inline">\(\Pr[X_i = 1] = x^*_{i,j}\)</span>, for <span class="math inline">\(\forall i \in N(j)\)</span>;</li>
<li><span class="math inline">\(\Pr[\mathbb{1}_{[ Y_i = 0, \forall i \in N(j)]} = 1 ] \le 1/e\)</span>.</li>
</ol>
<p>Any such generation method satisfies to bound the assignment cost of client <span class="math inline">\(j\)</span>: <span class="math display">\[
\begin{aligned}
    E[Z] 
    &amp;\le E \left[ \sum_{i \in N(j)}  c_{i,j} X_i  + 3 v^*_j \cdot \mathbb{1}_{[ X_i = 0, \forall i \in N(j)] } \right] \\
    &amp;= \sum_{i \in N(j)}  c_{i,j} E[X_i]  + 3 v^*_j \cdot E\left[ \mathbb{1}_{[ X_i = 0, \forall i \in N(j)] } \right] \\
    &amp;\le \sum_{i \in N(j) } c_{i,j} x^*_{i,j} + \frac{3}{e} v^*_j
\end{aligned}
\]</span></p>
<p>Note that the inequality here may not be tight, as we replace the <span class="math inline">\(\min\)</span> operation into <span class="math inline">\(\sum\)</span>. But it suffices to prove the expected approximation ratio. When combined with the expected facility opening cost, we know that total expected cost is bounded by <span class="math display">\[
\sum_{i \in F} y^*_i f_i + \sum_{j \in C} \sum_{i \in N(j) } c_{i,j} x^*_{i,j} + \frac{3}{e} v^*_j = \left( 1 + \frac{3}{e} \right) \cdot OPT
\]</span></p>
<p>The <span class="math inline">\(S(j)\)</span> is generated as follows. If <span class="math inline">\(j \in D\)</span>, then we let <span class="math inline">\(S(j) = S\)</span>. Otherwise, we initialize <span class="math inline">\(S(j)\)</span> with <span class="math inline">\(S - N(j)\)</span>, and for facility <span class="math inline">\(i \in N(j) \cap S\)</span>, we perform some carefully designed operations to ensure that <span class="math inline">\(\Pr[i \in S(j) ]= x^*_{i,j}\)</span>.</p>
<ol type="1">
<li>If <span class="math inline">\(i \in S_3\)</span>, we keep it in <span class="math inline">\(S(j)\)</span> with probability <span class="math inline">\(\frac{x^*_{i,j} } {y^*_i}\)</span>. Therefore, <span class="math display">\[
 \Pr[i \in S(j)] = \Pr[i \in S(j) \mid i \in S] \cdot \Pr[i \in S] = x^*_{i,j}
 \]</span></li>
<li>Otherwise, <span class="math inline">\(\exists j_k \in D\)</span>, such that <span class="math inline">\(i \in N(j_k)\)</span>. There are two possible cases
<ol type="1">
<li><p>Case 1: <span class="math inline">\(x^*_{i,j_k} \ge x^*_{i,j}\)</span>, the probability of selecting <span class="math inline">\(i\)</span> is defined as follows: <span class="math display">\[
 \Pr[i \in S(j) \mid i \in S] =
 \begin{cases}
     \begin{array}{lr}
         {x^*_{i,j} } / { x^*_{i,j_k} },   &amp;i \in S_1 \\
         0,                                 &amp;
         i \in S_2
     \end{array}
 \end{cases}
 \]</span> Therefore, <span class="math display">\[
 \begin{array}{ll}
     \Pr[i \in S(j)] 
         &amp;= \Pr[i \in S(j) |i \in S_1 ] \cdot \Pr[ i \in S_1 ] + \Pr[i \in S(j) |i \in S_2 ] \cdot \Pr[ i \in S_2 ] \\
         &amp;= x^*_{i,j}  /  x^*_{i,j_k}  \cdot  x^*_{i,j_k}  \\
         &amp;= x^*_{i,j} 
 \end{array}
 \]</span></p></li>
<li><p>Case 2: <span class="math inline">\(x^*_{i,j_k} &lt; x^*_{i,j}\)</span>, the probability of selecting <span class="math inline">\(i\)</span> is defined as follows: <span class="math display">\[
 \Pr[i \in S(j) \mid i \in S] =
 \begin{cases}
     \begin{array}{lr}
         1,   &amp;i \in S_1 \\
         (x^*_{i,j} - x^*_{i, j_k}  ) \cdot ( 1 - x^*_{i,j_k } ) / (y^*_{i} - x^*_{i,j_k } ),                                 &amp; i \in S_2
     \end{array}
 \end{cases}
 \]</span></p>
<p>The probability is well defined as <span class="math inline">\(y^*_i \ge x^*_{i,j}\)</span>. It follows</p>
<p><span class="math display">\[
 \begin{array}{ll}
     \Pr[i \in S(j)] 
         &amp;= \Pr[i \in S(j) |i \in S_1 ] \cdot \Pr[ i \in S_1 ]  + \Pr[i \in S(j) |i \in S_2 ] \cdot \Pr[ i \in S_2  ] \\
         &amp;=  x^*_{i,j_k}  +  (x^*_{i,j} - x^*_{i, j_k}  ) \cdot ( 1 - x^*_{i,j_k } ) / (y^*_{i} - x^*_{i,j_k } ) \cdot (y^*_{i} - x^*_{i,j_k } ) / (x^*_{i,j} - x^*_{i, j_k}  )\\
         &amp;= x^*_{i,j} 
 \end{array}
 \]</span></p></li>
</ol></li>
</ol>
<p>It is left to show that <span class="math inline">\(\Pr[\mathbb{1}_{[ Y_i = 0, \forall i \in N(j)]} = 1 ] \le 1/e\)</span>. For <span class="math inline">\(j \in D\)</span>, this holds trivially. If not, we prove the following lemma.</p>
<p><strong><em>Lemma 2.</em></strong> For any client <span class="math inline">\(j \in C \setminus D\)</span>, the probability that none of facility in <span class="math inline">\(N(j)\)</span> belongs to <span class="math inline">\(S(j)\)</span> is bounded by <span class="math inline">\(1/ e\)</span>.</p>
<p><strong><em>Proof.</em></strong></p>
<p>Observe that <span class="math display">\[
N(j_1) \cup N(j_2) \cup ... \cup N(j_{|D| } ) \cup T = F
\]</span></p>
<p>constitutes a partition of <span class="math inline">\(F\)</span>. For any client <span class="math inline">\(j\)</span>, define <span class="math inline">\(R_k = N(j_k) \cap N(j)\)</span>, where <span class="math inline">\(1 \le k \le |D|\)</span>. Further, let <span class="math inline">\(R_{|D| + 1} = T \cap N(j)\)</span>. Then <span class="math inline">\(\{ R_k \}_{k \in [|D| + 1]}\)</span> is a partition of <span class="math inline">\(N(j)\)</span>.</p>
<p>Consider facilities in <span class="math inline">\(N(j_k)\)</span> (<span class="math inline">\(k \in [|D|]\)</span>). The probability of none of them being in <span class="math inline">\(S(j)\)</span> is <span class="math display">\[
\begin{aligned}
    &amp;\left( 1 - \sum_{i \in R_k \wedge x^*_{i, j_k} &lt; x^*_{i,j} } x^*_{i, j_k}   - \sum_{i \in R_k \wedge x^*_{i, j_k} \ge x^*_{i,j} } x^*_{i, j_k} \cdot \frac{x^*_{i,j} }{ x^*_{i, j_k} }     \right)
     \cdot \prod_{i \in R_k \wedge x^*_{i, j_k} &lt; x^*_{i,j} } \left(1 - \frac{y^*_{i} - x^*_{i,j } }{ 1- x^*_{i,j}} 
    \frac{ 1- x^*_{i,j}}{y^*_{i} - x^*_{i,j } } (x^*_{i,j} - x^*_{i, j_k}  )
    \right) \\
    &amp;\le \exp \left( - \sum_{i \in R_k \wedge x^*_{i, j_k} &lt; x^*_{i,j} } x^*_{i, j_k}  - \sum_{i \in R_k \wedge x^*_{i, j_k} \ge x^*_{i,j} } x^*_{i,j}\right) 
    \cdot \prod_{i \in R_k \wedge x^*_{i, j_k} &lt; x^*_{i,j} } \left(1 -  (x^*_{i,j} - x^*_{i, j_k}  )
    \right) \\
    &amp;\le \exp \left( - \sum_{i \in R_k \wedge x^*_{i, j_k} &lt; x^*_{i,j} } x^*_{i, j_k}  - \sum_{i \in R_k \wedge x^*_{i, j_k} \ge x^*_{i,j} } x^*_{i,j}\right) 
    \cdot \exp \left( -\sum_{i \in R_k \wedge x^*_{i, j_k} &lt; x^*_{i,j} } (x^*_{i,j} - x^*_{i, j_k}  )
    \right) \\
    &amp;= \exp \left( { - \sum_{i \in R_k} x^*_{i, j} } \right) 
\end{aligned}
\]</span></p>
<p>The relation holds even if <span class="math inline">\(R_k = \emptyset\)</span>, in which <span class="math inline">\(\sum_{i \in R_k} x^*_{i, j} = 0\)</span>.</p>
<p>For <span class="math inline">\(k = |D| + 1\)</span>, the probability that none of the facility in <span class="math inline">\(R_k\)</span> is sampled is given by <span class="math display">\[
\prod_{i \in R_{k + 1} } \left( 1 - y^*_i \frac{x^*_{i,j} } {y^*_i}  \right) \le e^{- \sum_{i \in R_{k + 1} } x^*_{i,j} } 
\]</span></p>
<p>Therefore, taking product over all the events, we know that <span class="math display">\[
\begin{aligned}
    \prod_{k \in [|D| + 1] } e^{- \sum_{i \in R_k } x^*_{i,j} } 
        &amp;= e^{ - \sum_{i \in N(j) } x^*_{i,j} } \\
        &amp;= \frac{1}{e}
\end{aligned}
\]</span> <span class="math inline">\(\blacksquare\)</span></p>
<!-- #### ***$(1 + 2/e)$-Approximation Rounding***

> Algorithm 4:     
> 1. $S \leftarrow \emptyset$.  
> 2. $D \leftarrow \emptyset$.  
> 3. $T \leftarrow F$.   
> 2. While there exists un-assigned client   
> 3. $\quad$ Let $j$ be the unassigned one with smallest $\alpha^*_j + A_j$, add $j$ to $D$.        
> 5. $\quad$ Sample a facility $i$ in $N(j)$ with probability $x^*_{i,j}$, add it to $S$.    
> 6. $\quad$ $T \leftarrow T \setminus N(j)$.
> 6. $\quad$ Assign $j$ to $i$:  $\mu(j) \leftarrow i$  
> 6. $\quad$ For each un-assigned client $j' \in N^2(j)$ do  
> 8. $\quad$ $\quad$ $\quad$ Assign $j'$ to $i$: $\mu(j')   \leftarrow i$
> 9. Sample each facility $i \in T$ independently with probability $y^*_i$.

***Theorem.*** For any client $j$, the expected assignment cost is give by $(1 - p_j) A_j + p_j (2v^*_j + A_j)$.

***Proof*** -->
<h2 id="primal-dual-algorithm-2"><strong><em>Primal-Dual Algorithm</em></strong> [2]</h2>
<p>In this section we show a primal-dual algorithm that is purely combinatorial.</p>
<ol type="1">
<li>Initially we have a set of dual variables <span class="math inline">\(\alpha_j\)</span>'s and <span class="math inline">\(\beta_{i,j}\)</span>'s that are set to 0. Note that they are feasible.<br />
</li>
<li>Then we try to optimize this set of variables by increasing all <span class="math inline">\(\alpha_j\)</span>'s in parallel until some <span class="math inline">\(\alpha_j\)</span>'s are blocked.</li>
</ol>
<p>Why are they blocked? Because the dual constraint <span class="math display">\[
\alpha_j \le c_{i,j} + \beta_{i,j}
\]</span></p>
<p>becomes tight for some facilities <span class="math inline">\(i \in F\)</span>. If we increase <span class="math inline">\(\alpha_j\)</span> further, the variables are no longer dual feasible. However, we can modify our strategy by increasing these <span class="math inline">\(\beta_{i,j}\)</span> simultaneously with <span class="math inline">\(\alpha_j\)</span> until facility <span class="math inline">\(i\)</span> is <em>blocked</em>, i.e., <span class="math display">\[
\sum_{j \in C} \beta_{i,j} = f_i
\]</span></p>
<p>Before we proceed, for a given facility <span class="math inline">\(i\)</span>, we define its neighbors <span class="math inline">\(N(i)\)</span> as to be the clients such that <span class="math inline">\(\alpha_j \ge c_{i,j}\)</span>.</p>
<blockquote>
<p>Algorithm: Dual Variable Increment.<br />
1. <span class="math inline">\(U \leftarrow C\)</span>: the set of un-blocked clients.<br />
2. <span class="math inline">\(B \leftarrow \emptyset\)</span>: the set of blocked facilities.<br />
3. <em>while</em> <span class="math inline">\(U \neq \emptyset\)</span> <em>do</em><br />
4. <span class="math inline">\(\quad\)</span> <em>For</em> <span class="math inline">\(\forall j \in U\)</span><br />
5. <span class="math inline">\(\qquad\)</span> Increase all <span class="math inline">\(\alpha_j\)</span> (if necessary, <span class="math inline">\(\beta_{i,j}\)</span> for some <span class="math inline">\(i\)</span> ) simultaneously<br />
6. <span class="math inline">\(\quad\)</span> <em>Until</em> either<br />
7. <span class="math inline">\(\qquad\)</span> * some facility <span class="math inline">\(i \notin B\)</span> is blocked:<br />
8. <span class="math inline">\(\qquad\quad\)</span> <span class="math inline">\(B \leftarrow B \cup \{i \}\)</span><br />
9. <span class="math inline">\(\qquad\quad\)</span> <span class="math inline">\(U \leftarrow U \setminus N(i)\)</span><br />
10. <span class="math inline">\(\qquad\)</span> * some client <span class="math inline">\(j\)</span> neighbors a blocked facility <span class="math inline">\(i \in B\)</span>:<br />
11. <span class="math inline">\(\qquad\quad\)</span> <span class="math inline">\(U \leftarrow U \setminus \{ j \}\)</span></p>
</blockquote>
<p><em>Question to ponder</em>: what is the running time for the <em>Dual Variable Increment</em> algorithm:</p>
<p>After running the algorithm above, we get a set of maximal variable which we can't simultaneously increase any more. It has the following property</p>
<blockquote>
<p><em>Property.</em> Each client <span class="math inline">\(j \in C\)</span> neighbors at least one block facility.</p>
</blockquote>
<p>If not, the algorithm will increase the <span class="math inline">\(\alpha_j\)</span> further.</p>
<p>We show how to construct an approximate solution from the maximal dual variables. First we construct a derived graph <span class="math inline">\(G = (V, E)\)</span> from primal LP.</p>
<ol type="1">
<li>The vertex set <span class="math inline">\(V = B \cup C\)</span>.</li>
<li>The edge set <span class="math inline">\(E = \{ (i, j) : \beta_j \ge c_{i,j}, \forall i \in B, j \in C\}\)</span>.</li>
</ol>
<p>Moreover, if <span class="math inline">\(\beta_{i,j} &gt; 0\)</span> for some <span class="math inline">\(i \in F\)</span>, <span class="math inline">\(j \in C\)</span>, we say that <span class="math inline">\(j\)</span> contributes to <span class="math inline">\(i\)</span>. Given a facility <span class="math inline">\(i\)</span>, we are particular interested in the set of clients that contributes to it, denoted as <span class="math inline">\(N_+(i)\)</span>.</p>
<blockquote>
<p>Algorithm: Facility Selection and Client Assignment<br />
1. <span class="math inline">\(S \leftarrow \emptyset\)</span>. 2. <em>while</em> <span class="math inline">\(B \neq \emptyset\)</span> <em>do</em><br />
3. <span class="math inline">\(\quad\)</span> Let <span class="math inline">\(i \in B\)</span> be the earliest blocked facility.<br />
4. <span class="math inline">\(\quad\)</span> <span class="math inline">\(S \leftarrow S \cup \{ i \}\)</span><br />
5. <span class="math inline">\(\quad\)</span> <span class="math inline">\(B \leftarrow B \setminus \{ i \}\)</span><br />
8. <span class="math inline">\(\quad\)</span> // Assign all <span class="math inline">\(j \in C\)</span> that contributes to both <span class="math inline">\(i\)</span>. 8. <span class="math inline">\(\quad\)</span> <span class="math inline">\(\mu_S(j) \leftarrow i\)</span> for all <span class="math inline">\(j \in N_+(i)\)</span>. 8. <span class="math inline">\(\quad\)</span> // Remove all facilities <span class="math inline">\(i&#39;\)</span> if <span class="math inline">\(\exists j \in C\)</span> that contributes to both <span class="math inline">\(i\)</span> and <span class="math inline">\(i&#39;\)</span>. 9. <span class="math inline">\(\quad\)</span> <span class="math inline">\(B \leftarrow B \setminus \{ i&#39; \in B : N_+(i) \cap N_+(i&#39;) \neq \emptyset \}\)</span>. 10. Assign each unassigned client to its closest facility in <span class="math inline">\(S\)</span>.</p>
</blockquote>
<p>The figure below shows an example of dual variable increment algorithm. <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm2.2.png" /></p>
<p>The figure below shows the corresponding derived graph. <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm2.3.png" /></p>
<p>The figure below shows an example of facility selection. The selected facilities are marked with dark green. The clients contributing to theses facilities are connected to them red lines. <img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm2.4.png" /></p>
<h4 id="facility-cost-3">Facility Cost</h4>
<p>We can show by induction that when a blocked facility is selected, its opening cost is fully covered by all clients contributing to this facility. Note that if any other blocked facility is connected to any of these clients, it is removed from the candidate set. Therefore, when a new blocked facility <span class="math inline">\(i\)</span> is selected, the clients in <span class="math inline">\(N_+(i)\)</span> can contribute to any previous selected facility.</p>
<p>The cost of open facilities in <span class="math inline">\(S\)</span>, plus the cost of connecting clients in <span class="math inline">\(N_+(i)\)</span> for <span class="math inline">\(i \in S\)</span>, is given by <span class="math display">\[
\sum_{i \in S} (f_i + \sum_{j \in N_+(i)} c_{ij}) = \sum_{i \in S} (\sum_{j \in N_+(i)} \beta_{ij} + \sum_{j \in N_+(i)} c_{ij}) = \sum_{i \in S} \sum_{j \in N_+(i)} \alpha_j
\]</span></p>
<h4 id="connection-cost-3">Connection Cost</h4>
<p>It is left to analyze the connection of other clients. If a client <span class="math inline">\(j \in C\)</span> is in <span class="math inline">\(N(i)\)</span> for some <span class="math inline">\(i \in S\)</span>, then the connection cost if <span class="math display">\[
c_{ij} \le \alpha_j
\]</span> Otherwise, by the property of the algorithm, <strong><em>we know that there exists a facility <span class="math inline">\(i\)</span> that stops <span class="math inline">\(\alpha_j\)</span> from increasing</em></strong>. The reason that <span class="math inline">\(i\)</span> is not selected is that when some other facility <span class="math inline">\(i&#39;\)</span> is selected into <span class="math inline">\(S\)</span>, <span class="math inline">\(i\)</span> is removed from the candidate set <span class="math inline">\(B\)</span> because <span class="math inline">\(N_+(i) \cap N_+(i&#39;) \neq \emptyset\)</span> . Let <span class="math inline">\(j&#39; \in N_+(i) \cap N_+(i&#39;) \neq \emptyset\)</span>. We claim</p>
<blockquote>
<p><span class="math inline">\(\alpha_{j&#39;} \le \alpha_{j}\)</span></p>
</blockquote>
<p>To see this, when <span class="math inline">\(i\)</span> stops <span class="math inline">\(\alpha_j\)</span>, we know that either <span class="math inline">\(\alpha_{j&#39;}\)</span> has stopped from increasing or <span class="math inline">\(\alpha_j\)</span> stops simultaneously with <span class="math inline">\(j\)</span>, as <span class="math inline">\(j&#39;\)</span> contributes to <span class="math inline">\(i\)</span>.</p>
<p>Therefore, the cost of assigning <span class="math inline">\(j\)</span> to <span class="math inline">\(i&#39;\)</span> is at most <span class="math display">\[
c_{i&#39;j} \le c_{i&#39;j&#39;} + c_{ij&#39;} + c_{ij} \le 2 \alpha_{j&#39;} + \alpha_j \le 3 \alpha_j
\]</span> <em>Question to ponder</em>: what is the running time of the algorithm?</p>
<p>Finally we show another example where the edge weight between (b,y) is changed to 1.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm2.5.png" /></p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm2.6.png" /></p>
<p>Note that compared to the previous example, only facility <span class="math inline">\(x\)</span> is selected (marked by dark green), because we can use <span class="math inline">\(b\)</span> to contribute only one facility. Now facility <span class="math inline">\(y\)</span> is the one that stops <span class="math inline">\(\alpha_c\)</span> and <span class="math inline">\(\alpha_d\)</span> from increasing.</p>
<p><img src="https://github.com/wuhao-wu-jiang/BlogImgs/raw/master/FacilityLocation/algorithm2.7.png" /></p>
<h3 id="reference.">Reference.</h3>
<p>[1] Shmoys DB, Tardos É, Aardal K. Approximation algorithms for facility location problems. InProceedings of the twenty-ninth annual ACM symposium on Theory of computing 1997 May 4 (pp. 265-274).</p>
<p>[2] Jain K, Vazirani VV. Primal-dual approximation algorithms for metric facility location and k-median problems. In 40th annual symposium on foundations of computer science (Cat. No. 99CB37039) 1999 Oct 17 (pp. 2-13). IEEE.</p>
<p>[3] Chudak FA, Shmoys DB. Improved approximation algorithms for the uncapacitated facility location problem. SIAM Journal on Computing. 2003;33(1):1-25.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/09/11/Confidence-Interval-of-Berstein-Inequality/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/09/11/Confidence-Interval-of-Berstein-Inequality/" class="post-title-link" itemprop="url">Confidence Interval of Berstein Inequality</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-09-11 21:07:20" itemprop="dateCreated datePublished" datetime="2018-09-11T21:07:20+10:00">2018-09-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-12-02 19:57:23" itemprop="dateModified" datetime="2019-12-02T19:57:23+11:00">2019-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>(Berstein inequality).<br />
Let <span class="math inline">\(X_1, ..., X_n\)</span> be random variables with range <span class="math inline">\([0, 1]\)</span> and <span class="math display">\[
\sum_{t = 1}^n Var[X_t \mid X_{t - 1}, ..., X_1] = \sigma^2
\]</span></p>
<p>Let <span class="math inline">\(S_n = X_1 + ... + X_n\)</span>. Then for all <span class="math inline">\(a \ge 0\)</span> <span class="math display">\[
\Pr[S_n \ge E[S_n] + an] \le \exp\left(- \frac{n^2 a^2 / 2}{\sigma^2 + n a / 2} \right)
\]</span></p>
<p>Suppose we would like to calculate the confidence interval with probability <span class="math inline">\(\delta\)</span>, then we need to solve the following equation: <span class="math display">\[
\exp\left( -\frac{n^2 a^2 / 2}{\sigma^2 + n a / 2} \right) = \delta 
\]</span></p>
<p>After transformation, we get <span class="math display">\[
n^2 a^2 - n a \ln \frac{1}{\delta} - 2 \sigma^2 \ln \frac{1}{\delta} = 0
\]</span></p>
<p>Therefore, <span class="math display">\[
a = \frac{n \ln \frac{1}{\delta} + \sqrt{n^2 \ln^2 \frac{1}{\delta} + 8 \sigma^2 n^2 \ln \frac{1}{\delta}} }{2n^2 } = \frac{\ln \frac{1}{\delta} + \sqrt{\ln^2 \frac{1}{\delta} + 8 \sigma^2 \ln \frac{1}{\delta}} }{2n }
\]</span></p>
<p>But <span class="math display">\[
\sqrt{\ln^2 \frac{1}{\delta} + 8 \sigma^2 \ln \frac{1}{\delta}} \le \sqrt{\ln^2 \frac{1}{\delta}}  + \sqrt{8\sigma^2 \ln \frac{1}{\delta}} = \ln \frac{1}{\delta} + 2\sigma \sqrt{2 \ln \frac{1}{\delta}}
\]</span></p>
<p>It follows that <span class="math display">\[
a = \frac{\ln \frac{1}{\delta} }{n} + \frac{\sigma \sqrt{2\ln \frac{1}{\delta} } }{n}
\]</span></p>
<p><strong>Corollary:</strong> If <span class="math inline">\(X_1, ..., X_n\)</span> are i.i.d. random variables and <span class="math display">\[
\sum_{t = 1}^n Var[X_t \mid X_{t - 1}, ..., X_1] = n Var[X_1]
\]</span> Then <span class="math display">\[
a = \frac{\ln \frac{1}{\delta}}{n} + \sqrt{\frac{2 Var[X_1] \ln \frac{1}{\delta}}{n}}
\]</span></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/09/02/Interval-Estimate/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="WOW">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WOW">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/09/02/Interval-Estimate/" class="post-title-link" itemprop="url">Interval Estimate</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-09-02 19:23:25" itemprop="dateCreated datePublished" datetime="2018-09-02T19:23:25+10:00">2018-09-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2018-09-16 19:52:14" itemprop="dateModified" datetime="2018-09-16T19:52:14+10:00">2018-09-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Let <span class="math inline">\(X\)</span> be a Bernoulli random variable with unknown probability <span class="math display">\[
\begin{aligned}
P[X = 1] &amp;= \mu. \\
P[X = 0] &amp;= 1 - \mu
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\frac{1}{n} \le \mu \le 1\)</span> for some integer <span class="math inline">\(n &gt; 0\)</span>. The goal is to estimate <span class="math inline">\(\mu\)</span> (denoted by <span class="math inline">\(\tilde \mu\)</span>) via sampling.</p>
<p>By law of large number, <span class="math inline">\(\tilde \mu\)</span> converges to <span class="math inline">\(\mu\)</span> when we sample enough numbers of <span class="math inline">\(X\)</span>. The convergence behavior is captured by Chernoff inequality and <span class="math inline">\(O(\frac{1}{\delta^2 \mu}\log{1 \over p_{fail} })\)</span> samples are needed to get an estimation <span class="math inline">\(\tilde \mu\)</span> such that <span class="math inline">\(P [ \tilde \mu \in (1 \pm \delta) \mu] \ge 1 - p_{fail}\)</span> (See Exercise 1). Such an <span class="math inline">\(\tilde \mu\)</span> is called an <span class="math inline">\((\delta, p_{fail})\)</span>-estimation of <span class="math inline">\(\mu\)</span>.</p>
<p>As <span class="math inline">\(\mu \ge \frac{1}{n}\)</span>, <span class="math inline">\(O(\frac{n}{\delta^2}\log{1 \over p_{fail} })\)</span> samples are enough. The problem is, if <span class="math inline">\(\mu\)</span> is much larger than <span class="math inline">\(1/n\)</span>, we waste a lot of samples. E.g., when <span class="math inline">\(n = 1000\)</span> and <span class="math inline">\(\mu = \frac{1}{2}\)</span>, <span class="math inline">\(\frac{1}{\delta^2 \mu}\log{1 \over p_{fail} }\)</span> gives us <span class="math inline">\(\frac{2}{\delta^2}\log{1 \over p_{fail} }\)</span> while <span class="math inline">\(\frac{n}{\delta^2}\log{1 \over p_{fail} }\)</span> equals to <span class="math inline">\(\frac{1000}{\delta^2}\log{1 \over p_{fail} }\)</span>.</p>
<p>Can we obtain an <span class="math inline">\((\delta, p_{fail})\)</span>-estimation <span class="math inline">\(\tilde \mu\)</span> with just <span class="math inline">\(O(\frac{1}{\delta^2 \mu}\log{1 \over p_{fail} })\)</span> samples, even though <span class="math inline">\(\mu\)</span> itself is unknown?</p>
<p>Yes we can (with the lost of a factor <span class="math inline">\(\log \log n\)</span>, which is almost negligible). First we relax the goal a little bit -- finding a <span class="math inline">\(\tilde \mu \in [\mu/2, 2 \mu]\)</span> instead of a <span class="math inline">\(\tilde \mu \in (1 \pm \delta) \mu\)</span>. We show how to achieve this with <span class="math inline">\(O(\frac{1}{\mu}\log{\log n \over p_{fail} })\)</span> samples.</p>
<p>The high level idea is to divide <span class="math inline">\([\frac{1}{n}, 1]\)</span> into a set of intervals <span class="math display">\[
\{ [\frac{1}{n}, \frac{1}{2^{ \log n  -1} }], ..., [\frac{1}{2^{i} }, \frac{1}{2^{i - 1} }], ...,, [\frac{1}{4}, \frac{1}{2}],   [\frac{1}{2}, 1]\}
\]</span> Let <span class="math inline">\([\frac{1}{2^{j} }, \frac{1}{2^{j - 1} }]\)</span> <span class="math inline">\((j \in N)\)</span> be the interval that <span class="math inline">\(u\)</span> belongs to.</p>
<figure>
<img src="http://imglf6.nosdn.127.net/img/Y1FUYmVJRmJqaTNrbC9RWmRCdlpzYVQyNS9OR00wSUwzdGgwRU9rZGV0anhzUlpaMVhBWVB3PT0.jpg?imageView&amp;thumbnail=1969y285&amp;type=jpg&amp;quality=96&amp;stripmeta=0&amp;type=jpg" alt="" /><figcaption>Figure</figcaption>
</figure>
<p>Given an integer <span class="math inline">\(i\)</span>, such that <span class="math inline">\(i \le j - 2\)</span> or <span class="math inline">\(i \ge j + 1\)</span>, we can determine whether <span class="math inline">\(\mu \ge \frac{1}{2^i}\)</span> with high probability. We generate <span class="math inline">\(O(2^i \log \frac{\log n}{p_{fail} })\)</span> samples and test whether their average (i.e., <span class="math inline">\(\tilde \mu\)</span>) is greater than <span class="math inline">\(\frac{1}{2^i}\)</span>. If <span class="math inline">\(\tilde \mu &gt; \frac{1}{2^i}\)</span>, by Chernoff inequality, <span class="math inline">\(\mu &gt; \frac{1}{2^i}\)</span> with high probability and the test returns true.</p>
<p>To search for the interval <span class="math inline">\([\frac{1}{2^{j} }, \frac{1}{2^{j - 1} }]\)</span> that <span class="math inline">\(\mu\)</span> belongs to, we perform the test for increasing values of <span class="math inline">\(i = 1, 2, ...\)</span> until we find the first <span class="math inline">\(i\)</span>, such that the test for <span class="math inline">\(\mu \ge \frac{1}{2^i}\)</span> returns true. We claim that with high probability, <span class="math inline">\(i\)</span> takes one of the following values: <span class="math inline">\(\{j - 1, j, j + 1 \}\)</span>. The reason is that the test returns false (with high probability) when <span class="math inline">\(i \le j - 2\)</span>. The results for <span class="math inline">\(i = j - 1\)</span> and <span class="math inline">\(j\)</span> are undetermined. Even if the test fails to return true for both <span class="math inline">\(i = j - 1\)</span> and <span class="math inline">\(j\)</span>, it returns true for <span class="math inline">\(i = j + 1\)</span> with high probability.</p>
<p>Finally, after we find an <span class="math inline">\(i \in \{j - 1, j, j + 1 \}\)</span>, we know that <span class="math inline">\(\mu \ge \frac{1}{2 \cdot 2^i}\)</span>. Therefore, <span class="math inline">\(O(2^i \log \frac{\log n}{p_{fail} })\)</span> samples gives an <span class="math inline">\((\delta, p_{fail})\)</span>-estimate of <span class="math inline">\(\mu\)</span>.</p>
<p>Then the total number of samples we generate is at most: <span class="math display">\[
\sum_{k = 1}^{j+1}O(2^k\log \frac{\log n}{p_{fail} }) = O(2^{j+2}\log \frac{\log n}{p_{fail} }) = O(\frac{1}{\mu}\log \frac{\log n}{p_{fail} })
\]</span></p>
<p>The procedure code is shown by Algorithm 1.</p>
<blockquote>
<p><strong>Algorithm 1</strong></p>
<ol type="1">
<li><strong>for</strong> <span class="math inline">\(i \leftarrow 1\)</span> to <span class="math inline">\(\log n - 1\)</span> <strong>do</strong></li>
<li><span class="math inline">\(\quad\)</span> Let <span class="math inline">\(\theta = 6 \cdot 2^i \log \frac{\log n}{p_{fail} }\)</span>.</li>
<li><span class="math inline">\(\quad\)</span> Let <span class="math inline">\(Y = 0\)</span></li>
<li><span class="math inline">\(\quad\)</span> <strong>for</strong> <span class="math inline">\(j \leftarrow 1\)</span> to <span class="math inline">\(\theta\)</span> <strong>do</strong></li>
<li><span class="math inline">\(\quad\)</span><span class="math inline">\(\quad\)</span> Generate a sample of <span class="math inline">\(X\)</span>, denoted by <span class="math inline">\(X_j\)</span>.</li>
<li><span class="math inline">\(\quad\)</span><span class="math inline">\(\quad\)</span> <span class="math inline">\(Y = Y + X_j\)</span>.</li>
<li><span class="math inline">\(\quad\)</span> <strong>if</strong> <span class="math inline">\(\frac{Y}{\theta} &gt; \frac{1}{2^i}\)</span> <strong>then</strong></li>
<li><span class="math inline">\(\quad\)</span> <span class="math inline">\(\quad\)</span> <strong>return</strong> <span class="math inline">\(\frac{Y}{\theta}\)</span></li>
<li><strong>return</strong> <span class="math inline">\(\frac{1}{n}\)</span></li>
</ol>
</blockquote>
<p>To analyse Algorithm 1, we use the following Chernoff Bounds.</p>
<p><strong>Chernoff Bound</strong></p>
<blockquote>
<p>Let <span class="math inline">\(X_1, X_2, ..., X_\theta\)</span> be <span class="math inline">\(i.i.d.\)</span> Bernoulli random variables with mean <span class="math inline">\(\mu\)</span> and <span class="math inline">\(Y = \frac{1}{\theta} \sum_{k =1}^\theta X_k\)</span>. Then</p>
<ol type="1">
<li><span class="math inline">\(P[Y \ge (1 + \delta) \mu] \le \exp(- \frac{\delta^2}{\delta + 2} \theta \mu)\)</span>.</li>
<li><span class="math inline">\(P[Y \le (1 - \delta) \mu] \le \exp(- \frac{\delta^2}{2} \theta \mu)\)</span></li>
</ol>
</blockquote>
<p>Corollary</p>
<blockquote>
<p>For an integer <span class="math inline">\(k \ge 1\)</span>,</p>
<ol type="1">
<li><span class="math inline">\(P[Y \ge 2^k \mu] \le \exp (- \frac{(2^k -1)^2}{2^k + 1} \theta \mu) \le \exp(- \frac{2^{2k - 2} }{2^k + 1} \theta \mu) = \exp(-\frac{2^k}{4(1+ {1} / {2^k})} \theta \mu) \le \exp(-\frac{2^k}{6} \theta \mu)\)</span></li>
<li><span class="math inline">\(P[Y \le \frac{1}{2^k}\mu] \le \exp(-\frac{(1-\frac{1}{2^k})^2}{2} \theta \mu) \le \exp(-\frac{1}{8}\theta \mu)\)</span></li>
</ol>
</blockquote>
<p><strong>Theorem</strong></p>
<blockquote>
<p>Let <span class="math inline">\(X_1, X_2, ..., X_\theta\)</span> be <span class="math inline">\(i.i.d.\)</span> Bernoulli random variables with mean <span class="math inline">\(\mu \in [\frac{1}{2^j}, \frac{1}{2^{j - 1} }]\)</span> and <span class="math inline">\(Y = \frac{1}{\theta} \sum_{k =1}^\theta X_k\)</span>. Suppose <span class="math inline">\(\theta = 6 \cdot 2^i \log \frac{\log n}{p_{fail} }\)</span> for some <span class="math inline">\(i\)</span>, then</p>
<ol type="1">
<li><span class="math inline">\(P[Y \ge \frac{1}{2^i}] \le \frac{p_{fail} }{\log n}\)</span>, if <span class="math inline">\(i \le j - 2\)</span>,</li>
<li><span class="math inline">\(P[Y \le \frac{1}{2^i}] \le \frac{p_{fail} }{2^{i - j - 1} \log n}\)</span>, if <span class="math inline">\(i \ge j + 1\)</span>.</li>
</ol>
</blockquote>
<p>Proof: First consider <span class="math inline">\(i \le j - 2\)</span>. Then <span class="math inline">\(\frac{1}{2^i} \ge 2^{j - 1 - i} \mu\)</span> , <span class="math inline">\(2^{j - 1} \mu \ge 1\)</span> and <span class="math display">\[
\begin{aligned}
P[Y \ge \frac{1}{2^i}] 
&amp;\le P[Y \ge 2^{j - 1 - i} \mu] \\
&amp;\le \exp(-\frac{2^{j- 1 - i} }{6}\theta \mu) \\
&amp;= \exp(-\frac{2^{j - 1} \mu \cdot 2^{-i}\theta}{6}) \\
&amp;\le\exp(-\frac{2^{-i}\theta}{6}) \\
&amp;\le \frac{p_{fail} }{\log n}
\end{aligned}
\]</span></p>
<p>For <span class="math inline">\(i \ge j + 1\)</span>, we have <span class="math inline">\(\frac{1}{2^{i} } \le \frac{1}{2^{i - j} } \mu\)</span> , <span class="math inline">\(i - j \ge 1\)</span> and <span class="math display">\[
\begin{aligned}
P[ Y \le \frac{1}{2^{i} }] &amp;\le P [Y \le \frac{1}{2^{i - j} } \mu] \\
&amp;\le \exp(-\frac{\mu \theta}{8}) \\
&amp;\le \exp(-\frac{2^{-j}\theta }{8}) \\
&amp;\le \frac{p_{fail} }{2^{i - j -1}\log n}
\end{aligned}
\]</span></p>
<p>It follows that by union bound the test fails for all <span class="math inline">\(i = 1, 2, ..., j - 2, j + 1\)</span> is at most <span class="math inline">\(\frac{p_{fail} }{\log n} \cdot (j - 1) \le p_{fail}\)</span>.</p>
<h5 id="exercise">Exercise</h5>
<ol type="1">
<li>Given a Bernoulli random variable <span class="math inline">\(X\)</span> with mean <span class="math inline">\(\mu\)</span>, prove that (with Chernoff bound) if we generate <span class="math inline">\(\Omega(\frac{1}{\delta^2 \mu}\log{1 \over p_{fail} })\)</span> independent samples, we get an estimate of <span class="math inline">\(X\)</span> with relative error <span class="math inline">\(\delta\)</span> with probability <span class="math inline">\(1 - p_{fail}\)</span>.</li>
</ol>
<h5 id="reference">Reference:</h5>
<ol type="1">
<li>Tang Youze, Xiaokui Xiao, and Yanchen Shi. "Influence maximization: Near-optimal time complexity meets practical efficiency." <em>Proceedings of the 2014 ACM SIGMOD international conference on Management of data</em>. ACM, 2014.</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/33/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/33/">33</a><span class="page-number current">34</span><a class="page-number" href="/page/35/">35</a><span class="space">&hellip;</span><a class="page-number" href="/page/44/">44</a><a class="extend next" rel="next" href="/page/35/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">WOW</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">131</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WOW</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
